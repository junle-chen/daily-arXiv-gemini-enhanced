#!/bin/bash
set -e

echo "ğŸš€ Starting Daily ArXiv Update Workflow..."

# --- 1. ä½¿ç”¨åŒ—äº¬æ—¶åŒºè·å–æ­£ç¡®çš„å½“å¤©æ—¥æœŸ ---
today=$(TZ=Asia/Shanghai date "+%Y-%m-%d")
yesterday=$(TZ=Asia/Shanghai date -d "yesterday" "+%Y-%m-%d")
echo "âœ… Workflow date set to: ${today} (Asia/Shanghai)"

# --- 2. å®šä¹‰æ‰€æœ‰æ–‡ä»¶å ---
RAW_JSONL_FILE="data/${today}.jsonl"
UNIQUE_JSONL_FILE="data/${today}_unique.jsonl"
YESTERDAY_UNIQUE_FILE="data/${yesterday}_unique.jsonl"
ENHANCED_JSONL_FILE="data/${today}_unique_AI_enhanced_Chinese.jsonl"
FINAL_MD_FILE="data/${today}.md"

# --- 3. è¿è¡Œ Scrapy çˆ¬è™« ---
echo "--- Step 1: Crawling data from ArXiv ---"
(cd daily_arxiv && scrapy crawl arxiv -o ../${RAW_JSONL_FILE})
echo "âœ… Raw data saved to ${RAW_JSONL_FILE}"

# --- 4. è¿è¡Œå»é‡è„šæœ¬ ---
echo "--- Step 2: Deduplicating raw data ---"
python deduplicate.py ${RAW_JSONL_FILE} -o ${UNIQUE_JSONL_FILE}
echo "âœ… Unique data saved to ${UNIQUE_JSONL_FILE}"

# --- 5. æ–°å¢ï¼šæ™ºèƒ½æ¯”è¾ƒä»Šå¤©å’Œæ˜¨å¤©çš„å†…å®¹ (å¿½ç•¥è¡Œåº) ---
echo "--- Step 3: Checking for new content (ignoring line order) ---"
if [ -f "$YESTERDAY_UNIQUE_FILE" ]; then
    # æå–ã€æ’åºå¹¶æ¯”è¾ƒä¸¤ä¸ªæ–‡ä»¶çš„ ID é›†åˆ
    # diff <(command1) <(command2) æ˜¯ä¸€ç§é«˜çº§ç”¨æ³•ï¼Œç”¨äºæ¯”è¾ƒä¸¤ä¸ªå‘½ä»¤çš„è¾“å‡º
    # grep -o '"id": "[^"]*"' ä¼šåªæå–å‡º id å­—æ®µ
    # sort ä¼šå¯¹æå–å‡ºçš„ id æ’åº
    # å¦‚æœä¸¤ä¸ªæ’åºåçš„ id åˆ—è¡¨æ²¡æœ‰å·®å¼‚ï¼Œdiff å‘½ä»¤çš„è¾“å‡ºå°±æ˜¯ç©ºçš„
    if [ -z "$(diff <(grep -o '"id": "[^"]*"' "$UNIQUE_JSONL_FILE" | sort) <(grep -o '"id": "[^"]*"' "$YESTERDAY_UNIQUE_FILE" | sort))" ]; then
        echo "â„¹ï¸  No new papers found. The set of papers is the same as yesterday. Exiting workflow."
        rm "$RAW_JSONL_FILE" "$UNIQUE_JSONL_FILE"
        exit 0
    else
        echo "âœ… New content found. Proceeding with the workflow."
    fi
else
    echo "â„¹ï¸  Yesterday's file not found. Assuming first run."
fi

# --- 6. è¿è¡Œ AI å¢å¼ºè„šæœ¬ ---
echo "--- Step 4: Enhancing data with AI ---"
# ç¡®ä¿å®ƒçš„è¾“å…¥æ˜¯å»é‡åçš„æ–‡ä»¶
python ai/enhance.py --data ${UNIQUE_JSONL_FILE}
# æˆ‘å·²ç»ç§»é™¤äº†ä½ è„šæœ¬ä¸­é‚£ä¸ªåœ¨ enhance.py ä¹‹åå¤šä½™çš„å»é‡å‘½ä»¤
echo "âœ… AI enhancement complete. Output is ${ENHANCED_JSONL_FILE}"

# --- 7. è¿è¡Œ Markdown ç”Ÿæˆè„šæœ¬ ---
echo "--- Step 5: Converting JSONL to Markdown ---"
python to_md/convert.py --data ${ENHANCED_JSONL_FILE}
echo "âœ… Markdown report generated at ${FINAL_MD_FILE}"

# --- 8. æ›´æ–°ä¸» README æ–‡ä»¶ ---
echo "--- Step 6: Updating main README.md ---"
python update_readme.py
echo "âœ… README.md updated."

echo "ğŸ‰ Workflow finished successfully!"
