import json
import argparse
import os
from collections import defaultdict


def format_paper_to_markdown(paper: dict, index: int) -> str:
    """
    å°†å•ä¸ªè®ºæ–‡çš„å­—å…¸æ•°æ®ï¼Œæ ¼å¼åŒ–æˆä¸€æ®µæ¼‚äº®çš„ Markdown æ–‡æœ¬ã€‚
    æŒ‰ç…§paper_template.mdæ¨¡æ¿å±•ç¤ºï¼šmotivation, method, result, conclusion
    """
    # --- æå–åŸºç¡€ä¿¡æ¯ ---
    title = paper.get("title", "No Title Provided").strip()
    authors = ", ".join(paper.get("authors", ["N/A"]))
    abs_url = paper.get("abs", "#")
    pdf_url = abs_url.replace("abs", "pdf") if abs_url != "#" else "#"
    categories = paper.get("categories", [])
    main_category = categories[0] if categories else "Unknown"

    ai_data = paper.get("AI", {})

    # æå–ç»“æ„åŒ–å†…å®¹
    tldr = ai_data.get("tldr", "AI one-sentence summary is not available.")
    motivation = ai_data.get("motivation", "Not available")
    method = ai_data.get("method", "Not available")
    result = ai_data.get("result", "Not available")
    conclusion = ai_data.get("conclusion", "Not available")
    summary = paper.get("summary", "No summary available.").replace("\n", " ").strip()
    # è·å–ä¸­æ–‡æ‘˜è¦ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹æ‘˜è¦
    summary_zh = ai_data.get("summary_zh", summary).replace("\n", " ").strip()

    return f"""### [{index}] [{title}]({abs_url})
*{authors}*

Main category: {main_category}

TL;DR: {tldr}


<details>
  <summary>Details</summary>
Motivation: {motivation}

Method: {method}

Result: {result}

Conclusion: {conclusion}

Abstract: {summary_zh}

</details>

[**[PDF]**]({pdf_url}) | **Categories:** {', '.join(categories)}

---
"""


def main():
    """
    ä¸»å‡½æ•°ï¼šè¯»å– JSONL æ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªæ ¼å¼åŒ–çš„ Markdown æ–‡ä»¶ã€‚
    ä¸“æ³¨äºè½¨è¿¹é¢„æµ‹å’Œå¤§æ¨¡å‹ç›¸å…³è®ºæ–‡ï¼Œå¹¶æŒ‰ç±»åˆ«ç»„ç»‡å†…å®¹
    """
    parser = argparse.ArgumentParser(
        description="Convert an ArXiv JSONL file to a formatted Markdown file."
    )
    parser.add_argument(
        "--data",
        dest="input_file",
        required=True,
        help="Path to the input .jsonl file (can be raw, unique, or AI-enhanced).",
    )
    parser.add_argument(
        "--output",
        "-o",
        dest="output_file",
        help="Path to the output markdown file. If not provided, a default name will be generated.",
    )
    args = parser.parse_args()

    input_path = args.input_file

    if not os.path.exists(input_path):
        print(f"âŒ Error: Input file not found at '{input_path}'")
        return

    print(f"â–¶ï¸  Reading from: {input_path}")

    papers = []
    with open(input_path, "r", encoding="utf-8") as f:
        for line in f:
            try:
                papers.append(json.loads(line))
            except json.JSONDecodeError:
                print(f"âš ï¸ Warning: Skipping malformed JSON line: {line.strip()}")

    if not papers:
        print(
            "â„¹ï¸ No papers found in the input file. An empty Markdown file will be created."
        )

    # --- ä»è¾“å…¥æ–‡ä»¶åä¸­æå–æ—¥æœŸ ---
    base_name = os.path.basename(input_path)
    date_str = base_name.split("_")[0].split(".")[0]

    # --- åˆ›å»ºæ–‡æ¡£å¤§æ ‡é¢˜ ---
    header = f"# æ¯æ—¥ ArXiv è½¨è¿¹é¢„æµ‹ä¸å¤§æ¨¡å‹æ‘˜è¦é€Ÿé€’: {date_str}\n\n"

    # --- æŒ‰ç±»åˆ«ç»„ç»‡è®ºæ–‡ ---
    papers_by_category = defaultdict(list)

    # å…ˆç»Ÿè®¡æ‰€æœ‰ç±»åˆ«åŠå…¶ä¸»ç±»åˆ«
    category_counts = defaultdict(int)
    main_categories = {}

    # æ³¨æ„ï¼šä¸å†åœ¨æ­¤å¤„ç­›é€‰è®ºæ–‡ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨è¾“å…¥çš„è®ºæ–‡é›†åˆ
    # ç­›é€‰å·¥ä½œå·²ç»ç”±filter_papers.pyå®Œæˆ

    print(f"ğŸ“Š å¤„ç† {len(papers)} ç¯‡è®ºæ–‡")

    # æ¸…ç©ºå¹¶é‡å»ºæŒ‰ç±»åˆ«åˆ†ç±»çš„è®ºæ–‡
    papers_by_category.clear()
    category_counts.clear()
    main_categories.clear()

    # æŒ‰ä¸»ç±»åˆ«å½’ç±»
    for paper in papers:
        categories = paper.get("categories", ["Unknown"])
        if categories:
            main_cat = categories[0]
            papers_by_category[main_cat].append(paper)

            # æ›´æ–°ä¸»ç±»åˆ«è®¡æ•°
            for cat in categories:
                category_counts[cat] += 1
                if cat not in main_categories:
                    main_categories[cat] = main_cat

    # --- ç”Ÿæˆç›®å½• ---
    toc_items = []
    category_display_names = {
        "cs.CV": "è®¡ç®—æœºè§†è§‰ (Computer Vision)",
        "cs.RO": "æœºå™¨äººå­¦ (Robotics)",
        "cs.LG": "æœºå™¨å­¦ä¹  (Machine Learning)",
        "cs.AI": "äººå·¥æ™ºèƒ½ (Artificial Intelligence)",
        "cs.CL": "è®¡ç®—è¯­è¨€å­¦ (Computation and Language)",
        "stat.ML": "ç»Ÿè®¡æœºå™¨å­¦ä¹  (Machine Learning Statistics)",
        "cs.HC": "äººæœºäº¤äº’ (Human-Computer Interaction)",
        "cs.NE": "ç¥ç»ä¸è¿›åŒ–è®¡ç®— (Neural and Evolutionary Computing)",
    }

    # æŒ‰ç±»åˆ«ç”Ÿæˆç›®å½•
    toc_items = []
    for cat, cat_papers in sorted(papers_by_category.items()):
        display_name = category_display_names.get(cat, cat)
        toc_items.append(
            f"- [{display_name} ({len(cat_papers)})](#{cat.lower().replace('.', '-')})"
        )

    toc_content = "## ç›®å½•\n\n" + "\n".join(toc_items) + "\n\n"

    # --- ç”Ÿæˆåˆ†ç±»å†…å®¹ ---
    category_sections = []
    for cat, cat_papers in sorted(papers_by_category.items()):
        display_name = category_display_names.get(cat, cat)
        section = [f"## {display_name} [{cat}]"]

        # ä¸ºæ¯ä¸ªç±»åˆ«çš„è®ºæ–‡ç”Ÿæˆå†…å®¹
        for i, paper in enumerate(cat_papers):
            section.append(format_paper_to_markdown(paper, i + 1))

        category_sections.append("\n".join(section))

    # --- åˆå¹¶æ‰€æœ‰å†…å®¹ ---
    final_markdown = header + toc_content + "\n\n".join(category_sections)

    # --- å†™å…¥æ–‡ä»¶ ---
    if args.output_file:
        output_path = args.output_file
    else:
        # é»˜è®¤è·¯å¾„
        output_filename = f"{date_str}_trajectory_and_large_models.md"
        output_path = os.path.join(os.path.dirname(input_path), output_filename)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(final_markdown)

    print(f"âœ… æˆåŠŸè½¬æ¢ {len(papers)} ç¯‡è®ºæ–‡åˆ°: {output_path}")


if __name__ == "__main__":
    main()
