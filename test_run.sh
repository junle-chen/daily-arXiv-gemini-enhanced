#!/bin/bash
set -e

echo "ğŸš€ Starting Daily ArXiv Update Workflow..."

# --- æµ‹è¯•è„šæœ¬ï¼šä½¿ç”¨å›ºå®šçš„æµ‹è¯•æ•°æ® ---
today="test-run"
yesterday="2025-06-07"
echo "âœ… Test workflow using fixed date: ${today}"

# --- 2. å®šä¹‰æ‰€æœ‰æ–‡ä»¶å ---

RAW_JSONL_FILE="data/2025-06-07.jsonl"
UNIQUE_JSONL_FILE="data/2025-06-07_unique.jsonl"
YESTERDAY_UNIQUE_FILE="data/${yesterday}_unique.jsonl"
ENHANCED_JSONL_FILE="data/${today}_unique_AI_enhanced_Chinese.jsonl"
FINAL_MD_FILE="data/${today}.md"

# å»æ‰çˆ¬è™«éƒ¨åˆ†ï¼ŒåŠ å¿«æµ‹è¯•é€Ÿåº¦

# --- 4. è¿è¡Œå»é‡è„šæœ¬ ---
echo "--- Step 2: Deduplicating raw data ---"
python deduplicate.py ${RAW_JSONL_FILE} -o ${UNIQUE_JSONL_FILE}
echo "âœ… Unique data saved to ${UNIQUE_JSONL_FILE}"

# --- æ–°å¢: ç­›é€‰è½¨è¿¹é¢„æµ‹å’Œå¤§æ¨¡å‹ç›¸å…³è®ºæ–‡ ---
TRAJECTORY_LLM_FILE="data/${today}_trajectory_llm.jsonl"
echo "--- Step 2.1: Filtering papers related to trajectory prediction and large models using LLM ---"
# ä½¿ç”¨ä¸AIå¢å¼ºç›¸åŒçš„æ¨¡å‹
MODEL_NAME=${MODEL_NAME:-"gemini-2.0-flash"}

# æ‰§è¡Œè¿‡æ»¤
echo "Filtering papers with ${MODEL_NAME} model"
if python filter_papers.py --data ${UNIQUE_JSONL_FILE} -o ${TRAJECTORY_LLM_FILE} --model ${MODEL_NAME} --threshold 0.6; then
    echo "âœ… Filtered data saved to ${TRAJECTORY_LLM_FILE}"
else
    echo "âš ï¸ Filtering failed. Continuing workflow without filtered papers."
    # åˆ›å»ºä¸€ä¸ªç©ºçš„ç­›é€‰æ–‡ä»¶ï¼Œä»¥ä¾¿åç»­æ­¥éª¤å¯ä»¥ç»§ç»­
    touch ${TRAJECTORY_LLM_FILE}
fi

# --- 5. æ–°å¢ï¼šæ™ºèƒ½æ¯”è¾ƒä»Šå¤©å’Œæ˜¨å¤©çš„å†…å®¹ (å¿½ç•¥è¡Œåº) ---
echo "--- Step 3: Checking for new content (ignoring line order) ---"
if [ -f "$YESTERDAY_UNIQUE_FILE" ]; then
    # æå–ã€æ’åºå¹¶æ¯”è¾ƒä¸¤ä¸ªæ–‡ä»¶çš„ ID é›†åˆ
    # diff <(command1) <(command2) æ˜¯ä¸€ç§é«˜çº§ç”¨æ³•ï¼Œç”¨äºæ¯”è¾ƒä¸¤ä¸ªå‘½ä»¤çš„è¾“å‡º
    # grep -o '"id": "[^"]*"' ä¼šåªæå–å‡º id å­—æ®µ
    # sort ä¼šå¯¹æå–å‡ºçš„ id æ’åº
    # å¦‚æœä¸¤ä¸ªæ’åºåçš„ id åˆ—è¡¨æ²¡æœ‰å·®å¼‚ï¼Œdiff å‘½ä»¤çš„è¾“å‡ºå°±æ˜¯ç©ºçš„
    if [ -z "$(diff <(grep -o '"id": "[^"]*"' "$UNIQUE_JSONL_FILE" | sort) <(grep -o '"id": "[^"]*"' "$YESTERDAY_UNIQUE_FILE" | sort))" ]; then
        echo "â„¹ï¸  No new papers found. The set of papers is the same as yesterday. Exiting workflow."
        # rm "$RAW_JSONL_FILE" "$UNIQUE_JSONL_FILE"
        exit 0
    else
        echo "âœ… New content found. Proceeding with the workflow."
    fi
else
    echo "â„¹ï¸  Yesterday's file not found. Assuming first run."
fi

# --- 6. å¤„ç†æ•°æ®åº“ç›¸å…³è®ºæ–‡ ---
DB_FILE="data/${today}_database.jsonl"
echo "--- Step 4: Processing database-related papers ---"

if ./process_db_papers.py --data ${UNIQUE_JSONL_FILE} -o ${DB_FILE}; then
    echo "âœ… Database papers extracted to ${DB_FILE}"
else
    echo "âš ï¸ Database paper extraction failed. Creating empty file to continue workflow."
    touch ${DB_FILE}
fi

# --- 7. ä¸ºè½¨è¿¹é¢„æµ‹å’Œå¤§æ¨¡å‹ä»¥åŠæ•°æ®åº“ç”Ÿæˆå¢å¼ºå†…å®¹ ---
TRAJECTORY_LLM_ENHANCED_FILE="data/${today}_trajectory_llm_AI_enhanced_Chinese.jsonl"
echo "--- Step 5: Enhancing trajectory prediction and large model data with AI ---"

DB_ENHANCED_FILE="data/${today}_database_AI_enhanced_Chinese.jsonl"
echo "--- Step 5: Enhancing database-related data with AI ---"
if [ -s "${DB_FILE}" ]; then
    echo "Enhancing database data with ${MODEL_NAME} model"
    if python ai/enhance.py --data ${DB_FILE}; then
        echo "âœ… AI enhancement for database papers complete. Output is ${DB_ENHANCED_FILE}"
    else
        echo "âš ï¸ Database enhancement failed. Continuing without enhanced database data."
        # åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶ä»¥ä¾¿åç»­æ­¥éª¤å¯ä»¥ç»§ç»­
        touch ${DB_ENHANCED_FILE}
    fi
else
    echo "âš ï¸ Database data file is empty or doesn't exist. Skipping enhancement."
    touch ${DB_ENHANCED_FILE}
fi

# æ£€æŸ¥è½¨è¿¹é¢„æµ‹æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”éç©º
if [ -s "${TRAJECTORY_LLM_FILE}" ]; then
    echo "Enhancing trajectory data with ${MODEL_NAME} model"
    if python ai/enhance.py --data ${TRAJECTORY_LLM_FILE}; then
        echo "âœ… AI enhancement for trajectory prediction papers complete. Output is ${TRAJECTORY_LLM_ENHANCED_FILE}"
    else
        echo "âš ï¸ Trajectory enhancement failed. Continuing without enhanced trajectory data."
        # åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶ä»¥ä¾¿åç»­æ­¥éª¤å¯ä»¥ç»§ç»­
        touch ${TRAJECTORY_LLM_ENHANCED_FILE}
    fi
else
    echo "âš ï¸ Trajectory prediction data file is empty or doesn't exist. Skipping enhancement."
    touch ${TRAJECTORY_LLM_ENHANCED_FILE}
fi

# --- 8. ä¸ºè½¨è¿¹é¢„æµ‹ã€å¤§æ¨¡å‹å’Œæ•°æ®åº“ç›¸å…³æ•°æ®ç”ŸæˆMarkdown ---
echo "--- Step 6: Converting JSONL to Markdown ---"

# å¤„ç†è½¨è¿¹é¢„æµ‹å’Œå¤§æ¨¡å‹æ•°æ®
TRAJECTORY_LLM_MD_FILE="data/${today}_trajectory_and_large_models.md"
if [ -s "${TRAJECTORY_LLM_ENHANCED_FILE}" ]; then
    python to_md/convert.py --data ${TRAJECTORY_LLM_ENHANCED_FILE} --output ${TRAJECTORY_LLM_MD_FILE}
    echo "âœ… Markdown report for trajectory and large model papers generated at ${TRAJECTORY_LLM_MD_FILE}"
else
    echo "âš ï¸ No trajectory and large model papers data available. Creating empty markdown file."
    echo "# No trajectory and large model papers found today" > ${TRAJECTORY_LLM_MD_FILE}
fi

# å¤„ç†æ•°æ®åº“ç›¸å…³æ•°æ®
DB_MD_FILE="data/${today}_database.md"
if [ -s "${DB_FILE}" ]; then
    python to_md/convert.py --data ${DB_ENHANCED_FILE} --output ${DB_MD_FILE}
    echo "âœ… Markdown report for database papers generated at ${DB_MD_FILE}"
else
    echo "âš ï¸ No database papers data available. Creating empty markdown file."
    echo "# No database papers found today" > ${DB_MD_FILE}
fi

# --- 9. æ›´æ–°ä¸» README æ–‡ä»¶ ---
echo "--- Step 7: Updating main README.md ---"
python update_readme.py
echo "âœ… README.md updated."

echo "ğŸ‰ Test workflow finished successfully!"
