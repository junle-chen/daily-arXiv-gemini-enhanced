{"id": "2511.16700", "pdf": "https://arxiv.org/pdf/2511.16700", "abs": "https://arxiv.org/abs/2511.16700", "authors": ["Sedat Bin Vedat", "Enes Kutay Yarkan", "Meftun Akarsu", "Recep Kaan Karaman", "Arda Sar", "\u00c7a\u011fr\u0131 \u00c7elikbilek", "Sava\u015f Sayg\u0131l\u0131"], "title": "RAG-Driven Data Quality Governance for Enterprise ERP Systems", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Enterprise ERP systems managing hundreds of thousands of employee records face critical data quality challenges when human resources departments perform decentralized manual entry across multiple languages. We present an end-to-end pipeline combining automated data cleaning with LLM-driven SQL query generation, deployed on a production system managing 240,000 employee records over six months.\n  The system operates in two integrated stages: a multi-stage cleaning pipeline that performs translation normalization, spelling correction, and entity deduplication during periodic synchronization from Microsoft SQL Server to PostgreSQL; and a retrieval-augmented generation framework powered by GPT-4o that translates natural-language questions in Turkish, Russian, and English into validated SQL queries. The query engine employs LangChain orchestration, FAISS vector similarity search, and few-shot learning with 500+ validated examples.\n  Our evaluation demonstrates 92.5% query validity, 95.1% schema compliance, and 90.7\\% semantic accuracy on 2,847 production queries. The system reduces query turnaround time from 2.3 days to under 5 seconds while maintaining 99.2% uptime, with GPT-4o achieving 46% lower latency and 68% cost reduction versus GPT-3.5. This modular architecture provides a reproducible framework for AI-native enterprise data governance, demonstrating real-world viability at enterprise scale with 4.3/5.0 user satisfaction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6d41\u6c34\u7ebf\uff0c\u7ed3\u5408\u4e86\u81ea\u52a8\u6570\u636e\u6e05\u7406\u548cLLM\u9a71\u52a8\u7684SQL\u67e5\u8be2\u751f\u6210\uff0c\u7528\u4e8e\u89e3\u51b3\u4f01\u4e1aERP\u7cfb\u7edf\u4e2d\u591a\u8bed\u8a00\u4eba\u5de5\u5f55\u5165\u5bfc\u81f4\u7684\u6570\u636e\u8d28\u91cf\u95ee\u9898\u3002", "motivation": "\u4f01\u4e1aERP\u7cfb\u7edf\u5728\u5904\u7406\u5927\u91cf\u5458\u5de5\u8bb0\u5f55\u65f6\uff0c\u9762\u4e34\u7740\u7531\u4e8e\u4eba\u529b\u8d44\u6e90\u90e8\u95e8\u5206\u6563\u5f0f\u591a\u8bed\u8a00\u624b\u52a8\u5f55\u5165\u800c\u5bfc\u81f4\u7684\u5173\u952e\u6570\u636e\u8d28\u91cf\u6311\u6218\u3002", "method": "\u8be5\u7cfb\u7edf\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u591a\u9636\u6bb5\u6570\u636e\u6e05\u6d17\u6d41\u6c34\u7ebf\uff08\u6267\u884c\u7ffb\u8bd1\u6807\u51c6\u5316\u3001\u62fc\u5199\u7ea0\u6b63\u548c\u5b9e\u4f53\u53bb\u91cd\uff09\uff0c\u4ee5\u53ca\u7531GPT-4o\u9a71\u52a8\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff08\u5c06\u571f\u8033\u5176\u8bed\u3001\u4fc4\u8bed\u548c\u82f1\u8bed\u7684\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u7ffb\u8bd1\u6210\u6709\u6548\u7684SQL\u67e5\u8be2\uff09\u3002", "result": "\u57282847\u4e2a\u751f\u4ea7\u67e5\u8be2\u4e2d\uff0c\u67e5\u8be2\u6709\u6548\u6027\u8fbe\u523092.5%\uff0c\u6a21\u5f0f\u4e00\u81f4\u6027\u8fbe\u523095.1%\uff0c\u8bed\u4e49\u51c6\u786e\u6027\u8fbe\u523090.7%\u3002\u67e5\u8be2\u54cd\u5e94\u65f6\u95f4\u4ece2.3\u5929\u51cf\u5c11\u52305\u79d2\u4ee5\u5185\uff0c\u6b63\u5e38\u8fd0\u884c\u65f6\u95f4\u4fdd\u6301\u572899.2%\u3002GPT-4o\u76f8\u6bd4GPT-3.5\uff0c\u5ef6\u8fdf\u964d\u4f4e46%\uff0c\u6210\u672c\u964d\u4f4e68%\u3002\u7528\u6237\u6ee1\u610f\u5ea6\u4e3a4.3/5.0\u3002", "conclusion": "\u8be5\u6a21\u5757\u5316\u67b6\u6784\u4e3aAI\u539f\u751f\u4f01\u4e1a\u6570\u636e\u6cbb\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5728\u4f01\u4e1a\u89c4\u6a21\u4e0b\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002", "summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6d41\u6c34\u7ebf\uff0c\u8be5\u6d41\u6c34\u7ebf\u7ed3\u5408\u4e86\u81ea\u52a8\u6570\u636e\u6e05\u7406\u548cLLM\u9a71\u52a8\u7684SQL\u67e5\u8be2\u751f\u6210\uff0c\u65e8\u5728\u89e3\u51b3\u4f01\u4e1aERP\u7cfb\u7edf\u4e2d\u56e0\u4eba\u529b\u8d44\u6e90\u90e8\u95e8\u4ee5\u591a\u79cd\u8bed\u8a00\u8fdb\u884c\u5206\u6563\u5f0f\u624b\u52a8\u5f55\u5165\u800c\u5bfc\u81f4\u7684\u5173\u952e\u6570\u636e\u8d28\u91cf\u6311\u6218\u3002\u8be5\u7cfb\u7edf\u5305\u542b\u4e24\u4e2a\u96c6\u6210\u9636\u6bb5\uff1a\u4e00\u4e2a\u591a\u9636\u6bb5\u6e05\u6d17\u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u5728\u4eceMicrosoft SQL Server\u5230PostgreSQL\u7684\u5b9a\u671f\u540c\u6b65\u8fc7\u7a0b\u4e2d\u6267\u884c\u7ffb\u8bd1\u6807\u51c6\u5316\u3001\u62fc\u5199\u7ea0\u6b63\u548c\u5b9e\u4f53\u53bb\u91cd\uff1b\u4ee5\u53ca\u4e00\u4e2a\u7531GPT-4o\u9a71\u52a8\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5c06\u571f\u8033\u5176\u8bed\u3001\u4fc4\u8bed\u548c\u82f1\u8bed\u7684\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u7ffb\u8bd1\u6210\u7ecf\u8fc7\u9a8c\u8bc1\u7684SQL\u67e5\u8be2\u3002\u8be5\u67e5\u8be2\u5f15\u64ce\u91c7\u7528LangChain\u7f16\u6392\u3001FAISS\u5411\u91cf\u76f8\u4f3c\u6027\u641c\u7d22\u4ee5\u53ca\u8d85\u8fc7500\u4e2a\u9a8c\u8bc1\u793a\u4f8b\u7684\u5c0f\u6837\u672c\u5b66\u4e60\u3002\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u57282847\u4e2a\u751f\u4ea7\u67e5\u8be2\u4e2d\uff0c\u67e5\u8be2\u6709\u6548\u6027\u8fbe\u523092.5%\uff0c\u6a21\u5f0f\u4e00\u81f4\u6027\u8fbe\u523095.1%\uff0c\u8bed\u4e49\u51c6\u786e\u6027\u8fbe\u523090.7%\u3002\u8be5\u7cfb\u7edf\u5728\u4fdd\u630199.2%\u6b63\u5e38\u8fd0\u884c\u65f6\u95f4\u7684\u540c\u65f6\uff0c\u5c06\u67e5\u8be2\u54cd\u5e94\u65f6\u95f4\u4ece2.3\u5929\u7f29\u77ed\u81f35\u79d2\u4ee5\u5185\uff0c\u5e76\u4e14GPT-4o\u76f8\u6bd4GPT-3.5\u5b9e\u73b0\u4e8646%\u7684\u5ef6\u8fdf\u964d\u4f4e\u548c68%\u7684\u6210\u672c\u964d\u4f4e\u3002\u8fd9\u79cd\u6a21\u5757\u5316\u67b6\u6784\u4e3aAI\u539f\u751f\u4f01\u4e1a\u6570\u636e\u6cbb\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u6846\u67b6\uff0c\u5e76\u5728\u4f01\u4e1a\u89c4\u6a21\u4e0a\u5c55\u793a\u4e86\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u7528\u6237\u6ee1\u610f\u5ea6\u8fbe\u52304.3/5.0\u3002"}}
{"id": "2511.16935", "pdf": "https://arxiv.org/pdf/2511.16935", "abs": "https://arxiv.org/abs/2511.16935", "authors": ["Sierra A. T. Moxon", "Harold Solbrig", "Nomi L. Harris", "Patrick Kalita", "Mark A. Miller", "Sujay Patil", "Kevin Schaper", "Chris Bizon", "J. Harry Caufield", "Silvano Cirujano Cuesta", "Corey Cox", "Frank Dekervel", "Damion M. Dooley", "William D. Duncan", "Tim Fliss", "Sarah Gehrke", "Adam S. L. Graefe", "Harshad Hegde", "AJ Ireland", "Julius O. B. Jacobsen", "Madan Krishnamurthy", "Carlo Kroll", "David Linke", "Ryan Ly", "Nicolas Matentzoglu", "James A. Overton", "Jonny L. Saunders", "Deepak R. Unni", "Gaurav Vaidya", "Wouter-Michiel A. M. Vierdag", "LinkML Community Contributors", "Oliver Ruebel", "Christopher G. Chute", "Matthew H. Brush", "Melissa A. Haendel", "Christopher J. Mungall"], "title": "LinkML: An Open Data Modeling Framework", "categories": ["cs.DB"], "comment": null, "summary": "Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.\n  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.17377", "pdf": "https://arxiv.org/pdf/2511.17377", "abs": "https://arxiv.org/abs/2511.17377", "authors": ["Huicong Xu", "Shuang Liu", "Xianyu Zhu", "Qiyu Zhuang", "Wei Lu", "Xiaoyong Du"], "title": "Anomaly Pattern-guided Transaction Bug Testing in Relational Databases", "categories": ["cs.DB"], "comment": null, "summary": "Concurrent transaction processing is a fundamental capability of Relational Database Management Systems (RDBMSs), widely utilized in applications requiring high levels of parallel user interaction, such as banking systems, e-commerce platforms, and telecommunications infrastructure. Isolation levels offer a configurable mechanism to manage the interaction between concurrent transactions, enabling varying degrees of consistency and performance trade-offs. These isolation guarantees are supported by all major RDBMSs. However, testing transaction behavior under different isolation levels remains a significant challenge due to two primary reasons. First, automatically generating test transactions that can effectively expose bugs in transaction handling logic is non-trivial, as such bugs are typically triggered under specific transactional constraints. Second, detecting logic anomalies in transaction outcomes is difficult because the correct execution results are often unknown for randomly generated transactions. To address these challenges, we propose an anomaly pattern-guided testing approach for uncovering transaction bugs in RDBMSs. Our solution tackles the first challenge by introducing a test case generation technique guided by predefined anomaly patterns, which increases the likelihood of exposing transactional bugs. For the second challenge, we present a two-phase detection process, involving explicit error detection and implicit error detection, to identify bugs in transaction execution. We have implemented our approach in a tool, APTrans, and evaluated it on three widely-used RDBMSs: MySQL, MariaDB, and OceanBase. APTrans successfully identified 13 previously unknown transaction-related bugs, 11 of which have been confirmed by the respective development teams.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.16929", "pdf": "https://arxiv.org/pdf/2511.16929", "abs": "https://arxiv.org/abs/2511.16929", "authors": ["Rui Xue", "Dan He", "Fengmei Jin", "Chen Zhang", "Xiaofang Zhou"], "title": "CroTad: A Contrastive Reinforcement Learning Framework for Online Trajectory Anomaly Detection", "categories": ["cs.LG", "cs.DB"], "comment": "18 pages, 4 figures, will be submitted to VLDBJ", "summary": "Detecting trajectory anomalies is a vital task in modern Intelligent Transportation Systems (ITS), enabling the identification of unsafe, inefficient, or irregular travel behaviours. While deep learning has emerged as the dominant approach, several key challenges remain unresolved. First, sub-trajectory anomaly detection, capable of pinpointing the precise segments where anomalies occur, remains underexplored compared to whole-trajectory analysis. Second, many existing methods depend on carefully tuned thresholds, limiting their adaptability in real-world applications. Moreover, the irregular sampling of trajectory data and the presence of noise in training sets further degrade model performance, making it difficult to learn reliable representations of normal routes. To address these challenges, we propose a contrastive reinforcement learning framework for online trajectory anomaly detection, CroTad. Our method is threshold-free and robust to noisy, irregularly sampled data. By incorporating contrastive learning, CroTad learns to extract diverse normal travel patterns for different itineraries and effectively distinguish anomalous behaviours at both sub-trajectory and point levels. The detection module leverages deep reinforcement learning to perform online, real-time anomaly scoring, enabling timely and fine-grained identification of abnormal segments. Extensive experiments on two real-world datasets demonstrate the effectiveness and robustness of our framework across various evaluation scenarios.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.17190", "pdf": "https://arxiv.org/pdf/2511.17190", "abs": "https://arxiv.org/abs/2511.17190", "authors": ["Ziyang Wang", "Yuanlei Zheng", "Zhenbiao Cao", "Xiaojin Zhang", "Zhongyu Wei", "Pei Fu", "Zhenbo Luo", "Wei Chen", "Xiang Bai"], "title": "AutoLink: Autonomous Schema Exploration and Expansion for Scalable Schema Linking in Text-to-SQL at Scale", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "For industrial-scale text-to-SQL, supplying the entire database schema to Large Language Models (LLMs) is impractical due to context window limits and irrelevant noise. Schema linking, which filters the schema to a relevant subset, is therefore critical. However, existing methods incur prohibitive costs, struggle to trade off recall and noise, and scale poorly to large databases. We present \\textbf{AutoLink}, an autonomous agent framework that reformulates schema linking as an iterative, agent-driven process. Guided by an LLM, AutoLink dynamically explores and expands the linked schema subset, progressively identifying necessary schema components without inputting the full database schema. Our experiments demonstrate AutoLink's superior performance, achieving state-of-the-art strict schema linking recall of \\textbf{97.4\\%} on Bird-Dev and \\textbf{91.2\\%} on Spider-2.0-Lite, with competitive execution accuracy, i.e., \\textbf{68.7\\%} EX on Bird-Dev (better than CHESS) and \\textbf{34.9\\%} EX on Spider-2.0-Lite (ranking 2nd on the official leaderboard). Crucially, AutoLink exhibits \\textbf{exceptional scalability}, \\textbf{maintaining high recall}, \\textbf{efficient token consumption}, and \\textbf{robust execution accuracy} on large schemas (e.g., over 3,000 columns) where existing methods severely degrade-making it a highly scalable, high-recall schema-linking solution for industrial text-to-SQL systems.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
