{"id": "2506.13785", "pdf": "https://arxiv.org/pdf/2506.13785", "abs": "https://arxiv.org/abs/2506.13785", "authors": ["Patrick Sutanto", "Jonathan Kenrick", "Max Lorenz", "Joan Santoso"], "title": "LLM-Driven Data Generation and a Novel Soft Metric for Evaluating Text-to-SQL in Aviation MRO", "categories": ["cs.DB", "cs.IR"], "comment": null, "summary": "The application of Large Language Models (LLMs) to text-to-SQL tasks promises to democratize data access, particularly in critical industries like aviation Maintenance, Repair, and Operation (MRO). However, progress is hindered by two key challenges: the rigidity of conventional evaluation metrics such as execution accuracy, which offer coarse, binary feedback, and the scarcity of domain-specific evaluation datasets. This paper addresses these gaps. To enable more nuanced assessment, we introduce a novel F1-score-based 'soft' metric that quantifies the informational overlap between generated and ground-truth SQL results. To address data scarcity, we propose an LLM-driven pipeline that synthesizes realistic question-SQL pairs from database schemas. We demonstrate our contributions through an empirical evaluation on an authentic MRO database. Our experiments show that the proposed soft metric provides more insightful performance analysis than strict accuracy, and our data generation technique is effective in creating a domain-specific benchmark. Together, these contributions offer a robust framework for evaluating and advancing text-to-SQL systems in specialized environments."}
{"id": "2506.14034", "pdf": "https://arxiv.org/pdf/2506.14034", "abs": "https://arxiv.org/abs/2506.14034", "authors": ["Brian Tsan", "Abylay Amanbayev", "Asoke Datta", "Florin Rusu"], "title": "Sketched Sum-Product Networks for Joins", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Sketches have shown high accuracy in multi-way join cardinality estimation, a critical problem in cost-based query optimization. Accurately estimating the cardinality of a join operation -- analogous to its computational cost -- allows the optimization of query execution costs in relational database systems. However, although sketches have shown high efficacy in query optimization, they are typically constructed specifically for predefined selections in queries that are assumed to be given a priori, hindering their applicability to new queries. As a more general solution, we propose for Sum-Product Networks to dynamically approximate sketches on-the-fly. Sum-Product Networks can decompose and model multivariate distributions, such as relations, as linear combinations of multiple univariate distributions. By representing these univariate distributions as sketches, Sum-Product Networks can combine them element-wise to efficiently approximate the sketch of any query selection. These approximate sketches can then be applied to join cardinality estimation. In particular, we implement the Fast-AGMS and Bound Sketch methods, which have successfully been used in prior work, despite their costly construction. By accurately approximating them instead, our work provides a practical alternative to apply these sketches to query optimization."}
{"id": "2506.14707", "pdf": "https://arxiv.org/pdf/2506.14707", "abs": "https://arxiv.org/abs/2506.14707", "authors": ["Qian Xu", "Feng Zhang", "Chengxi Li", "Lei Cao", "Zheng Chen", "Jidong Zhai", "Xiaoyong Du"], "title": "HARMONY: A Scalable Distributed Vector Database for High-Throughput Approximate Nearest Neighbor Search", "categories": ["cs.DB"], "comment": null, "summary": "Approximate Nearest Neighbor Search (ANNS) is essential for various data-intensive applications, including recommendation systems, image retrieval, and machine learning. Scaling ANNS to handle billions of high-dimensional vectors on a single machine presents significant challenges in memory capacity and processing efficiency. To address these challenges, distributed vector databases leverage multiple nodes for the parallel storage and processing of vectors. However, existing solutions often suffer from load imbalance and high communication overhead, primarily due to traditional partition strategies that fail to effectively distribute the workload. In this paper, we introduce Harmony, a distributed ANNS system that employs a novel multi-granularity partition strategy, combining dimension-based and vector-based partition. This strategy ensures a balanced distribution of computational load across all nodes while effectively minimizing communication costs. Furthermore, Harmony incorporates an early-stop pruning mechanism that leverages the monotonicity of distance computations in dimension-based partition, resulting in significant reductions in both computational and communication overhead. We conducted extensive experiments on diverse real-world datasets, demonstrating that Harmony outperforms leading distributed vector databases, achieving 4.63 times throughput on average in four nodes and 58% performance improvement over traditional distribution for skewed workloads."}
{"id": "2506.13989", "pdf": "https://arxiv.org/pdf/2506.13989", "abs": "https://arxiv.org/abs/2506.13989", "authors": ["Johan \u00d6stman", "Edvin Callisen", "Anton Chen", "Kristiina Ausmees", "Emanuel G\u00e5rdh", "Jovan Zamac", "Jolanta Goldsteine", "Hugo Wefer", "Simon Whelan", "Markus Reimeg\u00e5rd"], "title": "AMLgentex: Mobilizing Data-Driven Research to Combat Money Laundering", "categories": ["cs.SI", "cs.AI", "cs.DB", "cs.LG"], "comment": "21 figures, 22 pages", "summary": "Money laundering enables organized crime by allowing illicit funds to enter the legitimate economy. Although trillions of dollars are laundered each year, only a small fraction is ever uncovered. This stems from a range of factors, including deliberate evasion by launderers, the rarity of confirmed cases, and the limited visibility each financial institution has into the global transaction network. While several synthetic datasets are available, they fail to model the structural and behavioral complexity of real-world money laundering. In particular, they often overlook partial observability, sparse and uncertain labels, strategic behavior, temporal dynamics, class imbalance, and network-level dependencies. To address these limitations, we present AMLGentex, an open-source suite for generating realistic, configurable transaction data and benchmarking detection methods. It enables systematic evaluation of anti-money laundering (AML) systems in a controlled environment that captures key real-world challenges. We demonstrate how the framework can be used to rigorously evaluate methods under conditions that reflect the complexity of practical AML scenarios."}
{"id": "2506.14630", "pdf": "https://arxiv.org/pdf/2506.14630", "abs": "https://arxiv.org/abs/2506.14630", "authors": ["R\u00faben Ad\u00e3o", "Zhongjie Wu", "Changjun Zhou", "Oana Balmau", "Jo\u00e3o Paulo", "Ricardo Macedo"], "title": "Keigo: Co-designing Log-Structured Merge Key-Value Stores with a Non-Volatile, Concurrency-aware Storage Hierarchy (Extended Version)", "categories": ["cs.DC", "cs.DB"], "comment": "This is an extended version of the full paper to appear in VLDB 2025", "summary": "We present Keigo, a concurrency- and workload-aware storage middleware that enhances the performance of log-structured merge key-value stores (LSM KVS) when they are deployed on a hierarchy of storage devices. The key observation behind Keigo is that there is no one-size-fits-all placement of data across the storage hierarchy that optimizes for all workloads. Hence, to leverage the benefits of combining different storage devices, Keigo places files across different devices based on their parallelism, I/O bandwidth, and capacity. We introduce three techniques - concurrency-aware data placement, persistent read-only caching, and context-based I/O differentiation. Keigo is portable across different LSMs, is adaptable to dynamic workloads, and does not require extensive profiling. Our system enables established production KVS such as RocksDB, LevelDB, and Speedb to benefit from heterogeneous storage setups. We evaluate Keigo using synthetic and realistic workloads, showing that it improves the throughput of production-grade LSMs up to 4x for write- and 18x for read-heavy workloads when compared to general-purpose storage systems and specialized LSM KVS."}
