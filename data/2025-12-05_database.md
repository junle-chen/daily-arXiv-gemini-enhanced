# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-12-05

## 目录

- [cs.CR (1)](#cs-cr)
- [cs.DB (5)](#cs-db)

## cs.CR [cs.CR]
### [1] [Towards Privacy-Preserving Range Queries with Secure Learned Spatial Index over Encrypted Data](https://arxiv.org/abs/2512.03669)
*Zuan Wang, Juntao Lu, Jiazhuang Wu, Youliang Tian, Wei Song, Qiuxian Li, Duo Zhang*

Main category: cs.CR

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: With the growing reliance on cloud services for large-scale data management, preserving the security and privacy of outsourced datasets has become increasingly critical. While encrypting data and queries can prevent direct content exposure, recent research reveals that adversaries can still infer sensitive information via access pattern and search path analysis. However, existing solutions that offer strong access pattern privacy often incur substantial performance overhead. In this paper, we propose a novel privacy-preserving range query scheme over encrypted datasets, offering strong security guarantees while maintaining high efficiency. To achieve this, we develop secure learned spatial index (SLS-INDEX), a secure learned index that integrates the Paillier cryptosystem with a hierarchical prediction architecture and noise-injected buckets, enabling data-aware query acceleration in the encrypted domain. To further obfuscate query execution paths, SLS-INDEXbased Range Queries (SLRQ) employs a permutation-based secure bucket prediction protocol. Additionally, we introduce a secure point extraction protocol that generates candidate results to reduce the overhead of secure computation. We provide formal security analysis under realistic leakage functions and implement a prototype to evaluate its practical performance. Extensive experiments on both real-world and synthetic datasets demonstrate that SLRQ significantly outperforms existing solutions in query efficiency while ensuring dataset, query, result, and access pattern privacy.

</details>

[**[PDF]**](https://arxiv.org/pdf/2512.03669) | **Categories:** cs.CR, cs.DB

---


## cs.DB [cs.DB]
### [1] [Thucy: An LLM-based Multi-Agent System for Claim Verification across Relational Databases](https://arxiv.org/abs/2512.03278)
*Michael Theologitis, Dan Suciu*

Main category: cs.DB

TL;DR: Thucy是一个跨数据库、跨表格的多智能体声明验证系统，它能为每个验证结论提供具体的证据，并在TabFact数据集上超越了现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 当前难以辨别真假信息，尤其是在可以根据结构化数据验证的声明上。现有验证系统通常只能在小型单表数据库上运行，无法满足需求。

Method: Thucy系统自主发现、检查和推理所有可用的关系数据库来验证声明，并报告支持其结论的SQL查询。

Result: 在TabFact数据集上，Thucy的准确率超过了之前的state of the art 5.6个百分点（94.3% vs. 88.7%）。

Conclusion: Thucy是第一个跨数据库、跨表格的多智能体声明验证系统，它通过提供透明的SQL查询来支持其验证结果，并在事实核查方面取得了显著进展。

Abstract: 当今时代，辨别真假变得越来越困难。政客、媒体和公众人物每天都在发表相互矛盾的声明，这些声明通常是关于原则上可以根据结构化数据进行验证的主题。例如，关于犯罪率、经济增长或医疗保健的声明都可以根据官方公共记录和结构化数据集进行验证。构建一个能够自动执行此操作的系统在几年前听起来还像是科幻小说。然而，随着LLM和Agentic AI的非凡进步，现在已经触手可及。尽管如此，在技术上可行的和最近的工作所展示的之间仍然存在显着差距。大多数现有的验证系统仅在小型单表数据库上运行，这些数据库通常只有几百行，可以方便地放入LLM的上下文窗口中。在本文中，我们报告了我们在Thucy上的进展，Thucy是第一个跨数据库、跨表的多智能体声明验证系统，它还为每个验证结论提供具体的证据。Thucy在部署之前完全不知道底层数据源，因此必须自主发现、检查和推理所有可用的关系数据库来验证声明。重要的是，Thucy还会报告支持其结论（无论声明是否准确）的确切SQL查询，从而为熟悉SQL的专家用户提供完全的透明度。当在TabFact数据集（结构化数据上事实验证的标准基准）上进行评估时，Thucy在准确率方面超过了之前的state of the art 5.6个百分点（94.3% vs. 88.7%）。

</details>

[**[PDF]**](https://arxiv.org/pdf/2512.03278) | **Categories:** cs.DB, cs.AI

---

### [2] [Continuous Prompts: LLM-Augmented Pipeline Processing over Unstructured Streams](https://arxiv.org/abs/2512.03389)
*Shu Chen, Deepti Raghavan, Uğur Çetintemel*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Monitoring unstructured streams increasingly requires persistent, semantics-aware computation, yet today's LLM frameworks remain stateless and one-shot, limiting their usefulness for long-running analytics. We introduce Continuous Prompts (CPs), the first framework that brings LLM reasoning into continuous stream processing. CPs extend RAG to streaming settings, define continuous semantic operators, and provide multiple implementations, primarily focusing on LLM-based approaches but also reporting one embedding-based variants. Furthermore, we study two LLM-centric optimizations, tuple batching and operator fusion, to significantly improve efficiency while managing accuracy loss.   Because these optimizations inherently trade accuracy for speed, we present a dynamic optimization framework that uses lightweight shadow executions and cost-aware multi-objective Bayesian optimization (MOBO) to learn throughput-accuracy frontiers and adapt plans under probing budgets.   We implement CPs in the VectraFlow stream processing system. Using operator-level microbenchmarks and streaming pipelines on real datasets, we show that VectraFlow can adapt to workload dynamics, navigate accuracy-efficiency trade-offs, and sustain persistent semantic queries over evolving unstructured streams.

</details>

[**[PDF]**](https://arxiv.org/pdf/2512.03389) | **Categories:** cs.DB

---

### [3] [Enterprise Data Science Platform: A Unified Architecture for Federated Data Access](https://arxiv.org/abs/2512.03401)
*Ryoto Miyamoto, Akira Kasuga*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Organizations struggle to share data across departments that have adopted different data analytics platforms. If n datasets must serve m environments, up to n*m replicas can emerge, increasing inconsistency and cost. Traditional warehouses copy data into vendor-specific stores; cross-platform access is hard. This study proposes the Enterprise Data Science Platform (EDSP), which builds on data lakehouse architecture and follows a Write-Once, Read-Anywhere principle. EDSP enables federated data access for multi-query engine environments, targeting data science workloads with periodic data updates and query response times ranging from seconds to minutes. By providing centralized data management with federated access from multiple query engines to the same data sources, EDSP eliminates data duplication and vendor lock-in inherent in traditional data warehouses. The platform employs a four-layer architecture: Data Preparation, Data Store, Access Interface, and Query Engines. This design enforces separation of concerns and reduces the need for data migration when integrating additional analytical environments. Experimental results demonstrate that major cloud data warehouses and programming environments can directly query EDSP-managed datasets. We implemented and deployed EDSP in production, confirming interoperability across multiple query engines. For data sharing across different analytical environments, EDSP achieves a 33-44% reduction in operational steps compared with conventional approaches requiring data migration. Although query latency may increase by up to a factor of 2.6 compared with native tables, end-to-end completion times remain on the order of seconds, maintaining practical performance for analytical use cases. Based on our production experience, EDSP provides practical design guidelines for addressing the data-silo problem in multi-query engine environments.

</details>

[**[PDF]**](https://arxiv.org/pdf/2512.03401) | **Categories:** cs.DB

---

### [4] [ExOAR: Expert-Guided Object and Activity Recognition from Textual Data](https://arxiv.org/abs/2512.03790)
*Iris Beerepoot, Vinicius Stein Dani, Xixi Lu*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Object-centric process mining requires structured data, but extracting it from unstructured text remains a challenge. We introduce ExOAR (Expert-Guided Object and Activity Recognition), an interactive method that combines large language models (LLMs) with human verification to identify objects and activities from textual data. ExOAR guides users through consecutive stages in which an LLM generates candidate object types, activities, and object instances based on contextual input, such as a user's profession, and textual data. Users review and refine these suggestions before proceeding to the next stage. Implemented as a practical tool, ExOAR is initially validated through a demonstration and then evaluated with real-world Active Window Tracking data from five users. Our results show that ExOAR can effectively bridge the gap between unstructured textual data and the structured log with clear semantics needed for object-centric process analysis, while it maintains flexibility and human oversight.

</details>

[**[PDF]**](https://arxiv.org/pdf/2512.03790) | **Categories:** cs.DB, cs.CY

---

### [5] [IBM Multilevel Process Mining vs de facto Object-Centric Process Mining approaches](https://arxiv.org/abs/2512.03906)
*Alberto Ronzoni, Anina Antony, Anjana M R, Francesca De Leo, Jesna Jose, Mattia Freda, Nandini Narayanankutty, Rafflesia Khan, Raji RV, Thomas Diacci*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: The academic evolution of process mining is moving toward object centric process mining, marking a significant shift in how processes are modeled and analyzed. IBM has developed its own distinctive approach called Multilevel Process Mining. This paper provides a description of the two approaches and presents a comparative analysis of their respective advantages and limitations. IBM leveraged this comparison to drive the evolution of IBM Process Mining product, creating the new Organizational Mining feature, an innovation that combines the best of the two approaches. Demonstrate the potential of this novel, innovative and distinct methodology with an example.

</details>

[**[PDF]**](https://arxiv.org/pdf/2512.03906) | **Categories:** cs.DB

---
