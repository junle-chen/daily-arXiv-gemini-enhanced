{"id": "2506.06541", "pdf": "https://arxiv.org/pdf/2506.06541", "abs": "https://arxiv.org/abs/2506.06541", "authors": ["Eugenie Lai", "Gerardo Vitagliano", "Ziyu Zhang", "Sivaprasad Sudhir", "Om Chabra", "Anna Zeng", "Anton A. Zabreyko", "Chenning Li", "Ferdi Kossmann", "Jialin Ding", "Jun Chen", "Markos Markakis", "Matthew Russo", "Weiyang Wang", "Ziniu Wu", "Michael J. Cafarella", "Lei Cao", "Samuel Madden", "Tim Kraska"], "title": "KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes", "categories": ["cs.DB", "cs.AI", "cs.MA"], "comment": null, "summary": "Constructing real-world data-to-insight pipelines often involves data\nextraction from data lakes, data integration across heterogeneous data sources,\nand diverse operations from data cleaning to analysis. The design and\nimplementation of data science pipelines require domain knowledge, technical\nexpertise, and even project-specific insights. AI systems have shown remarkable\nreasoning, coding, and understanding capabilities. However, it remains unclear\nto what extent these capabilities translate into successful design and\nexecution of such complex pipelines. We introduce KRAMABENCH: a benchmark\ncomposed of 104 manually-curated real-world data science pipelines spanning\n1700 data files from 24 data sources in 6 different domains. We show that these\npipelines test the end-to-end capabilities of AI systems on data processing,\nrequiring data discovery, wrangling and cleaning, efficient processing,\nstatistical reasoning, and orchestrating data processing steps given a\nhigh-level task. Our evaluation tests 5 general models and 3 code generation\nmodels using our reference framework, DS-GURU, which instructs the AI model to\ndecompose a question into a sequence of subtasks, reason through each step, and\nsynthesize Python code that implements the proposed design. Our results on\nKRAMABENCH show that, although the models are sufficiently capable of solving\nwell-specified data science code generation tasks, when extensive data\nprocessing and domain knowledge are required to construct real-world data\nscience pipelines, existing out-of-box models fall short. Progress on\nKramaBench represents crucial steps towards developing autonomous data science\nagents for real-world applications. Our code, reference framework, and data are\navailable at https://github.com/mitdbg/KramaBench."}
{"id": "2506.07675", "pdf": "https://arxiv.org/pdf/2506.07675", "abs": "https://arxiv.org/abs/2506.07675", "authors": ["Yuyang Song", "Hanxu Yan", "Jiale Lao", "Yibo Wang", "Yufei Li", "Yuanchun Zhou", "Jianguo Wang", "Mingjie Tang"], "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "categories": ["cs.DB"], "comment": null, "summary": "Query rewrite transforms SQL queries into semantically equivalent forms that\nrun more efficiently. Existing approaches mainly rely on predefined rewrite\nrules, but they handle a limited subset of queries and can cause performance\nregressions. This limitation stems from three challenges of rule-based query\nrewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite\nrules do not generalize to new query patterns, and (3) some rewrite techniques\ncannot be expressed as fixed rules. Motivated by the fact that human experts\nexhibit significantly better rewrite ability but suffer from scalability, and\nLarge Language Models (LLMs) have demonstrated nearly human-level semantic and\nreasoning abilities, we propose a new approach of using LLMs to rewrite SQL\nqueries beyond rules. Due to the hallucination problems in LLMs, directly\napplying LLMs often leads to nonequivalent and suboptimal queries. To address\nthis issue, we propose QUITE (query rewrite), a training-free and\nfeedback-aware system based on LLM agents that rewrites SQL queries into\nsemantically equivalent forms with significantly better performance, covering a\nbroader range of query patterns and rewrite strategies compared to rule-based\nmethods. Firstly, we design a multi-agent framework controlled by a finite\nstate machine (FSM) to equip LLMs with the ability to use external tools and\nenhance the rewrite process with real-time database feedback. Secondly, we\ndevelop a rewrite middleware to enhance the ability of LLMs to generate\noptimized query equivalents. Finally, we employ a novel hint injection\ntechnique to improve execution plans for rewritten queries. Extensive\nexperiments show that QUITE reduces query execution time by up to 35.8% over\nstate-of-the-art approaches and produces 24.1% more rewrites than prior\nmethods, covering query cases that earlier systems did not handle."}
{"id": "2506.06396", "pdf": "https://arxiv.org/pdf/2506.06396", "abs": "https://arxiv.org/abs/2506.06396", "authors": ["Christopher D. Molek", "Roberto Fronteddu", "K. Brent Venable", "Niranjan Suri"], "title": "Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": null, "summary": "The expansion of the Internet of Things (IoT) in the battlefield, Internet of\nBattlefield Things (IoBT), gives rise to new opportunities for enhancing\nsituational awareness. To increase the potential of IoBT for situational\nawareness in critical decision making, the data from these devices must be\nprocessed into consumer-ready information objects, and made available to\nconsumers on demand. To address this challenge we propose a workflow that makes\nuse of natural language processing (NLP) to query a database technology and\nreturn a response in natural language. Our solution utilizes Large Language\nModels (LLMs) that are sized for edge devices to perform NLP as well as\ngraphical databases which are well suited for dynamic connected networks which\nare pervasive in the IoBT. Our architecture employs LLMs for both mapping\nquestions in natural language to Cypher database queries as well as to\nsummarize the database output back to the user in natural language. We evaluate\nseveral medium sized LLMs for both of these tasks on a database representing\npublicly available data from the US Army's Multipurpose Sensing Area (MSA) at\nthe Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion\nparameters) outperforms the other models across all the considered metrics.\nMost importantly, we note that, unlike current methods, our two step approach\nallows the relaxation of the Exact Match (EM) requirement of the produced\nCypher queries with ground truth code and, in this way, it achieves a 19.4%\nincrease in accuracy. Our workflow lays the ground work for deploying LLMs on\nedge devices to enable natural language interactions with databases containing\ninformation objects for critical decision making."}
{"id": "2506.07552", "pdf": "https://arxiv.org/pdf/2506.07552", "abs": "https://arxiv.org/abs/2506.07552", "authors": ["Valter Uotila", "Jiaheng Lu"], "title": "Quantum Information-Theoretical Size Bounds for Conjunctive Queries with Functional Dependencies", "categories": ["quant-ph", "cs.DB"], "comment": "13 pages, 3 figures", "summary": "Deriving formulations for computing and estimating tight worst-case size\nincreases for conjunctive queries with various constraints has been at the core\nof theoretical database research. If the problem has no constraints or only one\nconstraint, such as functional dependencies or degree constraints, tight\nworst-case size bounds have been proven, and they are even practically\ncomputable. If the problem has more than one constraint, computing tight bounds\ncan be difficult in practice and may even require an infinite number of linear\ninequalities in its optimization formulation. While these challenges have been\naddressed with varying methods, no prior research has employed quantum\ninformation theory to address this problem. In this work, we establish a\nconnection between earlier work on estimating size bounds for conjunctive\nqueries with classical information theory and the field of quantum information\ntheory. We propose replacing the classical Shannon entropy formulation with the\nquantum R\\'enyi entropy. Whereas classical Shannon entropy requires infinitely\nmany inequalities to characterize the optimization space, R\\'enyi entropy\nrequires only one type of inequality, which is non-negativity. Although this is\na promising modification, optimization with respect to the quantum states\ninstead of classical distributions creates a new set of challenges that prevent\nus from finding a practically computable, tight worst-case size bound. In this\nline, we propose a quantum version to derive worst-case size bounds. The\nprevious tight classical worst-case size bound can be viewed as a special limit\nof this quantum bound. We also provide a comprehensive background on prior\nresearch and discuss the future possibilities of quantum information theory in\ntheoretical database research."}
