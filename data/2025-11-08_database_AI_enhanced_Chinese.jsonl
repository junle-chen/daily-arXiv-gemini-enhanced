{"id": "2511.04140", "pdf": "https://arxiv.org/pdf/2511.04140", "abs": "https://arxiv.org/abs/2511.04140", "authors": ["Zheng Li", "Weiyan Wang", "Ruiyuan Li", "Chao Chen", "Xianlei Long", "Linjiang Zheng", "Quanqing Xu", "Chuanhui Yang"], "title": "GPU-Based Floating-point Adaptive Lossless Compression", "categories": ["cs.DB", "cs.DS"], "comment": null, "summary": "Domains such as IoT (Internet of Things) and HPC (High Performance Computing)\ngenerate a torrential influx of floating-point time-series data. Compressing\nthese data while preserving their absolute fidelity is critical, and leveraging\nthe massive parallelism of modern GPUs offers a path to unprecedented\nthroughput. Nevertheless, designing such a high-performance GPU-based lossless\ncompressor faces three key challenges: 1) heterogeneous data movement\nbottlenecks, 2) precision-preserving conversion complexity, and 3)\nanomaly-induced sparsity degradation. To address these challenges, this paper\nproposes Falcon, a GPU-based Floating-point Adaptive Lossless COmpressioN\nframework. Specifically, Falcon first introduces a lightweight asynchronous\npipeline, which hides the I/O latency during the data transmission between the\nCPU and GPU. Then, we propose an accurate and fast float-to-integer\ntransformation method with theoretical guarantees, which eliminates the errors\ncaused by floating-point arithmetic. Moreover, we devise an adaptive sparse\nbit-plane lossless encoding strategy, which reduces the sparsity caused by\noutliers. Extensive experiments on 12 diverse datasets show that our\ncompression ratio improves by 9.1% over the most advanced CPU-based method,\nwith compression throughput 2.43X higher and decompression throughput 2.4X\nhigher than the fastest GPU-based competitors, respectively.", "AI": {"tldr": "Falcon\u662f\u4e00\u4e2a\u57fa\u4e8eGPU\u7684\u6d6e\u70b9\u81ea\u9002\u5e94\u65e0\u635f\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5f02\u6b65\u6d41\u6c34\u7ebf\u3001\u7cbe\u786e\u5feb\u901f\u7684\u6d6e\u70b9\u5230\u6574\u6570\u8f6c\u6362\u65b9\u6cd5\u548c\u81ea\u9002\u5e94\u7a00\u758f\u4f4d\u5e73\u9762\u65e0\u635f\u7f16\u7801\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u538b\u7f29\u6bd4\u548c\u541e\u5410\u91cf\u3002", "motivation": "\u7269\u8054\u7f51\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u7b49\u9886\u57df\u4ea7\u751f\u5927\u91cf\u7684\u6d6e\u70b9\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5bf9\u5176\u8fdb\u884c\u65e0\u635f\u538b\u7f29\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u4e14\u5229\u7528GPU\u7684\u5e76\u884c\u6027\u53ef\u4ee5\u5b9e\u73b0\u524d\u6240\u672a\u6709\u7684\u541e\u5410\u91cf\u3002\u7136\u800c\uff0c\u8bbe\u8ba1\u9ad8\u6027\u80fd\u7684GPU\u65e0\u635f\u538b\u7f29\u5668\u9762\u4e34\u5f02\u6784\u6570\u636e\u79fb\u52a8\u74f6\u9888\u3001\u7cbe\u5ea6\u4fdd\u6301\u8f6c\u6362\u590d\u6742\u6027\u548c\u5f02\u5e38\u5f15\u8d77\u7684\u7a00\u758f\u6027\u964d\u4f4e\u8fd9\u4e09\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Falcon\uff0c\u4e00\u4e2aGPU-based\u7684\u6d6e\u70b9\u81ea\u9002\u5e94\u65e0\u635f\u538b\u7f29\u6846\u67b6\u3002Falcon\u9996\u5148\u5f15\u5165\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5f02\u6b65\u6d41\u6c34\u7ebf\uff0c\u9690\u85cf\u4e86CPU\u548cGPU\u4e4b\u95f4\u6570\u636e\u4f20\u8f93\u7684I/O\u5ef6\u8fdf\u3002\u7136\u540e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u786e\u5feb\u901f\u7684\u6d6e\u70b9\u5230\u6574\u6570\u8f6c\u6362\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\uff0c\u6d88\u9664\u4e86\u6d6e\u70b9\u8fd0\u7b97\u5f15\u8d77\u7684\u8bef\u5dee\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7a00\u758f\u4f4d\u5e73\u9762\u65e0\u635f\u7f16\u7801\u7b56\u7565\uff0c\u51cf\u5c11\u4e86\u5f02\u5e38\u503c\u5f15\u8d77\u7684\u7a00\u758f\u6027\u3002", "result": "\u572812\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFalcon\u7684\u538b\u7f29\u6bd4\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8eCPU\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e869.1%\uff0c\u538b\u7f29\u541e\u5410\u91cf\u6bd4\u6700\u5feb\u7684\u57fa\u4e8eGPU\u7684\u7ade\u4e89\u5bf9\u624b\u9ad82.43\u500d\uff0c\u89e3\u538b\u7f29\u541e\u5410\u91cf\u9ad82.4\u500d\u3002", "conclusion": "Falcon\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5f02\u6b65\u6d41\u6c34\u7ebf\u3001\u7cbe\u786e\u5feb\u901f\u7684\u6d6e\u70b9\u5230\u6574\u6570\u8f6c\u6362\u65b9\u6cd5\u548c\u81ea\u9002\u5e94\u7a00\u758f\u4f4d\u5e73\u9762\u65e0\u635f\u7f16\u7801\u7b56\u7565\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86GPU\u65e0\u635f\u538b\u7f29\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u5728\u538b\u7f29\u6bd4\u548c\u541e\u5410\u91cf\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347\u3002", "summary_zh": "\u7269\u8054\u7f51\uff08IoT\uff09\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u7b49\u9886\u57df\u4f1a\u4ea7\u751f\u5927\u91cf\u7684\u6d6e\u70b9\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002\u538b\u7f29\u8fd9\u4e9b\u6570\u636e\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u7edd\u5bf9\u7684\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\u3002\u5229\u7528\u73b0\u4ee3GPU\u7684\u5927\u89c4\u6a21\u5e76\u884c\u6027\uff0c\u53ef\u4ee5\u5b9e\u73b0\u524d\u6240\u672a\u6709\u7684\u541e\u5410\u91cf\u3002\u7136\u800c\uff0c\u8bbe\u8ba1\u8fd9\u79cd\u9ad8\u6027\u80fd\u7684\u57fa\u4e8eGPU\u7684\u65e0\u635f\u538b\u7f29\u5668\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a1\uff09\u5f02\u6784\u6570\u636e\u79fb\u52a8\u74f6\u9888\uff0c2\uff09\u7cbe\u5ea6\u4fdd\u6301\u8f6c\u6362\u7684\u590d\u6742\u6027\uff0c\u4ee5\u53ca3\uff09\u5f02\u5e38\u5f15\u8d77\u7684\u7a00\u758f\u6027\u964d\u4f4e\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86Falcon\uff0c\u4e00\u4e2a\u57fa\u4e8eGPU\u7684\u6d6e\u70b9\u81ea\u9002\u5e94\u65e0\u635f\u538b\u7f29\u6846\u67b6\u3002\u5177\u4f53\u6765\u8bf4\uff0cFalcon\u9996\u5148\u5f15\u5165\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5f02\u6b65\u6d41\u6c34\u7ebf\uff0c\u5b83\u9690\u85cf\u4e86CPU\u548cGPU\u4e4b\u95f4\u6570\u636e\u4f20\u8f93\u8fc7\u7a0b\u4e2d\u7684I/O\u5ef6\u8fdf\u3002\u7136\u540e\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u786e\u800c\u5feb\u901f\u7684\u6d6e\u70b9\u5230\u6574\u6570\u8f6c\u6362\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\uff0c\u6d88\u9664\u4e86\u6d6e\u70b9\u8fd0\u7b97\u5f15\u8d77\u7684\u8bef\u5dee\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7a00\u758f\u4f4d\u5e73\u9762\u65e0\u635f\u7f16\u7801\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u51cf\u5c11\u4e86\u7531\u5f02\u5e38\u503c\u5f15\u8d77\u7684\u7a00\u758f\u6027\u3002\u572812\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u538b\u7f29\u6bd4\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8eCPU\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e869.1%\uff0c\u538b\u7f29\u541e\u5410\u91cf\u6bd4\u6700\u5feb\u7684\u57fa\u4e8eGPU\u7684\u7ade\u4e89\u5bf9\u624b\u9ad82.43\u500d\uff0c\u89e3\u538b\u7f29\u541e\u5410\u91cf\u9ad82.4\u500d\u3002"}}
{"id": "2511.04148", "pdf": "https://arxiv.org/pdf/2511.04148", "abs": "https://arxiv.org/abs/2511.04148", "authors": ["Xiaobo Zhao", "Daniel E. Lucani"], "title": "EntroGD: Efficient Compression and Accurate Direct Analytics on Compressed Data", "categories": ["cs.DB"], "comment": "6 pages, 7 figures", "summary": "Generalized Deduplication (GD) enables lossless compression with direct\nanalytics on compressed data by dividing data into \\emph{bases} and\n\\emph{deviations} and performing dictionary encoding on the former. However, GD\nalgorithms face scalability challenges for high-dimensional data. For example,\nthe GreedyGD algorithm relies on an iterative bit-selection process across\n$d$-dimensional data resulting in $O(nd^2)$ complexity for $n$ data rows to\nselect bits to be used as bases and deviations. Although the $n$ data rows can\nbe reduced during training at the expense of performance, highly dimensional\ndata still experiences a marked loss in performance. This paper introduces\nEntroGD, an entropy-guided GD framework that reduces complexity of the\nbit-selection algorithm to $O(nd)$. EntroGD operates considers a two-step\nprocess. First, it generates condensed samples to preserve analytic fidelity.\nSecond, it applies entropy-guided bit selection to maximize compression\nefficiency. Across 18 datasets of varying types and dimensionalities, EntroGD\nachieves compression performance comparable to GD-based and universal\ncompressors, while reducing configuration time by up to 53.5$\\times$ over\nGreedyGD and accelerating clustering by up to 31.6$\\times$ over the original\ndata with negligible accuracy loss by performing analytics on the condensed\nsamples, which are much fewer than original samples. Thus, EntroGD provides an\nefficient and scalable solution to performing analytics directly on compressed\ndata.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.03891", "pdf": "https://arxiv.org/pdf/2511.03891", "abs": "https://arxiv.org/abs/2511.03891", "authors": ["Hlali Azzeddine", "Majid Ben Yakhlef", "Soulaiman El Hazzat"], "title": "Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition", "categories": ["cs.CV", "cs.AI", "cs.DB"], "comment": null, "summary": "Small, imbalanced datasets and poor input image quality can lead to high\nfalse predictions rates with deep learning models. This paper introduces\nClass-Based Image Composition, an approach that allows us to reformulate\ntraining inputs through a fusion of multiple images of the same class into\ncombined visual composites, named Composite Input Images (CoImg). That enhances\nthe intra-class variance and improves the valuable information density per\ntraining sample and increases the ability of the model to distinguish between\nsubtle disease patterns. Our method was evaluated on the Optical Coherence\nTomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et\nal., 2024), which contains 2,064 high-resolution optical coherence tomography\n(OCT) scans of the human retina, representing seven distinct diseases with a\nsignificant class imbalance. We constructed a perfectly class-balanced version\nof this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout\ncomposite image. To assess the effectiveness of this new representation, we\nconducted a comparative analysis between the original dataset and its variant\nusing a VGG16 model. A fair comparison was ensured by utilizing the identical\nmodel architecture and hyperparameters for all experiments. The proposed\napproach markedly improved diagnostic results.The enhanced Dataset achieved\nnear-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared\nto a baseline model trained on raw dataset. The false prediction rate was also\nsignificantly lower, this demonstrates that the method can producehigh-quality\npredictions even for weak datasets affected by class imbalance or small sample\nsize.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.03761", "pdf": "https://arxiv.org/pdf/2511.03761", "abs": "https://arxiv.org/abs/2511.03761", "authors": ["Umut \u00c7al\u0131ky\u0131lmaz", "Nitin Nayak", "Jinghua Groppe", "Sven Groppe"], "title": "OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.DB"], "comment": null, "summary": "In recent years, the research of multi-agent systems has taken a direction to\nexplore larger and more complex models to fulfill sophisticated tasks. We point\nout two possible pitfalls that might be caused by increasing complexity;\nsusceptibilities to faults, and performance bottlenecks. To prevent the former\nthreat, we propose a transaction-based framework to design very complex\nmulti-agent systems (VCMAS). To address the second threat, we offer to\nintegrate transaction scheduling into the proposed framework. We implemented\nboth of these ideas to develop the OptiMA framework and show that it is able to\nfacilitate the execution of VCMAS with more than a hundred agents. We also\ndemonstrate the effect of transaction scheduling on such a system by showing\nimprovements up to more than 16\\%. Furthermore, we also performed a theoretical\nanalysis on the transaction scheduling problem and provided practical tools\nthat can be used for future research on it.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.04073", "pdf": "https://arxiv.org/pdf/2511.04073", "abs": "https://arxiv.org/abs/2511.04073", "authors": ["Ananya Sutradhar", "Suryansh Gupta", "Ravishankar Krishnaswamy", "Haiyang Xu", "Aseem Rastogi", "Gopal Srinivasa"], "title": "Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters", "categories": ["cs.LG", "cs.DB", "cs.IR"], "comment": "1st Workshop on Vector Databases at International Conference on\n  Machine Learning, 2025", "summary": "Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest\nvectors for a query vector from a dataset. It enforces that a specified set of\ndiscrete labels $S$ for the query must be included in the labels of each\nretrieved vector. Existing graph-based methods typically incorporate filter\nawareness by assigning fixed penalties or prioritizing nodes based on filter\nsatisfaction. However, since these methods use fixed, data in- dependent\npenalties, they often fail to generalize across datasets with diverse label and\nvector distributions. In this work, we propose a principled alternative that\nlearns the optimal trade-off between vector distance and filter match directly\nfrom the data, rather than relying on fixed penalties. We formulate this as a\nconstrained linear optimization problem, deriving weights that better reflect\nthe underlying filter distribution and more effectively address the filtered\nANN search problem. These learned weights guide both the search process and\nindex construction, leading to graph structures that more effectively capture\nthe underlying filter distribution and filter semantics. Our experiments\ndemonstrate that adapting the distance function to the data significantly im-\nproves accuracy by 5-10% over fixed-penalty methods, providing a more flexible\nand generalizable framework for the filtered ANN search problem.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.04153", "pdf": "https://arxiv.org/pdf/2511.04153", "abs": "https://arxiv.org/abs/2511.04153", "authors": ["Fahim Ahmed", "Md Mubtasim Ahasan", "Jahir Sadik Monon", "Muntasir Wahed", "M Ashraful Amin", "A K M Mahbubur Rahman", "Amin Ahsan Ali"], "title": "BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.MA"], "comment": null, "summary": "Text-to-SQL systems provide a natural language interface that can enable even\nlaymen to access information stored in databases. However, existing Large\nLanguage Models (LLM) struggle with SQL generation from natural instructions\ndue to large schema sizes and complex reasoning. Prior work often focuses on\ncomplex, somewhat impractical pipelines using flagship models, while smaller,\nefficient models remain overlooked. In this work, we explore three multi-agent\nLLM pipelines, with systematic performance benchmarking across a range of small\nto large open-source models: (1) Multi-agent discussion pipeline, where agents\niteratively critique and refine SQL queries, and a judge synthesizes the final\nanswer; (2) Planner-Coder pipeline, where a thinking model planner generates\nstepwise SQL generation plans and a coder synthesizes queries; and (3)\nCoder-Aggregator pipeline, where multiple coders independently generate SQL\nqueries, and a reasoning agent selects the best query. Experiments on the\nBird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small\nmodel performance, with up to 10.6% increase in Execution Accuracy for\nQwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines,\nthe LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B\nand QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest\nscore of 56.4%. Codes are available at\nhttps://github.com/treeDweller98/bappa-sql.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.04221", "pdf": "https://arxiv.org/pdf/2511.04221", "abs": "https://arxiv.org/abs/2511.04221", "authors": ["Carl Kugblenu", "Petri Vuorimaa"], "title": "Coordination-Free Lane Partitioning for Convergent ANN Search", "categories": ["cs.IR", "cs.DB"], "comment": "10 pages, 6 figures; arXiv preprint", "summary": "Production vector search systems often fan out each query across parallel\nlanes (threads, replicas, or shards) to meet latency service-level objectives\n(SLOs). In practice, these lanes rediscover the same candidates, so extra\ncompute does not increase coverage. We present a coordination-free lane\npartitioner that turns duplication into complementary work at the same cost and\ndeadline. For each query we (1) build a deterministic candidate pool sized to\nthe total top-k budget, (2) apply a per-query pseudorandom permutation, and (3)\nassign each lane a disjoint slice of positions. Lanes then return different\nresults by construction, with no runtime coordination.\n  At equal cost with four lanes (total candidate budget 64), on SIFT1M (1M SIFT\nfeature vectors) with Hierarchical Navigable Small World graphs (HNSW)\nrecall@10 rises from 0.249 to 0.999 while lane overlap falls from nearly 100%\nto 0%. On MS MARCO (8.8M passages) with HNSW, hit@10 improves from 0.200 to\n0.601 and Mean Reciprocal Rank at 10 (MRR@10) from 0.133 to 0.330. For inverted\nfile (IVF) indexes we see smaller but consistent gains (for example, +11% on MS\nMARCO) by de-duplicating list routing. A microbenchmark shows planner overhead\nof ~37 microseconds per query (mean at the main setting) with linear growth in\nthe number of merged candidates.\n  These results yield a simple operational guideline: size the per-query pool\nto the total budget, deterministically partition positions across lanes, and\nturn redundant fan-out into complementary coverage without changing budget or\ndeadline.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.04491", "pdf": "https://arxiv.org/pdf/2511.04491", "abs": "https://arxiv.org/abs/2511.04491", "authors": ["Nikhil Abhyankar", "Purvi Chaurasia", "Sanchit Kabra", "Ananya Srivastava", "Vivek Gupta", "Chandan K. Reddy"], "title": "RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR", "cs.LG"], "comment": null, "summary": "Existing tabular reasoning benchmarks mostly test models on small, uniform\ntables, underrepresenting the complexity of real-world data and giving an\nincomplete view of Large Language Models' (LLMs) reasoning abilities. Real\ntables are long, heterogeneous, and domain-specific, mixing structured fields\nwith free text and requiring multi-hop reasoning across thousands of tokens. To\naddress this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from\n2031 real-world tables spanning two domains: i) RB-Science (NSF grant records)\nand ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates\nLLMs jointly across scale, heterogeneity, domain specificity, and reasoning\ncomplexity. Experiments with open-source and proprietary models show that LLMs\nstruggle with heterogeneous schemas and complex multi-hop inference, revealing\npersistent weaknesses in current architectures and prompting strategies.\nRUST-BENCH establishes a challenging new testbed for advancing tabular\nreasoning research.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.04584", "pdf": "https://arxiv.org/pdf/2511.04584", "abs": "https://arxiv.org/abs/2511.04584", "authors": ["Daniel Gomm", "Cornelius Wolff", "Madelon Hulsebos"], "title": "Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.HC"], "comment": "Accepted to the AI for Tabular Data workshop at EurIPS 2025", "summary": "Natural language interfaces to tabular data must handle ambiguities inherent\nto queries. Instead of treating ambiguity as a deficiency, we reframe it as a\nfeature of cooperative interaction, where the responsibility of query\nspecification is shared among the user and the system. We develop a principled\nframework distinguishing cooperative queries, i.e., queries that yield a\nresolvable interpretation, from uncooperative queries that cannot be resolved.\nApplying the framework to evaluations for tabular question answering and\nanalysis, we analyze the queries in 15 popular datasets, and observe an\nuncontrolled mixing of query types neither adequate for evaluating a system's\nexecution accuracy nor for evaluating interpretation capabilities. Our\nframework and analysis of queries shifts the perspective from fixing ambiguity\nto embracing cooperation in resolving queries. This reflection enables more\ninformed design and evaluation for natural language interfaces for tabular\ndata, for which we outline implications and directions for future research.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
