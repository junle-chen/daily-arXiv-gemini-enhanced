# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-10-21

## 目录

- [人工智能 (Artificial Intelligence) (2)](#cs-ai)
- [cs.CR (1)](#cs-cr)
- [cs.DB (2)](#cs-db)
- [cs.DC (1)](#cs-dc)

## 人工智能 (Artificial Intelligence) [cs.AI]
### [1] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai, Xuan-guang Pan, Chongyang Tao, Shuai Ma*

Main category: cs.AI

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and structured data access, yet it remains fundamentally challenging due to semantic ambiguity and complex compositional reasoning. While large language models (LLMs) have greatly advanced SQL generation though prompting, supervised finetuning and reinforced tuning, the shift toward test-time scaling exposes a new bottleneck: selecting the correct query from a diverse candidate pool. Existing selection approaches, such as self-consistency or best-of-$N$ decoding, provide only shallow signals, making them prone to inconsistent scoring, fragile reasoning chains, and a failure to capture fine-grained semantic distinctions between closely related SQL candidates. To this end, we introduce JudgeSQL, a principled framework that redefines SQL candidate selection through structured reasoning and weighted consensus tournament mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills reasoning traces with reinforcement learning guided by verifiable rewards, enabling accurate and interpretable judgments. Building on this, a weighted consensus tournament integrates explicit reasoning preferences with implicit generator confidence, yielding selections that are both more reliable and more efficient. Extensive experiments on the BIRD benchmark demonstrate that JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale generalization and robustness to generator capacity.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.15560) | **Categories:** cs.AI, cs.DB

---

### [2] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant, Anurag Dubey, Praneeth Paikray, Gantala Thulsiram*

Main category: cs.AI

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: This paper presents methods for extracting structured information from invoice documents and proposes a set of evaluation metrics (EM) to assess the accuracy of the extracted data against annotated ground truth. The approach involves pre-processing scanned or digital invoices, applying Docling and LlamaCloud Services to identify and extract key fields such as invoice number, date, total amount, and vendor details. To ensure the reliability of the extraction process, we establish a robust evaluation framework comprising field-level precision, consistency check failures, and exact match accuracy. The proposed metrics provide a standardized way to compare different extraction methods and highlight strengths and weaknesses in field-specific performance.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.15727) | **Categories:** cs.AI, cs.DB

---


## cs.CR [cs.CR]
### [1] [FHE-SQL: Fully Homomorphic Encrypted SQL Database](https://arxiv.org/abs/2510.15413)
*Po-Yu Tseng, Po-Chu Hsu, Shih-Wei Liao*

Main category: cs.CR

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: FHE-SQL is a privacy-preserving database system that enables secure query processing on encrypted data using Fully Homomorphic Encryption (FHE), providing privacy guaranties where an untrusted server can execute encrypted queries without learning either the query contents or the underlying data. Unlike property-preserving encryption-based systems such as CryptDB, which rely on deterministic or order-preserving encryption and are vulnerable to frequency, order, and equality-pattern inference attacks, FHE-SQL performs computations entirely under encryption, eliminating these leakage channels. Compared to trusted-hardware approaches such as TrustedDB, which depend on a hardware security module and thus inherit its trust and side-channel limitations, our design achieves end-to-end cryptographic protection without requiring trusted execution environments. In contrast to high-performance FHE-based engines-Hermes, which target specialized workloads such as vector search, FHE-SQL supports general SQL query semantics with schema-aware, type-safe definitions suitable for relational data management. FHE-SQL mitigates the high cost of ciphertext space by using an indirection architecture that separates metadata in RocksDB from large ciphertexts in blob storage. It supports oblivious selection via homomorphic boolean masks, multi-tier caching, and garbage collection, with security proven under the Universal Composability framework.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.15413) | **Categories:** cs.CR, cs.DB

---


## cs.DB [cs.DB]
### [1] [TKHist: Cardinality Estimation for Join Queries via Histograms with Dominant Attribute Correlation Finding](https://arxiv.org/abs/2510.15368)
*Renrui Li, Qingzhi Ma, Jiajie Xu, Lei Zhao, An Liu*

Main category: cs.DB

TL;DR: TKHist 通过捕获 bin-wise 的非均匀信息，并结合 dominating join path correlation discovery 算法，实现了对多表连接查询的高精度基数估计。


<details>
  <summary>Details</summary>
Motivation: 现有的基数估计方法在提高多表连接查询估计准确性的同时，引入了更高的空间开销、延迟和复杂性，尤其是在与二元连接框架集成时。

Method: 提出了一种新的基数估计方法 TKHist，它通过放宽直方图中的均匀性假设来解决这些挑战。TKHist 捕获 bin-wise 的非均匀信息，从而能够准确估计没有过滤谓词的连接查询的基数。此外，还探索了属性独立性假设，并提出了 dominating join path correlation discovery 算法来突出和管理连接键和过滤谓词之间的相关性。

Result: 在流行的基准测试中进行的大量实验表明，与 SOTA 方法相比，TKHist 将误差方差降低了 2-3 个数量级，同时保持了相当或更低的内存使用率。

Conclusion: TKHist 是一种有效的基数估计方法，它能够在保持较低内存开销的同时，显著提高多表连接查询的估计准确性。

Abstract: 基数估计长期以来对于基于成本的数据库优化器识别最佳查询执行计划至关重要，并在过去几十年中引起了广泛关注。虽然最近的进展显着提高了多表连接查询估计的准确性，但这些方法引入了更高的空间开销、延迟和复杂性，尤其是在与二元连接框架集成时。在本文中，我们介绍了一种名为 TKHist 的新型基数估计方法，该方法通过放宽直方图中的均匀性假设来解决这些挑战。TKHist 捕获 bin-wise 的非均匀信息，从而能够准确估计没有过滤谓词的连接查询的基数。此外，我们探索了属性独立性假设，该假设可能导致多表连接查询中的显着高估而不是低估。为了解决这个问题，我们提出了一种 dominating join path correlation discovery 算法，以突出和管理连接键和过滤谓词之间的相关性。我们在流行的基准测试中进行的大量实验表明，与 SOTA 方法相比，TKHist 将误差方差降低了 2-3 个数量级，同时保持了相当或更低的内存使用率。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.15368) | **Categories:** cs.DB

---

### [2] [Optimizing Data Lakes' Queries](https://arxiv.org/abs/2510.15445)
*Gregory, Weintraub*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Cloud data lakes provide a modern solution for managing large volumes of data. The fundamental principle behind these systems is the separation of compute and storage layers. In this architecture, inexpensive cloud storage is utilized for data storage, while compute engines are employed to perform analytics on this data in an "on-demand" mode. However, to execute any calculations on the data, it must be transferred from the storage layer to the compute layer over the network for each query. This transfer can negatively impact calculation performance and requires significant network bandwidth. In this thesis, we examine various strategies to enhance query performance within a cloud data lake architecture. We begin by formalizing the problem and proposing a straightforward yet robust theoretical framework that clearly outlines the associated trade-offs. Central to our framework is the concept of a "query coverage set," which is defined as the collection of files that need to be accessed from storage to fulfill a specific query. Our objective is to identify the minimal coverage set for each query and execute the query exclusively on this subset of files. This approach enables us to significantly improve query performance.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.15445) | **Categories:** cs.DB

---


## cs.DC [cs.DC]
### [1] [Balancing Fairness and Performance in Multi-User Spark Workloads with Dynamic Scheduling (extended version)](https://arxiv.org/abs/2510.15485)
*Dāvis Kažemaks, Laurens Versluis, Burcu Kulahcioglu Ozkan, Jérémie Decouchant*

Main category: cs.DC

TL;DR: 本文提出了一种用户加权公平队列（UWFQ）调度器，旨在最小化作业响应时间，同时确保跨用户及其各自作业的公平资源分配。


<details>
  <summary>Details</summary>
Motivation: 在工业分析环境中，Spark的内置调度器难以维持用户级别的公平性和低平均响应时间，特别是在长时间运行的共享应用程序中。

Method: UWFQ模拟了一个虚拟公平队列系统，并根据在有界公平模型下估计的完成时间来调度作业；引入运行时分区，这是一种基于预期运行时动态细化任务粒度的方法。

Result: UWFQ与现有的内置Spark调度器和最先进的公平调度算法相比，UWFQ将小型作业的平均响应时间减少了高达74%。

Conclusion: UWFQ调度器能够有效减少作业响应时间，并确保用户之间的公平资源分配。

Abstract: Apache Spark是一个被广泛采用的大规模数据处理框架。然而，在工业分析环境中，Spark的内置调度器（如FIFO和公平调度）难以维持用户级别的公平性和低平均响应时间，特别是在长时间运行的共享应用程序中。现有的解决方案通常侧重于作业级别的公平性，但这会无意中偏袒提交更多作业的用户。虽然Spark提供了一个内置的公平调度器，但它缺乏对动态用户工作负载的适应性，并可能降低整体作业性能。我们提出了用户加权公平队列（UWFQ）调度器，旨在最小化作业响应时间，同时确保跨用户及其各自作业的公平资源分配。UWFQ模拟了一个虚拟公平队列系统，并根据在有界公平模型下估计的完成时间来调度作业。为了进一步解决任务倾斜并减少Spark工作负载中常见的优先级反转，我们引入了运行时分区，这是一种基于预期运行时动态细化任务粒度的方法。我们在Spark框架内实现了UWFQ，并使用多用户合成工作负载和Google集群跟踪评估了其性能。我们表明，与现有的内置Spark调度器和最先进的公平调度算法相比，UWFQ将小型作业的平均响应时间减少了高达74%。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.15485) | **Categories:** cs.DC, cs.DB, cs.SY, eess.SY

---
