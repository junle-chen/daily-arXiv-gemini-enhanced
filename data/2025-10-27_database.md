# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-10-27

## 目录

- [人工智能 (Artificial Intelligence) (2)](#cs-ai)
- [cs.DB (7)](#cs-db)

## 人工智能 (Artificial Intelligence) [cs.AI]
### [1] [RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs](https://arxiv.org/abs/2510.19954)
*Joseph Meyer, Divyansha Lachi, Reza Mohammadi, Roshan Reddy Upendra, Eva L. Dyer, Mark Li, Tom Palczewski*

Main category: cs.AI

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Relational multi-table data is common in domains such as e-commerce, healthcare, and scientific research, and can be naturally represented as heterogeneous temporal graphs with multi-modal node attributes. Existing graph neural networks (GNNs) rely on schema-specific feature encoders, requiring separate modules for each node type and feature column, which hinders scalability and parameter sharing. We introduce RELATE (Relational Encoder for Latent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature encoder that can be used with any general purpose GNN. RELATE employs shared modality-specific encoders for categorical, numerical, textual, and temporal attributes, followed by a Perceiver-style cross-attention module that aggregates features into a fixed-size, permutation-invariant node representation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark, where it achieves performance within 3% of schema-specific encoders while reducing parameter counts by up to 5x. This design supports varying schemas and enables multi-dataset pretraining for general-purpose GNNs, paving the way toward foundation models for relational graph data.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.19954) | **Categories:** cs.AI, cs.DB, cs.LG

---

### [2] [FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic](https://arxiv.org/abs/2510.20467)
*Yiwen Peng, Thomas Bonald, Fabian M. Suchanek*

Main category: cs.AI

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Knowledge graph alignment is the task of matching equivalent entities (that is, instances and classes) and relations across two knowledge graphs. Most existing methods focus on pure entity-level alignment, computing the similarity of entities in some embedding space. They lack interpretable reasoning and need training data to work. In this paper, we propose FLORA, a simple yet effective method that (1) is unsupervised, i.e., does not require training data, (2) provides a holistic alignment for entities and relations iteratively, (3) is based on fuzzy logic and thus delivers interpretable results, (4) provably converges, (5) allows dangling entities, i.e., entities without a counterpart in the other KG, and (6) achieves state-of-the-art results on major benchmarks.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.20467) | **Categories:** cs.AI, cs.DB

---


## cs.DB [cs.DB]
### [1] [Query Optimization in the Wild: Realities and Trends](https://arxiv.org/abs/2510.20082)
*Yuanyuan Tian*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: For nearly half a century, the core design of query optimizers in industrial database systems has remained remarkably stable, relying on foundational principles from System R and the Volcano/Cascades framework. However, the rise of cloud computing, massive data volumes, and unified data platforms has exposed the limitations of this traditional, monolithic architecture. Taking an industrial perspective, this paper reviews the past and present of query optimization in production systems and identifies the challenges they face today. Then this paper highlights three key trends gaining momentum in the industry that promise to address these challenges. First, a tighter feedback loop between query optimization and query execution is being used to improve the robustness of query performance. Second, the scope of optimization is expanding from a single query to entire workloads through the convergence of query optimization and workload optimization. Third, and perhaps most transformatively, the industry is moving from monolithic designs to composable architectures that foster agility and cross-engine collaboration. Together, these trends chart a clear path toward a more dynamic, holistic, and adaptable future for query optimization in practice.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.20082) | **Categories:** cs.DB

---

### [2] [UREM: A High-performance Unified and Resilient Enhancement Method for Multi- and High-Dimensional Indexes](https://arxiv.org/abs/2510.20110)
*Ming Sheng, Shuliang Wang, Yong Zhang, Yi Luo, Xianbo Liu, Zeming Li*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Numerous multi- or high-dimensional indexes with distinct advantages have been proposed on various platforms to meet application requirements. To achieve higher-performance queries, most indexes employ enhancement methods, including structure-oriented and layout-oriented enhancement methods. Existing structure-oriented methods tailored to specific indexes work well under static workloads but lack generality and degrade under dynamic workloads. The layout-oriented methods exhibit good generality and perform well under dynamic workloads, but exhibit suboptimal performance under static workloads. Therefore, it is an open challenge to develop a unified and resilient enhancement method that can improve query performance for different indexes adaptively under different scenarios. In this paper, we propose UREM, which is the first high-performance Unified and Resilient Enhancement Method designed for both multi- and high-dimensional indexes, capable of adapting to different scenarios. Specifically, UREM (1) can be uniformly applied with different indexes on various platforms; (2) enhances the query performance of indexes by layout optimization under static workloads; (3) enables indexes to stabilize performance when queries shift through partial layout reorganization. We evaluate UREM on 20 widely used indexes. Experimental results demonstrate that UREM improves the query performance of multi- and high-dimensional indexes by up to 5.73x and 9.18x under static workloads, and by an average of 5.72x and 9.47x under dynamic workloads. Moreover, some traditional indexes enhanced by UREM even achieve performance comparable to or even surpassing that of recent advanced indexes.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.20110) | **Categories:** cs.DB

---

### [3] [RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector Database Perspective](https://arxiv.org/abs/2510.20296)
*Wenqi Jiang*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Retrieval-augmented generation (RAG) has emerged as one of the most prominent applications of vector databases. By integrating documents retrieved from a database into the prompt of a large language model (LLM), RAG enables more reliable and informative content generation. While there has been extensive research on vector databases, many open research problems remain once they are considered in the wider context of end-to-end RAG pipelines. One practical yet challenging problem is how to jointly optimize both system performance and generation quality in RAG, which is significantly more complex than it appears due to the numerous knobs on both the algorithmic side (spanning models and databases) and the systems side (from software to hardware). In this paper, we present RAG-Stack, a three-pillar blueprint for quality-performance co-optimization in RAG systems. RAG-Stack comprises: (1) RAG-IR, an intermediate representation that serves as an abstraction layer to decouple quality and performance aspects; (2) RAG-CM, a cost model for estimating system performance given an RAG-IR; and (3) RAG-PE, a plan exploration algorithm that searches for high-quality, high-performance RAG configurations. We believe this three-pillar blueprint will become the de facto paradigm for RAG quality-performance co-optimization in the years to come.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.20296) | **Categories:** cs.DB, cs.AI

---

### [4] [Hybrid Mixed Integer Linear Programming for Large-Scale Join Order Optimisation](https://arxiv.org/abs/2510.20308)
*Manuel Schönberger, Immanuel Trummer, Wolfgang Mauerer*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Finding optimal join orders is among the most crucial steps to be performed by query optimisers. Though extensively studied in data management research, the problem remains far from solved: While query optimisers rely on exhaustive search methods to determine ideal solutions for small problems, such methods reach their limits once queries grow in size. Yet, large queries become increasingly common in real-world scenarios, and require suitable methods to generate efficient execution plans. While a variety of heuristics have been proposed for large-scale query optimisation, they suffer from degrading solution quality as queries grow in size, or feature highly sub-optimal worst-case behavior, as we will show.   We propose a novel method based on the paradigm of mixed integer linear programming (MILP): By deriving a novel MILP model capable of optimising arbitrary bushy tree structures, we address the limitations of existing MILP methods for join ordering, and can rely on highly optimised MILP solvers to derive efficient tree structures that elude competing methods. To ensure optimisation efficiency, we embed our MILP method into a hybrid framework, which applies MILP solvers precisely where they provide the greatest advantage over competitors, while relying on more efficient methods for less complex optimisation steps. Thereby, our approach gracefully scales to extremely large query sizes joining up to 100 relations, and consistently achieves the most robust plan quality among a large variety of competing join ordering methods.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.20308) | **Categories:** cs.DB

---

### [5] [An Empirical Study on Database Usage in Microservices](https://arxiv.org/abs/2510.20582)
*Maxime André, Marco Raglianti, Souhaila Serbout, Anthony Cleve, Michele Lanza*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Microservices architectures are an integral part of modern software development. Their adoption brings significant changes to database management. Instead of relying on a single database, a microservices architecture is typically composed of multiple, smaller, heterogeneous, and distributed DBs. In these data-intensive systems, the variety and combination of database categories and technologies play a crucial role in storing and managing data. While data management in microservices is a major challenge, research literature is scarce.   We present an empirical study on how databases are used in microservices. On the dataset we collected (and released as open data for future research), considering 15 years of microservices, we examine ca. 1,000 GitHub projects that use databases selected among 180 technologies from 14 categories. We perform a comprehensive analysis of current practices, providing researchers and practitioners with empirical evidence to better understand database usage in microservices. We report 18 findings and 9 recommendations. We show that microservices predominantly use Relational, Key-Value, Document, and Search databases. Notably, 52% of microservices combine multiple database categories. Complexity correlates with database count, with older systems favoring Relational databases and newer ones increasingly adopting Key-Value and Document technologies. Niche databases (e.g., EventStoreDB, PostGIS), while not widespread, are often combined with a mainstream one.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.20582) | **Categories:** cs.DB

---

### [6] [Balanced Popularity in Multi-Product Billboard Advertisement](https://arxiv.org/abs/2510.20600)
*Dildar Ali, Suman Banerjee, Yamuna Prasad*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: The billboard advertisement has emerged as an effective out-of-home advertisement technique where the objective is to choose a limited number of slots to play some advertisement content (e.g., animation, video, etc.) with the hope that the content will be visible to a large number of travelers, and this will be helpful to earn more revenue. In this paper, we study a variant of the influential slot selection problem where the advertiser wants to promote multiple products. Formally, we call this problem the \textsc{Multi-Product Influence Maximization Problem for the Balanced Popularity} Problem. The input to our problem is a trajectory and a billboard database, as well as a budget for each product. The goal here is to choose a subset of slots for each product such that the aggregated influence of all the products gets maximized subject to the following two constraints: total selection cost for each product is less than or equal to the allocated budget for that product, and the difference between the influence for any two products is less than or equal to a given threshold. We show that the problem is NP-hard to solve optimally. We formulate this problem as a linear programming problem and use linear programming relaxation with randomized rounding. Further, we propose a greedy-based heuristic with balance correction to solve this problem. We conduct a number of experiments with real-world trajectory and billboard datasets, and the results are reported. From the reported results, we observe that the proposed solution approaches lead to more influence compared to many baseline methods.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.20600) | **Categories:** cs.DB

---

### [7] [Downsizing Diffusion Models for Cardinality Estimation](https://arxiv.org/abs/2510.20681)
*Xinhe Mu, Zhaoqi Zhou, Zaijiu Shang, Chuan Zhou, Gang Fu, Guiying Yan, Guoliang Li, Zhiming Ma*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Inspired by the performance of score-based diffusion models in estimating complex text, video, and image distributions with thousands of dimensions, we introduce Accelerated Diffusion Cardest (ADC), the first joint distribution cardinality estimator based on a downsized diffusion model.   To calculate the pointwise density value of data distributions, ADC's density estimator uses a formula that evaluates log-likelihood by integrating the score function, a gradient mapping which ADC has learned to efficiently approximate using its lightweight score estimator. To answer ranged queries, ADC's selectivity estimator first predicts their selectivity using a Gaussian Mixture Model (GMM), then uses importance sampling Monte Carlo to correct its predictions with more accurate pointwise density values calculated by the density estimator. ADC+ further trains a decision tree to identify the high-volume, high-selectivity queries that the GMM alone can predict very accurately, in which case it skips the correction phase to prevent Monte Carlo from adding more variance. Doing so lowers median Q-error and cuts per-query latency by 25 percent, making ADC+ usually twice as fast as Naru, arguably the state-of-the-art joint distribution cardinality estimator.   Numerical experiments using well-established benchmarks show that on all real-world datasets tested, ADC+ is capable of rivaling Naru and outperforming MSCN, DeepDB, LW-Tree, and LW-NN using around 66 percent their storage space, being at least 3 times as accurate as MSCN on 95th and 99th percentile error. Furthermore, on a synthetic dataset where attributes exhibit complex, multilateral correlations, ADC and ADC+ are considerably robust while almost every other learned model suffered significant accuracy declines. In this case, ADC+ performs better than any other tested model, being 10 times as accurate as Naru on 95th and 99th percentile error.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.20681) | **Categories:** cs.DB

---
