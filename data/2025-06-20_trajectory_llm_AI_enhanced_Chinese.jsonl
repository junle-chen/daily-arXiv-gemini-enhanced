{"id": "2506.14831", "pdf": "https://arxiv.org/pdf/2506.14831", "abs": "https://arxiv.org/abs/2506.14831", "authors": ["C\u00e9line Finet", "Stephane Da Silva Martins", "Jean-Bernard Hayet", "Ioannis Karamouzas", "Javad Amirian", "Sylvie Le H\u00e9garat-Mascle", "Julien Pettr\u00e9", "Emanuel Aldea"], "title": "Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "30 pages", "summary": "With the emergence of powerful data-driven methods in human trajectory\nprediction (HTP), gaining a finer understanding of multi-agent interactions\nlies within hand's reach, with important implications in areas such as\nautonomous navigation and crowd modeling. This survey reviews some of the most\nrecent advancements in deep learning-based multi-agent trajectory prediction,\nfocusing on studies published between 2020 and 2024. We categorize the existing\nmethods based on their architectural design, their input representations, and\ntheir overall prediction strategies, placing a particular emphasis on models\nevaluated using the ETH/UCY benchmark. Furthermore, we highlight key challenges\nand future research directions in the field of multi-agent HTP.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "The paper is highly relevant to trajectory prediction, specifically multi-agent human trajectory prediction. While it doesn't directly involve large language models, its focus on trajectory prediction makes it substantially relevant to the task.", "keywords": ["trajectory prediction", "multi-agent", "human trajectory prediction", "autonomous navigation", "crowd modeling"]}, "AI": {"tldr": "\u672c\u7814\u7a76\u7efc\u8ff0\u4e86 2020-2024 \u5e74\u95f4\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u8fdb\u5c55\uff0c\u5e76\u7a81\u51fa\u4e86\u8be5\u9886\u57df\u7684\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b (HTP) \u4e2d\u5174\u8d77\uff0c\u66f4\u597d\u5730\u7406\u89e3\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u6210\u4e3a\u53ef\u80fd\uff0c\u8fd9\u5bf9\u81ea\u4e3b\u5bfc\u822a\u548c\u4eba\u7fa4\u5efa\u6a21\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u6839\u636e\u67b6\u6784\u8bbe\u8ba1\u3001\u8f93\u5165\u8868\u793a\u548c\u9884\u6d4b\u7b56\u7565\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\uff0c\u7279\u522b\u5173\u6ce8\u4f7f\u7528 ETH/UCY \u57fa\u51c6\u8bc4\u4f30\u7684\u6a21\u578b\u3002", "result": "\u56de\u987e\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u5173\u6ce8 2020 \u5e74\u81f3 2024 \u5e74\u95f4\u53d1\u8868\u7684\u7814\u7a76\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u591a\u667a\u80fd\u4f53 HTP \u9886\u57df\u7684\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "summary_zh": "\u968f\u7740\u5f3a\u5927\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\uff08HTP\uff09\u4e2d\u6d8c\u73b0\uff0c\u66f4\u6df1\u5165\u5730\u7406\u89e3\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u89e6\u624b\u53ef\u53ca\uff0c\u8fd9\u5bf9\u81ea\u4e3b\u5bfc\u822a\u548c\u4eba\u7fa4\u5efa\u6a21\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u672c\u7efc\u8ff0\u56de\u987e\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u7684\u4e00\u4e9b\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u5173\u6ce8 2020 \u5e74\u81f3 2024 \u5e74\u95f4\u53d1\u8868\u7684\u7814\u7a76\u3002\u6211\u4eec\u6839\u636e\u73b0\u6709\u65b9\u6cd5\u7684\u67b6\u6784\u8bbe\u8ba1\u3001\u8f93\u5165\u8868\u793a\u548c\u6574\u4f53\u9884\u6d4b\u7b56\u7565\u5bf9\u5176\u8fdb\u884c\u5206\u7c7b\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u4f7f\u7528 ETH/UCY \u57fa\u51c6\u8bc4\u4f30\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5f3a\u8c03\u4e86\u591a\u667a\u80fd\u4f53 HTP \u9886\u57df\u7684\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.15157", "pdf": "https://arxiv.org/pdf/2506.15157", "abs": "https://arxiv.org/abs/2506.15157", "authors": ["Hanbit Oh", "Andrea M. Salcedo-V\u00e1zquez", "Ixchel G. Ramirez-Alpizar", "Yukiyasu Domae"], "title": "Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS) 2025 accepted", "summary": "Imitation learning (IL) aims to enable robots to perform tasks autonomously\nby observing a few human demonstrations. Recently, a variant of IL, called\nIn-Context IL, utilized off-the-shelf large language models (LLMs) as instant\npolicies that understand the context from a few given demonstrations to perform\na new task, rather than explicitly updating network models with large-scale\ndemonstrations. However, its reliability in the robotics domain is undermined\nby hallucination issues such as LLM-based instant policy, which occasionally\ngenerates poor trajectories that deviate from the given demonstrations. To\nalleviate this problem, we propose a new robust in-context imitation learning\nalgorithm called the robust instant policy (RIP), which utilizes a Student's\nt-regression model to be robust against the hallucinated trajectories of\ninstant policies to allow reliable trajectory generation. Specifically, RIP\ngenerates several candidate robot trajectories to complete a given task from an\nLLM and aggregates them using the Student's t-distribution, which is beneficial\nfor ignoring outliers (i.e., hallucinations); thereby, a robust trajectory\nagainst hallucinations is generated. Our experiments, conducted in both\nsimulated and real-world environments, show that RIP significantly outperforms\nstate-of-the-art IL methods, with at least $26\\%$ improvement in task success\nrates, particularly in low-data scenarios for everyday tasks. Video results\navailable at https://sites.google.com/view/robustinstantpolicy.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "\u8be5\u8bba\u6587\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u8f68\u8ff9\u751f\u6210\uff0c\u5229\u7528LLMs\u751f\u6210\u5019\u9009\u8f68\u8ff9\uff0c\u5e76\u4f7f\u7528Student's t-\u5206\u5e03\u6765\u5904\u7406\u8f68\u8ff9\u4e2d\u7684\u5f02\u5e38\u503c\uff0c\u4ee5\u5b9e\u73b0\u9c81\u68d2\u7684\u8f68\u8ff9\u751f\u6210\u3002\u867d\u7136\u4e3b\u8981\u5173\u6ce8\u673a\u5668\u4eba\u64cd\u4f5c\uff0c\u4f46\u5176\u6838\u5fc3\u662f\u5229\u7528LLM\u8fdb\u884c\u8f68\u8ff9\u751f\u6210\u548c\u4f18\u5316\uff0c\u56e0\u6b64\u4e0e\u8f68\u8ff9\u9884\u6d4b\u548c\u5927\u6a21\u578b\u5177\u6709\u8f83\u9ad8\u7684\u76f8\u5173\u6027\u3002", "keywords": ["Large Language Models", "LLMs", "trajectory generation", "robot manipulation", "imitation learning"]}, "AI": {"tldr": "\u63d0\u51faRIP\u7b97\u6cd5\uff0c\u5229\u7528Student's t-\u56de\u5f52\u6a21\u578b\uff0c\u589e\u5f3a\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u62b5\u6297LLM\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u77ac\u65f6\u7b56\u7565\u7684\u5e7b\u89c9\u95ee\u9898\u4f1a\u964d\u4f4e\u5176\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u53ef\u9760\u6027\uff0c\u4f8b\u5982LLM\u6709\u65f6\u4f1a\u751f\u6210\u504f\u79bb\u7ed9\u5b9a\u6f14\u793a\u7684\u5dee\u8f68\u8ff9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u7684\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\uff0c\u79f0\u4e3a\u9c81\u68d2\u77ac\u65f6\u7b56\u7565\uff08RIP\uff09\uff0c\u5b83\u5229\u7528Student's t-\u56de\u5f52\u6a21\u578b\u6765\u62b5\u6297\u77ac\u65f6\u7b56\u7565\u7684\u5e7b\u89c9\u8f68\u8ff9\uff0c\u4ee5\u5b9e\u73b0\u53ef\u9760\u7684\u8f68\u8ff9\u751f\u6210\u3002", "result": "RIP\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u7684\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRIP\u660e\u663e\u4f18\u4e8e\u6700\u5148\u8fdb\u7684IL\u65b9\u6cd5\uff0c\u4efb\u52a1\u6210\u529f\u7387\u81f3\u5c11\u63d0\u9ad8\u4e8626\uff05\uff0c\u5c24\u5176\u662f\u5728\u65e5\u5e38\u4efb\u52a1\u7684\u4f4e\u6570\u636e\u573a\u666f\u4e2d\u3002", "conclusion": "RIP\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u7684\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684IL\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u65e5\u5e38\u4efb\u52a1\u7684\u4f4e\u6570\u636e\u573a\u666f\u4e2d\uff0c\u4efb\u52a1\u6210\u529f\u7387\u81f3\u5c11\u63d0\u9ad8\u4e8626%\u3002", "summary_zh": "\u6a21\u4eff\u5b66\u4e60\uff08IL\uff09\u65e8\u5728\u901a\u8fc7\u89c2\u5bdf\u4e00\u4e9b\u4eba\u7c7b\u6f14\u793a\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u81ea\u4e3b\u6267\u884c\u4efb\u52a1\u3002\u6700\u8fd1\uff0cIL\u7684\u4e00\u79cd\u53d8\u4f53\uff0c\u79f0\u4e3a\u4e0a\u4e0b\u6587IL\uff0c\u5229\u7528\u73b0\u6210\u7684\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u5373\u65f6\u7b56\u7565\uff0c\u7406\u89e3\u6765\u81ea\u4e00\u4e9b\u7ed9\u5b9a\u6f14\u793a\u7684\u4e0a\u4e0b\u6587\u4ee5\u6267\u884c\u65b0\u4efb\u52a1\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u5927\u89c4\u6a21\u6f14\u793a\u6765\u663e\u5f0f\u66f4\u65b0\u7f51\u7edc\u6a21\u578b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u57fa\u4e8eLLM\u7684\u5373\u65f6\u7b56\u7565\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u4f8b\u5982LLM\u6709\u65f6\u4f1a\u751f\u6210\u504f\u79bb\u7ed9\u5b9a\u6f14\u793a\u7684\u5dee\u8f68\u8ff9\uff0c\u56e0\u6b64\u5176\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u53ef\u9760\u6027\u53d7\u5230\u635f\u5bb3\u3002\u4e3a\u4e86\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u7684\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\uff0c\u79f0\u4e3a\u9c81\u68d2\u77ac\u65f6\u7b56\u7565\uff08RIP\uff09\uff0c\u5b83\u5229\u7528Student's t-\u56de\u5f52\u6a21\u578b\u6765\u62b5\u6297\u77ac\u65f6\u7b56\u7565\u7684\u5e7b\u89c9\u8f68\u8ff9\uff0c\u4ee5\u5b9e\u73b0\u53ef\u9760\u7684\u8f68\u8ff9\u751f\u6210\u3002\u5177\u4f53\u6765\u8bf4\uff0cRIP\u751f\u6210\u591a\u4e2a\u5019\u9009\u673a\u5668\u4eba\u8f68\u8ff9\uff0c\u4ee5\u4eceLLM\u5b8c\u6210\u7ed9\u5b9a\u7684\u4efb\u52a1\uff0c\u5e76\u4f7f\u7528Student's t-\u5206\u5e03\u5bf9\u5176\u8fdb\u884c\u805a\u5408\uff0c\u8fd9\u6709\u5229\u4e8e\u5ffd\u7565\u5f02\u5e38\u503c\uff08\u5373\u5e7b\u89c9\uff09\uff1b\u56e0\u6b64\uff0c\u751f\u6210\u4e86\u9488\u5bf9\u5e7b\u89c9\u7684\u9c81\u68d2\u8f68\u8ff9\u3002\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRIP\u660e\u663e\u4f18\u4e8e\u6700\u5148\u8fdb\u7684IL\u65b9\u6cd5\uff0c\u4efb\u52a1\u6210\u529f\u7387\u81f3\u5c11\u63d0\u9ad8\u4e8626\uff05\uff0c\u5c24\u5176\u662f\u5728\u65e5\u5e38\u4efb\u52a1\u7684\u4f4e\u6570\u636e\u573a\u666f\u4e2d\u3002\u89c6\u9891\u7ed3\u679c\u53ef\u5728https://sites.google.com/view/robustinstantpolicy\u4e0a\u627e\u5230\u3002"}}
{"id": "2506.15043", "pdf": "https://arxiv.org/pdf/2506.15043", "abs": "https://arxiv.org/abs/2506.15043", "authors": ["Amir Hossein Baradaran"], "title": "Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Advancements in the defense industry are paramount for ensuring the safety\nand security of nations, providing robust protection against emerging threats.\nAmong these threats, hypersonic missiles pose a significant challenge due to\ntheir extreme speeds and maneuverability, making accurate trajectory prediction\na critical necessity for effective countermeasures. This paper addresses this\nchallenge by employing a novel hybrid deep learning approach, integrating\nConvolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks,\nand Gated Recurrent Units (GRUs). By leveraging the strengths of these\narchitectures, the proposed method successfully predicts the complex\ntrajectories of hypersonic missiles with high accuracy, offering a significant\ncontribution to defense strategies and missile interception technologies. This\nresearch demonstrates the potential of advanced machine learning techniques in\nenhancing the predictive capabilities of defense systems.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f7f\u7528\u4e86CNN\u3001LSTM\u548cGRU\u7b49\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5176\u6838\u5fc3\u5728\u4e8e\u8f68\u8ff9\u9884\u6d4b\uff0c\u5e76\u4f7f\u7528\u4e86\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["trajectory prediction", "CNN", "LSTM", "GRU", "hypersonic missile"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u590d\u6742\u8f68\u8ff9\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u4ee5\u5176\u6781\u9ad8\u7684\u901f\u5ea6\u548c\u673a\u52a8\u6027\u6784\u6210\u4e86\u4e25\u5cfb\u7684\u6311\u6218\uff0c\u56e0\u6b64\u51c6\u786e\u7684\u8f68\u8ff9\u9884\u6d4b\u5bf9\u4e8e\u6709\u6548\u7684\u5bf9\u6297\u63aa\u65bd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u96c6\u6210\u4e86\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3001\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u4e86\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u590d\u6742\u8f68\u8ff9\u3002", "conclusion": "\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u589e\u5f3a\u4e86\u9632\u5fa1\u7cfb\u7edf\u7684\u9884\u6d4b\u80fd\u529b\u3002", "summary_zh": "\u56fd\u9632\u5de5\u4e1a\u7684\u8fdb\u6b65\u5bf9\u4e8e\u786e\u4fdd\u56fd\u5bb6\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u4e3a\u5e94\u5bf9\u65b0\u5174\u5a01\u80c1\u63d0\u4f9b\u5f3a\u5927\u7684\u4fdd\u62a4\u3002\u5176\u4e2d\uff0c\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u4ee5\u5176\u6781\u9ad8\u7684\u901f\u5ea6\u548c\u673a\u52a8\u6027\u6784\u6210\u4e86\u4e25\u5cfb\u7684\u6311\u6218\uff0c\u56e0\u6b64\u51c6\u786e\u7684\u8f68\u8ff9\u9884\u6d4b\u5bf9\u4e8e\u6709\u6548\u7684\u5bf9\u6297\u63aa\u65bd\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u91c7\u7528\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u96c6\u6210\u4e86\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3001\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\uff0c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002\u901a\u8fc7\u5229\u7528\u8fd9\u4e9b\u67b6\u6784\u7684\u4f18\u52bf\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u4e86\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u590d\u6742\u8f68\u8ff9\uff0c\u4e3a\u9632\u5fa1\u7b56\u7565\u548c\u5bfc\u5f39\u62e6\u622a\u6280\u672f\u505a\u51fa\u4e86\u91cd\u5927\u8d21\u732e\u3002\u8fd9\u9879\u7814\u7a76\u8bc1\u660e\u4e86\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u589e\u5f3a\u9632\u5fa1\u7cfb\u7edf\u9884\u6d4b\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.15167", "pdf": "https://arxiv.org/pdf/2506.15167", "abs": "https://arxiv.org/abs/2506.15167", "authors": ["Wanzhe Wang", "Jianqiu Peng", "Menghao Hu", "Weihuang Zhong", "Tong Zhang", "Shuai Wang", "Yixin Zhang", "Mingjie Shao", "Wanli Ni"], "title": "LLM Agent for Hyper-Parameter Optimization", "categories": ["cs.IT", "cs.AI", "math.IT"], "comment": "6 pages, 6 figures", "summary": "Hyper-parameters are essential and critical for the performance of\ncommunication algorithms. However, current hyper-parameters tuning methods for\nwarm-start particles swarm optimization with cross and mutation (WS-PSO-CM)\nalgortihm for radio map-enabled unmanned aerial vehicle (UAV) trajectory and\ncommunication are primarily heuristic-based, exhibiting low levels of\nautomation and unsatisfactory performance. In this paper, we design an large\nlanguage model (LLM) agent for automatic hyper-parameters-tuning, where an\niterative framework and model context protocol (MCP) are applied. In\nparticular, the LLM agent is first setup via a profile, which specifies the\nmission, background, and output format. Then, the LLM agent is driven by the\nprompt requirement, and iteratively invokes WS-PSO-CM algorithm for\nexploration. Finally, the LLM agent autonomously terminates the loop and\nreturns a set of hyper-parameters. Our experiment results show that the minimal\nsum-rate achieved by hyper-parameters generated via our LLM agent is\nsignificantly higher than those by both human heuristics and random generation\nmethods. This indicates that an LLM agent with PSO knowledge and WS-PSO-CM\nalgorithm background is useful in finding high-performance hyper-parameters.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "The paper focuses on using LLMs for hyperparameter optimization of an algorithm used in UAV trajectory planning. While the main focus is on hyperparameter optimization using LLMs, the application domain includes UAV trajectory planning, connecting it to trajectory prediction. The connection is not direct trajectory prediction using LLMs, but rather using LLMs to optimize trajectory-related algorithms.", "keywords": ["Large Language Model (LLM)", "UAV trajectory", "trajectory", "hyper-parameter optimization"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\uff0c\u7528\u4e8e\u81ea\u52a8\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u4e86\u901a\u4fe1\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u8d85\u53c2\u6570\u8c03\u6574\u65b9\u6cd5\u81ea\u52a8\u5316\u7a0b\u5ea6\u4f4e\uff0c\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\uff0c\u7528\u4e8e\u81ea\u52a8\u8d85\u53c2\u6570\u8c03\u6574\uff0c\u5e94\u7528\u4e86\u8fed\u4ee3\u6846\u67b6\u548c\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7LLM agent\u751f\u6210\u7684\u8d85\u53c2\u6570\u5b9e\u73b0\u7684\u6700\u5c0f\u603b\u901f\u7387\u660e\u663e\u9ad8\u4e8e\u4eba\u5de5\u542f\u53d1\u5f0f\u548c\u968f\u673a\u751f\u6210\u65b9\u6cd5\u3002", "conclusion": "LLM agent \u53ef\u4ee5\u6709\u6548\u5730\u627e\u5230\u9ad8\u6027\u80fd\u7684\u8d85\u53c2\u6570\u3002", "summary_zh": "\u8d85\u53c2\u6570\u5bf9\u4e8e\u901a\u4fe1\u7b97\u6cd5\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u7528\u4e8e\u65e0\u7ebf\u7535\u5730\u56fe\u65e0\u4eba\u673a\uff08UAV\uff09\u8f68\u8ff9\u548c\u901a\u4fe1\u7684\u5e26\u6709\u4ea4\u53c9\u548c\u53d8\u5f02\u7684\u6e29\u542f\u52a8\u7c92\u5b50\u7fa4\u4f18\u5316\uff08WS-PSO-CM\uff09\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\u8c03\u6574\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u542f\u53d1\u5f0f\uff0c\u81ea\u52a8\u5316\u7a0b\u5ea6\u4f4e\uff0c\u6027\u80fd\u4e0d\u4f73\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\uff0c\u7528\u4e8e\u81ea\u52a8\u8d85\u53c2\u6570\u8c03\u6574\uff0c\u5176\u4e2d\u5e94\u7528\u4e86\u8fed\u4ee3\u6846\u67b6\u548c\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u3002\u7279\u522b\u5730\uff0c\u9996\u5148\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u8bbe\u7f6eLLM\u667a\u80fd\u4f53\uff0c\u8be5\u6587\u4ef6\u6307\u5b9a\u4efb\u52a1\u3001\u80cc\u666f\u548c\u8f93\u51fa\u683c\u5f0f\u3002\u7136\u540e\uff0cLLM\u667a\u80fd\u4f53\u7531\u63d0\u793a\u9700\u6c42\u9a71\u52a8\uff0c\u5e76\u8fed\u4ee3\u5730\u8c03\u7528WS-PSO-CM\u7b97\u6cd5\u8fdb\u884c\u63a2\u7d22\u3002\u6700\u540e\uff0cLLM\u667a\u80fd\u4f53\u81ea\u4e3b\u7ec8\u6b62\u5faa\u73af\u5e76\u8fd4\u56de\u4e00\u7ec4\u8d85\u53c2\u6570\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f53\u751f\u6210\u7684\u8d85\u53c2\u6570\u5b9e\u73b0\u7684\u6700\u5c0f\u603b\u901f\u7387\u660e\u663e\u9ad8\u4e8e\u4eba\u5de5\u542f\u53d1\u5f0f\u548c\u968f\u673a\u751f\u6210\u65b9\u6cd5\u3002\u8fd9\u8868\u660e\u5177\u6709PSO\u77e5\u8bc6\u548cWS-PSO-CM\u7b97\u6cd5\u80cc\u666f\u7684LLM\u667a\u80fd\u4f53\u5728\u5bfb\u627e\u9ad8\u6027\u80fd\u8d85\u53c2\u6570\u65b9\u9762\u975e\u5e38\u6709\u7528\u3002"}}
{"id": "2506.14855", "pdf": "https://arxiv.org/pdf/2506.14855", "abs": "https://arxiv.org/abs/2506.14855", "authors": ["Tommaso Belvedere", "Michael Ziegltrum", "Giulio Turrisi", "Valerio Modugno"], "title": "Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Model Predictive Path Integral control is a powerful sampling-based approach\nsuitable for complex robotic tasks due to its flexibility in handling nonlinear\ndynamics and non-convex costs. However, its applicability in real-time,\nhighfrequency robotic control scenarios is limited by computational demands.\nThis paper introduces Feedback-MPPI (F-MPPI), a novel framework that augments\nstandard MPPI by computing local linear feedback gains derived from sensitivity\nanalysis inspired by Riccati-based feedback used in gradient-based MPC. These\ngains allow for rapid closed-loop corrections around the current state without\nrequiring full re-optimization at each timestep. We demonstrate the\neffectiveness of F-MPPI through simulations and real-world experiments on two\nrobotic platforms: a quadrupedal robot performing dynamic locomotion on uneven\nterrain and a quadrotor executing aggressive maneuvers with onboard\ncomputation. Results illustrate that incorporating local feedback significantly\nimproves control performance and stability, enabling robust, high-frequency\noperation suitable for complex robotic systems.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8fd9\u7bc7\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u4e8e\u4f7f\u7528Model Predictive Path Integral (MPPI) \u63a7\u5236\u65b9\u6cd5\u8fdb\u884c\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u548c\u63a7\u5236\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u73af\u5883\u4e0b\u7684\u5e94\u7528\u3002\u867d\u7136\u6d89\u53ca\u8def\u5f84\u89c4\u5212\uff0c\u5373\u8f68\u8ff9\u9884\u6d4b\u7684\u4e00\u4e2a\u65b9\u9762\uff0c\u4f46\u6ca1\u6709\u76f4\u63a5\u63d0\u5230\u884c\u4eba\u6216\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\uff0c\u4e5f\u6ca1\u6709\u6d89\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u76f8\u5173\u6027\u4e3b\u8981\u4f53\u73b0\u5728\u5176\u8def\u5f84\u89c4\u5212\u548c\u63a7\u5236\u65b9\u9762\u3002", "keywords": ["trajectory prediction", "path planning", "MPC", "Model Predictive Control", "robotic control"]}, "AI": {"tldr": "F-MPPI\u901a\u8fc7\u589e\u52a0\u5c40\u90e8\u7ebf\u6027\u53cd\u9988\u589e\u76ca\u6765\u589e\u5f3a\u6807\u51c6MPPI\uff0c\u4ece\u800c\u5b9e\u73b0\u9c81\u68d2\u3001\u9ad8\u9891\u7387\u7684\u673a\u5668\u4eba\u63a7\u5236\u3002", "motivation": "\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\uff0c\u7531\u4e8e\u5176\u5728\u5904\u7406\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u548c\u975e\u51f8\u6210\u672c\u65b9\u9762\u7684\u7075\u6d3b\u6027\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u673a\u5668\u4eba\u4efb\u52a1\u3002\u7136\u800c\uff0c\u5b83\u5728\u5b9e\u65f6\u3001\u9ad8\u9891\u673a\u5668\u4eba\u63a7\u5236\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u53d7\u5230\u8ba1\u7b97\u9700\u6c42\u7684\u9650\u5236\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u4ece\u7075\u654f\u5ea6\u5206\u6790\u4e2d\u5bfc\u51fa\u7684\u5c40\u90e8\u7ebf\u6027\u53cd\u9988\u589e\u76ca\u6765\u589e\u5f3a\u6807\u51c6MPPI\uff0c\u7075\u611f\u6765\u81ea\u57fa\u4e8eRiccati\u7684\u53cd\u9988\uff0c\u7528\u4e8e\u57fa\u4e8e\u68af\u5ea6\u7684MPC\u3002", "result": "\u5728\u56db\u8db3\u673a\u5668\u4eba\u6267\u884c\u4e0d\u5e73\u5766\u5730\u5f62\u4e0a\u7684\u52a8\u6001\u8fd0\u52a8\u548c\u56db\u65cb\u7ffc\u98de\u884c\u5668\u6267\u884c\u5177\u6709\u677f\u8f7d\u8ba1\u7b97\u7684\u6fc0\u8fdb\u673a\u52a8\u7684\u4e24\u4e2a\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u7684\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8bc1\u660e\u4e86F-MPPI\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u5408\u5c40\u90e8\u53cd\u9988\u663e\u8457\u63d0\u9ad8\u4e86\u63a7\u5236\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e86\u9002\u7528\u4e8e\u590d\u6742\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u9ad8\u9891\u7387\u9c81\u68d2\u64cd\u4f5c\u3002", "summary_zh": "\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\uff08MPPI\uff09\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u673a\u5668\u4eba\u4efb\u52a1\uff0c\u56e0\u4e3a\u5b83\u5728\u5904\u7406\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u548c\u975e\u51f8\u6210\u672c\u65b9\u9762\u5177\u6709\u7075\u6d3b\u6027\u3002\u7136\u800c\uff0c\u5176\u5728\u5b9e\u65f6\u3001\u9ad8\u9891\u673a\u5668\u4eba\u63a7\u5236\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u53d7\u5230\u8ba1\u7b97\u9700\u6c42\u7684\u9650\u5236\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6Feedback-MPPI\uff08F-MPPI\uff09\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u8ba1\u7b97\u4ece\u7075\u654f\u5ea6\u5206\u6790\u4e2d\u5bfc\u51fa\u7684\u5c40\u90e8\u7ebf\u6027\u53cd\u9988\u589e\u76ca\u6765\u589e\u5f3a\u6807\u51c6MPPI\uff0c\u7075\u611f\u6765\u81ea\u57fa\u4e8eRiccati\u7684\u53cd\u9988\uff0c\u7528\u4e8e\u57fa\u4e8e\u68af\u5ea6\u7684MPC\u3002\u8fd9\u4e9b\u589e\u76ca\u5141\u8bb8\u5728\u5f53\u524d\u72b6\u6001\u4e0b\u8fdb\u884c\u5feb\u901f\u95ed\u73af\u6821\u6b63\uff0c\u800c\u65e0\u9700\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u8fdb\u884c\u5b8c\u5168\u91cd\u65b0\u4f18\u5316\u3002\u6211\u4eec\u901a\u8fc7\u5728\u4e24\u4e2a\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u7684\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8bc1\u660e\u4e86F-MPPI\u7684\u6709\u6548\u6027\uff1a\u4e00\u4e2a\u56db\u8db3\u673a\u5668\u4eba\u6267\u884c\u4e0d\u5e73\u5766\u5730\u5f62\u4e0a\u7684\u52a8\u6001\u8fd0\u52a8\uff0c\u4e00\u4e2a\u56db\u65cb\u7ffc\u98de\u884c\u5668\u6267\u884c\u5177\u6709\u677f\u8f7d\u8ba1\u7b97\u7684\u6fc0\u8fdb\u673a\u52a8\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u5c40\u90e8\u53cd\u9988\u663e\u8457\u63d0\u9ad8\u4e86\u63a7\u5236\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e86\u9002\u7528\u4e8e\u590d\u6742\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u9ad8\u9891\u7387\u9c81\u68d2\u64cd\u4f5c\u3002"}}
{"id": "2506.14857", "pdf": "https://arxiv.org/pdf/2506.14857", "abs": "https://arxiv.org/abs/2506.14857", "authors": ["Suman Raj", "Swapnil Padhi", "Ruchi Bhoot", "Prince Modi", "Yogesh Simmhan"], "title": "Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired", "categories": ["cs.RO", "cs.CV"], "comment": "16 pages, 7 figures; Accepted as Late-Breaking Results at the\n  IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n  2023", "summary": "Autonomous navigation by drones using onboard sensors combined with machine\nlearning and computer vision algorithms is impacting a number of domains,\nincluding agriculture, logistics, and disaster management. In this paper, we\nexamine the use of drones for assisting visually impaired people (VIPs) in\nnavigating through outdoor urban environments. Specifically, we present a\nperception-based path planning system for local planning around the\nneighborhood of the VIP, integrated with a global planner based on GPS and maps\nfor coarse planning. We represent the problem using a geometric formulation and\npropose a multi DNN based framework for obstacle avoidance of the UAV as well\nas the VIP. Our evaluations conducted on a drone human system in a university\ncampus environment verifies the feasibility of our algorithms in three\nscenarios; when the VIP walks on a footpath, near parked vehicles, and in a\ncrowded street.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper discusses perception-based path planning for UAVs to assist visually impaired people, which involves collision avoidance and navigation. While it doesn't explicitly mention large language models, the use of DNNs for obstacle avoidance and path planning connects to the broader area of machine learning in trajectory prediction. The focus is more on perception and path planning than LLMs.", "keywords": ["path planning", "collision avoidance", "obstacle avoidance", "DNN"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u7684\u89c6\u89c9\u8f85\u52a9\u5bfc\u822a\u7cfb\u7edf\uff0c\u65e8\u5728\u5e2e\u52a9\u89c6\u969c\u4eba\u58eb\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u5b89\u5168\u5bfc\u822a\u3002", "motivation": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u65e0\u4eba\u673a\u5e2e\u52a9\u89c6\u969c\u4eba\u58eb\uff08VIP\uff09\u5728\u6237\u5916\u57ce\u5e02\u73af\u5883\u4e2d\u5bfc\u822a\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u51e0\u4f55\u516c\u5f0f\u8868\u793a\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591aDNN\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u548cVIP\u7684\u907f\u969c\u3002", "result": "\u5728\u5927\u5b66\u6821\u56ed\u73af\u5883\u4e2d\u7684\u65e0\u4eba\u673a-\u4eba\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u4e09\u79cd\u573a\u666f\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u5728\u5927\u5b66\u6821\u56ed\u73af\u5883\u4e2d\u7684\u65e0\u4eba\u673a-\u4eba\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u4e09\u79cd\u573a\u666f\u4e2d\u7684\u53ef\u884c\u6027\uff1a\u5f53VIP\u5728\u4eba\u884c\u9053\u4e0a\u884c\u8d70\u3001\u9760\u8fd1\u505c\u653e\u7684\u8f66\u8f86\u4ee5\u53ca\u5728\u62e5\u6324\u7684\u8857\u9053\u4e0a\u3002", "summary_zh": "\u65e0\u4eba\u673a\u7ed3\u5408\u673a\u8f7d\u4f20\u611f\u5668\u3001\u673a\u5668\u5b66\u4e60\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u7b97\u6cd5\u7684\u81ea\u4e3b\u5bfc\u822a\u6b63\u5728\u5f71\u54cd\u519c\u4e1a\u3001\u7269\u6d41\u548c\u707e\u5bb3\u7ba1\u7406\u7b49\u591a\u4e2a\u9886\u57df\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4f7f\u7528\u65e0\u4eba\u673a\u5e2e\u52a9\u89c6\u969c\u4eba\u58eb\uff08VIP\uff09\u5728\u6237\u5916\u57ce\u5e02\u73af\u5883\u4e2d\u5bfc\u822a\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u611f\u77e5\u7684\u8def\u5f84\u89c4\u5212\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728VIP\u9644\u8fd1\u8fdb\u884c\u5c40\u90e8\u89c4\u5212\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8eGPS\u548c\u5730\u56fe\u7684\u5168\u5c40\u89c4\u5212\u5668\u8fdb\u884c\u7c97\u7565\u89c4\u5212\u3002\u6211\u4eec\u4f7f\u7528\u51e0\u4f55\u516c\u5f0f\u8868\u793a\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591aDNN\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u548cVIP\u7684\u907f\u969c\u3002\u5728\u5927\u5b66\u6821\u56ed\u73af\u5883\u4e2d\u7684\u65e0\u4eba\u673a-\u4eba\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u4e09\u79cd\u573a\u666f\u4e2d\u7684\u53ef\u884c\u6027\uff1a\u5f53VIP\u5728\u4eba\u884c\u9053\u4e0a\u884c\u8d70\u3001\u9760\u8fd1\u505c\u653e\u7684\u8f66\u8f86\u4ee5\u53ca\u5728\u62e5\u6324\u7684\u8857\u9053\u4e0a\u3002"}}
{"id": "2506.15096", "pdf": "https://arxiv.org/pdf/2506.15096", "abs": "https://arxiv.org/abs/2506.15096", "authors": ["Zihe Ji", "Huangxuan Lin", "Yue Gao"], "title": "DyNaVLM: Zero-Shot Vision-Language Navigation System with Dynamic Viewpoints and Self-Refining Graph Memory", "categories": ["cs.RO"], "comment": null, "summary": "We present DyNaVLM, an end-to-end vision-language navigation framework using\nVision-Language Models (VLM). In contrast to prior methods constrained by fixed\nangular or distance intervals, our system empowers agents to freely select\nnavigation targets via visual-language reasoning. At its core lies a\nself-refining graph memory that 1) stores object locations as executable\ntopological relations, 2) enables cross-robot memory sharing through\ndistributed graph updates, and 3) enhances VLM's decision-making via retrieval\naugmentation. Operating without task-specific training or fine-tuning, DyNaVLM\ndemonstrates high performance on GOAT and ObjectNav benchmarks. Real-world\ntests further validate its robustness and generalization. The system's three\ninnovations: dynamic action space formulation, collaborative graph memory, and\ntraining-free deployment, establish a new paradigm for scalable embodied robot,\nbridging the gap between discrete VLN tasks and continuous real-world\nnavigation.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9-\u8bed\u8a00\u5bfc\u822a\uff08VLN\uff09\uff0c\u5229\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u8fdb\u884c\u673a\u5668\u4eba\u5bfc\u822a\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u5bfc\u822a\u4efb\u52a1\u9690\u542b\u4e86\u5bf9\u672a\u6765\u8def\u5f84\u7684\u89c4\u5212\u548c\u9884\u6d4b\u3002\u540c\u65f6\uff0c\u8bba\u6587\u660e\u786e\u4f7f\u7528\u4e86\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u8868\u660e\u4e0e\u5927\u6a21\u578b\u76f8\u5173\u3002\u56e0\u6b64\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["Vision-Language Models", "navigation", "robot navigation"]}, "AI": {"tldr": "DyNaVLM \u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u7aef\u5230\u7aef\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u5b83\u4f7f\u7528\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u548c\u534f\u4f5c\u56fe\u8bb0\u5fc6\u6765\u5b9e\u73b0\u9ad8\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u56fa\u5b9a\u7684\u89d2\u5ea6\u6216\u8ddd\u79bb\u95f4\u9694\uff0c\u8be5\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u8be5\u6587\u63d0\u51fa\u4e86 DyNaVLM\uff0c\u4e00\u4e2a\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u7684\u7aef\u5230\u7aef\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u5b83\u5141\u8bb8\u667a\u80fd\u4f53\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u81ea\u7531\u9009\u62e9\u5bfc\u822a\u76ee\u6807\u3002", "result": "DyNaVLM \u5728 GOAT \u548c ObjectNav \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u6027\u80fd\u3002\u771f\u5b9e\u4e16\u754c\u7684\u6d4b\u8bd5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u3001\u534f\u4f5c\u56fe\u8bb0\u5fc6\u548c\u65e0\u8bad\u7ec3\u90e8\u7f72\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u5177\u8eab\u673a\u5668\u4eba\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u8303\u4f8b\uff0c\u5f25\u5408\u4e86\u79bb\u6563 VLN \u4efb\u52a1\u548c\u8fde\u7eed\u73b0\u5b9e\u4e16\u754c\u5bfc\u822a\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "summary_zh": "\u6211\u4eec\u63d0\u51fa\u4e86 DyNaVLM\uff0c\u4e00\u4e2a\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u7684\u7aef\u5230\u7aef\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\u3002\u4e0e\u4e4b\u524d\u53d7\u9650\u4e8e\u56fa\u5b9a\u89d2\u5ea6\u6216\u8ddd\u79bb\u95f4\u9694\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u81ea\u7531\u9009\u62e9\u5bfc\u822a\u76ee\u6807\u3002\u5176\u6838\u5fc3\u5728\u4e8e\u4e00\u4e2a\u81ea\u5b8c\u5584\u7684\u56fe\u8bb0\u5fc6\uff0c\u5b83 1) \u5c06\u5bf9\u8c61\u4f4d\u7f6e\u5b58\u50a8\u4e3a\u53ef\u6267\u884c\u7684\u62d3\u6251\u5173\u7cfb\uff0c2) \u901a\u8fc7\u5206\u5e03\u5f0f\u56fe\u66f4\u65b0\u5b9e\u73b0\u8de8\u673a\u5668\u4eba\u8bb0\u5fc6\u5171\u4eab\uff0c3) \u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u6765\u589e\u5f3a VLM \u7684\u51b3\u7b56\u80fd\u529b\u3002DyNaVLM \u65e0\u9700\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u8bad\u7ec3\u6216\u5fae\u8c03\u5373\u53ef\u8fd0\u884c\uff0c\u5728 GOAT \u548c ObjectNav \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u6027\u80fd\u3002\u771f\u5b9e\u4e16\u754c\u7684\u6d4b\u8bd5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002\u8be5\u7cfb\u7edf\u7684\u4e09\u9879\u521b\u65b0\uff1a\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u516c\u5f0f\u3001\u534f\u4f5c\u56fe\u8bb0\u5fc6\u548c\u65e0\u8bad\u7ec3\u90e8\u7f72\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u5177\u8eab\u673a\u5668\u4eba\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u8303\u4f8b\uff0c\u5f25\u5408\u4e86\u79bb\u6563 VLN \u4efb\u52a1\u548c\u8fde\u7eed\u73b0\u5b9e\u4e16\u754c\u5bfc\u822a\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2506.15672", "pdf": "https://arxiv.org/pdf/2506.15672", "abs": "https://arxiv.org/abs/2506.15672", "authors": ["Yao Zhang", "Chenyang Lin", "Shijie Tang", "Haokun Chen", "Shijie Zhou", "Yunpu Ma", "Volker Tresp"], "title": "SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence", "categories": ["cs.AI", "cs.MA"], "comment": "41 pages", "summary": "The rapid progress of Large Language Models has advanced agentic systems in\ndecision-making, coordination, and task execution. Yet, existing agentic system\ngeneration frameworks lack full autonomy, missing from-scratch agent\ngeneration, self-optimizing agent functionality, and collaboration, limiting\nadaptability and scalability. We propose SwarmAgentic, a framework for fully\nautomated agentic system generation that constructs agentic systems from\nscratch and jointly optimizes agent functionality and collaboration as\ninterdependent components through language-driven exploration. To enable\nefficient search over system-level structures, SwarmAgentic maintains a\npopulation of candidate systems and evolves them via feedback-guided updates,\ndrawing inspiration from Particle Swarm Optimization (PSO). We evaluate our\nmethod on six real-world, open-ended, and exploratory tasks involving\nhigh-level planning, system-level coordination, and creative reasoning. Given\nonly a task description and an objective function, SwarmAgentic outperforms all\nbaselines, achieving a +261.8% relative improvement over ADAS on the\nTravelPlanner benchmark, highlighting the effectiveness of full automation in\nstructurally unconstrained tasks. This framework marks a significant step\ntoward scalable and autonomous agentic system design, bridging swarm\nintelligence with fully automated system multi-agent generation. Our code is\npublicly released at https://yaoz720.github.io/SwarmAgentic/.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on automated agentic system generation using Large Language Models and swarm intelligence. While it doesn't directly address trajectory prediction, the generated agentic systems *could* potentially be applied to trajectory prediction tasks, particularly in multi-agent scenarios. The core focus is on LLMs and multi-agent systems, giving it moderate relevance.", "keywords": ["Large Language Models", "agentic systems", "multi-agent", "swarm intelligence"]}, "AI": {"tldr": "SwarmAgentic\u662f\u4e00\u4e2a\u5168\u81ea\u52a8\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u6846\u67b6\uff0c\u5b83\u4ece\u5934\u5f00\u59cb\u6784\u5efa\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u8bed\u8a00\u9a71\u52a8\u7684\u63a2\u7d22\uff0c\u5c06\u667a\u80fd\u4f53\u529f\u80fd\u548c\u534f\u4f5c\u4f5c\u4e3a\u76f8\u4e92\u4f9d\u8d56\u7684\u7ec4\u4ef6\u8fdb\u884c\u8054\u5408\u4f18\u5316\u3002", "motivation": "Yet, existing agentic system generation frameworks lack full autonomy, missing from-scratch agent generation, self-optimizing agent functionality, and collaboration, limiting adaptability and scalability.", "method": "We propose SwarmAgentic, a framework for fully automated agentic system generation that constructs agentic systems from scratch and jointly optimizes agent functionality and collaboration as interdependent components through language-driven exploration. To enable efficient search over system-level structures, SwarmAgentic maintains a population of candidate systems and evolves them via feedback-guided updates, drawing inspiration from Particle Swarm Optimization (PSO).", "result": "Given only a task description and an objective function, SwarmAgentic outperforms all baselines, achieving a +261.8% relative improvement over ADAS on the TravelPlanner benchmark, highlighting the effectiveness of full automation in structurally unconstrained tasks.", "conclusion": "This framework marks a significant step toward scalable and autonomous agentic system design, bridging swarm intelligence with fully automated system multi-agent generation.", "summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u63a8\u52a8\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u51b3\u7b56\u3001\u534f\u8c03\u548c\u4efb\u52a1\u6267\u884c\u65b9\u9762\u7684\u8fdb\u6b65\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u6846\u67b6\u7f3a\u4e4f\u5b8c\u5168\u7684\u81ea\u4e3b\u6027\uff0c\u7f3a\u5c11\u4ece\u5934\u5f00\u59cb\u7684\u667a\u80fd\u4f53\u751f\u6210\u3001\u81ea\u4f18\u5316\u667a\u80fd\u4f53\u529f\u80fd\u548c\u534f\u4f5c\uff0c\u4ece\u800c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86SwarmAgentic\uff0c\u8fd9\u662f\u4e00\u4e2a\u5168\u81ea\u52a8\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u6846\u67b6\uff0c\u5b83\u4ece\u5934\u5f00\u59cb\u6784\u5efa\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u8bed\u8a00\u9a71\u52a8\u7684\u63a2\u7d22\uff0c\u5c06\u667a\u80fd\u4f53\u529f\u80fd\u548c\u534f\u4f5c\u4f5c\u4e3a\u76f8\u4e92\u4f9d\u8d56\u7684\u7ec4\u4ef6\u8fdb\u884c\u8054\u5408\u4f18\u5316\u3002\u4e3a\u4e86\u5b9e\u73b0\u5bf9\u7cfb\u7edf\u7ea7\u7ed3\u6784\u7684\u9ad8\u6548\u641c\u7d22\uff0cSwarmAgentic\u7ef4\u62a4\u4e86\u4e00\u4e2a\u5019\u9009\u7cfb\u7edf\u7fa4\u4f53\uff0c\u5e76\u901a\u8fc7\u53cd\u9988\u5f15\u5bfc\u7684\u66f4\u65b0\u6765\u8fdb\u5316\u5b83\u4eec\uff0c\u5176\u7075\u611f\u6765\u81ea\u7c92\u5b50\u7fa4\u4f18\u5316\uff08PSO\uff09\u3002\u6211\u4eec\u5728\u516d\u4e2a\u771f\u5b9e\u7684\u3001\u5f00\u653e\u5f0f\u7684\u548c\u63a2\u7d22\u6027\u7684\u4efb\u52a1\u4e2d\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u4efb\u52a1\u6d89\u53ca\u9ad8\u5c42\u6b21\u7684\u89c4\u5212\u3001\u7cfb\u7edf\u7ea7\u7684\u534f\u8c03\u548c\u521b\u9020\u6027\u7684\u63a8\u7406\u3002\u4ec5\u7ed9\u5b9a\u4efb\u52a1\u63cf\u8ff0\u548c\u76ee\u6807\u51fd\u6570\uff0cSwarmAgentic\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\uff0c\u5728TravelPlanner\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6bd4ADAS\u9ad8+261.8%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u7a81\u51fa\u4e86\u5b8c\u5168\u81ea\u52a8\u5316\u5728\u7ed3\u6784\u4e0a\u65e0\u7ea6\u675f\u7684\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002\u8be5\u6846\u67b6\u6807\u5fd7\u7740\u5728\u53ef\u6269\u5c55\u548c\u81ea\u4e3b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u9762\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u5c06\u7fa4\u4f53\u667a\u80fd\u4e0e\u5168\u81ea\u52a8\u7cfb\u7edf\u591a\u667a\u80fd\u4f53\u751f\u6210\u8054\u7cfb\u8d77\u6765\u3002\u6211\u4eec\u7684\u4ee3\u7801\u5df2\u5728https://yaoz720.github.io/SwarmAgentic/\u4e0a\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2506.15065", "pdf": "https://arxiv.org/pdf/2506.15065", "abs": "https://arxiv.org/abs/2506.15065", "authors": ["Trishna Chakraborty", "Udita Ghosh", "Xiaopan Zhang", "Fahim Faisal Niloy", "Yue Dong", "Jiachen Li", "Amit K. Roy-Chowdhury", "Chengyu Song"], "title": "HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Large language models (LLMs) are increasingly being adopted as the cognitive\ncore of embodied agents. However, inherited hallucinations, which stem from\nfailures to ground user instructions in the observed physical environment, can\nlead to navigation errors, such as searching for a refrigerator that does not\nexist. In this paper, we present the first systematic study of hallucinations\nin LLM-based embodied agents performing long-horizon tasks under scene-task\ninconsistencies. Our goal is to understand to what extent hallucinations occur,\nwhat types of inconsistencies trigger them, and how current models respond. To\nachieve these goals, we construct a hallucination probing set by building on an\nexisting benchmark, capable of inducing hallucination rates up to 40x higher\nthan base prompts. Evaluating 12 models across two simulation environments, we\nfind that while models exhibit reasoning, they fail to resolve scene-task\ninconsistencies-highlighting fundamental limitations in handling infeasible\ntasks. We also provide actionable insights on ideal model behavior for each\nscenario, offering guidance for developing more robust and reliable planning\nstrategies.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on the hallucinations of large language models in embodied agents performing long-horizon tasks. While it doesn't directly address trajectory prediction, the embodied agents' navigation implicitly involves trajectory generation. The core focus is on LLMs and their limitations in grounding instructions within a physical environment, which is relevant to applying LLMs in robotics and navigation tasks that could involve trajectory prediction.", "keywords": ["Large Language Models", "LLMs", "embodied agents", "navigation", "hallucinations"]}, "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86LLM\u5177\u8eab\u667a\u80fd\u4f53\u5728\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u60c5\u51b5\u4e0b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u5904\u7406\u4e0d\u5207\u5b9e\u9645\u4efb\u52a1\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u5177\u8eab\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u6838\u5fc3\uff0c\u4f46\u7531\u4e8e\u672a\u80fd\u5c06\u7528\u6237\u6307\u4ee4\u4e0e\u89c2\u5bdf\u5230\u7684\u7269\u7406\u73af\u5883\u76f8\u7ed3\u5408\u800c\u4ea7\u751f\u7684\u5e7b\u89c9\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bfc\u822a\u9519\u8bef\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5e7b\u89c9\u63a2\u6d4b\u96c6\uff0c\u53ef\u4ee5\u5728\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u5e7b\u89c9\u7387\u63d0\u9ad8\u5230\u6bd4\u57fa\u672c\u63d0\u793a\u9ad8 40 \u500d\u3002", "result": "\u5728\u4e24\u4e2a\u6a21\u62df\u73af\u5883\u4e2d\u8bc4\u4f30\u4e86 12 \u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u8868\u73b0\u51fa\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u65e0\u6cd5\u89e3\u51b3\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "conclusion": "\u6a21\u578b\u5728\u5904\u7406\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u65f6\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u65e0\u6cd5\u89e3\u51b3\u4e0d\u5207\u5b9e\u9645\u7684\u4efb\u52a1\u3002", "summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u5177\u8eab\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u6838\u5fc3\u3002\u7136\u800c\uff0c\u7531\u4e8e\u672a\u80fd\u5c06\u7528\u6237\u6307\u4ee4\u4e0e\u89c2\u5bdf\u5230\u7684\u7269\u7406\u73af\u5883\u76f8\u7ed3\u5408\u800c\u4ea7\u751f\u7684\u5e7b\u89c9\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bfc\u822a\u9519\u8bef\uff0c\u4f8b\u5982\u641c\u7d22\u4e0d\u5b58\u5728\u7684\u51b0\u7bb1\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u9996\u6b21\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u57fa\u4e8e LLM \u7684\u5177\u8eab\u667a\u80fd\u4f53\u5728\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u957f\u65f6\u4efb\u52a1\u65f6\u7684\u5e7b\u89c9\u95ee\u9898\u3002\u6211\u4eec\u7684\u76ee\u6807\u662f\u4e86\u89e3\u5e7b\u89c9\u53d1\u751f\u7684\u7a0b\u5ea6\uff0c\u54ea\u4e9b\u7c7b\u578b\u7684\u4e0d\u4e00\u81f4\u4f1a\u89e6\u53d1\u5e7b\u89c9\uff0c\u4ee5\u53ca\u5f53\u524d\u6a21\u578b\u7684\u53cd\u5e94\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e9b\u76ee\u6807\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5e7b\u89c9\u63a2\u6d4b\u96c6\uff0c\u8be5\u63a2\u6d4b\u96c6\u5efa\u7acb\u5728\u73b0\u6709\u57fa\u51c6\u4e4b\u4e0a\uff0c\u80fd\u591f\u5c06\u5e7b\u89c9\u7387\u63d0\u9ad8\u5230\u6bd4\u57fa\u672c\u63d0\u793a\u9ad8 40 \u500d\u3002\u6211\u4eec\u8bc4\u4f30\u4e86\u4e24\u4e2a\u6a21\u62df\u73af\u5883\u4e2d\u7684 12 \u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u867d\u7136\u6a21\u578b\u8868\u73b0\u51fa\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u65e0\u6cd5\u89e3\u51b3\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u2014\u2014\u7a81\u51fa\u4e86\u5904\u7406\u4e0d\u53ef\u884c\u4efb\u52a1\u7684\u6839\u672c\u5c40\u9650\u6027\u3002\u6211\u4eec\u8fd8\u9488\u5bf9\u6bcf\u79cd\u573a\u666f\u63d0\u4f9b\u4e86\u7406\u60f3\u6a21\u578b\u884c\u4e3a\u7684\u53ef\u64cd\u4f5c\u89c1\u89e3\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u66f4\u53ef\u9760\u7684\u89c4\u5212\u7b56\u7565\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2506.15313", "pdf": "https://arxiv.org/pdf/2506.15313", "abs": "https://arxiv.org/abs/2506.15313", "authors": ["Leonid Ivanov", "Vasily Yuryev", "Dmitry Yudin"], "title": "MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint. Submitted. 12 pages, 4 figures", "summary": "In autonomous driving, high-definition (HD) maps and semantic maps in\nbird's-eye view (BEV) are essential for accurate localization, planning, and\ndecision-making. This paper introduces an enhanced End-to-End model named MapFM\nfor online vectorized HD map generation. We show significantly boost feature\nrepresentation quality by incorporating powerful foundation model for encoding\ncamera images. To further enrich the model's understanding of the environment\nand improve prediction quality, we integrate auxiliary prediction heads for\nsemantic segmentation in the BEV representation. This multi-task learning\napproach provides richer contextual supervision, leading to a more\ncomprehensive scene representation and ultimately resulting in higher accuracy\nand improved quality of the predicted vectorized HD maps. The source code is\navailable at https://github.com/LIvanoff/MapFM.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on HD map generation for autonomous driving, which is closely related to trajectory prediction as accurate maps are crucial for planning and decision-making. It also leverages foundation models (a type of large model) for image encoding. While it doesn't directly predict trajectories, the underlying technology and application are relevant.", "keywords": ["foundation model", "HD map", "autonomous driving", "semantic segmentation", "large model"]}, "AI": {"tldr": "MapFM \u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u548c\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u7ebf\u77e2\u91cf\u5316 HD \u5730\u56fe\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002", "motivation": "\u9ad8\u6e05 (HD) \u5730\u56fe\u548c\u9e1f\u77b0\u56fe (BEV) \u4e2d\u7684\u8bed\u4e49\u5730\u56fe\u5bf9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u4e2d\u51c6\u786e\u5b9a\u4f4d\u3001\u89c4\u5212\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a MapFM \u7684\u589e\u5f3a\u578b\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u7ebf\u751f\u6210\u77e2\u91cf\u5316 HD \u5730\u56fe\u3002\u8be5\u6a21\u578b\u5229\u7528\u5f3a\u5927\u7684\u57fa\u7840\u6a21\u578b\u5bf9\u76f8\u673a\u56fe\u50cf\u8fdb\u884c\u7f16\u7801\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7279\u5f81\u8868\u793a\u8d28\u91cf\uff0c\u5e76\u96c6\u6210\u4e86\u8f85\u52a9\u9884\u6d4b\u5934\uff0c\u7528\u4e8e\u5728 BEV \u8868\u793a\u4e2d\u8fdb\u884c\u8bed\u4e49\u5206\u5272\u3002", "result": "\u901a\u8fc7\u96c6\u6210\u8f85\u52a9\u9884\u6d4b\u5934\u548c\u4f7f\u7528\u591a\u4efb\u52a1\u5b66\u4e60\uff0cMapFM \u80fd\u591f\u66f4\u5168\u9762\u5730\u8868\u793a\u573a\u666f\uff0c\u5e76\u6700\u7ec8\u63d0\u9ad8\u9884\u6d4b\u77e2\u91cf\u5316 HD \u5730\u56fe\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\uff0cMapFM \u80fd\u591f\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u77e2\u91cf\u5316 HD \u5730\u56fe\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002", "summary_zh": "\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\uff0c\u9ad8\u6e05 (HD) \u5730\u56fe\u548c\u9e1f\u77b0\u56fe (BEV) \u4e2d\u7684\u8bed\u4e49\u5730\u56fe\u5bf9\u4e8e\u51c6\u786e\u5b9a\u4f4d\u3001\u89c4\u5212\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a MapFM \u7684\u589e\u5f3a\u578b\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u7ebf\u751f\u6210\u77e2\u91cf\u5316 HD \u5730\u56fe\u3002\u6211\u4eec\u5c55\u793a\u4e86\u901a\u8fc7\u7ed3\u5408\u5f3a\u5927\u7684\u57fa\u7840\u6a21\u578b\u6765\u7f16\u7801\u76f8\u673a\u56fe\u50cf\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u7279\u5f81\u8868\u793a\u8d28\u91cf\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u4e30\u5bcc\u6a21\u578b\u5bf9\u73af\u5883\u7684\u7406\u89e3\u5e76\u63d0\u9ad8\u9884\u6d4b\u8d28\u91cf\uff0c\u6211\u4eec\u96c6\u6210\u4e86\u8f85\u52a9\u9884\u6d4b\u5934\uff0c\u7528\u4e8e\u5728 BEV \u8868\u793a\u4e2d\u8fdb\u884c\u8bed\u4e49\u5206\u5272\u3002\u8fd9\u79cd\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u76d1\u7763\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u5168\u9762\u7684\u573a\u666f\u8868\u793a\uff0c\u5e76\u6700\u7ec8\u63d0\u9ad8\u9884\u6d4b\u77e2\u91cf\u5316 HD \u5730\u56fe\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002\u6e90\u4ee3\u7801\u53ef\u5728 https://github.com/LIvanoff/MapFM \u83b7\u53d6\u3002"}}
{"id": "2506.15447", "pdf": "https://arxiv.org/pdf/2506.15447", "abs": "https://arxiv.org/abs/2506.15447", "authors": ["David Leprich", "Mario Rosenfelder", "Mario Hermle", "Jingshan Chen", "Peter Eberhard"], "title": "Model Predictive Path-Following Control for a Quadrotor", "categories": ["eess.SY", "cs.RO", "cs.SY", "93-XX"], "comment": "15 pages, 11 figures, submitted to PAMM 2025", "summary": "Automating drone-assisted processes is a complex task. Many solutions rely on\ntrajectory generation and tracking, whereas in contrast, path-following control\nis a particularly promising approach, offering an intuitive and natural\napproach to automate tasks for drones and other vehicles. While different\nsolutions to the path-following problem have been proposed, most of them lack\nthe capability to explicitly handle state and input constraints, are formulated\nin a conservative two-stage approach, or are only applicable to linear systems.\nTo address these challenges, the paper is built upon a Model Predictive\nControl-based path-following framework and extends its application to the\nCrazyflie quadrotor, which is investigated in hardware experiments. A cascaded\ncontrol structure including an underlying attitude controller is included in\nthe Model Predictive Path-Following Control formulation to meet the challenging\nreal-time demands of quadrotor control. The effectiveness of the proposed\nmethod is demonstrated through real-world experiments, representing, to the\nbest of the authors' knowledge, a novel application of this MPC-based\npath-following approach to the quadrotor. Additionally, as an extension to the\noriginal method, to allow for deviations of the path in cases where the precise\nfollowing of the path might be overly restrictive, a corridor path-following\napproach is presented.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on path-following control for a quadrotor using Model Predictive Control (MPC). While it doesn't directly involve Large Language Models, it's related to trajectory prediction through the 'path-following' aspect and 'trajectory generation and tracking' mentioned in the abstract. The paper primarily deals with control and path planning, which are adjacent to trajectory prediction. It does not mention anything about LLMs.", "keywords": ["trajectory generation", "path-following control", "Model Predictive Control", "path planning"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u6210\u529f\u5e94\u7528\u4e8e\u56db\u65cb\u7ffc\u98de\u884c\u5668\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u79cd\u8d70\u5eca\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u4ee5\u5141\u8bb8\u8def\u5f84\u504f\u5dee\u3002", "motivation": "\u73b0\u6709\u7684\u8def\u5f84\u8ddf\u8e2a\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u663e\u5f0f\u5904\u7406\u72b6\u6001\u548c\u8f93\u5165\u7ea6\u675f\u7684\u80fd\u529b\uff0c\u901a\u5e38\u91c7\u7528\u4fdd\u5b88\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u6216\u8005\u4ec5\u9002\u7528\u4e8e\u7ebf\u6027\u7cfb\u7edf\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u8def\u5f84\u8ddf\u8e2a\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u7684\u8def\u5f84\u8ddf\u8e2a\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eCrazyflie\u56db\u65cb\u7ffc\u98de\u884c\u5668\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u5e95\u5c42\u7684\u59ff\u6001\u63a7\u5236\u5668\uff0c\u4ee5\u6ee1\u8db3\u56db\u65cb\u7ffc\u63a7\u5236\u7684\u5b9e\u65f6\u6027\u9700\u6c42\u3002", "result": "\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8d70\u5eca\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u57fa\u4e8eMPC\u7684\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u5728\u56db\u65cb\u7ffc\u98de\u884c\u5668\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8d70\u5eca\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u5141\u8bb8\u5728\u8def\u5f84\u8ddf\u8e2a\u8fc7\u4e8e\u4e25\u683c\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u504f\u5dee\u3002", "summary_zh": "\u65e0\u4eba\u673a\u8f85\u52a9\u6d41\u7a0b\u7684\u81ea\u52a8\u5316\u662f\u4e00\u4e2a\u590d\u6742\u7684\u4efb\u52a1\u3002\u8bb8\u591a\u89e3\u51b3\u65b9\u6848\u4f9d\u8d56\u4e8e\u8f68\u8ff9\u751f\u6210\u548c\u8ddf\u8e2a\uff0c\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u8def\u5f84\u8ddf\u8e2a\u63a7\u5236\u662f\u4e00\u79cd\u7279\u522b\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u5b83\u4e3a\u65e0\u4eba\u673a\u548c\u5176\u4ed6\u8f66\u8f86\u7684\u81ea\u52a8\u5316\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u76f4\u89c2\u548c\u81ea\u7136\u7684\u65b9\u6cd5\u3002\u867d\u7136\u5df2\u7ecf\u63d0\u51fa\u4e86\u4e0d\u540c\u7684\u8def\u5f84\u8ddf\u8e2a\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b83\u4eec\u4e2d\u7684\u5927\u591a\u6570\u7f3a\u4e4f\u663e\u5f0f\u5904\u7406\u72b6\u6001\u548c\u8f93\u5165\u7ea6\u675f\u7684\u80fd\u529b\uff0c\u4ee5\u4fdd\u5b88\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u5236\u5b9a\uff0c\u6216\u8005\u4ec5\u9002\u7528\u4e8e\u7ebf\u6027\u7cfb\u7edf\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u672c\u6587\u5efa\u7acb\u5728\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u8def\u5f84\u8ddf\u8e2a\u6846\u67b6\u4e4b\u4e0a\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u6269\u5c55\u5230Crazyflie\u56db\u65cb\u7ffc\u98de\u884c\u5668\uff0c\u5e76\u5728\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u8fdb\u884c\u4e86\u7814\u7a76\u3002\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u8ddf\u8e2a\u63a7\u5236\u516c\u5f0f\u4e2d\u5305\u542b\u4e00\u4e2a\u5305\u542b\u5e95\u5c42\u59ff\u6001\u63a7\u5236\u5668\u7684\u7ea7\u8054\u63a7\u5236\u7ed3\u6784\uff0c\u4ee5\u6ee1\u8db3\u56db\u65cb\u7ffc\u63a7\u5236\u7684\u5177\u6709\u6311\u6218\u6027\u7684\u5b9e\u65f6\u9700\u6c42\u3002\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u636e\u4f5c\u8005\u6240\u77e5\uff0c\u8fd9\u4ee3\u8868\u4e86\u8fd9\u79cd\u57fa\u4e8eMPC\u7684\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u5728\u56db\u65cb\u7ffc\u98de\u884c\u5668\u4e0a\u7684\u65b0\u9896\u5e94\u7528\u3002\u6b64\u5916\uff0c\u4f5c\u4e3a\u539f\u59cb\u65b9\u6cd5\u7684\u6269\u5c55\uff0c\u4e3a\u4e86\u5141\u8bb8\u5728\u8def\u5f84\u7684\u7cbe\u786e\u8ddf\u8e2a\u53ef\u80fd\u8fc7\u4e8e\u4e25\u683c\u7684\u60c5\u51b5\u4e0b\u504f\u79bb\u8def\u5f84\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8d70\u5eca\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u3002"}}
{"id": "2506.15079", "pdf": "https://arxiv.org/pdf/2506.15079", "abs": "https://arxiv.org/abs/2506.15079", "authors": ["Yikai Hou", "Peng Tang"], "title": "Neural Canonical Polyadic Factorization for Traffic Analysis", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Modern intelligent transportation systems rely on accurate spatiotemporal\ntraffic analysis to optimize urban mobility and infrastructure resilience.\nHowever, pervasive missing data caused by sensor failures and heterogeneous\nsensing gaps fundamentally hinders reliable traffic modeling. This paper\nproposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes\nlow-rank tensor algebra with deep representation learning for robust traffic\ndata imputation. The model innovatively embeds CP decomposition into neural\narchitecture through learnable embedding projections, where sparse traffic\ntensors are encoded into dense latent factors across road segments, time\nintervals, and mobility metrics. A hierarchical feature fusion mechanism\nemploys Hadamard products to explicitly model multilinear interactions, while\nstacked multilayer perceptron layers nonlinearly refine these representations\nto capture complex spatiotemporal couplings. Extensive evaluations on six urban\ntraffic datasets demonstrate NCPF's superiority over six state-of-the-art\nbaselines. By unifying CP decomposition's interpretable factor analysis with\nneural network's nonlinear expressive power, NCPF provides a principled yet\nflexible approaches for high-dimensional traffic data imputation, offering\ncritical support for next-generation transportation digital twins and adaptive\ntraffic control systems.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on traffic analysis using neural networks and tensor factorization for data imputation. While it deals with spatiotemporal data, which is relevant to trajectory prediction, it doesn't directly address trajectory prediction itself. It also does not mention or utilize large language models. However, the use of neural networks for spatiotemporal data analysis justifies a moderate relevance score.", "keywords": ["traffic analysis", "spatiotemporal", "neural networks", "data imputation"]}, "AI": {"tldr": "NCPF\u6a21\u578b\u7ed3\u5408CP\u5206\u89e3\u548c\u795e\u7ecf\u7f51\u7edc\uff0c\u6709\u6548\u89e3\u51b3\u9ad8\u7ef4\u4ea4\u901a\u6570\u636e\u63d2\u8865\u95ee\u9898\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u73b0\u4ee3\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u7cbe\u786e\u7684\u65f6\u7a7a\u4ea4\u901a\u5206\u6790\u6765\u4f18\u5316\u57ce\u5e02\u4ea4\u901a\u548c\u57fa\u7840\u8bbe\u65bd\u5f39\u6027\uff0c\u4f46\u4f20\u611f\u5668\u6545\u969c\u548c\u5f02\u6784\u4f20\u611f\u95f4\u9699\u5bfc\u81f4\u666e\u904d\u5b58\u5728\u7684\u6570\u636e\u7f3a\u5931\uff0c\u4ece\u6839\u672c\u4e0a\u963b\u788d\u4e86\u53ef\u9760\u7684\u4ea4\u901a\u5efa\u6a21\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u89c4\u8303Polyadic\u5206\u89e3(NCPF)\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u4f4e\u79e9\u5f20\u91cf\u4ee3\u6570\u4e0e\u6df1\u5ea6\u8868\u793a\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u9c81\u68d2\u7684\u4ea4\u901a\u6570\u636e\u63d2\u8865\u3002", "result": "\u5728\u516d\u4e2a\u57ce\u5e02\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cNCPF\u4f18\u4e8e\u516d\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u3002", "conclusion": "NCPF\u6a21\u578b\u901a\u8fc7\u7ed3\u5408CP\u5206\u89e3\u7684\u53ef\u89e3\u91ca\u6027\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u975e\u7ebf\u6027\u8868\u8fbe\u80fd\u529b\uff0c\u4e3a\u9ad8\u7ef4\u4ea4\u901a\u6570\u636e\u63d2\u8865\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "summary_zh": "\u73b0\u4ee3\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u7cbe\u786e\u7684\u65f6\u7a7a\u4ea4\u901a\u5206\u6790\u6765\u4f18\u5316\u57ce\u5e02\u4ea4\u901a\u548c\u57fa\u7840\u8bbe\u65bd\u7684\u5f39\u6027\u3002\u7136\u800c\uff0c\u7531\u4f20\u611f\u5668\u6545\u969c\u548c\u5f02\u6784\u4f20\u611f\u95f4\u9699\u5bfc\u81f4\u7684\u666e\u904d\u6570\u636e\u7f3a\u5931\u4ece\u6839\u672c\u4e0a\u963b\u788d\u4e86\u53ef\u9760\u7684\u4ea4\u901a\u5efa\u6a21\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u89c4\u8303Polyadic\u5206\u89e3(NCPF)\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u4f4e\u79e9\u5f20\u91cf\u4ee3\u6570\u4e0e\u6df1\u5ea6\u8868\u793a\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u9c81\u68d2\u7684\u4ea4\u901a\u6570\u636e\u63d2\u8865\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5d4c\u5165\u6295\u5f71\uff0c\u521b\u65b0\u5730\u5c06CP\u5206\u89e3\u5d4c\u5165\u5230\u795e\u7ecf\u67b6\u6784\u4e2d\uff0c\u5176\u4e2d\u7a00\u758f\u4ea4\u901a\u5f20\u91cf\u88ab\u7f16\u7801\u6210\u8de8\u8def\u6bb5\u3001\u65f6\u95f4\u95f4\u9694\u548c\u79fb\u52a8\u6027\u6307\u6807\u7684\u5bc6\u96c6\u6f5c\u5728\u56e0\u5b50\u3002\u4e00\u79cd\u5206\u5c42\u7279\u5f81\u878d\u5408\u673a\u5236\u91c7\u7528Hadamard\u79ef\u6765\u663e\u5f0f\u5730\u5efa\u6a21\u591a\u7ebf\u6027\u4ea4\u4e92\uff0c\u800c\u5806\u53e0\u7684\u591a\u5c42\u611f\u77e5\u5668\u5c42\u975e\u7ebf\u6027\u5730\u7ec6\u5316\u8fd9\u4e9b\u8868\u793a\uff0c\u4ee5\u6355\u83b7\u590d\u6742\u7684\u65f6\u7a7a\u8026\u5408\u3002\u5728\u516d\u4e2a\u57ce\u5e02\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cNCPF\u4f18\u4e8e\u516d\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u3002\u901a\u8fc7\u7edf\u4e00CP\u5206\u89e3\u7684\u53ef\u89e3\u91ca\u56e0\u5b50\u5206\u6790\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u975e\u7ebf\u6027\u8868\u8fbe\u80fd\u529b\uff0cNCPF\u4e3a\u9ad8\u7ef4\u4ea4\u901a\u6570\u636e\u63d2\u8865\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u800c\u7075\u6d3b\u7684\u65b9\u6cd5\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4ea4\u901a\u6570\u5b57\u5b6a\u751f\u548c\u81ea\u9002\u5e94\u4ea4\u901a\u63a7\u5236\u7cfb\u7edf\u63d0\u4f9b\u5173\u952e\u652f\u6301\u3002"}}
{"id": "2506.15190", "pdf": "https://arxiv.org/pdf/2506.15190", "abs": "https://arxiv.org/abs/2506.15190", "authors": ["Jiyi Wang", "Jingyang Ke", "Bo Dai", "Anqi Wu"], "title": "Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors", "categories": ["cs.LG", "q-bio.NC"], "comment": "9 pages and 4 figures for the main text", "summary": "Animals flexibly recombine a finite set of core motor primitives to meet\ndiverse task demands, but existing behavior-segmentation methods oversimplify\nthis process by imposing discrete syllables under restrictive generative\nassumptions. To reflect the animal behavior generation procedure, we introduce\nskill-based imitation learning (SKIL) for behavior understanding, a\nreinforcement learning-based imitation framework that (1) infers interpretable\nskill sets, i.e., latent basis functions of behavior, by leveraging\nrepresentation learning on transition probabilities, and (2) parameterizes\npolicies as dynamic mixtures of these skills. We validate our approach on a\nsimple grid world, a discrete labyrinth, and unconstrained videos of freely\nmoving animals. Across tasks, it identifies reusable skill components, learns\ncontinuously evolving compositional policies, and generates realistic\ntrajectories beyond the capabilities of traditional discrete models. By\nexploiting generative behavior modeling with compositional representations, our\nmethod offers a concise, principled account of how complex animal behaviors\nemerge from dynamic combinations of fundamental motor primitives.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on learning motor primitives and generating realistic trajectories of animal behaviors using reinforcement learning. While it doesn't directly involve Large Language Models, the generation of trajectories and the learning of skills can be considered related to trajectory prediction. The use of representation learning also suggests a connection to modern machine learning techniques often used in conjunction with large models, albeit indirectly.", "keywords": ["trajectory prediction", "imitation learning", "representation learning", "motor primitives", "skill learning"]}, "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6280\u80fd\u7684\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff08SKIL\uff09\uff0c\u7528\u4e8e\u7406\u89e3\u52a8\u7269\u884c\u4e3a\uff0c\u901a\u8fc7\u52a8\u6001\u7ec4\u5408\u57fa\u672c\u8fd0\u52a8\u539f\u8bed\u6765\u751f\u6210\u590d\u6742\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7684\u884c\u4e3a\u5206\u5272\u65b9\u6cd5\u901a\u8fc7\u5728\u9650\u5236\u6027\u751f\u6210\u5047\u8bbe\u4e0b\u65bd\u52a0\u79bb\u6563\u97f3\u8282\uff0c\u8fc7\u5ea6\u7b80\u5316\u4e86\u8fd9\u4e2a\u8fc7\u7a0b\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u57fa\u4e8e\u6280\u80fd\u7684\u6a21\u4eff\u5b66\u4e60\uff08SKIL\uff09\u7528\u4e8e\u884c\u4e3a\u7406\u89e3\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6a21\u4eff\u6846\u67b6\uff0c\u5b83\uff081\uff09\u901a\u8fc7\u5229\u7528\u8f6c\u6362\u6982\u7387\u7684\u8868\u5f81\u5b66\u4e60\u6765\u63a8\u65ad\u53ef\u89e3\u91ca\u7684\u6280\u80fd\u96c6\uff0c\u5373\u884c\u4e3a\u7684\u6f5c\u5728\u57fa\u51fd\u6570\uff0c\u5e76\u4e14\uff082\uff09\u5c06\u7b56\u7565\u53c2\u6570\u5316\u4e3a\u8fd9\u4e9b\u6280\u80fd\u7684\u52a8\u6001\u6df7\u5408\u3002", "result": "\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\uff0c\u5b83\u53ef\u4ee5\u8bc6\u522b\u53ef\u91cd\u7528\u7684\u6280\u80fd\u7ec4\u4ef6\uff0c\u5b66\u4e60\u4e0d\u65ad\u53d1\u5c55\u7684\u7ec4\u5408\u7b56\u7565\uff0c\u5e76\u751f\u6210\u8d85\u51fa\u4f20\u7edf\u79bb\u6563\u6a21\u578b\u80fd\u529b\u7684\u771f\u5b9e\u8f68\u8ff9\u3002", "conclusion": "\u901a\u8fc7\u52a8\u6001\u7ec4\u5408\u57fa\u672c\u8fd0\u52a8\u539f\u8bed\uff0c\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u52a8\u7269\u884c\u4e3a\u7684\u51fa\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u6d01\u3001\u6709\u539f\u5219\u7684\u89e3\u91ca\u3002", "summary_zh": "\u52a8\u7269\u7075\u6d3b\u5730\u91cd\u7ec4\u4e00\u7ec4\u6709\u9650\u7684\u6838\u5fc3\u8fd0\u52a8\u539f\u8bed\uff0c\u4ee5\u6ee1\u8db3\u4e0d\u540c\u7684\u4efb\u52a1\u9700\u6c42\uff0c\u4f46\u73b0\u6709\u7684\u884c\u4e3a\u5206\u5272\u65b9\u6cd5\u901a\u8fc7\u5728\u9650\u5236\u6027\u751f\u6210\u5047\u8bbe\u4e0b\u65bd\u52a0\u79bb\u6563\u97f3\u8282\uff0c\u8fc7\u5ea6\u7b80\u5316\u4e86\u8fd9\u4e2a\u8fc7\u7a0b\u3002\u4e3a\u4e86\u53cd\u6620\u52a8\u7269\u884c\u4e3a\u7684\u751f\u6210\u8fc7\u7a0b\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u57fa\u4e8e\u6280\u80fd\u7684\u6a21\u4eff\u5b66\u4e60\uff08SKIL\uff09\u7528\u4e8e\u884c\u4e3a\u7406\u89e3\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6a21\u4eff\u6846\u67b6\uff0c\u5b83\uff081\uff09\u901a\u8fc7\u5229\u7528\u8f6c\u6362\u6982\u7387\u7684\u8868\u5f81\u5b66\u4e60\u6765\u63a8\u65ad\u53ef\u89e3\u91ca\u7684\u6280\u80fd\u96c6\uff0c\u5373\u884c\u4e3a\u7684\u6f5c\u5728\u57fa\u51fd\u6570\uff0c\u5e76\u4e14\uff082\uff09\u5c06\u7b56\u7565\u53c2\u6570\u5316\u4e3a\u8fd9\u4e9b\u6280\u80fd\u7684\u52a8\u6001\u6df7\u5408\u3002\u6211\u4eec\u5728\u4e00\u4e2a\u7b80\u5355\u7684\u7f51\u683c\u4e16\u754c\u3001\u4e00\u4e2a\u79bb\u6563\u7684\u8ff7\u5bab\u548c\u81ea\u7531\u79fb\u52a8\u52a8\u7269\u7684\u65e0\u7ea6\u675f\u89c6\u9891\u4e0a\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u3002\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\uff0c\u5b83\u53ef\u4ee5\u8bc6\u522b\u53ef\u91cd\u7528\u7684\u6280\u80fd\u7ec4\u4ef6\uff0c\u5b66\u4e60\u4e0d\u65ad\u53d1\u5c55\u7684\u7ec4\u5408\u7b56\u7565\uff0c\u5e76\u751f\u6210\u8d85\u51fa\u4f20\u7edf\u79bb\u6563\u6a21\u578b\u80fd\u529b\u7684\u771f\u5b9e\u8f68\u8ff9\u3002\u901a\u8fc7\u5229\u7528\u5177\u6709\u7ec4\u5408\u8868\u793a\u7684\u751f\u6210\u884c\u4e3a\u5efa\u6a21\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4e3a\u590d\u6742\u52a8\u7269\u884c\u4e3a\u5982\u4f55\u4ece\u57fa\u672c\u8fd0\u52a8\u539f\u8bed\u7684\u52a8\u6001\u7ec4\u5408\u4e2d\u51fa\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u6d01\u3001\u6709\u539f\u5219\u7684\u89e3\u91ca\u3002"}}
{"id": "2506.14913", "pdf": "https://arxiv.org/pdf/2506.14913", "abs": "https://arxiv.org/abs/2506.14913", "authors": ["Wassim Bouaziz", "Mathurin Videau", "Nicolas Usunier", "El-Mahdi El-Mhamdi"], "title": "Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning", "categories": ["cs.CR", "cs.LG", "stat.ML"], "comment": "18 pages, 12 figures", "summary": "The pre-training of large language models (LLMs) relies on massive text\ndatasets sourced from diverse and difficult-to-curate origins. Although\nmembership inference attacks and hidden canaries have been explored to trace\ndata usage, such methods rely on memorization of training data, which LM\nproviders try to limit. In this work, we demonstrate that indirect data\npoisoning (where the targeted behavior is absent from training data) is not\nonly feasible but also allow to effectively protect a dataset and trace its\nuse. Using gradient-based optimization prompt-tuning, we make a model learn\narbitrary secret sequences: secret responses to secret prompts that are absent\nfrom the training corpus. We validate our approach on language models\npre-trained from scratch and show that less than 0.005% of poisoned tokens are\nsufficient to covertly make a LM learn a secret and detect it with extremely\nhigh confidence ($p < 10^{-55}$) with a theoretically certifiable scheme.\nCrucially, this occurs without performance degradation (on LM benchmarks) and\ndespite secrets never appearing in the training set.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on backdooring large language models (LLMs) during pre-training using data poisoning techniques. While it directly deals with LLMs, it does not involve trajectory prediction. The connection is through the use of large language models, a key component of the defined scope. However, the main topic is security and data poisoning, not trajectory prediction.", "keywords": ["large language models", "LLMs", "pre-training", "data poisoning"]}, "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u95f4\u63a5\u6570\u636e\u4e2d\u6bd2\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c11\u91cf\u4e2d\u6bd2token\u5373\u53ef\u4f7f\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u5e76\u68c0\u6d4b\u79d8\u5bc6\uff0c\u4e14\u4e0d\u5f71\u54cd\u6027\u80fd\uff0c\u4ece\u800c\u4fdd\u62a4\u6570\u636e\u96c6\u5e76\u8ffd\u8e2a\u5176\u4f7f\u7528\u60c5\u51b5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9884\u8bad\u7ec3\u4f9d\u8d56\u4e8e\u6765\u81ea\u4e0d\u540c\u4e14\u96be\u4ee5\u7ba1\u7406\u7684\u6765\u6e90\u7684\u6d77\u91cf\u6587\u672c\u6570\u636e\u96c6\u3002\u867d\u7136\u5df2\u7ecf\u63a2\u7d22\u4e86\u6210\u5458\u63a8\u7406\u653b\u51fb\u548c\u9690\u85cfcanaries\u6765\u8ffd\u8e2a\u6570\u636e\u4f7f\u7528\u60c5\u51b5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u8bb0\u5fc6\uff0c\u800cLM\u63d0\u4f9b\u5546\u8bd5\u56fe\u9650\u5236\u8fd9\u79cd\u8bb0\u5fc6\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316prompt\u8c03\u6574\uff0c\u4f7f\u6a21\u578b\u5b66\u4e60\u4efb\u610f\u79d8\u5bc6\u5e8f\u5217\u3002", "result": "\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4ece\u5934\u5f00\u59cb\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u5c11\u4e8e0.005%\u7684\u4e2d\u6bd2token\u8db3\u4ee5\u9690\u853d\u5730\u4f7fLM\u5b66\u4e60\u79d8\u5bc6\uff0c\u5e76\u4ee5\u6781\u9ad8\u7684\u7f6e\u4fe1\u5ea6\uff08$p < 10^{-55}$\uff09\u68c0\u6d4b\u5230\u5b83\uff0c\u4e14\u5177\u6709\u7406\u8bba\u4e0a\u53ef\u8bc1\u660e\u7684\u65b9\u6848\u3002", "conclusion": "\u5728\u6ca1\u6709\u6027\u80fd\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u901a\u8fc7\u5bf9\u5c11\u91cf\u4e2d\u6bd2token\u8fdb\u884c\u68af\u5ea6\u4f18\u5316prompt\u8c03\u6574\uff0c\u9690\u853d\u5730\u4f7f\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u79d8\u5bc6\u5e76\u4ee5\u6781\u9ad8\u7684\u7f6e\u4fe1\u5ea6\u68c0\u6d4b\u5b83\u3002", "summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9884\u8bad\u7ec3\u4f9d\u8d56\u4e8e\u6765\u81ea\u4e0d\u540c\u4e14\u96be\u4ee5\u7ba1\u7406\u7684\u6765\u6e90\u7684\u6d77\u91cf\u6587\u672c\u6570\u636e\u96c6\u3002\u867d\u7136\u5df2\u7ecf\u63a2\u7d22\u4e86\u6210\u5458\u63a8\u7406\u653b\u51fb\u548c\u9690\u85cfcanaries\u6765\u8ffd\u8e2a\u6570\u636e\u4f7f\u7528\u60c5\u51b5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u8bb0\u5fc6\uff0c\u800cLM\u63d0\u4f9b\u5546\u8bd5\u56fe\u9650\u5236\u8fd9\u79cd\u8bb0\u5fc6\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u95f4\u63a5\u6570\u636e\u4e2d\u6bd2\uff08\u76ee\u6807\u884c\u4e3a\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u4e0d\u5b58\u5728\uff09\u4e0d\u4ec5\u662f\u53ef\u884c\u7684\uff0c\u800c\u4e14\u8fd8\u53ef\u4ee5\u6709\u6548\u5730\u4fdd\u62a4\u6570\u636e\u96c6\u5e76\u8ffd\u8e2a\u5176\u4f7f\u7528\u60c5\u51b5\u3002\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316prompt\u8c03\u6574\uff0c\u6211\u4eec\u4f7f\u6a21\u578b\u5b66\u4e60\u4efb\u610f\u79d8\u5bc6\u5e8f\u5217\uff1a\u5bf9\u8bad\u7ec3\u8bed\u6599\u5e93\u4e2d\u4e0d\u5b58\u5728\u7684\u79d8\u5bc6\u63d0\u793a\u7684\u79d8\u5bc6\u54cd\u5e94\u3002\u6211\u4eec\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4ece\u5934\u5f00\u59cb\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u5c11\u4e8e0.005%\u7684\u4e2d\u6bd2token\u8db3\u4ee5\u9690\u853d\u5730\u4f7fLM\u5b66\u4e60\u79d8\u5bc6\uff0c\u5e76\u4ee5\u6781\u9ad8\u7684\u7f6e\u4fe1\u5ea6\uff08$p < 10^{-55}$\uff09\u68c0\u6d4b\u5230\u5b83\uff0c\u4e14\u5177\u6709\u7406\u8bba\u4e0a\u53ef\u8bc1\u660e\u7684\u65b9\u6848\u3002 \u91cd\u8981\u7684\u662f\uff0c\u8fd9\u53d1\u751f\u5728\u6ca1\u6709\u6027\u80fd\u4e0b\u964d\uff08\u5728LM\u57fa\u51c6\u4e0a\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5e76\u4e14\u5c3d\u7ba1\u79d8\u5bc6\u4ece\u672a\u51fa\u73b0\u5728\u8bad\u7ec3\u96c6\u4e2d\u3002"}}
