# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-10-20

## 目录

- [计算语言学 (Computation and Language) (1)](#cs-cl)
- [cs.DB (1)](#cs-db)

## 计算语言学 (Computation and Language) [cs.CL]
### [1] [BenchPress: A Human-in-the-Loop Annotation System for Rapid Text-to-SQL Benchmark Curation](https://arxiv.org/abs/2510.13853)
*Fabian Wenz, Omar Bouattour, Devin Yang, Justin Choi, Cecil Gregg, Nesime Tatbul, Çağatay Demiralp*

Main category: cs.CL

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Large language models (LLMs) have been successfully applied to many tasks, including text-to-SQL generation. However, much of this work has focused on publicly available datasets, such as Fiben, Spider, and Bird. Our earlier work showed that LLMs are much less effective in querying large private enterprise data warehouses and released Beaver, the first private enterprise text-to-SQL benchmark. To create Beaver, we leveraged SQL logs, which are often readily available. However, manually annotating these logs to identify which natural language questions they answer is a daunting task. Asking database administrators, who are highly trained experts, to take on additional work to construct and validate corresponding natural language utterances is not only challenging but also quite costly. To address this challenge, we introduce BenchPress, a human-in-the-loop system designed to accelerate the creation of domain-specific text-to-SQL benchmarks. Given a SQL query, BenchPress uses retrieval-augmented generation (RAG) and LLMs to propose multiple natural language descriptions. Human experts then select, rank, or edit these drafts to ensure accuracy and domain alignment. We evaluated BenchPress on annotated enterprise SQL logs, demonstrating that LLM-assisted annotation drastically reduces the time and effort required to create high-quality benchmarks. Our results show that combining human verification with LLM-generated suggestions enhances annotation accuracy, benchmark reliability, and model evaluation robustness. By streamlining the creation of custom benchmarks, BenchPress offers researchers and practitioners a mechanism for assessing text-to-SQL models on a given domain-specific workload. BenchPress is freely available via our public GitHub repository at https://github.com/fabian-wenz/enterprise-txt2sql and is also accessible on our website at http://dsg-mcgraw.csail.mit.edu:5000.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.13853) | **Categories:** cs.CL, cs.AI, cs.DB, cs.HC

---


## cs.DB [cs.DB]
### [1] [Towards a Multimodal Stream Processing System](https://arxiv.org/abs/2510.14631)
*Uélison Jean Lopes dos Santos, Alessandro Ferri, Szilard Nistor, Riccardo Tommasini, Carsten Binnig, Manisha Luthra*

Main category: cs.DB

TL;DR: 本文提出了一种新的多模态流系统，该系统将多模态大型语言模型（MLLM）嵌入为一等算子，以实现跨多种模态的实时查询处理。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态查询数据库方法无法满足流系统的严格延迟和吞吐量要求。

Method: 该方法提出了逻辑、物理和语义查询转换等多个层面的优化，以减少模型负载，提高吞吐量，同时保持准确性。

Result: 通过原型系统\[系统名]的实验表明，该优化方法可以将性能提高一个数量级以上。

Conclusion: 本文为构建可扩展且高效的多模态流处理系统提出了一个研究路线图，概述了开放的研究挑战。

Abstract: 本文提出了一种新型的多模态流系统愿景，该系统将多模态大型语言模型（MLLM）嵌入为一等算子，从而能够跨多种模态进行实时查询处理。实现这一目标并非易事：虽然最近的研究工作已将MLLM集成到数据库中以进行多模态查询，但流系统由于其严格的延迟和吞吐量要求，需要从根本上不同的方法。我们的方法提出了在逻辑、物理和语义查询转换等各个层面的新型优化，从而减少模型负载，提高吞吐量，同时保持准确性。我们通过原型系统\[系统名]展示了这一点，该原型系统利用这些优化将性能提高了一个数量级以上。此外，我们还讨论了一个研究路线图，概述了构建可扩展且高效的多模态流处理系统的开放研究挑战。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.14631) | **Categories:** cs.DB

---
