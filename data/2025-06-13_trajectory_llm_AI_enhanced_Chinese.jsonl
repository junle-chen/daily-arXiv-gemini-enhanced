{"id": "2506.09985", "pdf": "https://arxiv.org/pdf/2506.09985", "abs": "https://arxiv.org/abs/2506.09985", "authors": ["Mido Assran", "Adrien Bardes", "David Fan", "Quentin Garrido", "Russell Howes", "Mojtaba", "Komeili", "Matthew Muckley", "Ammar Rizvi", "Claire Roberts", "Koustuv Sinha", "Artem Zholus", "Sergio Arnaud", "Abha Gejji", "Ada Martin", "Francois Robert Hogan", "Daniel Dugas", "Piotr Bojanowski", "Vasil Khalidov", "Patrick Labatut", "Francisco Massa", "Marc Szafraniec", "Kapil Krishnakumar", "Yong Li", "Xiaodong Ma", "Sarath Chandar", "Franziska Meier", "Yann LeCun", "Michael Rabbat", "Nicolas Ballas"], "title": "V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "comment": "48 pages, 19 figures", "summary": "A major challenge for modern AI is to learn to understand the world and learn\nto act largely by observation. This paper explores a self-supervised approach\nthat combines internet-scale video data with a small amount of interaction data\n(robot trajectories), to develop models capable of understanding, predicting,\nand planning in the physical world. We first pre-train an action-free\njoint-embedding-predictive architecture, V-JEPA 2, on a video and image dataset\ncomprising over 1 million hours of internet video. V-JEPA 2 achieves strong\nperformance on motion understanding (77.3 top-1 accuracy on Something-Something\nv2) and state-of-the-art performance on human action anticipation (39.7\nrecall-at-5 on Epic-Kitchens-100) surpassing previous task-specific models.\nAdditionally, after aligning V-JEPA 2 with a large language model, we\ndemonstrate state-of-the-art performance on multiple video question-answering\ntasks at the 8 billion parameter scale (e.g., 84.0 on PerceptionTest, 76.9 on\nTempCompass). Finally, we show how self-supervised learning can be applied to\nrobotic planning tasks by post-training a latent action-conditioned world\nmodel, V-JEPA 2-AC, using less than 62 hours of unlabeled robot videos from the\nDroid dataset. We deploy V-JEPA 2-AC zero-shot on Franka arms in two different\nlabs and enable picking and placing of objects using planning with image goals.\nNotably, this is achieved without collecting any data from the robots in these\nenvironments, and without any task-specific training or reward. This work\ndemonstrates how self-supervised learning from web-scale data and a small\namount of robot interaction data can yield a world model capable of planning in\nthe physical world.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "This paper is highly relevant because it explicitly discusses prediction and planning in the context of video data and robot trajectories. Furthermore, it integrates a large language model and explores its application to robotic planning, connecting both trajectory prediction and large language models.", "keywords": ["prediction", "planning", "robot trajectories", "large language model", "world model", "action anticipation"]}, "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e92\u8054\u7f51\u89c6\u9891\u548c\u5c11\u91cf\u673a\u5668\u4eba\u4ea4\u4e92\u6570\u636e\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u80fd\u591f\u5728\u7269\u7406\u4e16\u754c\u4e2d\u8fdb\u884c\u89c4\u5212\u7684\u4e16\u754c\u6a21\u578b\u3002", "motivation": "\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u5b66\u4e60\u7406\u89e3\u4e16\u754c\uff0c\u5e76\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u901a\u8fc7\u89c2\u5bdf\u6765\u5b66\u4e60\u884c\u52a8\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e92\u8054\u7f51\u89c4\u6a21\u7684\u89c6\u9891\u6570\u636e\u548c\u5c11\u91cf\u7684\u4ea4\u4e92\u6570\u636e\uff08\u673a\u5668\u4eba\u8f68\u8ff9\uff09\uff0c\u4ee5\u5f00\u53d1\u80fd\u591f\u7406\u89e3\u3001\u9884\u6d4b\u548c\u89c4\u5212\u7269\u7406\u4e16\u754c\u7684\u6a21\u578b\u3002", "method": "\u8be5\u7814\u7a76\u9996\u5148\u5728\u5305\u542b\u8d85\u8fc7100\u4e07\u5c0f\u65f6\u4e92\u8054\u7f51\u89c6\u9891\u7684\u89c6\u9891\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u4e00\u4e2a\u65e0\u52a8\u4f5c\u7684\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784V-JEPA 2\uff0c\u7136\u540e\u5728Droid\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u4e0d\u523062\u5c0f\u65f6\u7684\u65e0\u6807\u7b7e\u673a\u5668\u4eba\u89c6\u9891\u5bf9\u4e00\u4e2a\u6f5c\u5728\u7684\u52a8\u4f5c\u6761\u4ef6\u4e16\u754c\u6a21\u578bV-JEPA 2-AC\u8fdb\u884c\u540e\u8bad\u7ec3\u3002", "result": "V-JEPA 2 \u5728\u8fd0\u52a8\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u5f3a\u5927\u7684\u6027\u80fd\uff08\u5728 Something-Something v2 \u4e0a\u8fbe\u5230 77.3 \u7684 top-1 \u51c6\u786e\u7387\uff09\uff0c\u5e76\u5728\u4eba\u7c7b\u52a8\u4f5c\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff08\u5728 Epic-Kitchens-100 \u4e0a\u8fbe\u5230 39.7 \u7684 recall-at-5\uff09\uff0c\u8d85\u8fc7\u4e86\u4ee5\u524d\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u5728\u5c06 V-JEPA 2 \u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u540e\uff0c\u6211\u4eec\u5728 80 \u4ebf\u53c2\u6570\u89c4\u6a21\u7684\u591a\u4e2a\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff08\u4f8b\u5982\uff0c\u5728 PerceptionTest \u4e0a\u4e3a 84.0\uff0c\u5728 TempCompass \u4e0a\u4e3a 76.9\uff09\u3002\u6700\u540e\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4f7f\u7528\u6765\u81ea Droid \u6570\u636e\u96c6\u7684\u4e0d\u5230 62 \u5c0f\u65f6\u7684\u65e0\u6807\u7b7e\u673a\u5668\u4eba\u89c6\u9891\u5bf9\u6f5c\u5728\u7684\u52a8\u4f5c\u6761\u4ef6\u4e16\u754c\u6a21\u578b V-JEPA 2-AC \u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u5c06\u81ea\u76d1\u7763\u5b66\u4e60\u5e94\u7528\u4e8e\u673a\u5668\u4eba\u89c4\u5212\u4efb\u52a1\u3002\u6211\u4eec\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u5b9e\u9a8c\u5ba4\u4e2d\u96f6\u6837\u672c\u90e8\u7f72 V-JEPA 2-AC \u5728 Franka \u673a\u68b0\u81c2\u4e0a\uff0c\u5e76\u80fd\u591f\u4f7f\u7528\u56fe\u50cf\u76ee\u6807\u8fdb\u884c\u89c4\u5212\u6765\u62fe\u53d6\u548c\u653e\u7f6e\u7269\u4f53\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u662f\u5728\u6ca1\u6709\u4ece\u8fd9\u4e9b\u73af\u5883\u4e2d\u7684\u673a\u5668\u4eba\u6536\u96c6\u4efb\u4f55\u6570\u636e\uff0c\u5e76\u4e14\u6ca1\u6709\u4efb\u4f55\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u8bad\u7ec3\u6216\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7684\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u7f51\u7edc\u89c4\u6a21\u7684\u89c6\u9891\u6570\u636e\u548c\u5c11\u91cf\u673a\u5668\u4eba\u4ea4\u4e92\u6570\u636e\uff0c\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u80fd\u591f\u5728\u7269\u7406\u4e16\u754c\u4e2d\u8fdb\u884c\u89c4\u5212\u7684\u4e16\u754c\u6a21\u578b\u3002", "summary_zh": "\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u9762\u4e34\u7684\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\u662f\u5b66\u4e60\u7406\u89e3\u4e16\u754c\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u89c2\u5bdf\u6765\u5b66\u4e60\u884c\u52a8\u3002\u672c\u6587\u63a2\u7d22\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e92\u8054\u7f51\u89c4\u6a21\u7684\u89c6\u9891\u6570\u636e\u548c\u5c11\u91cf\u7684\u4ea4\u4e92\u6570\u636e\uff08\u673a\u5668\u4eba\u8f68\u8ff9\uff09\uff0c\u4ee5\u5f00\u53d1\u80fd\u591f\u7406\u89e3\u3001\u9884\u6d4b\u548c\u89c4\u5212\u7269\u7406\u4e16\u754c\u7684\u6a21\u578b\u3002\u6211\u4eec\u9996\u5148\u5728\u5305\u542b\u8d85\u8fc7 100 \u4e07\u5c0f\u65f6\u4e92\u8054\u7f51\u89c6\u9891\u7684\u89c6\u9891\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u4e00\u4e2a\u65e0\u52a8\u4f5c\u7684\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784 V-JEPA 2\u3002V-JEPA 2 \u5728\u8fd0\u52a8\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u5f3a\u5927\u7684\u6027\u80fd\uff08\u5728 Something-Something v2 \u4e0a\u8fbe\u5230 77.3 \u7684 top-1 \u51c6\u786e\u7387\uff09\uff0c\u5e76\u5728\u4eba\u7c7b\u52a8\u4f5c\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff08\u5728 Epic-Kitchens-100 \u4e0a\u8fbe\u5230 39.7 \u7684 recall-at-5\uff09\uff0c\u8d85\u8fc7\u4e86\u4ee5\u524d\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u5728\u5c06 V-JEPA 2 \u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u540e\uff0c\u6211\u4eec\u5728 80 \u4ebf\u53c2\u6570\u89c4\u6a21\u7684\u591a\u4e2a\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff08\u4f8b\u5982\uff0c\u5728 PerceptionTest \u4e0a\u4e3a 84.0\uff0c\u5728 TempCompass \u4e0a\u4e3a 76.9\uff09\u3002\u6700\u540e\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4f7f\u7528\u6765\u81ea Droid \u6570\u636e\u96c6\u7684\u4e0d\u5230 62 \u5c0f\u65f6\u7684\u65e0\u6807\u7b7e\u673a\u5668\u4eba\u89c6\u9891\u5bf9\u6f5c\u5728\u7684\u52a8\u4f5c\u6761\u4ef6\u4e16\u754c\u6a21\u578b V-JEPA 2-AC \u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u5c06\u81ea\u76d1\u7763\u5b66\u4e60\u5e94\u7528\u4e8e\u673a\u5668\u4eba\u89c4\u5212\u4efb\u52a1\u3002\u6211\u4eec\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u5b9e\u9a8c\u5ba4\u4e2d\u96f6\u6837\u672c\u90e8\u7f72 V-JEPA 2-AC \u5728 Franka \u673a\u68b0\u81c2\u4e0a\uff0c\u5e76\u80fd\u591f\u4f7f\u7528\u56fe\u50cf\u76ee\u6807\u8fdb\u884c\u89c4\u5212\u6765\u62fe\u53d6\u548c\u653e\u7f6e\u7269\u4f53\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u662f\u5728\u6ca1\u6709\u4ece\u8fd9\u4e9b\u73af\u5883\u4e2d\u7684\u673a\u5668\u4eba\u6536\u96c6\u4efb\u4f55\u6570\u636e\uff0c\u5e76\u4e14\u6ca1\u6709\u4efb\u4f55\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u8bad\u7ec3\u6216\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7684\u3002\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u7f51\u7edc\u89c4\u6a21\u6570\u636e\u548c\u5c11\u91cf\u673a\u5668\u4eba\u4ea4\u4e92\u6570\u636e\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u4ea7\u751f\u4e00\u4e2a\u80fd\u591f\u5728\u7269\u7406\u4e16\u754c\u4e2d\u8fdb\u884c\u89c4\u5212\u7684\u4e16\u754c\u6a21\u578b\u3002"}}
{"id": "2506.09485", "pdf": "https://arxiv.org/pdf/2506.09485", "abs": "https://arxiv.org/abs/2506.09485", "authors": ["Yuxin Liu", "Zhenghao Peng", "Xuanhao Cui", "Bolei Zhou"], "title": "Adv-BMT: Bidirectional Motion Transformer for Safety-Critical Traffic Scenario Generation", "categories": ["cs.RO", "cs.AI", "cs.GR"], "comment": null, "summary": "Scenario-based testing is essential for validating the performance of\nautonomous driving (AD) systems. However, such testing is limited by the\nscarcity of long-tailed, safety-critical scenarios in existing datasets\ncollected in the real world. To tackle the data issue, we propose the Adv-BMT\nframework, which augments real-world scenarios with diverse and realistic\nadversarial interactions. The core component of Adv-BMT is a bidirectional\nmotion transformer (BMT) model to perform inverse traffic motion predictions,\nwhich takes agent information in the last time step of the scenario as input,\nand reconstruct the traffic in the inverse of chronological order until the\ninitial time step. The Adv-BMT framework is a two-staged pipeline: it first\nconducts adversarial initializations and then inverse motion predictions.\nDifferent from previous work, we do not need any collision data for\npretraining, and are able to generate realistic and diverse collision\ninteractions. Our experimental results validate the quality of generated\ncollision scenarios by Adv-BMT: training in our augmented dataset would reduce\nepisode collision rates by 20\\% compared to previous work.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u4ea4\u901a\u573a\u666f\u751f\u6210\uff0c\u4f7f\u7528\u4e86Motion Transformer\u8fdb\u884c\u9006\u5411\u8fd0\u52a8\u9884\u6d4b\uff0c\u5c5e\u4e8e\u8f68\u8ff9\u9884\u6d4b\u9886\u57df\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46Transformer\u6a21\u578b\u672c\u8eab\u662f\u5927\u578b\u6a21\u578b\u7684\u57fa\u7840\uff0c\u4e14\u8be5\u5de5\u4f5c\u4e0e\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u76f8\u5173\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u56e0\u6b64\u5177\u6709\u4e2d\u7b49\u504f\u4e0a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["trajectory prediction", "motion transformer", "autonomous driving", "traffic scenario generation", "motion prediction"]}, "AI": {"tldr": "Adv-BMT \u6846\u67b6\u901a\u8fc7\u9006\u5411\u9884\u6d4b\u4ea4\u901a\u8fd0\u52a8\u6765\u589e\u5f3a\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\uff0c\u6709\u6548\u964d\u4f4e\u78b0\u649e\u7387\u3002", "motivation": "\u57fa\u4e8e\u573a\u666f\u7684\u6d4b\u8bd5\u5bf9\u4e8e\u9a8c\u8bc1\u81ea\u52a8\u9a7e\u9a76 (AD) \u7cfb\u7edf\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u6d4b\u8bd5\u53d7\u5230\u73b0\u5b9e\u4e16\u754c\u4e2d\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u7a00\u7f3a\u7684\u957f\u5c3e\u3001\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86 Adv-BMT \u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u53cc\u5411\u8fd0\u52a8 Transformer (BMT) \u6a21\u578b\u6267\u884c\u9006\u5411\u4ea4\u901a\u8fd0\u52a8\u9884\u6d4b\uff0c\u4ee5\u589e\u5f3a\u771f\u5b9e\u4e16\u754c\u7684\u573a\u666f\u4e0e\u591a\u6837\u5316\u548c\u73b0\u5b9e\u7684\u5bf9\u6297\u6027\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86 Adv-BMT \u751f\u6210\u7684\u78b0\u649e\u573a\u666f\u7684\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7\u5728\u589e\u5f3a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e0e\u4e4b\u524d\u7684\u5de5\u4f5c\u76f8\u6bd4\uff0c\u78b0\u649e\u7387\u964d\u4f4e\u4e86 20%\u3002", "summary_zh": "\u57fa\u4e8e\u573a\u666f\u7684\u6d4b\u8bd5\u5bf9\u4e8e\u9a8c\u8bc1\u81ea\u52a8\u9a7e\u9a76 (AD) \u7cfb\u7edf\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u6d4b\u8bd5\u53d7\u5230\u73b0\u5b9e\u4e16\u754c\u4e2d\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u7a00\u7f3a\u7684\u957f\u5c3e\u3001\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u9650\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u6570\u636e\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Adv-BMT \u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u591a\u6837\u5316\u548c\u73b0\u5b9e\u7684\u5bf9\u6297\u6027\u4ea4\u4e92\u6765\u589e\u5f3a\u771f\u5b9e\u4e16\u754c\u7684\u573a\u666f\u3002Adv-BMT \u7684\u6838\u5fc3\u7ec4\u4ef6\u662f\u4e00\u4e2a\u53cc\u5411\u8fd0\u52a8 Transformer (BMT) \u6a21\u578b\uff0c\u7528\u4e8e\u6267\u884c\u9006\u5411\u4ea4\u901a\u8fd0\u52a8\u9884\u6d4b\uff0c\u5b83\u4ee5\u573a\u666f\u4e2d\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u667a\u80fd\u4f53\u4fe1\u606f\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u4ee5\u65f6\u95f4\u987a\u5e8f\u7684\u9006\u5411\u91cd\u5efa\u4ea4\u901a\uff0c\u76f4\u5230\u521d\u59cb\u65f6\u95f4\u6b65\u3002Adv-BMT \u6846\u67b6\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u6d41\u6c34\u7ebf\uff1a\u5b83\u9996\u5148\u8fdb\u884c\u5bf9\u6297\u6027\u521d\u59cb\u5316\uff0c\u7136\u540e\u8fdb\u884c\u9006\u5411\u8fd0\u52a8\u9884\u6d4b\u3002\u4e0e\u4e4b\u524d\u7684\u5de5\u4f5c\u4e0d\u540c\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u4efb\u4f55\u78b0\u649e\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5e76\u4e14\u80fd\u591f\u751f\u6210\u771f\u5b9e\u548c\u591a\u6837\u5316\u7684\u78b0\u649e\u4ea4\u4e92\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86 Adv-BMT \u751f\u6210\u7684\u78b0\u649e\u573a\u666f\u7684\u8d28\u91cf\uff1a\u5728\u6211\u4eec\u7684\u589e\u5f3a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u5c06\u6bd4\u4e4b\u524d\u7684\u5de5\u4f5c\u964d\u4f4e 20% \u7684\u78b0\u649e\u7387\u3002"}}
{"id": "2506.09839", "pdf": "https://arxiv.org/pdf/2506.09839", "abs": "https://arxiv.org/abs/2506.09839", "authors": ["Chen Gao", "Liankai Jin", "Xingyu Peng", "Jiazhao Zhang", "Yue Deng", "Annan Li", "He Wang", "Si Liu"], "title": "OctoNav: Towards Generalist Embodied Navigation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "31 pages, 25 figures", "summary": "Embodied navigation stands as a foundation pillar within the broader pursuit\nof embodied AI. However, previous navigation research is divided into different\ntasks/capabilities, e.g., ObjNav, ImgNav and VLN, where they differ in task\nobjectives and modalities, making datasets and methods are designed\nindividually. In this work, we take steps toward generalist navigation agents,\nwhich can follow free-form instructions that include arbitrary compounds of\nmulti-modal and multi-capability. To achieve this, we propose a large-scale\nbenchmark and corresponding method, termed OctoNav-Bench and OctoNav-R1.\nSpecifically, OctoNav-Bench features continuous environments and is constructed\nvia a designed annotation pipeline. We thoroughly craft instruction-trajectory\npairs, where instructions are diverse in free-form with arbitrary modality and\ncapability. Also, we construct a Think-Before-Action (TBA-CoT) dataset within\nOctoNav-Bench to provide the thinking process behind actions. For OctoNav-R1,\nwe build it upon MLLMs and adapt it to a VLA-type model, which can produce\nlow-level actions solely based on 2D visual observations. Moreover, we design a\nHybrid Training Paradigm (HTP) that consists of three stages, i.e.,\nAction-/TBA-SFT, Nav-GPRO, and Online RL stages. Each stage contains\nspecifically designed learning policies and rewards. Importantly, for TBA-SFT\nand Nav-GRPO designs, we are inspired by the OpenAI-o1 and DeepSeek-R1, which\nshow impressive reasoning ability via thinking-before-answer. Thus, we aim to\ninvestigate how to achieve thinking-before-action in the embodied navigation\nfield, to improve model's reasoning ability toward generalists. Specifically,\nwe propose TBA-SFT to utilize the TBA-CoT dataset to fine-tune the model as a\ncold-start phrase and then leverage Nav-GPRO to improve its thinking ability.\nFinally, OctoNav-R1 shows superior performance compared with previous methods.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper focuses on embodied navigation, which is related to trajectory prediction. It also leverages and adapts Multi-Modal Large Language Models (MLLMs) and is inspired by large models like OpenAI-o1 and DeepSeek-R1. Therefore, it has a significant relevance to both trajectory prediction and large language models.", "keywords": ["embodied navigation", "trajectory", "large language models", "MLLMs", "foundation models", "reasoning", "action prediction"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86 OctoNav-Bench \u548c OctoNav-R1\uff0c\u65e8\u5728\u6784\u5efa\u80fd\u591f\u9075\u5faa\u590d\u6742\u6307\u4ee4\u7684\u901a\u7528\u5177\u8eab\u5bfc\u822a\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u201c\u884c\u52a8\u524d\u601d\u8003\u201d\u63d0\u9ad8\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4ee5\u5f80\u7684\u5bfc\u822a\u7814\u7a76\u88ab\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u4efb\u52a1/\u80fd\u529b\uff0c\u4f8b\u5982ObjNav\u3001ImgNav\u548cVLN\uff0c\u5b83\u4eec\u5728\u4efb\u52a1\u76ee\u6807\u548c\u6a21\u6001\u4e0a\u6709\u6240\u4e0d\u540c\uff0c\u4f7f\u5f97\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u90fd\u662f\u5355\u72ec\u8bbe\u8ba1\u7684\u3002\u672c\u6587\u65e8\u5728\u6784\u5efa\u80fd\u591f\u9075\u5faa\u5305\u542b\u591a\u6a21\u6001\u548c\u591a\u80fd\u529b\u4efb\u610f\u7ec4\u5408\u7684\u81ea\u7531\u5f62\u5f0f\u6307\u4ee4\u7684\u901a\u7528\u5bfc\u822a\u4ee3\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eMLLM\u5e76\u9002\u5e94\u4e8eVLA\u7c7b\u578b\u6a21\u578b\u7684OctoNav-R1\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5305\u542b\u52a8\u4f5c/TBA-SFT\u3001Nav-GPRO\u548c\u5728\u7ebfRL\u4e09\u4e2a\u9636\u6bb5\u7684\u6df7\u5408\u8bad\u7ec3\u8303\u5f0f\uff08HTP\uff09\u3002", "result": "OctoNav-R1 \u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "OctoNav-R1 \u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5177\u8eab\u5bfc\u822a\u9886\u57df\u5b9e\u73b0\u201c\u884c\u52a8\u524d\u601d\u8003\u201d\u7684\u6f5c\u529b\u3002", "summary_zh": "\u5177\u8eab\u5bfc\u822a\u662f\u5177\u8eab\u4eba\u5de5\u667a\u80fd\u7684\u91cd\u8981\u57fa\u77f3\u3002\u7136\u800c\uff0c\u4ee5\u5f80\u7684\u5bfc\u822a\u7814\u7a76\u88ab\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u4efb\u52a1/\u80fd\u529b\uff0c\u4f8b\u5982ObjNav\u3001ImgNav\u548cVLN\uff0c\u5b83\u4eec\u5728\u4efb\u52a1\u76ee\u6807\u548c\u6a21\u6001\u4e0a\u6709\u6240\u4e0d\u540c\uff0c\u4f7f\u5f97\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u90fd\u662f\u5355\u72ec\u8bbe\u8ba1\u7684\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u671d\u7740\u901a\u7528\u5bfc\u822a\u4ee3\u7406\u8fc8\u8fdb\u4e86\u4e00\u6b65\uff0c\u5b83\u53ef\u4ee5\u9075\u5faa\u5305\u542b\u591a\u6a21\u6001\u548c\u591a\u80fd\u529b\u4efb\u610f\u7ec4\u5408\u7684\u81ea\u7531\u5f62\u5f0f\u6307\u4ee4\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u76f8\u5e94\u7684\u65b9\u6cd5\uff0c\u5206\u522b\u79f0\u4e3aOctoNav-Bench\u548cOctoNav-R1\u3002\u5177\u4f53\u6765\u8bf4\uff0cOctoNav-Bench\u5177\u6709\u8fde\u7eed\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u8bbe\u8ba1\u7684\u6807\u6ce8\u6d41\u7a0b\u6784\u5efa\u3002\u6211\u4eec\u7cbe\u5fc3\u5236\u4f5c\u4e86\u6307\u4ee4-\u8f68\u8ff9\u5bf9\uff0c\u5176\u4e2d\u6307\u4ee4\u4ee5\u81ea\u7531\u5f62\u5f0f\u5448\u73b0\uff0c\u5177\u6709\u4efb\u610f\u7684\u6a21\u6001\u548c\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5728OctoNav-Bench\u4e2d\u6784\u5efa\u4e86\u4e00\u4e2a\u201c\u884c\u52a8\u524d\u601d\u8003\u201d\uff08TBA-CoT\uff09\u6570\u636e\u96c6\uff0c\u4ee5\u63d0\u4f9b\u884c\u52a8\u80cc\u540e\u7684\u601d\u8003\u8fc7\u7a0b\u3002\u5bf9\u4e8eOctoNav-R1\uff0c\u6211\u4eec\u4ee5MLLM\u4e3a\u57fa\u7840\uff0c\u5e76\u5c06\u5176\u9002\u914d\u4e3a\u4e00\u4e2aVLA\u7c7b\u578b\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u53ef\u4ee5\u4ec5\u57fa\u4e8e2D\u89c6\u89c9\u89c2\u5bdf\u4ea7\u751f\u4f4e\u7ea7\u52a8\u4f5c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\u7684\u6df7\u5408\u8bad\u7ec3\u8303\u5f0f\uff08HTP\uff09\uff0c\u5373\u52a8\u4f5c/TBA-SFT\u3001Nav-GPRO\u548c\u5728\u7ebfRL\u9636\u6bb5\u3002\u6bcf\u4e2a\u9636\u6bb5\u90fd\u5305\u542b\u4e13\u95e8\u8bbe\u8ba1\u7684\u5b66\u4e60\u7b56\u7565\u548c\u5956\u52b1\u3002\u91cd\u8981\u7684\u662f\uff0c\u5bf9\u4e8eTBA-SFT\u548cNav-GRPO\u7684\u8bbe\u8ba1\uff0c\u6211\u4eec\u53d7\u5230\u4e86OpenAI-o1\u548cDeepSeek-R1\u7684\u542f\u53d1\uff0c\u5b83\u4eec\u901a\u8fc7\u201c\u884c\u52a8\u524d\u601d\u8003\u201d\u5c55\u793a\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u63a8\u7406\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u7814\u7a76\u5982\u4f55\u5728\u5177\u8eab\u5bfc\u822a\u9886\u57df\u5b9e\u73b0\u201c\u884c\u52a8\u524d\u601d\u8003\u201d\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u5bf9\u901a\u7528\u6027\u7684\u63a8\u7406\u80fd\u529b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u63d0\u51faTBA-SFT\u6765\u5229\u7528TBA-CoT\u6570\u636e\u96c6\u6765\u5fae\u8c03\u6a21\u578b\uff0c\u4f5c\u4e3a\u4e00\u4e2a\u51b7\u542f\u52a8\u9636\u6bb5\uff0c\u7136\u540e\u5229\u7528Nav-GPRO\u6765\u63d0\u9ad8\u5176\u601d\u8003\u80fd\u529b\u3002\u6700\u540e\uff0cOctoNav-R1 \u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2506.09981", "pdf": "https://arxiv.org/pdf/2506.09981", "abs": "https://arxiv.org/abs/2506.09981", "authors": ["Jiazhi Yang", "Kashyap Chitta", "Shenyuan Gao", "Long Chen", "Yuqian Shao", "Xiaosong Jia", "Hongyang Li", "Andreas Geiger", "Xiangyu Yue", "Li Chen"], "title": "ReSim: Reliable World Simulation for Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": "Project page: https://opendrivelab.com/ReSim", "summary": "How can we reliably simulate future driving scenarios under a wide range of\nego driving behaviors? Recent driving world models, developed exclusively on\nreal-world driving data composed mainly of safe expert trajectories, struggle\nto follow hazardous or non-expert behaviors, which are rare in such data. This\nlimitation restricts their applicability to tasks such as policy evaluation. In\nthis work, we address this challenge by enriching real-world human\ndemonstrations with diverse non-expert data collected from a driving simulator\n(e.g., CARLA), and building a controllable world model trained on this\nheterogeneous corpus. Starting with a video generator featuring a diffusion\ntransformer architecture, we devise several strategies to effectively integrate\nconditioning signals and improve prediction controllability and fidelity. The\nresulting model, ReSim, enables Reliable Simulation of diverse open-world\ndriving scenarios under various actions, including hazardous non-expert ones.\nTo close the gap between high-fidelity simulation and applications that require\nreward signals to judge different actions, we introduce a Video2Reward module\nthat estimates a reward from ReSim's simulated future. Our ReSim paradigm\nachieves up to 44% higher visual fidelity, improves controllability for both\nexpert and non-expert actions by over 50%, and boosts planning and policy\nselection performance on NAVSIM by 2% and 25%, respectively.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e0b\u7684\u4e16\u754c\u6a21\u62df\uff0c\u5229\u7528diffusion transformer\u67b6\u6784\u8fdb\u884c\u89c6\u9891\u751f\u6210\uff0c\u4ee5\u9884\u6d4b\u672a\u6765\u7684\u9a7e\u9a76\u573a\u666f\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u4f7f\u7528\u4e86Transformer\u67b6\u6784\uff0c\u5e76\u4e14\u4e0e\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u8f68\u8ff9\u9884\u6d4b\uff08\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\uff09\u76f8\u5173\u3002\u540c\u65f6\uff0c\u8bba\u6587\u63d0\u5230\u4e86policy evaluation, planning\u7b49\uff0c\u4e5f\u4e0e\u8f68\u8ff9\u9884\u6d4b\u4e0b\u6e38\u4efb\u52a1\u76f8\u5173\u3002", "keywords": ["autonomous driving", "world model", "trajectory prediction", "diffusion transformer", "policy evaluation", "planning"]}, "AI": {"tldr": "ReSim \u901a\u8fc7\u7ed3\u5408\u771f\u5b9e\u548c\u6a21\u62df\u6570\u636e\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u53ef\u63a7\u7684\u9a7e\u9a76\u4e16\u754c\u6a21\u578b\uff0c\u80fd\u591f\u53ef\u9760\u5730\u6a21\u62df\u5404\u79cd\u9a7e\u9a76\u884c\u4e3a\uff0c\u5e76\u4f7f\u7528 Video2Reward \u6a21\u5757\u4f30\u8ba1\u5956\u52b1\u3002", "motivation": "\u73b0\u6709\u7684\u9a7e\u9a76\u4e16\u754c\u6a21\u578b\u96be\u4ee5\u6a21\u62df\u5371\u9669\u6216\u975e\u4e13\u4e1a\u884c\u4e3a\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u7b56\u7565\u8bc4\u4f30\u7b49\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4e30\u5bcc\u771f\u5b9e\u4e16\u754c\u4eba\u7c7b\u6f14\u793a\u6570\u636e\uff0c\u4f7f\u5176\u5305\u542b\u6765\u81ea\u9a7e\u9a76\u6a21\u62df\u5668\u7684\u5404\u79cd\u975e\u4e13\u4e1a\u6570\u636e\uff0c\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u6269\u6563 Transformer \u67b6\u6784\u7684\u89c6\u9891\u751f\u6210\u5668\uff0c\u5e76\u8bbe\u8ba1\u591a\u79cd\u7b56\u7565\u6765\u6709\u6548\u6574\u5408\u8c03\u8282\u4fe1\u53f7\uff0c\u4ece\u800c\u6784\u5efa\u53ef\u63a7\u7684\u4e16\u754c\u6a21\u578b\u3002", "result": "ReSim \u5728\u89c6\u89c9\u4fdd\u771f\u5ea6\u4e0a\u63d0\u9ad8\u4e86 44%\uff0c\u5bf9\u4e13\u4e1a\u548c\u975e\u4e13\u4e1a\u884c\u4e3a\u7684\u53ef\u63a7\u6027\u63d0\u9ad8\u4e86 50% \u4ee5\u4e0a\uff0c\u5e76\u5728 NAVSIM \u4e0a\u7684\u89c4\u5212\u548c\u7b56\u7565\u9009\u62e9\u6027\u80fd\u5206\u522b\u63d0\u9ad8\u4e86 2% \u548c 25%\u3002", "conclusion": "ReSim \u5b9e\u73b0\u4e86\u5bf9\u5404\u79cd\u5f00\u653e\u4e16\u754c\u9a7e\u9a76\u573a\u666f\u4e0b\u5404\u79cd\u884c\u4e3a\uff08\u5305\u62ec\u5371\u9669\u7684\u975e\u4e13\u4e1a\u884c\u4e3a\uff09\u7684\u53ef\u9760\u6a21\u62df\uff0c\u5e76\u901a\u8fc7 Video2Reward \u6a21\u5757\u4f30\u8ba1\u5956\u52b1\u3002", "summary_zh": "\u5982\u4f55\u53ef\u9760\u5730\u6a21\u62df\u5404\u79cd\u81ea\u6211\u9a7e\u9a76\u884c\u4e3a\u4e0b\u7684\u672a\u6765\u9a7e\u9a76\u573a\u666f\uff1f\u6700\u8fd1\u7684\u9a7e\u9a76\u4e16\u754c\u6a21\u578b\u4ec5\u5728\u771f\u5b9e\u4e16\u754c\u7684\u9a7e\u9a76\u6570\u636e\u4e0a\u5f00\u53d1\uff0c\u8fd9\u4e9b\u6570\u636e\u4e3b\u8981\u7531\u5b89\u5168\u7684\u4e13\u5bb6\u8f68\u8ff9\u7ec4\u6210\uff0c\u96be\u4ee5\u6a21\u62df\u5371\u9669\u6216\u975e\u4e13\u4e1a\u884c\u4e3a\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u884c\u4e3a\u5728\u6570\u636e\u4e2d\u5f88\u5c11\u89c1\u3002\u8fd9\u4e00\u9650\u5236\u9650\u5236\u4e86\u5b83\u4eec\u5728\u7b56\u7565\u8bc4\u4f30\u7b49\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u4ece\u9a7e\u9a76\u6a21\u62df\u5668\uff08\u4f8b\u5982\uff0cCARLA\uff09\u6536\u96c6\u7684\u5404\u79cd\u975e\u4e13\u4e1a\u6570\u636e\u6765\u4e30\u5bcc\u771f\u5b9e\u4e16\u754c\u7684\u4eba\u7c7b\u6f14\u793a\uff0c\u5e76\u6784\u5efa\u4e00\u4e2a\u5728\u6b64\u5f02\u6784\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3\u7684\u53ef\u63a7\u4e16\u754c\u6a21\u578b\uff0c\u4ece\u800c\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002\u4ece\u5177\u6709\u6269\u6563 Transformer \u67b6\u6784\u7684\u89c6\u9891\u751f\u6210\u5668\u5f00\u59cb\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u51e0\u79cd\u7b56\u7565\u6765\u6709\u6548\u5730\u6574\u5408\u8c03\u8282\u4fe1\u53f7\uff0c\u5e76\u63d0\u9ad8\u9884\u6d4b\u7684\u53ef\u63a7\u6027\u548c\u4fdd\u771f\u5ea6\u3002\u7531\u6b64\u4ea7\u751f\u7684\u6a21\u578b ReSim \u80fd\u591f\u5728\u5404\u79cd\u52a8\u4f5c\u4e0b\u53ef\u9760\u5730\u6a21\u62df\u5404\u79cd\u5f00\u653e\u4e16\u754c\u9a7e\u9a76\u573a\u666f\uff0c\u5305\u62ec\u5371\u9669\u7684\u975e\u4e13\u4e1a\u52a8\u4f5c\u3002\u4e3a\u4e86\u7f29\u5c0f\u9ad8\u4fdd\u771f\u6a21\u62df\u4e0e\u9700\u8981\u5956\u52b1\u4fe1\u53f7\u6765\u5224\u65ad\u4e0d\u540c\u52a8\u4f5c\u7684\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a Video2Reward \u6a21\u5757\uff0c\u8be5\u6a21\u5757\u53ef\u4ee5\u4ece ReSim \u6a21\u62df\u7684\u672a\u6765\u4e2d\u4f30\u8ba1\u5956\u52b1\u3002\u6211\u4eec\u7684 ReSim \u8303\u4f8b\u5b9e\u73b0\u4e86\u9ad8\u8fbe 44% \u7684\u89c6\u89c9\u4fdd\u771f\u5ea6\uff0c\u5c06\u4e13\u5bb6\u548c\u975e\u4e13\u5bb6\u884c\u52a8\u7684\u53ef\u63a7\u6027\u63d0\u9ad8\u4e86 50% \u4ee5\u4e0a\uff0c\u5e76\u5206\u522b\u63d0\u9ad8\u4e86 NAVSIM \u4e0a 2% \u548c 25% \u7684\u89c4\u5212\u548c\u7b56\u7565\u9009\u62e9\u6027\u80fd\u3002"}}
{"id": "2506.09557", "pdf": "https://arxiv.org/pdf/2506.09557", "abs": "https://arxiv.org/abs/2506.09557", "authors": ["Zhaoyang Wei", "Chenhui Qiang", "Bowen Jiang", "Xumeng Han", "Xuehui Yu", "Zhenjun Han"], "title": "AD^2-Bench: A Hierarchical CoT Benchmark for MLLM in Autonomous Driving under Adverse Conditions", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Chain-of-Thought (CoT) reasoning has emerged as a powerful approach to\nenhance the structured, multi-step decision-making capabilities of Multi-Modal\nLarge Models (MLLMs), is particularly crucial for autonomous driving with\nadverse weather conditions and complex traffic environments. However, existing\nbenchmarks have largely overlooked the need for rigorous evaluation of CoT\nprocesses in these specific and challenging scenarios. To address this critical\ngap, we introduce AD^2-Bench, the first Chain-of-Thought benchmark specifically\ndesigned for autonomous driving with adverse weather and complex scenes.\nAD^2-Bench is meticulously constructed to fulfill three key criteria:\ncomprehensive data coverage across diverse adverse environments, fine-grained\nannotations that support multi-step reasoning, and a dedicated evaluation\nframework tailored for assessing CoT performance. The core contribution of\nAD^2-Bench is its extensive collection of over 5.4k high-quality, manually\nannotated CoT instances. Each intermediate reasoning step in these annotations\nis treated as an atomic unit with explicit ground truth, enabling unprecedented\nfine-grained analysis of MLLMs' inferential processes under text-level,\npoint-level, and region-level visual prompts. Our comprehensive evaluation of\nstate-of-the-art MLLMs on AD^2-Bench reveals accuracy below 60%, highlighting\nthe benchmark's difficulty and the need to advance robust, interpretable\nend-to-end autonomous driving systems. AD^2-Bench thus provides a standardized\nevaluation platform, driving research forward by improving MLLMs' reasoning in\nautonomous driving, making it an invaluable resource.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u5173\u6ce8\u4e8e\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e0b\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u51b3\u7b56\uff0c\u5e76\u6784\u5efa\u4e86CoT\u57fa\u51c6\u6d4b\u8bd5\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u81ea\u52a8\u9a7e\u9a76\u672c\u8eab\u5c31\u5305\u542b\u8f68\u8ff9\u9884\u6d4b\u8fd9\u4e00\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4e14\u8bba\u6587\u660e\u786e\u63d0\u5230\u4e86MLLM\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["Large Language Models", "MLLM", "Autonomous Driving", "Chain-of-Thought", "CoT"]}, "AI": {"tldr": "AD^2-Bench\u662f\u4e00\u4e2a\u4e13\u4e3a\u6076\u52a3\u5929\u6c14\u548c\u590d\u6742\u573a\u666f\u4e0b\u7684\u81ea\u52a8\u9a7e\u9a76\u8bbe\u8ba1\u7684\u94fe\u5f0f\u601d\u8003\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b5.4k\u4e2a\u624b\u52a8\u6ce8\u91ca\u7684CoT\u5b9e\u4f8b\uff0c\u65e8\u5728\u8bc4\u4f30\u548c\u63d0\u5347MLLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5ffd\u7565\u4e86\u5728\u8fd9\u4e9b\u7279\u5b9a\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\u5bf9CoT\u8fc7\u7a0b\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86AD^2-Bench\uff0c\u4e00\u4e2a\u4e13\u95e8\u4e3a\u6076\u52a3\u5929\u6c14\u548c\u590d\u6742\u573a\u666f\u4e0b\u7684\u81ea\u52a8\u9a7e\u9a76\u8bbe\u8ba1\u7684Chain-of-Thought\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "AD^2-Bench\u5305\u542b\u8d85\u8fc75.4k\u4e2a\u9ad8\u8d28\u91cf\u3001\u624b\u52a8\u6ce8\u91ca\u7684CoT\u5b9e\u4f8b\uff0c\u6bcf\u4e2a\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u90fd\u88ab\u89c6\u4e3a\u4e00\u4e2a\u5177\u6709\u660e\u786eground truth\u7684\u539f\u5b50\u5355\u5143\u3002", "conclusion": "\u5728AD^2-Bench\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u73b0\u6709MLLM\u5728\u6076\u52a3\u5929\u6c14\u548c\u590d\u6742\u573a\u666f\u4e0b\u7684\u81ea\u52a8\u9a7e\u9a76\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\uff0c\u51c6\u786e\u7387\u4f4e\u4e8e60%\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "summary_zh": "\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u63a8\u7406\u5df2\u7ecf\u6210\u4e3a\u4e00\u79cd\u589e\u5f3a\u591a\u6a21\u6001\u5927\u578b\u6a21\u578b\uff08MLLM\uff09\u7684\u7ed3\u6784\u5316\u3001\u591a\u6b65\u9aa4\u51b3\u7b56\u80fd\u529b\u7684\u5f3a\u5927\u65b9\u6cd5\uff0c\u8fd9\u5bf9\u4e8e\u5728\u6076\u52a3\u5929\u6c14\u6761\u4ef6\u548c\u590d\u6742\u4ea4\u901a\u73af\u5883\u4e0b\u7684\u81ea\u52a8\u9a7e\u9a76\u5c24\u4e3a\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5ffd\u7565\u4e86\u5728\u8fd9\u4e9b\u7279\u5b9a\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\u5bf9CoT\u8fc7\u7a0b\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u7684\u9700\u6c42\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u5173\u952e\u5dee\u8ddd\uff0c\u6211\u4eec\u63a8\u51fa\u4e86AD^2-Bench\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u4e13\u95e8\u4e3a\u6076\u52a3\u5929\u6c14\u548c\u590d\u6742\u573a\u666f\u4e0b\u7684\u81ea\u52a8\u9a7e\u9a76\u8bbe\u8ba1\u7684\u94fe\u5f0f\u601d\u8003\u57fa\u51c6\u6d4b\u8bd5\u3002AD^2-Bench\u7684\u7cbe\u5fc3\u6784\u5efa\u662f\u4e3a\u4e86\u6ee1\u8db3\u4e09\u4e2a\u5173\u952e\u6807\u51c6\uff1a\u8de8\u8d8a\u4e0d\u540c\u6076\u52a3\u73af\u5883\u7684\u5168\u9762\u6570\u636e\u8986\u76d6\u3001\u652f\u6301\u591a\u6b65\u9aa4\u63a8\u7406\u7684\u7ec6\u7c92\u5ea6\u6ce8\u91ca\uff0c\u4ee5\u53ca\u4e3a\u8bc4\u4f30CoT\u6027\u80fd\u91cf\u8eab\u5b9a\u5236\u7684\u4e13\u7528\u8bc4\u4f30\u6846\u67b6\u3002AD^2-Bench\u7684\u6838\u5fc3\u8d21\u732e\u662f\u5176\u8d85\u8fc75.4k\u4e2a\u9ad8\u8d28\u91cf\u3001\u624b\u52a8\u6ce8\u91ca\u7684CoT\u5b9e\u4f8b\u7684\u5e7f\u6cdb\u96c6\u5408\u3002\u8fd9\u4e9b\u6ce8\u91ca\u4e2d\u7684\u6bcf\u4e2a\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u90fd\u88ab\u89c6\u4e3a\u4e00\u4e2a\u5177\u6709\u660e\u786eground truth\u7684\u539f\u5b50\u5355\u5143\uff0c\u4ece\u800c\u80fd\u591f\u5bf9MLLM\u5728\u6587\u672c\u7ea7\u522b\u3001\u70b9\u7ea7\u522b\u548c\u533a\u57df\u7ea7\u522b\u89c6\u89c9\u63d0\u793a\u4e0b\u7684\u63a8\u7406\u8fc7\u7a0b\u8fdb\u884c\u524d\u6240\u672a\u6709\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u3002\u6211\u4eec\u5bf9\u6700\u5148\u8fdb\u7684MLLM\u5728AD^2-Bench\u4e0a\u7684\u5168\u9762\u8bc4\u4f30\u663e\u793a\uff0c\u51c6\u786e\u7387\u4f4e\u4e8e60%\uff0c\u8fd9\u7a81\u663e\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u96be\u5ea6\u4ee5\u53ca\u63a8\u8fdb\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5fc5\u8981\u6027\u3002\u56e0\u6b64\uff0cAD^2-Bench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u5e73\u53f0\uff0c\u901a\u8fc7\u6539\u8fdbMLLM\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u63a8\u7406\u6765\u63a8\u52a8\u7814\u7a76\uff0c\u4f7f\u5176\u6210\u4e3a\u4e00\u79cd\u5b9d\u8d35\u7684\u8d44\u6e90\u3002"}}
{"id": "2506.09626", "pdf": "https://arxiv.org/pdf/2506.09626", "abs": "https://arxiv.org/abs/2506.09626", "authors": ["Giacomo Rosin", "Muhammad Rameez Ur Rahman", "Sebastiano Vascon"], "title": "ECAM: A Contrastive Learning Approach to Avoid Environmental Collision in Trajectory Forecasting", "categories": ["cs.CV"], "comment": "IJCNN 2025", "summary": "Human trajectory forecasting is crucial in applications such as autonomous\ndriving, robotics and surveillance. Accurate forecasting requires models to\nconsider various factors, including social interactions, multi-modal\npredictions, pedestrian intention and environmental context. While existing\nmethods account for these factors, they often overlook the impact of the\nenvironment, which leads to collisions with obstacles. This paper introduces\nECAM (Environmental Collision Avoidance Module), a contrastive learning-based\nmodule to enhance collision avoidance ability with the environment. The\nproposed module can be integrated into existing trajectory forecasting models,\nimproving their ability to generate collision-free predictions. We evaluate our\nmethod on the ETH/UCY dataset and quantitatively and qualitatively demonstrate\nits collision avoidance capabilities. Our experiments show that\nstate-of-the-art methods significantly reduce (-40/50%) the collision rate when\nintegrated with the proposed module. The code is available at\nhttps://github.com/CVML-CFU/ECAM.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper focuses on trajectory forecasting, specifically addressing collision avoidance in human trajectory prediction. While it doesn't directly involve Large Language Models, the core topic of trajectory prediction is highly relevant.", "keywords": ["trajectory forecasting", "collision avoidance", "human trajectory prediction", "environmental context"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aECAM\u7684\u73af\u5883\u907f\u78b0\u6a21\u5757\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u907f\u78b0\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u73af\u5883\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u4e0e\u969c\u788d\u7269\u53d1\u751f\u78b0\u649e\u3002", "method": "\u63d0\u51fa\u4e86ECAM\uff08\u73af\u5883\u907f\u78b0\u6a21\u5757\uff09\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u6a21\u5757\uff0c\u4ee5\u589e\u5f3a\u73af\u5883\u907f\u78b0\u80fd\u529b\u3002", "result": "\u5728ETH/UCY\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u4e0a\u90fd\u5c55\u793a\u4e86\u5176\u907f\u78b0\u80fd\u529b\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u96c6\u6210\u540e\uff0c\u78b0\u649e\u7387\u663e\u8457\u964d\u4f4e\uff08-40/50%\uff09\u3002", "conclusion": "\u901a\u8fc7\u4e0eECAM\u6a21\u5757\u96c6\u6210\uff0c\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u78b0\u649e\u7387\uff08-40/50%\uff09\u3002", "summary_zh": "\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\u5728\u81ea\u52a8\u9a7e\u9a76\u3001\u673a\u5668\u4eba\u548c\u76d1\u63a7\u7b49\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u7cbe\u786e\u7684\u9884\u6d4b\u9700\u8981\u6a21\u578b\u8003\u8651\u5404\u79cd\u56e0\u7d20\uff0c\u5305\u62ec\u793e\u4f1a\u4e92\u52a8\u3001\u591a\u6a21\u6001\u9884\u6d4b\u3001\u884c\u4eba\u610f\u56fe\u548c\u73af\u5883\u80cc\u666f\u3002\u867d\u7136\u73b0\u6709\u65b9\u6cd5\u8003\u8651\u4e86\u8fd9\u4e9b\u56e0\u7d20\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u5ffd\u7565\u4e86\u73af\u5883\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u4e0e\u969c\u788d\u7269\u53d1\u751f\u78b0\u649e\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aECAM\uff08\u73af\u5883\u907f\u78b0\u6a21\u5757\uff09\u7684\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u6a21\u5757\uff0c\u4ee5\u589e\u5f3a\u73af\u5883\u907f\u78b0\u80fd\u529b\u3002\u6240\u63d0\u51fa\u7684\u6a21\u5757\u53ef\u4ee5\u96c6\u6210\u5230\u73b0\u6709\u7684\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u4e2d\uff0c\u63d0\u9ad8\u5176\u751f\u6210\u65e0\u78b0\u649e\u9884\u6d4b\u7684\u80fd\u529b\u3002\u6211\u4eec\u5728ETH/UCY\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9a\u91cf\u548c\u5b9a\u6027\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u907f\u78b0\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6240\u63d0\u51fa\u7684\u6a21\u5757\u96c6\u6210\u540e\uff0c\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\uff08-40/50%\uff09\u78b0\u649e\u7387\u3002\u4ee3\u7801\u53ef\u5728https://github.com/CVML-CFU/ECAM\u83b7\u53d6\u3002"}}
{"id": "2506.09498", "pdf": "https://arxiv.org/pdf/2506.09498", "abs": "https://arxiv.org/abs/2506.09498", "authors": ["Jaesik Yoon", "Hyeonseo Cho", "Yoshua Bengio", "Sungjin Ahn"], "title": "Fast Monte Carlo Tree Diffusion: 100x Speedup via Parallel Sparse Planning", "categories": ["cs.AI"], "comment": null, "summary": "Diffusion models have recently emerged as a powerful approach for trajectory\nplanning. However, their inherently non-sequential nature limits their\neffectiveness in long-horizon reasoning tasks at test time. The recently\nproposed Monte Carlo Tree Diffusion (MCTD) offers a promising solution by\ncombining diffusion with tree-based search, achieving state-of-the-art\nperformance on complex planning problems. Despite its strengths, our analysis\nshows that MCTD incurs substantial computational overhead due to the sequential\nnature of tree search and the cost of iterative denoising. To address this, we\npropose Fast-MCTD, a more efficient variant that preserves the strengths of\nMCTD while significantly improving its speed and scalability. Fast-MCTD\nintegrates two techniques: Parallel MCTD, which enables parallel rollouts via\ndelayed tree updates and redundancy-aware selection; and Sparse MCTD, which\nreduces rollout length through trajectory coarsening. Experiments show that\nFast-MCTD achieves up to 100x speedup over standard MCTD while maintaining or\nimproving planning performance. Remarkably, it even outperforms Diffuser in\ninference speed on some tasks, despite Diffuser requiring no search and\nyielding weaker solutions. These results position Fast-MCTD as a practical and\nscalable solution for diffusion-based inference-time reasoning.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u8f68\u8ff9\u89c4\u5212\uff0c\u5e76\u4f7f\u7528\u4e86Diffusion\u6a21\u578b\uff0cDiffusion\u6a21\u578b\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u751f\u6210\u6a21\u578b\u7684\u4e00\u79cd\uff0c\u4e0e\u5927\u6a21\u578b\u6709\u4e00\u5b9a\u5173\u8054\u3002\u4f46\u8bba\u6587\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u6216\u8005\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u56e0\u6b64\u76f8\u5173\u6027\u4e2d\u7b49\u3002", "keywords": ["trajectory planning", "diffusion models", "Monte Carlo Tree Diffusion", "planning"]}, "AI": {"tldr": "Fast-MCTD \u901a\u8fc7\u5e76\u884c\u5316\u548c\u7a00\u758f\u5316\u663e\u8457\u63d0\u9ad8\u4e86\u8499\u7279\u5361\u6d1b\u6811\u6269\u6563\uff08MCTD\uff09\u7684\u901f\u5ea6\u548c\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u89c4\u5212\u6027\u80fd\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u8f68\u8ff9\u89c4\u5212\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u975e\u5e8f\u5217\u6027\u9650\u5236\u4e86\u5176\u5728\u957f\u65f6\u7a0b\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002MCTD \u901a\u8fc7\u7ed3\u5408\u6269\u6563\u6a21\u578b\u548c\u6811\u641c\u7d22\uff0c\u5728\u590d\u6742\u89c4\u5212\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86 SOTA \u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u8f83\u5927\u3002", "method": "\u63d0\u51fa\u4e86 Fast-MCTD\uff0c\u5b83\u96c6\u6210\u4e86\u4e24\u79cd\u6280\u672f\uff1a\u5e76\u884c MCTD\uff0c\u901a\u8fc7\u5ef6\u8fdf\u6811\u66f4\u65b0\u548c\u5197\u4f59\u611f\u77e5\u9009\u62e9\u5b9e\u73b0\u5e76\u884c rollout\uff1b\u7a00\u758f MCTD\uff0c\u901a\u8fc7\u8f68\u8ff9\u7c97\u5316\u51cf\u5c11 rollout \u957f\u5ea6\u3002", "result": "Fast-MCTD \u6bd4\u6807\u51c6 MCTD \u63d0\u901f\u9ad8\u8fbe 100 \u500d\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u89c4\u5212\u6027\u80fd\u3002\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\uff0c\u5176\u63a8\u7406\u901f\u5ea6\u751a\u81f3\u8d85\u8fc7\u4e86 Diffuser\uff0c\u5c3d\u7ba1 Diffuser \u4e0d\u9700\u8981\u641c\u7d22\u5e76\u4e14\u89e3\u7684\u8d28\u91cf\u8f83\u5dee\u3002", "conclusion": "Fast-MCTD \u662f\u4e00\u79cd\u5b9e\u7528\u7684\u3001\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u6269\u6563\u7684\u63a8\u7406\u65f6\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u5b83\u901a\u8fc7\u5e76\u884c\u5316\u548c\u7a00\u758f\u5316\u663e\u8457\u63d0\u9ad8\u4e86 MCTD \u7684\u901f\u5ea6\u548c\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u89c4\u5212\u6027\u80fd\u3002", "summary_zh": "\u6269\u6563\u6a21\u578b\u6700\u8fd1\u6210\u4e3a\u8f68\u8ff9\u89c4\u5212\u7684\u5f3a\u5927\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u5b83\u4eec\u56fa\u6709\u7684\u975e\u5e8f\u5217\u6027\u8d28\u9650\u5236\u4e86\u5b83\u4eec\u5728\u6d4b\u8bd5\u65f6\u957f\u671f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002\u6700\u8fd1\u63d0\u51fa\u7684\u8499\u7279\u5361\u6d1b\u6811\u6269\u6563\uff08MCTD\uff09\u901a\u8fc7\u5c06\u6269\u6563\u4e0e\u57fa\u4e8e\u6811\u7684\u641c\u7d22\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u590d\u6742\u7684\u89c4\u5212\u95ee\u9898\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u5c3d\u7ba1\u5b83\u6709\u4f18\u52bf\uff0c\u4f46\u6211\u4eec\u7684\u5206\u6790\u8868\u660e\uff0c\u7531\u4e8e\u6811\u641c\u7d22\u7684\u987a\u5e8f\u6027\u8d28\u548c\u8fed\u4ee3\u53bb\u566a\u7684\u6210\u672c\uff0cMCTD \u4ea7\u751f\u4e86\u5927\u91cf\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Fast-MCTD\uff0c\u8fd9\u662f\u4e00\u79cd\u66f4\u6709\u6548\u7684\u53d8\u4f53\uff0c\u5b83\u4fdd\u7559\u4e86 MCTD \u7684\u4f18\u52bf\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u5176\u901f\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u3002Fast-MCTD \u96c6\u6210\u4e86\u4e24\u79cd\u6280\u672f\uff1a\u5e76\u884c MCTD\uff0c\u5b83\u901a\u8fc7\u5ef6\u8fdf\u6811\u66f4\u65b0\u548c\u5197\u4f59\u611f\u77e5\u9009\u62e9\u5b9e\u73b0\u5e76\u884c rollout\uff1b\u7a00\u758f MCTD\uff0c\u5b83\u901a\u8fc7\u8f68\u8ff9\u7c97\u5316\u51cf\u5c11 rollout \u957f\u5ea6\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFast-MCTD \u6bd4\u6807\u51c6 MCTD \u63d0\u901f\u9ad8\u8fbe 100 \u500d\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u89c4\u5212\u6027\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\uff0c\u5b83\u7684\u63a8\u7406\u901f\u5ea6\u751a\u81f3\u8d85\u8fc7\u4e86 Diffuser\uff0c\u5c3d\u7ba1 Diffuser \u4e0d\u9700\u8981\u641c\u7d22\u5e76\u4e14\u4ea7\u751f\u8f83\u5f31\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u4e9b\u7ed3\u679c\u5c06 Fast-MCTD \u5b9a\u4f4d\u4e3a\u4e00\u79cd\u5b9e\u7528\u7684\u3001\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u6269\u6563\u7684\u63a8\u7406\u65f6\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.09061", "pdf": "https://arxiv.org/pdf/2506.09061", "abs": "https://arxiv.org/abs/2506.09061", "authors": ["Alyssa Pinnock", "Shakya Jayakody", "Kawsher A Roxy", "Md Rubel Ahmed"], "title": "EdgeProfiler: A Fast Profiling Framework for Lightweight LLMs on Edge Using Analytical Model", "categories": ["cs.DC", "cs.AI", "cs.PF"], "comment": "4 figures, 7 pages, IEEE conference template", "summary": "This paper introduces EdgeProfiler, a fast profiling framework designed for\nevaluating lightweight Large Language Models (LLMs) on edge systems. While LLMs\noffer remarkable capabilities in natural language understanding and generation,\ntheir high computational, memory, and power requirements often confine them to\ncloud environments. EdgeProfiler addresses these challenges by providing a\nsystematic methodology for assessing LLM performance in resource-constrained\nedge settings. The framework profiles compact LLMs, including TinyLLaMA,\nGemma3.1B, Llama3.2-1B, and DeepSeek-r1-1.5B, using aggressive quantization\ntechniques and strict memory constraints. Analytical modeling is used to\nestimate latency, FLOPs, and energy consumption. The profiling reveals that\n4-bit quantization reduces model memory usage by approximately 60-70%, while\nmaintaining accuracy within 2-5% of full-precision baselines. Inference speeds\nare observed to improve by 2-3x compared to FP16 baselines across various edge\ndevices. Power modeling estimates a 35-50% reduction in energy consumption for\nINT4 configurations, enabling practical deployment on hardware such as\nRaspberry Pi 4/5 and Jetson Orin Nano Super. Our findings emphasize the\nimportance of efficient profiling tailored to lightweight LLMs in edge\nenvironments, balancing accuracy, energy efficiency, and computational\nfeasibility.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on profiling lightweight LLMs for edge devices. While it doesn't directly deal with trajectory prediction, it heavily involves Large Language Models and their optimization for resource-constrained environments, which is a relevant area in the broader context of applying LLMs to robotics and autonomous systems that might also perform trajectory prediction.", "keywords": ["Large Language Models", "LLMs", "edge systems", "quantization", "inference", "energy consumption"]}, "AI": {"tldr": "EdgeProfiler\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8f7b\u91cf\u7ea7LLM\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u6027\u80fd\u7684\u5feb\u901fProfiling\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5316\u548c\u5efa\u6a21\u5b9e\u73b0\u7cbe\u5ea6\u3001\u80fd\u6548\u548c\u8ba1\u7b97\u53ef\u884c\u6027\u7684\u5e73\u8861\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u867d\u7136\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u8ba1\u7b97\u3001\u5185\u5b58\u548c\u529f\u8017\u9700\u6c42\u901a\u5e38\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4e91\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002EdgeProfiler\u65e8\u5728\u89e3\u51b3\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u6027\u80fd\u7684\u6311\u6218\u3002", "method": "EdgeProfiler\u6846\u67b6\u901a\u8fc7\u91c7\u7528\u6fc0\u8fdb\u7684\u91cf\u5316\u6280\u672f\u548c\u4e25\u683c\u7684\u5185\u5b58\u7ea6\u675f\uff0c\u5bf9\u8f7b\u91cf\u7ea7LLM\uff08\u5982TinyLLaMA\u3001Gemma3.1B\u7b49\uff09\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u6027\u80fd\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4f7f\u7528\u5206\u6790\u5efa\u6a21\u6765\u4f30\u8ba1\u5ef6\u8fdf\u3001FLOPs\u548c\u80fd\u8017\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c4\u6bd4\u7279\u91cf\u5316\u53ef\u4ee5\u5c06\u6a21\u578b\u5185\u5b58\u4f7f\u7528\u91cf\u51cf\u5c11\u7ea660-70%\uff0c\u540c\u65f6\u4fdd\u6301\u7cbe\u5ea6\u5728\u5168\u7cbe\u5ea6\u57fa\u7ebf\u76842-5%\u4ee5\u5185\u3002\u63a8\u7406\u901f\u5ea6\u6bd4FP16\u57fa\u7ebf\u63d0\u9ad8\u4e862-3\u500d\u3002\u529f\u8017\u5efa\u6a21\u4f30\u8ba1INT4\u914d\u7f6e\u7684\u80fd\u8017\u964d\u4f4e\u4e8635-50%\u3002", "conclusion": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u8f7b\u91cf\u7ea7LLM\u9700\u8981\u4ed4\u7ec6\u6743\u8861\u7cbe\u5ea6\u3001\u80fd\u6548\u548c\u8ba1\u7b97\u53ef\u884c\u6027\uff0c\u800cEdgeProfiler\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "summary_zh": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5feb\u901fProfiling\u6846\u67b6EdgeProfiler\uff0c\u7528\u4e8e\u8bc4\u4f30\u8fb9\u7f18\u7cfb\u7edf\u4e0a\u7684\u8f7b\u91cf\u7ea7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3002\u867d\u7136LLM\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u63d0\u4f9b\u4e86\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u4f46\u5b83\u4eec\u7684\u9ad8\u8ba1\u7b97\u3001\u5185\u5b58\u548c\u529f\u8017\u9700\u6c42\u901a\u5e38\u5c06\u5b83\u4eec\u9650\u5236\u5728\u4e91\u73af\u5883\u4e2d\u3002EdgeProfiler\u901a\u8fc7\u63d0\u4f9b\u4e00\u79cd\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\u4e2d\u7684LLM\u6027\u80fd\uff0c\u4ece\u800c\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u6fc0\u8fdb\u7684\u91cf\u5316\u6280\u672f\u548c\u4e25\u683c\u7684\u5185\u5b58\u7ea6\u675f\u6765\u5206\u6790\u5c0f\u578bLLM\uff08\u5305\u62ecTinyLLaMA\u3001Gemma3.1B\u3001Llama3.2-1B\u548cDeepSeek-r1-1.5B\uff09\u3002\u5206\u6790\u5efa\u6a21\u7528\u4e8e\u4f30\u8ba1\u5ef6\u8fdf\u3001FLOPs\u548c\u80fd\u8017\u3002Profiling\u663e\u793a\uff0c4\u4f4d\u91cf\u5316\u5c06\u6a21\u578b\u5185\u5b58\u4f7f\u7528\u91cf\u51cf\u5c11\u4e86\u7ea660-70%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5728\u5168\u7cbe\u5ea6\u57fa\u7ebf2-5%\u7684\u7cbe\u5ea6\u3002\u4e0e\u5404\u79cd\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684FP16\u57fa\u7ebf\u76f8\u6bd4\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8\u4e862-3\u500d\u3002\u529f\u8017\u5efa\u6a21\u4f30\u8ba1INT4\u914d\u7f6e\u7684\u80fd\u8017\u964d\u4f4e\u4e8635-50%\uff0c\u4ece\u800c\u53ef\u4ee5\u5728Raspberry Pi 4/5\u548cJetson Orin Nano Super\u7b49\u786c\u4ef6\u4e0a\u8fdb\u884c\u5b9e\u9645\u90e8\u7f72\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9488\u5bf9\u8fb9\u7f18\u73af\u5883\u4e2d\u8f7b\u91cf\u7ea7LLM\u8fdb\u884c\u9ad8\u6548Profiling\u7684\u91cd\u8981\u6027\uff0c\u4ece\u800c\u5e73\u8861\u4e86\u7cbe\u5ea6\u3001\u80fd\u6548\u548c\u8ba1\u7b97\u53ef\u884c\u6027\u3002"}}
{"id": "2506.09581", "pdf": "https://arxiv.org/pdf/2506.09581", "abs": "https://arxiv.org/abs/2506.09581", "authors": ["Miguel \u00c1. Gonz\u00e1lez-Santamarta", "Francisco J. Rodr\u00edguez-Lera", "David Sobr\u00edn-Hidalgo", "\u00c1ngel Manuel Guerrero-Higueras", "Vicente Matell\u00c1n-Olivera"], "title": "Integrating Quantized LLMs into Robotics Systems as Edge AI to Leverage their Natural Language Processing Capabilities", "categories": ["cs.RO"], "comment": "10 pages, 4 figures, Submitted to 3rd edition of the Workshop on\n  Ontologies and Standards for Robotics and Automation (WOSRA) at ICRA 2024", "summary": "Large Language Models (LLMs) have experienced great advancements in the last\nyear resulting in an increase of these models in several fields to face natural\nlanguage tasks. The integration of these models in robotics can also help to\nimprove several aspects such as human-robot interaction, navigation, planning\nand decision-making. Therefore, this paper introduces llama\\_ros, a tool\ndesigned to integrate quantized Large Language Models (LLMs) into robotic\nsystems using ROS 2. Leveraging llama.cpp, a highly optimized runtime engine,\nllama\\_ros enables the efficient execution of quantized LLMs as edge artificial\nintelligence (AI) in robotics systems with resource-constrained environments,\naddressing the challenges of computational efficiency and memory limitations.\nBy deploying quantized LLMs, llama\\_ros empowers robots to leverage the natural\nlanguage understanding and generation for enhanced decision-making and\ninteraction which can be paired with prompt engineering, knowledge graphs,\nontologies or other tools to improve the capabilities of autonomous robots.\nAdditionally, this paper provides insights into some use cases of using\nllama\\_ros for planning and explainability in robotics.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u5c06\u91cf\u5316\u7684LLM\u96c6\u6210\u5230\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\uff0c\u4ee5\u5229\u7528\u5176\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\u3002\u867d\u7136\u63d0\u5230\u4e86\u673a\u5668\u4eba\u9886\u57df\u7684\u5e94\u7528\uff0c\u5982\u5bfc\u822a\u548c\u89c4\u5212\uff0c\u4f46\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\u3002\u7136\u800c\uff0c\u673a\u5668\u4eba\u5bfc\u822a\u548c\u89c4\u5212\u4e0e\u8f68\u8ff9\u9884\u6d4b\u5bc6\u5207\u76f8\u5173\uff0c\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002\u8bba\u6587\u4e2d\u91cd\u70b9\u5173\u6ce8LLM\u5728\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u5e94\u7528\u3002", "keywords": ["Large Language Models", "LLMs", "robotics", "planning", "navigation", "edge AI", "natural language processing"]}, "AI": {"tldr": "llama_ros\u662f\u4e00\u4e2a\u5c06\u91cf\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230ROS 2\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u5de5\u5177\uff0c\u65e8\u5728\u63d0\u9ad8\u673a\u5668\u4eba\u7684\u51b3\u7b56\u548c\u4ea4\u4e92\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8fc7\u53bb\u4e00\u5e74\u4e2d\u53d6\u5f97\u4e86\u5de8\u5927\u7684\u8fdb\u6b65\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u6a21\u578b\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u589e\u52a0\uff0c\u4ee5\u5e94\u5bf9\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u3002\u5c06\u8fd9\u4e9b\u6a21\u578b\u96c6\u6210\u5230\u673a\u5668\u4eba\u6280\u672f\u4e2d\u4e5f\u6709\u52a9\u4e8e\u6539\u5584\u4eba\u673a\u4ea4\u4e92\u3001\u5bfc\u822a\u3001\u89c4\u5212\u548c\u51b3\u7b56\u7b49\u591a\u4e2a\u65b9\u9762\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3allama_ros\u7684\u5de5\u5177\uff0c\u8be5\u5de5\u5177\u65e8\u5728\u5c06\u91cf\u5316\u7684LLM\u96c6\u6210\u5230\u4f7f\u7528ROS 2\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u3002llama_ros\u5229\u7528\u9ad8\u5ea6\u4f18\u5316\u7684\u8fd0\u884c\u65f6\u5f15\u64cellama.cpp\uff0c\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u9ad8\u6548\u6267\u884c\u91cf\u5316\u7684LLM\uff0c\u4f5c\u4e3a\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u8fb9\u7f18\u4eba\u5de5\u667a\u80fd\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u4e9b\u5173\u4e8e\u4f7f\u7528llama_ros\u8fdb\u884c\u673a\u5668\u4eba\u89c4\u5212\u548c\u53ef\u89e3\u91ca\u6027\u7684\u7528\u4f8b\u3002", "conclusion": "llama_ros\u901a\u8fc7\u5229\u7528\u91cf\u5316LLM\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5229\u7528\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u6765\u589e\u5f3a\u51b3\u7b56\u548c\u4ea4\u4e92\u80fd\u529b\uff0c\u5e76\u53ef\u4e0e\u63d0\u793a\u5de5\u7a0b\u3001\u77e5\u8bc6\u56fe\u8c31\u3001\u672c\u4f53\u6216\u5176\u4ed6\u5de5\u5177\u7ed3\u5408\u4f7f\u7528\uff0c\u4ee5\u63d0\u9ad8\u81ea\u4e3b\u673a\u5668\u4eba\u7684\u80fd\u529b\u3002", "summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8fc7\u53bb\u4e00\u5e74\u4e2d\u53d6\u5f97\u4e86\u5de8\u5927\u7684\u8fdb\u6b65\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u6a21\u578b\u88ab\u5e94\u7528\u5230\u5404\u4e2a\u9886\u57df\u4ee5\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u3002\u5c06\u8fd9\u4e9b\u6a21\u578b\u96c6\u6210\u5230\u673a\u5668\u4eba\u6280\u672f\u4e2d\u4e5f\u6709\u52a9\u4e8e\u6539\u5584\u4eba\u673a\u4ea4\u4e92\u3001\u5bfc\u822a\u3001\u89c4\u5212\u548c\u51b3\u7b56\u7b49\u591a\u4e2a\u65b9\u9762\u3002\u56e0\u6b64\uff0c\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3allama_ros\u7684\u5de5\u5177\uff0c\u8be5\u5de5\u5177\u65e8\u5728\u5c06\u91cf\u5316\u7684LLM\u96c6\u6210\u5230\u4f7f\u7528ROS 2\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u3002llama_ros\u5229\u7528\u9ad8\u5ea6\u4f18\u5316\u7684\u8fd0\u884c\u65f6\u5f15\u64cellama.cpp\uff0c\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u9ad8\u6548\u6267\u884c\u91cf\u5316\u7684LLM\uff0c\u4f5c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u8fb9\u7f18\u4eba\u5de5\u667a\u80fd\uff0c\u4ece\u800c\u89e3\u51b3\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u9650\u5236\u7684\u6311\u6218\u3002\u901a\u8fc7\u90e8\u7f72\u91cf\u5316\u7684LLM\uff0cllama_ros\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5229\u7528\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u6765\u589e\u5f3a\u51b3\u7b56\u548c\u4ea4\u4e92\u80fd\u529b\uff0c\u5e76\u53ef\u4e0e\u63d0\u793a\u5de5\u7a0b\u3001\u77e5\u8bc6\u56fe\u8c31\u3001\u672c\u4f53\u6216\u5176\u4ed6\u5de5\u5177\u7ed3\u5408\u4f7f\u7528\uff0c\u4ee5\u63d0\u9ad8\u81ea\u4e3b\u673a\u5668\u4eba\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e9b\u5173\u4e8e\u4f7f\u7528llama_ros\u8fdb\u884c\u673a\u5668\u4eba\u89c4\u5212\u548c\u53ef\u89e3\u91ca\u6027\u7684\u7528\u4f8b\u3002"}}
{"id": "2506.09800", "pdf": "https://arxiv.org/pdf/2506.09800", "abs": "https://arxiv.org/abs/2506.09800", "authors": ["Haochen Liu", "Tianyu Li", "Haohan Yang", "Li Chen", "Caojun Wang", "Ke Guo", "Haochen Tian", "Hongchen Li", "Hongyang Li", "Chen Lv"], "title": "Reinforced Refinement with Self-Aware Expansion for End-to-End Autonomous Driving", "categories": ["cs.RO"], "comment": null, "summary": "End-to-end autonomous driving has emerged as a promising paradigm for\ndirectly mapping sensor inputs to planning maneuvers using learning-based\nmodular integrations. However, existing imitation learning (IL)-based models\nsuffer from generalization to hard cases, and a lack of corrective feedback\nloop under post-deployment. While reinforcement learning (RL) offers a\npotential solution to tackle hard cases with optimality, it is often hindered\nby overfitting to specific driving cases, resulting in catastrophic forgetting\nof generalizable knowledge and sample inefficiency. To overcome these\nchallenges, we propose Reinforced Refinement with Self-aware Expansion (R2SE),\na novel learning pipeline that constantly refines hard domain while keeping\ngeneralizable driving policy for model-agnostic end-to-end driving systems.\nThrough reinforcement fine-tuning and policy expansion that facilitates\ncontinuous improvement, R2SE features three key components: 1) Generalist\nPretraining with hard-case allocation trains a generalist imitation learning\n(IL) driving system while dynamically identifying failure-prone cases for\ntargeted refinement; 2) Residual Reinforced Specialist Fine-tuning optimizes\nresidual corrections using reinforcement learning (RL) to improve performance\nin hard case domain while preserving global driving knowledge; 3) Self-aware\nAdapter Expansion dynamically integrates specialist policies back into the\ngeneralist model, enhancing continuous performance improvement. Experimental\nresults in closed-loop simulation and real-world datasets demonstrate\nimprovements in generalization, safety, and long-horizon policy robustness over\nstate-of-the-art E2E systems, highlighting the effectiveness of reinforce\nrefinement for scalable autonomous driving.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\uff0c\u5176\u4e2d\u6d89\u53ca\u8def\u5f84\u89c4\u5212\u548c\u7b56\u7565\u4f18\u5316\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u6709\u4e00\u5b9a\u76f8\u5173\u6027\u3002 \u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u7b56\u7565\u4f18\u5316\u4e5f\u4f53\u73b0\u4e86\u4e00\u79cd\u6a21\u578b\u5b66\u4e60\u548c\u63d0\u5347\u7684\u8fc7\u7a0b\u3002\u56e0\u6b64\uff0c\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\uff0c\u4f46\u4e0d\u662f\u975e\u5e38\u5f3a\u3002", "keywords": ["autonomous driving", "reinforcement learning", "policy optimization", "end-to-end", "generalization", "hard cases", "driving policy"]}, "AI": {"tldr": "R2SE \u662f\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u6d41\u7a0b\uff0c\u5b83\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4e0d\u65ad\u6539\u8fdb\u56f0\u96be\u9a7e\u9a76\u573a\u666f\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u9a7e\u9a76\u7b56\u7565\uff0c\u4ece\u800c\u63d0\u9ad8\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6a21\u4eff\u5b66\u4e60 (IL) \u7684\u6a21\u578b\u96be\u4ee5\u6cdb\u5316\u5230\u56f0\u96be\u6848\u4f8b\uff0c\u5e76\u4e14\u5728\u90e8\u7f72\u540e\u7f3a\u4e4f\u7ea0\u6b63\u53cd\u9988\u5faa\u73af\u3002\u5f3a\u5316\u5b66\u4e60 (RL) \u867d\u7136\u53ef\u4ee5\u89e3\u51b3\u56f0\u96be\u6848\u4f8b\uff0c\u4f46\u5e38\u5e38\u8fc7\u5ea6\u62df\u5408\u5230\u7279\u5b9a\u7684\u9a7e\u9a76\u6848\u4f8b\uff0c\u5bfc\u81f4\u901a\u7528\u77e5\u8bc6\u7684\u707e\u96be\u6027\u9057\u5fd8\u548c\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReinforced Refinement with Self-aware Expansion (R2SE) \u7684\u65b0\u578b\u5b66\u4e60\u6d41\u7a0b\uff0c\u8be5\u6d41\u7a0b\u4e0d\u65ad\u6539\u8fdb\u56f0\u96be\u9886\u57df\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u9a7e\u9a76\u7b56\u7565\uff0c\u7528\u4e8e\u6a21\u578b\u65e0\u5173\u7684\u7aef\u5230\u7aef\u9a7e\u9a76\u7cfb\u7edf\u3002R2SE \u5177\u6709\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u901a\u8fc7\u786c\u6848\u4f8b\u5206\u914d\u8fdb\u884c\u901a\u7528\u9884\u8bad\u7ec3\uff1b2) \u6b8b\u5dee\u5f3a\u5316\u4e13\u5bb6\u5fae\u8c03\uff1b3) \u81ea\u611f\u77e5\u9002\u914d\u5668\u6269\u5c55\u3002", "result": "\u5728\u95ed\u73af\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cR2SE \u5728\u6cdb\u5316\u6027\u3001\u5b89\u5168\u6027\u548c\u957f\u65f6\u7a0b\u7b56\u7565\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684 E2E \u7cfb\u7edf\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cR2SE\u5728\u6cdb\u5316\u6027\u3001\u5b89\u5168\u6027\u548c\u957f\u65f6\u7a0b\u7b56\u7565\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709E2E\u7cfb\u7edf\uff0c\u7a81\u51fa\u4e86\u5f3a\u5316\u6539\u8fdb\u5bf9\u4e8e\u53ef\u6269\u5c55\u81ea\u52a8\u9a7e\u9a76\u7684\u6709\u6548\u6027\u3002", "summary_zh": "\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u5df2\u7ecf\u6210\u4e3a\u4e00\u79cd\u5f88\u6709\u524d\u666f\u7684\u8303\u4f8b\uff0c\u5b83\u4f7f\u7528\u57fa\u4e8e\u5b66\u4e60\u7684\u6a21\u5757\u5316\u96c6\u6210\u5c06\u4f20\u611f\u5668\u8f93\u5165\u76f4\u63a5\u6620\u5c04\u5230\u89c4\u5212\u52a8\u4f5c\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u6a21\u4eff\u5b66\u4e60 (IL) \u7684\u6a21\u578b\u96be\u4ee5\u6cdb\u5316\u5230\u56f0\u96be\u6848\u4f8b\uff0c\u5e76\u4e14\u5728\u90e8\u7f72\u540e\u7f3a\u4e4f\u7ea0\u6b63\u53cd\u9988\u5faa\u73af\u3002\u867d\u7136\u5f3a\u5316\u5b66\u4e60 (RL) \u63d0\u4f9b\u4e86\u4e00\u79cd\u6f5c\u5728\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5904\u7406\u5177\u6709\u6700\u4f18\u6027\u7684\u56f0\u96be\u6848\u4f8b\uff0c\u4f46\u5b83\u5e38\u5e38\u53d7\u5230\u8fc7\u5ea6\u62df\u5408\u7279\u5b9a\u9a7e\u9a76\u6848\u4f8b\u7684\u963b\u788d\uff0c\u5bfc\u81f4\u901a\u7528\u77e5\u8bc6\u7684\u707e\u96be\u6027\u9057\u5fd8\u548c\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReinforced Refinement with Self-aware Expansion (R2SE) \u7684\u65b0\u578b\u5b66\u4e60\u6d41\u7a0b\uff0c\u8be5\u6d41\u7a0b\u4e0d\u65ad\u6539\u8fdb\u56f0\u96be\u9886\u57df\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u9a7e\u9a76\u7b56\u7565\uff0c\u7528\u4e8e\u6a21\u578b\u65e0\u5173\u7684\u7aef\u5230\u7aef\u9a7e\u9a76\u7cfb\u7edf\u3002\u901a\u8fc7\u5f3a\u5316\u5fae\u8c03\u548c\u4fc3\u8fdb\u6301\u7eed\u6539\u8fdb\u7684\u7b56\u7565\u6269\u5c55\uff0cR2SE \u5177\u6709\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u901a\u8fc7\u786c\u6848\u4f8b\u5206\u914d\u8fdb\u884c\u901a\u7528\u9884\u8bad\u7ec3\uff0c\u8bad\u7ec3\u901a\u7528\u6a21\u4eff\u5b66\u4e60 (IL) \u9a7e\u9a76\u7cfb\u7edf\uff0c\u540c\u65f6\u52a8\u6001\u8bc6\u522b\u5bb9\u6613\u51fa\u9519\u7684\u6848\u4f8b\u4ee5\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u6539\u8fdb\uff1b2) \u6b8b\u5dee\u5f3a\u5316\u4e13\u5bb6\u5fae\u8c03\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60 (RL) \u4f18\u5316\u6b8b\u5dee\u6821\u6b63\uff0c\u4ee5\u63d0\u9ad8\u56f0\u96be\u6848\u4f8b\u9886\u57df\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u7559\u5168\u5c40\u9a7e\u9a76\u77e5\u8bc6\uff1b3) \u81ea\u611f\u77e5\u9002\u914d\u5668\u6269\u5c55\uff0c\u5c06\u4e13\u5bb6\u7b56\u7565\u52a8\u6001\u96c6\u6210\u56de\u901a\u7528\u6a21\u578b\uff0c\u4ece\u800c\u589e\u5f3a\u6301\u7eed\u6027\u80fd\u6539\u8fdb\u3002\u5728\u95ed\u73af\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684 E2E \u7cfb\u7edf\u76f8\u6bd4\uff0c\u5728\u6cdb\u5316\u6027\u3001\u5b89\u5168\u6027\u548c\u957f\u65f6\u7a0b\u7b56\u7565\u9c81\u68d2\u6027\u65b9\u9762\u6709\u6240\u6539\u8fdb\uff0c\u7a81\u51fa\u4e86\u5f3a\u5316\u6539\u8fdb\u5bf9\u4e8e\u53ef\u6269\u5c55\u81ea\u52a8\u9a7e\u9a76\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.09859", "pdf": "https://arxiv.org/pdf/2506.09859", "abs": "https://arxiv.org/abs/2506.09859", "authors": ["Huajian Liu", "Yixuan Feng", "Wei Dong", "Kunpeng Fan", "Chao Wang", "Yongzhuo Gao"], "title": "Hierarchical Learning-Enhanced MPC for Safe Crowd Navigation with Heterogeneous Constraints", "categories": ["cs.RO"], "comment": null, "summary": "In this paper, we propose a novel hierarchical framework for robot navigation\nin dynamic environments with heterogeneous constraints. Our approach leverages\na graph neural network trained via reinforcement learning (RL) to efficiently\nestimate the robot's cost-to-go, formulated as local goal recommendations. A\nspatio-temporal path-searching module, which accounts for kinematic\nconstraints, is then employed to generate a reference trajectory to facilitate\nsolving the non-convex optimization problem used for explicit constraint\nenforcement. More importantly, we introduce an incremental action-masking\nmechanism and a privileged learning strategy, enabling end-to-end training of\nthe proposed planner. Both simulation and real-world experiments demonstrate\nthat the proposed method effectively addresses local planning in complex\ndynamic environments, achieving state-of-the-art (SOTA) performance. Compared\nwith existing learning-optimization hybrid methods, our approach eliminates the\ndependency on high-fidelity simulation environments, offering significant\nadvantages in computational efficiency and training scalability. The code will\nbe released as open-source upon acceptance of the paper.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on robot navigation in dynamic environments using a hierarchical learning-enhanced MPC approach. While it doesn't directly involve large language models, it utilizes reinforcement learning and graph neural networks for trajectory planning and cost-to-go estimation, which are related to trajectory prediction. The core focus is on safe crowd navigation and constraint satisfaction, making it moderately relevant to trajectory prediction.", "keywords": ["trajectory prediction", "robot navigation", "reinforcement learning", "graph neural network", "path planning", "dynamic environments"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u5c42\u673a\u5668\u4eba\u5bfc\u822a\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u5c40\u90e8\u89c4\u5212\u3002", "motivation": "\u89e3\u51b3\u5728\u5177\u6709\u5f02\u6784\u7ea6\u675f\u7684\u52a8\u6001\u73af\u5883\u4e2d\u673a\u5668\u4eba\u5bfc\u822a\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6765\u6709\u6548\u4f30\u8ba1\u673a\u5668\u4eba\u7684cost-to-go\uff0c\u5e76\u5c06\u5176\u5236\u5b9a\u4e3a\u5c40\u90e8\u76ee\u6807\u63a8\u8350\u3002", "result": "\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u8bad\u7ec3\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u590d\u6742\u7684\u52a8\u6001\u73af\u5883\u4e2d\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5c40\u90e8\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5206\u5c42\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5177\u6709\u5f02\u6784\u7ea6\u675f\u7684\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u884c\u673a\u5668\u4eba\u5bfc\u822a\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6765\u6709\u6548\u4f30\u8ba1\u673a\u5668\u4eba\u7684cost-to-go\uff0c\u5e76\u5c06\u5176\u5236\u5b9a\u4e3a\u5c40\u90e8\u76ee\u6807\u63a8\u8350\u3002\u7136\u540e\uff0c\u91c7\u7528\u8003\u8651\u8fd0\u52a8\u5b66\u7ea6\u675f\u7684\u65f6\u7a7a\u8def\u5f84\u641c\u7d22\u6a21\u5757\u6765\u751f\u6210\u53c2\u8003\u8f68\u8ff9\uff0c\u4ee5\u4fc3\u8fdb\u89e3\u51b3\u7528\u4e8e\u663e\u5f0f\u7ea6\u675f\u6267\u884c\u7684\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u589e\u91cf\u52a8\u4f5c\u5c4f\u853d\u673a\u5236\u548c\u4e00\u79cd\u7279\u6743\u5b66\u4e60\u7b56\u7565\uff0c\u4ece\u800c\u80fd\u591f\u5bf9\u6240\u63d0\u51fa\u7684\u89c4\u5212\u5668\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u590d\u6742\u7684\u52a8\u6001\u73af\u5883\u4e2d\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5c40\u90e8\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u4e0e\u73b0\u6709\u7684\u5b66\u4e60-\u4f18\u5316\u6df7\u5408\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6d88\u9664\u4e86\u5bf9\u9ad8\u4fdd\u771f\u4eff\u771f\u73af\u5883\u7684\u4f9d\u8d56\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u8bad\u7ec3\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002\u8be5\u4ee3\u7801\u5c06\u5728\u8bba\u6587\u88ab\u63a5\u53d7\u540e\u5f00\u6e90\u3002"}}
{"id": "2506.09930", "pdf": "https://arxiv.org/pdf/2506.09930", "abs": "https://arxiv.org/abs/2506.09930", "authors": ["Irving Fang", "Juexiao Zhang", "Shengbang Tong", "Chen Feng"], "title": "From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models", "categories": ["cs.RO", "cs.CV"], "comment": "Under review", "summary": "One promise that Vision-Language-Action (VLA) models hold over traditional\nimitation learning for robotics is to leverage the broad generalization\ncapabilities of large Vision-Language Models (VLMs) to produce versatile,\n\"generalist\" robot policies. However, current evaluations of VLAs remain\ninsufficient. Traditional imitation learning benchmarks are unsuitable due to\nthe lack of language instructions. Emerging benchmarks for VLAs that\nincorporate language often come with limited evaluation tasks and do not intend\nto investigate how much VLM pretraining truly contributes to the generalization\ncapabilities of the downstream robotic policy. Meanwhile, much research relies\non real-world robot setups designed in isolation by different institutions,\nwhich creates a barrier for reproducibility and accessibility. To address this\ngap, we introduce a unified probing suite of 50 simulation-based tasks across\n10 subcategories spanning language instruction, vision, and objects. We\nsystematically evaluate several state-of-the-art VLA architectures on this\nsuite to understand their generalization capability. Our results show that\nwhile VLM backbones endow VLAs with robust perceptual understanding and high\nlevel planning, which we refer to as good intentions, this does not reliably\ntranslate into precise motor execution: when faced with out-of-distribution\nobservations, policies often exhibit coherent intentions, but falter in action\nexecution. Moreover, finetuning on action data can erode the original VLM's\ngeneralist reasoning abilities. We release our task suite and evaluation code\nto serve as a standardized benchmark for future VLAs and to drive research on\nclosing the perception-to-action gap. More information, including the source\ncode, can be found at https://ai4ce.github.io/INT-ACT/", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on Vision-Language-Action (VLA) models, which leverage large Vision-Language Models (VLMs) for robotics. While it doesn't directly focus on trajectory prediction, the robotic policies discussed implicitly involve generating trajectories for robot actions. The paper's emphasis on VLMs and their application to action execution justifies a moderate relevance score. It explores the gap between high-level planning (intentions) and precise motor execution, which is related to trajectory generation and control.", "keywords": ["Vision-Language Models", "VLMs", "Vision-Language-Action Models", "VLA", "robot policies", "generalization", "action execution", "motor execution"]}, "AI": {"tldr": "VLA\u6a21\u578b\u62e5\u6709\u826f\u597d\u7684\u610f\u56fe\uff0c\u4f46\u884c\u52a8\u6267\u884c\u4e0d\u4f73\uff0c\u5e76\u4e14\u5728\u52a8\u4f5c\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\u4f1a\u524a\u5f31VLM\u539f\u6709\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684VLA\u8bc4\u4f30\u4ecd\u7136\u4e0d\u8db3\uff1b\u4f20\u7edf\u7684\u6a21\u4eff\u5b66\u4e60\u57fa\u51c6\u7531\u4e8e\u7f3a\u4e4f\u8bed\u8a00\u6307\u4ee4\u800c\u4e0d\u9002\u7528\u3002\u65b0\u5174\u7684VLA\u57fa\u51c6\u867d\u7136\u7ed3\u5408\u4e86\u8bed\u8a00\uff0c\u4f46\u8bc4\u4f30\u4efb\u52a1\u6709\u9650\uff0c\u5e76\u4e14\u6ca1\u6709\u7814\u7a76VLM\u9884\u8bad\u7ec3\u5bf9\u4e0b\u6e38\u673a\u5668\u4eba\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\u6709\u591a\u5927\u8d21\u732e\u3002\u540c\u65f6\uff0c\u8bb8\u591a\u7814\u7a76\u4f9d\u8d56\u4e8e\u4e0d\u540c\u673a\u6784\u72ec\u7acb\u8bbe\u8ba1\u7684\u771f\u5b9e\u673a\u5668\u4eba\u88c5\u7f6e\uff0c\u8fd9\u4e3a\u91cd\u73b0\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u5e26\u6765\u4e86\u969c\u788d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b50\u4e2a\u6a21\u62df\u4efb\u52a1\u7684\u7edf\u4e00\u63a2\u6d4b\u5957\u4ef6\uff0c\u6db5\u76d6\u8bed\u8a00\u6307\u4ee4\u3001\u89c6\u89c9\u548c\u5bf9\u8c61\u7b4910\u4e2a\u5b50\u7c7b\u522b\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u51e0\u79cd\u6700\u5148\u8fdb\u7684VLA\u67b6\u6784\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cVLM\u4e3b\u5e72\u7f51\u7edc\u8d4b\u4e88VLA\u5f3a\u5927\u7684\u611f\u77e5\u7406\u89e3\u548c\u9ad8\u5c42\u6b21\u89c4\u5212\u80fd\u529b\uff0c\u4f46\u4e0d\u80fd\u53ef\u9760\u5730\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684\u8fd0\u52a8\u6267\u884c\uff1b\u5f53\u9762\u5bf9\u5206\u5e03\u5916\u7684\u89c2\u5bdf\u65f6\uff0c\u7b56\u7565\u901a\u5e38\u8868\u73b0\u51fa\u8fde\u8d2f\u7684\u610f\u56fe\uff0c\u4f46\u5728\u52a8\u4f5c\u6267\u884c\u65b9\u9762\u4f1a\u5931\u8d25\u3002\u6b64\u5916\uff0c\u5728\u52a8\u4f5c\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\u4f1a\u524a\u5f31VLM\u539f\u6709\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "VLM\u4e3b\u5e72\u7f51\u7edc\u8d4b\u4e88VLA\u5f3a\u5927\u7684\u611f\u77e5\u7406\u89e3\u548c\u9ad8\u5c42\u6b21\u89c4\u5212\u80fd\u529b\uff0c\u4f46\u4e0d\u80fd\u53ef\u9760\u5730\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684\u8fd0\u52a8\u6267\u884c\uff1b\u5728\u52a8\u4f5c\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\u4f1a\u524a\u5f31VLM\u539f\u6709\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002", "summary_zh": "\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u76f8\u6bd4\u4f20\u7edf\u7684\u673a\u5668\u4eba\u6a21\u4eff\u5b66\u4e60\uff0c\u5177\u6709\u5229\u7528\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u5e7f\u6cdb\u6cdb\u5316\u80fd\u529b\uff0c\u4ece\u800c\u4ea7\u751f\u901a\u7528\u7684\u673a\u5668\u4eba\u7b56\u7565\u7684\u6f5c\u529b\u3002\u7136\u800c\uff0c\u76ee\u524d\u5bf9VLA\u7684\u8bc4\u4f30\u4ecd\u7136\u4e0d\u8db3\u3002\u4f20\u7edf\u7684\u6a21\u4eff\u5b66\u4e60\u57fa\u51c6\u7531\u4e8e\u7f3a\u4e4f\u8bed\u8a00\u6307\u4ee4\u800c\u4e0d\u9002\u7528\u3002\u65b0\u5174\u7684VLA\u57fa\u51c6\u867d\u7136\u7ed3\u5408\u4e86\u8bed\u8a00\uff0c\u4f46\u8bc4\u4f30\u4efb\u52a1\u6709\u9650\uff0c\u5e76\u4e14\u6ca1\u6709\u7814\u7a76VLM\u9884\u8bad\u7ec3\u5bf9\u4e0b\u6e38\u673a\u5668\u4eba\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\u6709\u591a\u5927\u8d21\u732e\u3002\u540c\u65f6\uff0c\u8bb8\u591a\u7814\u7a76\u4f9d\u8d56\u4e8e\u4e0d\u540c\u673a\u6784\u72ec\u7acb\u8bbe\u8ba1\u7684\u771f\u5b9e\u673a\u5668\u4eba\u88c5\u7f6e\uff0c\u8fd9\u4e3a\u91cd\u73b0\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u5e26\u6765\u4e86\u969c\u788d\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u63a2\u6d4b\u5957\u4ef6\uff0c\u5305\u542b50\u4e2a\u6a21\u62df\u4efb\u52a1\uff0c\u6db5\u76d6\u8bed\u8a00\u6307\u4ee4\u3001\u89c6\u89c9\u548c\u5bf9\u8c61\u7b4910\u4e2a\u5b50\u7c7b\u522b\u3002\u6211\u4eec\u5728\u6b64\u57fa\u7840\u4e0a\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u51e0\u79cd\u6700\u5148\u8fdb\u7684VLA\u67b6\u6784\uff0c\u4ee5\u4e86\u89e3\u5b83\u4eec\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136VLM\u4e3b\u5e72\u7f51\u7edc\u8d4b\u4e88VLA\u5f3a\u5927\u7684\u611f\u77e5\u7406\u89e3\u548c\u9ad8\u5c42\u6b21\u89c4\u5212\u80fd\u529b\uff0c\u4f46\u4e0d\u80fd\u53ef\u9760\u5730\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684\u8fd0\u52a8\u6267\u884c\uff1a\u5f53\u9762\u5bf9\u5206\u5e03\u5916\u7684\u89c2\u5bdf\u65f6\uff0c\u7b56\u7565\u901a\u5e38\u8868\u73b0\u51fa\u8fde\u8d2f\u7684\u610f\u56fe\uff0c\u4f46\u5728\u52a8\u4f5c\u6267\u884c\u65b9\u9762\u4f1a\u5931\u8d25\u3002\u6b64\u5916\uff0c\u5728\u52a8\u4f5c\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\u4f1a\u524a\u5f31VLM\u539f\u6709\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u6211\u4eec\u7684\u4efb\u52a1\u5957\u4ef6\u548c\u8bc4\u4f30\u4ee3\u7801\uff0c\u4f5c\u4e3a\u672a\u6765VLA\u7684\u6807\u51c6\u57fa\u51c6\uff0c\u5e76\u63a8\u52a8\u7f29\u5c0f\u611f\u77e5\u5230\u884c\u52a8\u5dee\u8ddd\u7684\u7814\u7a76\u3002\u66f4\u591a\u4fe1\u606f\uff0c\u5305\u62ec\u6e90\u4ee3\u7801\uff0c\u8bf7\u8bbf\u95eehttps://ai4ce.github.io/INT-ACT/"}}
{"id": "2506.09990", "pdf": "https://arxiv.org/pdf/2506.09990", "abs": "https://arxiv.org/abs/2506.09990", "authors": ["Wenbo Zhang", "Tianrun Hu", "Yanyuan Qiao", "Hanbo Zhang", "Yuchu Qin", "Yang Li", "Jiajun Liu", "Tao Kong", "Lingqiao Liu", "Xiao Ma"], "title": "Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": null, "summary": "We present Chain-of-Action (CoA), a novel visuo-motor policy paradigm built\nupon Trajectory Autoregressive Modeling. Unlike conventional approaches that\npredict next step action(s) forward, CoA generates an entire trajectory by\nexplicit backward reasoning with task-specific goals through an action-level\nChain-of-Thought (CoT) process. This process is unified within a single\nautoregressive structure: (1) the first token corresponds to a stable keyframe\naction that encodes the task-specific goals; and (2) subsequent action tokens\nare generated autoregressively, conditioned on the initial keyframe and\npreviously predicted actions. This backward action reasoning enforces a\nglobal-to-local structure, allowing each local action to be tightly constrained\nby the final goal. To further realize the action reasoning structure, CoA\nincorporates four complementary designs: continuous action token\nrepresentation; dynamic stopping for variable-length trajectory generation;\nreverse temporal ensemble; and multi-token prediction to balance action chunk\nmodeling with global structure. As a result, CoA gives strong spatial\ngeneralization capabilities while preserving the flexibility and simplicity of\na visuo-motor policy. Empirically, we observe CoA achieves the state-of-the-art\nperformance across 60 RLBench tasks and 8 real-world manipulation tasks.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on trajectory modeling for robotic manipulation using an autoregressive approach. While it doesn't explicitly use large language models, the 'Chain-of-Thought' concept and autoregressive modeling are related to LLM techniques. The core contribution is in trajectory generation, making it relevant to trajectory prediction, but the absence of direct LLM usage lowers the relevance score.", "keywords": ["Trajectory Autoregressive Modeling", "trajectory generation", "Chain-of-Thought", "robotic manipulation", "action prediction"]}, "AI": {"tldr": "CoA\u901a\u8fc7\u53cd\u5411\u63a8\u7406\u751f\u6210\u52a8\u4f5c\u8f68\u8ff9\uff0c\u5728\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u3002", "motivation": "\u4e0e\u9884\u6d4b\u4e0b\u4e00\u6b65\u52a8\u4f5c\u7684\u4f20\u7edf\u65b9\u6cd5\u4e0d\u540c\uff0cCoA\u901a\u8fc7\u52a8\u4f5c\u7ea7\u7684\u601d\u7ef4\u94fe(CoT)\u8fc7\u7a0b\uff0c\u5229\u7528\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u76ee\u6807\u8fdb\u884c\u663e\u5f0f\u7684\u540e\u5411\u63a8\u7406\uff0c\u751f\u6210\u6574\u4e2a\u8f68\u8ff9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f68\u8ff9\u81ea\u56de\u5f52\u5efa\u6a21\u7684\u65b0\u578b\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u8303\u5f0fChain-of-Action (CoA)\u3002", "result": "CoA\u5177\u6709\u5f3a\u5927\u7684\u7a7a\u95f4\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u7684\u7075\u6d3b\u6027\u548c\u7b80\u5355\u6027\u3002", "conclusion": "CoA\u572860\u4e2aRLBench\u4efb\u52a1\u548c8\u4e2a\u771f\u5b9e\u4e16\u754c\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "summary_zh": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChain-of-Action (CoA) \u7684\u65b0\u578b\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u8303\u5f0f\uff0c\u5b83\u5efa\u7acb\u5728\u8f68\u8ff9\u81ea\u56de\u5f52\u5efa\u6a21\u7684\u57fa\u7840\u4e0a\u3002\u4e0e\u4f20\u7edf\u7684\u524d\u5411\u9884\u6d4b\u4e0b\u4e00\u6b65\u52a8\u4f5c\u7684\u65b9\u6cd5\u4e0d\u540c\uff0cCoA \u901a\u8fc7\u52a8\u4f5c\u7ea7\u522b\u7684\u601d\u7ef4\u94fe (CoT) \u8fc7\u7a0b\uff0c\u5229\u7528\u7279\u5b9a\u4efb\u52a1\u7684\u76ee\u6807\u8fdb\u884c\u663e\u5f0f\u7684\u540e\u5411\u63a8\u7406\uff0c\u4ece\u800c\u751f\u6210\u5b8c\u6574\u7684\u8f68\u8ff9\u3002\u8fd9\u4e00\u8fc7\u7a0b\u7edf\u4e00\u5728\u5355\u4e2a\u81ea\u56de\u5f52\u7ed3\u6784\u4e2d\uff1a(1) \u7b2c\u4e00\u4e2a token \u5bf9\u5e94\u4e8e\u4e00\u4e2a\u7a33\u5b9a\u7684\u5173\u952e\u5e27\u52a8\u4f5c\uff0c\u5b83\u7f16\u7801\u4e86\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u76ee\u6807\uff1b(2) \u540e\u7eed\u7684\u52a8\u4f5c token \u4ee5\u81ea\u56de\u5f52\u7684\u65b9\u5f0f\u751f\u6210\uff0c\u5e76\u4ee5\u521d\u59cb\u5173\u952e\u5e27\u548c\u5148\u524d\u9884\u6d4b\u7684\u52a8\u4f5c\u4e3a\u6761\u4ef6\u3002\u8fd9\u79cd\u53cd\u5411\u52a8\u4f5c\u63a8\u7406\u5f3a\u5236\u6267\u884c\u4e86\u4e00\u79cd\u5168\u5c40\u5230\u5c40\u90e8\u7684\u7ed3\u6784\uff0c\u5141\u8bb8\u6bcf\u4e2a\u5c40\u90e8\u52a8\u4f5c\u53d7\u5230\u6700\u7ec8\u76ee\u6807\u7684\u4e25\u683c\u7ea6\u675f\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u5b9e\u73b0\u52a8\u4f5c\u63a8\u7406\u7ed3\u6784\uff0cCoA \u7ed3\u5408\u4e86\u56db\u4e2a\u4e92\u8865\u8bbe\u8ba1\uff1a\u8fde\u7eed\u52a8\u4f5c token \u8868\u793a\uff1b\u7528\u4e8e\u53ef\u53d8\u957f\u5ea6\u8f68\u8ff9\u751f\u6210\u7684\u52a8\u6001\u505c\u6b62\uff1b\u53cd\u5411\u65f6\u95f4\u96c6\u6210\uff1b\u4ee5\u53ca\u591a token \u9884\u6d4b\uff0c\u4ee5\u5e73\u8861\u52a8\u4f5c\u5757\u5efa\u6a21\u4e0e\u5168\u5c40\u7ed3\u6784\u3002\u56e0\u6b64\uff0cCoA \u5177\u6709\u5f3a\u5927\u7684\u7a7a\u95f4\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u7684\u7075\u6d3b\u6027\u548c\u7b80\u5355\u6027\u3002\u5728\u5b9e\u9a8c\u4e0a\uff0c\u6211\u4eec\u89c2\u5bdf\u5230 CoA \u5728 60 \u4e2a RLBench \u4efb\u52a1\u548c 8 \u4e2a\u771f\u5b9e\u4e16\u754c\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2506.09316", "pdf": "https://arxiv.org/pdf/2506.09316", "abs": "https://arxiv.org/abs/2506.09316", "authors": ["Yeonju Ro", "Zhenyu Zhang", "Souvik Kundu", "Zhangyang Wang", "Aditya Akella"], "title": "On-the-Fly Adaptive Distillation of Transformer to Dual-State Linear Attention", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at capturing global token dependencies via\nself-attention but face prohibitive compute and memory costs on lengthy inputs.\nWhile sub-quadratic methods (e.g., linear attention) can reduce these costs,\nthey often degrade accuracy due to overemphasizing recent tokens. In this work,\nwe first propose \\textit{dual-state linear attention} (\\textbf{\\dsla}), a novel\ndesign that maintains two specialized hidden states-one for preserving\nhistorical context and one for tracking recency-thereby mitigating the\nshort-range bias typical of linear-attention architectures. To further balance\nefficiency and accuracy under dynamic workload conditions, we introduce\n\\textbf{\\serve}, an online \\textit{adaptive distillation} framework that\nprogressively replaces Transformer layers with DSLA layers at inference time,\nguided by a sensitivity-based layer ordering. \\serve\\ uses a chained\nfine-tuning strategy to ensure that each newly converted DSLA layer remains\nconsistent with previously replaced layers, preserving the overall quality.\nExtensive evaluations on commonsense reasoning, long-context QA, and text\nsummarization demonstrate that \\serve\\ yields \\textbf{2.3x} faster inference\nthan Llama2-7B and \\textbf{3.0x} faster than the hybrid Zamba-7B, while\nretaining comparable performance across downstream tasks. Our ablation studies\nshow that DSLA's dual states capture both global and local dependencies,\naddressing the historical-token underrepresentation seen in prior linear\nattentions. Codes are available at https://github.com/utnslab/DSLA-Serve.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on improving the efficiency of large language models, specifically addressing the computational cost associated with self-attention mechanisms. While it doesn't directly deal with trajectory prediction, the optimization of LLMs is a relevant area, especially if LLMs are to be used in trajectory prediction tasks in the future. The paper explores techniques to make LLMs faster and more efficient, which can indirectly benefit other domains where LLMs are applied.", "keywords": ["Large language models", "LLMs", "Transformer", "self-attention", "linear attention", "distillation", "inference"]}, "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u72b6\u6001\u7ebf\u6027\u6ce8\u610f\u529b\uff08DSLA\uff09\u548c\u5728\u7ebf\u81ea\u9002\u5e94\u84b8\u998f\u6846\u67b6\uff08Serve\uff09\uff0c\u4ee5\u52a0\u901f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u64c5\u957f\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u6355\u6349\u5168\u5c40token\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46\u5728\u5197\u957f\u7684\u8f93\u5165\u4e0a\u9762\u4e34\u5de8\u5927\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u3002\u867d\u7136\u4e9a\u4e8c\u6b21\u65b9\u6cd5\uff08\u4f8b\u5982\uff0c\u7ebf\u6027\u6ce8\u610f\u529b\uff09\u53ef\u4ee5\u964d\u4f4e\u8fd9\u4e9b\u6210\u672c\uff0c\u4f46\u7531\u4e8e\u8fc7\u5ea6\u5f3a\u8c03\u6700\u8fd1\u7684token\uff0c\u5b83\u4eec\u901a\u5e38\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u53cc\u72b6\u6001\u7ebf\u6027\u6ce8\u610f\u529b\uff08DSLA\uff09\uff0c\u5b83\u7ef4\u62a4\u4e24\u4e2a\u4e13\u95e8\u7684\u9690\u85cf\u72b6\u6001\uff1a\u4e00\u4e2a\u7528\u4e8e\u4fdd\u5b58\u5386\u53f2\u4e0a\u4e0b\u6587\uff0c\u4e00\u4e2a\u7528\u4e8e\u8ddf\u8e2a\u6700\u8fd1\u4fe1\u606f\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86Serve\uff0c\u4e00\u4e2a\u5728\u7ebf\u81ea\u9002\u5e94\u84b8\u998f\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u63a8\u7406\u65f6\u6839\u636e\u57fa\u4e8e\u654f\u611f\u5ea6\u7684\u5c42\u6392\u5e8f\uff0c\u9010\u6b65\u7528DSLA\u5c42\u66ff\u6362Transformer\u5c42\u3002", "result": "\u5728\u5e38\u8bc6\u63a8\u7406\u3001\u957f\u6587\u672cQA\u548c\u6587\u672c\u6458\u8981\u4efb\u52a1\u4e0a\uff0cServe\u7684\u63a8\u7406\u901f\u5ea6\u6bd4Llama2-7B\u5feb2.3\u500d\uff0c\u6bd4\u6df7\u5408Zamba-7B\u5feb3.0\u500d\uff0c\u540c\u65f6\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u6027\u80fd\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0cDSLA\u7684\u53cc\u91cd\u72b6\u6001\u6355\u83b7\u4e86\u5168\u5c40\u548c\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u7ebf\u6027\u6ce8\u610f\u529b\u4e2d\u5386\u53f2token\u8868\u793a\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "conclusion": "Serve\u6846\u67b6\u901a\u8fc7\u5728\u7ebf\u81ea\u9002\u5e94\u84b8\u998f\uff0c\u7528DSLA\u5c42\u9010\u6b65\u66ff\u6362Transformer\u5c42\uff0c\u5728\u5e38\u8bc6\u63a8\u7406\u3001\u957f\u6587\u672cQA\u548c\u6587\u672c\u6458\u8981\u4efb\u52a1\u4e0a\uff0c\u5b9e\u73b0\u4e86\u6bd4Llama2-7B\u5feb2.3\u500d\u3001\u6bd4Zamba-7B\u5feb3.0\u500d\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u6027\u80fd\u3002", "summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(llm)\u64c5\u957f\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u6355\u6349\u5168\u5c40token\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46\u9762\u4e34\u7740\u5728\u5197\u957f\u8f93\u5165\u4e0a\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u8fc7\u9ad8\u7684\u95ee\u9898\u3002\u867d\u7136\u4e8c\u6b21\u65b9\u6cd5(\u4f8b\u5982\uff0c\u7ebf\u6027\u6ce8\u610f)\u53ef\u4ee5\u964d\u4f4e\u8fd9\u4e9b\u6210\u672c\uff0c\u4f46\u7531\u4e8e\u8fc7\u5ea6\u5f3a\u8c03\u6700\u8fd1\u7684token\uff0c\u5b83\u4eec\u901a\u5e38\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u63d0\u51fa\u4e86\u53cc\u72b6\u6001\u7ebf\u6027\u6ce8\u610f(dsla)\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8bbe\u8ba1\uff0c\u5b83\u7ef4\u62a4\u4e24\u4e2a\u4e13\u95e8\u7684\u9690\u85cf\u72b6\u6001\u2014\u2014\u4e00\u4e2a\u7528\u4e8e\u4fdd\u5b58\u5386\u53f2\u4e0a\u4e0b\u6587\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u8ddf\u8e2arecency\u2014\u2014\u4ece\u800c\u51cf\u8f7b\u4e86\u7ebf\u6027\u6ce8\u610f\u67b6\u6784\u7684\u5178\u578b\u77ed\u7a0b\u504f\u5dee\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u5e73\u8861\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u6211\u4eec\u5f15\u5165\u4e86Serve\uff0c\u4e00\u4e2a\u5728\u7ebf\u81ea\u9002\u5e94\u84b8\u998f\u6846\u67b6\uff0c\u5b83\u5728\u63a8\u7406\u65f6\u6839\u636e\u57fa\u4e8e\u654f\u611f\u5ea6\u7684\u5c42\u6392\u5e8f\uff0c\u9010\u6b65\u7528DSLA\u5c42\u66ff\u6362Transformer\u5c42\u3002Serve\u4f7f\u7528\u94fe\u5f0f\u5fae\u8c03\u7b56\u7565\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e2a\u65b0\u8f6c\u6362\u7684DSLA\u5c42\u4e0e\u5148\u524d\u66ff\u6362\u7684\u5c42\u4fdd\u6301\u4e00\u81f4\uff0c\u4ece\u800c\u4fdd\u6301\u6574\u4f53\u8d28\u91cf\u3002\u5728\u5e38\u8bc6\u63a8\u7406\u3001\u957f\u6587\u672c\u95ee\u7b54\u548c\u6587\u672c\u6458\u8981\u65b9\u9762\u7684\u5927\u91cf\u8bc4\u4f30\u8868\u660e\uff0cServe\u7684\u63a8\u7406\u901f\u5ea6\u6bd4Llama2-7B\u5feb2.3\u500d\uff0c\u6bd4\u6df7\u5408Zamba-7B\u5feb3.0\u500d\uff0c\u540c\u65f6\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u6027\u80fd\u3002\u6211\u4eec\u7684\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0cDSLA\u7684\u53cc\u91cd\u72b6\u6001\u6355\u83b7\u4e86\u5168\u5c40\u548c\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u7ebf\u6027\u6ce8\u610f\u4e2d\u5386\u53f2token\u8868\u793a\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u4ee3\u7801\u53ef\u5728https://github.com/utnslab/DSLA-Serve\u4e0a\u627e\u5230\u3002"}}
{"id": "2506.09901", "pdf": "https://arxiv.org/pdf/2506.09901", "abs": "https://arxiv.org/abs/2506.09901", "authors": ["Noel Brindise", "Vijeth Hebbar", "Riya Shah", "Cedric Langbort"], "title": "\"What are my options?\": Explaining RL Agents with Diverse Near-Optimal Alternatives (Extended)", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we provide an extended discussion of a new approach to\nexplainable Reinforcement Learning called Diverse Near-Optimal Alternatives\n(DNA), first proposed at L4DC 2025. DNA seeks a set of reasonable \"options\" for\ntrajectory-planning agents, optimizing policies to produce qualitatively\ndiverse trajectories in Euclidean space. In the spirit of explainability, these\ndistinct policies are used to \"explain\" an agent's options in terms of\navailable trajectory shapes from which a human user may choose. In particular,\nDNA applies to value function-based policies on Markov decision processes where\nagents are limited to continuous trajectories. Here, we describe DNA, which\nuses reward shaping in local, modified Q-learning problems to solve for\ndistinct policies with guaranteed epsilon-optimality. We show that it\nsuccessfully returns qualitatively different policies that constitute\nmeaningfully different \"options\" in simulation, including a brief comparison to\nrelated approaches in the stochastic optimization field of Quality Diversity.\nBeyond the explanatory motivation, this work opens new possibilities for\nexploration and adaptive planning in RL.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u5f3a\u5316\u5b66\u4e60\u4e2d\u8f68\u8ff9\u89c4\u5212\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u5bfb\u627e\u4e0d\u540c\u7684\u8fd1\u4f18\u8f68\u8ff9\u6765\u89e3\u91caagent\u7684\u51b3\u7b56\u3002\u867d\u7136\u63d0\u5230\u4e86trajectory-planning agents\u548c\u8f68\u8ff9\u5f62\u72b6\uff0c\u4f46\u5e76\u672a\u6d89\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u3002\u8f68\u8ff9\u9884\u6d4b\u662f\u5176\u6838\u5fc3\u4efb\u52a1\u4e4b\u4e00\uff0c\u4f46\u4e0e\u5927\u6a21\u578b\u7684\u5173\u8054\u4e0d\u5f3a\u3002", "keywords": ["trajectory-planning agents", "trajectories", "Reinforcement Learning", "options"]}, "AI": {"tldr": "DNA\u901a\u8fc7\u5bfb\u627e\u4e0d\u540c\u7684\u8fd1\u4f18\u7b56\u7565\u6765\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u884c\u4e3a\uff0c\u4ece\u800c\u4e3a\u8f68\u8ff9\u89c4\u5212\u63d0\u4f9b\u591a\u79cd\u9009\u62e9\u3002", "motivation": "\u8be5\u8bba\u6587\u65e8\u5728\u4e3a\u8f68\u8ff9\u89c4\u5212\u4ee3\u7406\u5bfb\u627e\u4e00\u7ec4\u5408\u7406\u7684\u201c\u9009\u9879\u201d\uff0c\u4f18\u5316\u7b56\u7565\u4ee5\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u4ea7\u751f\u6027\u8d28\u4e0a\u4e0d\u540c\u7684\u8f68\u8ff9\u3002", "method": "DNA\u4f7f\u7528\u5c40\u90e8\u4fee\u6539\u7684Q\u5b66\u4e60\u95ee\u9898\u4e2d\u7684\u5956\u52b1\u5851\u9020\u6765\u89e3\u51b3\u5177\u6709\u4fdd\u8bc1\u7684epsilon-\u6700\u4f18\u6027\u7684\u4e0d\u540c\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDNA\u6210\u529f\u8fd4\u56de\u4e86\u6027\u8d28\u4e0a\u4e0d\u540c\u7684\u7b56\u7565\uff0c\u8fd9\u4e9b\u7b56\u7565\u6784\u6210\u4e86\u6a21\u62df\u4e2d\u610f\u4e49\u4e0a\u4e0d\u540c\u7684\u201c\u9009\u9879\u201d\u3002", "conclusion": "DNA\u65b9\u6cd5\u6210\u529f\u8fd4\u56de\u4e86\u5728\u6a21\u62df\u4e2d\u6784\u6210\u6709\u610f\u4e49\u7684\u4e0d\u540c\u201c\u9009\u9879\u201d\u7684\u6027\u8d28\u4e0a\u4e0d\u540c\u7684\u7b56\u7565\uff0c\u4e3aRL\u4e2d\u7684\u63a2\u7d22\u548c\u81ea\u9002\u5e94\u89c4\u5212\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "summary_zh": "\u672c\u6587\u5bf9\u4e00\u79cd\u65b0\u7684\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u4e86\u6269\u5c55\u8ba8\u8bba\uff0c\u8be5\u65b9\u6cd5\u79f0\u4e3a\u591a\u6837\u6027\u8fd1\u4f18\u66ff\u4ee3\u65b9\u6848\uff08DNA\uff09\uff0c\u8be5\u65b9\u6cd5\u9996\u6b21\u5728L4DC 2025\u4e0a\u63d0\u51fa\u3002DNA\u65e8\u5728\u4e3a\u8f68\u8ff9\u89c4\u5212\u4ee3\u7406\u5bfb\u627e\u4e00\u7ec4\u5408\u7406\u7684\u201c\u9009\u9879\u201d\uff0c\u4f18\u5316\u7b56\u7565\u4ee5\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u4ea7\u751f\u6027\u8d28\u4e0a\u4e0d\u540c\u7684\u8f68\u8ff9\u3002\u672c\u7740\u53ef\u89e3\u91ca\u6027\u7684\u7cbe\u795e\uff0c\u8fd9\u4e9b\u4e0d\u540c\u7684\u7b56\u7565\u7528\u4e8e\u201c\u89e3\u91ca\u201d\u4ee3\u7406\u7684\u9009\u9879\uff0c\u5373\u4eba\u7c7b\u7528\u6237\u53ef\u4ee5\u4ece\u4e2d\u9009\u62e9\u7684\u53ef\u7528\u8f68\u8ff9\u5f62\u72b6\u3002\u7279\u522b\u5730\uff0cDNA\u9002\u7528\u4e8e\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u4ef7\u503c\u51fd\u6570\u7b56\u7565\uff0c\u5176\u4e2d\u4ee3\u7406\u4ec5\u9650\u4e8e\u8fde\u7eed\u8f68\u8ff9\u3002\u672c\u6587\u63cf\u8ff0\u4e86DNA\uff0c\u5b83\u4f7f\u7528\u5c40\u90e8\u4fee\u6539\u7684Q\u5b66\u4e60\u95ee\u9898\u4e2d\u7684\u5956\u52b1\u5851\u9020\u6765\u89e3\u51b3\u5177\u6709\u4fdd\u8bc1\u7684epsilon-\u6700\u4f18\u6027\u7684\u4e0d\u540c\u7b56\u7565\u3002\u6211\u4eec\u8868\u660e\uff0c\u5b83\u6210\u529f\u8fd4\u56de\u4e86\u5728\u6a21\u62df\u4e2d\u6784\u6210\u6709\u610f\u4e49\u7684\u4e0d\u540c\u201c\u9009\u9879\u201d\u7684\u6027\u8d28\u4e0a\u4e0d\u540c\u7684\u7b56\u7565\uff0c\u5305\u62ec\u4e0e\u8d28\u91cf\u591a\u6837\u6027\u968f\u673a\u4f18\u5316\u9886\u57df\u4e2d\u7684\u76f8\u5173\u65b9\u6cd5\u7684\u7b80\u8981\u6bd4\u8f83\u3002\u9664\u4e86\u89e3\u91ca\u6027\u52a8\u673a\u4e4b\u5916\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u548c\u81ea\u9002\u5e94\u89c4\u5212\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.09312", "pdf": "https://arxiv.org/pdf/2506.09312", "abs": "https://arxiv.org/abs/2506.09312", "authors": ["Erik Buchholz", "Natasha Fernandes", "David D. Nguyen", "Alsharif Abuadbba", "Surya Nepal", "Salil S. Kanhere"], "title": "What is the Cost of Differential Privacy for Deep Learning-Based Trajectory Generation?", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "While location trajectories offer valuable insights, they also reveal\nsensitive personal information. Differential Privacy (DP) offers formal\nprotection, but achieving a favourable utility-privacy trade-off remains\nchallenging. Recent works explore deep learning-based generative models to\nproduce synthetic trajectories. However, current models lack formal privacy\nguarantees and rely on conditional information derived from real data during\ngeneration. This work investigates the utility cost of enforcing DP in such\nmodels, addressing three research questions across two datasets and eleven\nutility metrics. (1) We evaluate how DP-SGD, the standard DP training method\nfor deep learning, affects the utility of state-of-the-art generative models.\n(2) Since DP-SGD is limited to unconditional models, we propose a novel DP\nmechanism for conditional generation that provides formal guarantees and assess\nits impact on utility. (3) We analyse how model types - Diffusion, VAE, and GAN\n- affect the utility-privacy trade-off. Our results show that DP-SGD\nsignificantly impacts performance, although some utility remains if the\ndatasets is sufficiently large. The proposed DP mechanism improves training\nstability, particularly when combined with DP-SGD, for unstable models such as\nGANs and on smaller datasets. Diffusion models yield the best utility without\nguarantees, but with DP-SGD, GANs perform best, indicating that the best\nnon-private model is not necessarily optimal when targeting formal guarantees.\nIn conclusion, DP trajectory generation remains a challenging task, and formal\nguarantees are currently only feasible with large datasets and in constrained\nuse cases.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on trajectory generation using deep learning models. While it doesn't explicitly mention large language models, it explores generative models like GANs, VAEs, and Diffusion models for trajectory generation. The connection to trajectory prediction is direct, but the connection to large language models is indirect, through the usage of deep learning based generative models. The paper also mentions 'state-of-the-art generative models', implying that the models used are relatively complex.", "keywords": ["trajectory generation", "deep learning", "generative models", "GAN", "VAE", "Diffusion models"]}, "AI": {"tldr": "DP\u8f68\u8ff9\u751f\u6210\u5177\u6709\u6311\u6218\u6027\uff0c\u5f62\u5f0f\u5316\u4fdd\u8bc1\u9700\u5927\u6570\u636e\u96c6\u548c\u53d7\u9650\u7528\u4f8b\u3002", "motivation": "\u867d\u7136\u4f4d\u7f6e\u8f68\u8ff9\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u4f46\u5b83\u4eec\u4e5f\u63ed\u793a\u4e86\u654f\u611f\u7684\u4e2a\u4eba\u4fe1\u606f\u3002\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u63d0\u4f9b\u4e86\u6b63\u5f0f\u7684\u4fdd\u62a4\uff0c\u4f46\u5b9e\u73b0\u6709\u5229\u7684\u6548\u7528-\u9690\u79c1\u6743\u8861\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u76ee\u524d\u7684\u5de5\u4f5c\u63a2\u7d22\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u751f\u6210\u6a21\u578b\u6765\u751f\u6210\u5408\u6210\u8f68\u8ff9\u3002\u4f46\u662f\uff0c\u5f53\u524d\u7684\u6a21\u578b\u7f3a\u4e4f\u6b63\u5f0f\u7684\u9690\u79c1\u4fdd\u8bc1\uff0c\u5e76\u4e14\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4f9d\u8d56\u4e8e\u4ece\u771f\u5b9e\u6570\u636e\u5f97\u51fa\u7684\u6761\u4ef6\u4fe1\u606f\u3002", "method": "\u6211\u4eec\u4e3a\u6761\u4ef6\u751f\u6210\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684DP\u673a\u5236\uff0c\u8be5\u673a\u5236\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5bf9\u6548\u7528\u7684\u5f71\u54cd\u3002", "result": "\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0cDP-SGD\u4f1a\u663e\u7740\u5f71\u54cd\u6027\u80fd\uff0c\u4f46\u662f\u5982\u679c\u6570\u636e\u96c6\u8db3\u591f\u5927\uff0c\u5219\u4ecd\u7136\u4fdd\u7559\u4e00\u4e9b\u6548\u7528\u3002\u6240\u63d0\u51fa\u7684DP\u673a\u5236\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5c24\u5176\u662f\u5f53\u4e0eDP-SGD\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u5bf9\u4e8e\u4e0d\u7a33\u5b9a\u7684\u6a21\u578b\uff08\u4f8b\u5982GAN\uff09\u4ee5\u53ca\u5728\u8f83\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u3002\u6269\u6563\u6a21\u578b\u5728\u6ca1\u6709\u4fdd\u8bc1\u7684\u60c5\u51b5\u4e0b\u53ef\u4ea7\u751f\u6700\u4f73\u6548\u7528\uff0c\u4f46\u662f\u4f7f\u7528DP-SGD\uff0cGAN\u7684\u6027\u80fd\u6700\u4f73\uff0c\u8fd9\u8868\u660e\u5728\u9488\u5bf9\u5f62\u5f0f\u4fdd\u8bc1\u65f6\uff0c\u6700\u4f73\u7684\u975e\u79c1\u6709\u6a21\u578b\u4e0d\u4e00\u5b9a\u662f\u6700\u4f73\u7684\u3002", "conclusion": "DP\u8f68\u8ff9\u751f\u6210\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u76ee\u524d\u7684\u5f62\u5f0f\u5316\u4fdd\u8bc1\u53ea\u80fd\u901a\u8fc7\u5927\u578b\u6570\u636e\u96c6\u548c\u5728\u53d7\u7ea6\u675f\u7684\u7528\u4f8b\u4e2d\u5b9e\u73b0\u3002", "summary_zh": "\u867d\u7136\u4f4d\u7f6e\u8f68\u8ff9\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u4f46\u5b83\u4eec\u4e5f\u63ed\u793a\u4e86\u654f\u611f\u7684\u4e2a\u4eba\u4fe1\u606f\u3002\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u63d0\u4f9b\u4e86\u6b63\u5f0f\u7684\u4fdd\u62a4\uff0c\u4f46\u5b9e\u73b0\u6709\u5229\u7684\u6548\u7528-\u9690\u79c1\u6743\u8861\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u6700\u8fd1\u7684\u5de5\u4f5c\u63a2\u7d22\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u751f\u6210\u6a21\u578b\u6765\u751f\u6210\u5408\u6210\u8f68\u8ff9\u3002\u4f46\u662f\uff0c\u5f53\u524d\u7684\u6a21\u578b\u7f3a\u4e4f\u6b63\u5f0f\u7684\u9690\u79c1\u4fdd\u8bc1\uff0c\u5e76\u4e14\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4f9d\u8d56\u4e8e\u4ece\u771f\u5b9e\u6570\u636e\u5f97\u51fa\u7684\u6761\u4ef6\u4fe1\u606f\u3002\u8fd9\u9879\u5de5\u4f5c\u7814\u7a76\u4e86\u5728\u6b64\u7c7b\u6a21\u578b\u4e2d\u5f3a\u5236\u6267\u884cDP\u7684\u6548\u7528\u6210\u672c\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u8de8\u4e24\u4e2a\u6570\u636e\u96c6\u548c11\u4e2a\u6548\u7528\u6307\u6807\u7684\u4e09\u4e2a\u7814\u7a76\u95ee\u9898\u3002(1) \u6211\u4eec\u8bc4\u4f30\u4e86DP-SGD\uff08\u6df1\u5ea6\u5b66\u4e60\u7684\u6807\u51c6DP\u8bad\u7ec3\u65b9\u6cd5\uff09\u5982\u4f55\u5f71\u54cd\u6700\u65b0\u751f\u6210\u6a21\u578b\u7684\u6548\u7528\u3002(2) \u7531\u4e8eDP-SGD\u4ec5\u9650\u4e8e\u65e0\u6761\u4ef6\u6a21\u578b\uff0c\u56e0\u6b64\u6211\u4eec\u4e3a\u6761\u4ef6\u751f\u6210\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684DP\u673a\u5236\uff0c\u8be5\u673a\u5236\u63d0\u4f9b\u4e86\u5f62\u5f0f\u4fdd\u8bc1\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5bf9\u6548\u7528\u7684\u5f71\u54cd\u3002(3) \u6211\u4eec\u5206\u6790\u4e86\u6a21\u578b\u7c7b\u578b\uff08\u6269\u6563\u3001VAE\u548cGAN\uff09\u5982\u4f55\u5f71\u54cd\u6548\u7528-\u9690\u79c1\u6743\u8861\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0cDP-SGD\u4f1a\u663e\u7740\u5f71\u54cd\u6027\u80fd\uff0c\u4f46\u662f\u5982\u679c\u6570\u636e\u96c6\u8db3\u591f\u5927\uff0c\u5219\u4ecd\u7136\u4fdd\u7559\u4e00\u4e9b\u6548\u7528\u3002\u6240\u63d0\u51fa\u7684DP\u673a\u5236\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5c24\u5176\u662f\u5f53\u4e0eDP-SGD\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u5bf9\u4e8e\u4e0d\u7a33\u5b9a\u7684\u6a21\u578b\uff08\u4f8b\u5982GAN\uff09\u4ee5\u53ca\u5728\u8f83\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u3002\u6269\u6563\u6a21\u578b\u5728\u6ca1\u6709\u4fdd\u8bc1\u7684\u60c5\u51b5\u4e0b\u53ef\u4ea7\u751f\u6700\u4f73\u6548\u7528\uff0c\u4f46\u662f\u4f7f\u7528DP-SGD\uff0cGAN\u7684\u6027\u80fd\u6700\u4f73\uff0c\u8fd9\u8868\u660e\u5728\u9488\u5bf9\u5f62\u5f0f\u4fdd\u8bc1\u65f6\uff0c\u6700\u4f73\u7684\u975e\u79c1\u6709\u6a21\u578b\u4e0d\u4e00\u5b9a\u662f\u6700\u4f73\u7684\u3002\u603b\u800c\u8a00\u4e4b\uff0cDP\u8f68\u8ff9\u751f\u6210\u4ecd\u7136\u662f\u4e00\u9879\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u5e76\u4e14\u76ee\u524d\u7684\u5f62\u5f0f\u4fdd\u8bc1\u53ea\u80fd\u901a\u8fc7\u5927\u578b\u6570\u636e\u96c6\u548c\u5728\u53d7\u7ea6\u675f\u7684\u7528\u4f8b\u4e2d\u5b9e\u73b0\u3002"}}
{"id": "2506.09441", "pdf": "https://arxiv.org/pdf/2506.09441", "abs": "https://arxiv.org/abs/2506.09441", "authors": ["Piyush Mishra", "Philippe Roudot"], "title": "Attention-Bayesian Hybrid Approach to Modular Multiple Particle Tracking", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Tracking multiple particles in noisy and cluttered scenes remains challenging\ndue to a combinatorial explosion of trajectory hypotheses, which scales\nsuper-exponentially with the number of particles and frames. The transformer\narchitecture has shown a significant improvement in robustness against this\nhigh combinatorial load. However, its performance still falls short of the\nconventional Bayesian filtering approaches in scenarios presenting a reduced\nset of trajectory hypothesis. This suggests that while transformers excel at\nnarrowing down possible associations, they may not be able to reach the\noptimality of the Bayesian approach in locally sparse scenario. Hence, we\nintroduce a hybrid tracking framework that combines the ability of\nself-attention to learn the underlying representation of particle behavior with\nthe reliability and interpretability of Bayesian filtering. We perform\ntrajectory-to-detection association by solving a label prediction problem,\nusing a transformer encoder to infer soft associations between detections\nacross frames. This prunes the hypothesis set, enabling efficient\nmultiple-particle tracking in Bayesian filtering framework. Our approach\ndemonstrates improved tracking accuracy and robustness against spurious\ndetections, offering a solution for high clutter multiple particle tracking\nscenarios.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on particle tracking, which is related to trajectory prediction. It also mentions using a transformer architecture, a type of model that is related to large language models although not directly using them. Therefore, it has moderate relevance.", "keywords": ["trajectory prediction", "particle tracking", "transformer architecture"]}, "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u8ddf\u8e2a\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u8d1d\u53f6\u65af\u6ee4\u6ce2\uff0c\u4ee5\u63d0\u9ad8\u591a\u7c92\u5b50\u8ddf\u8e2a\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u7531\u4e8e\u8f68\u8ff9\u5047\u8bbe\u7684\u7ec4\u5408\u7206\u70b8\uff0c\u5728\u5608\u6742\u548c\u6df7\u4e71\u7684\u573a\u666f\u4e2d\u8ddf\u8e2a\u591a\u4e2a\u7c92\u5b50\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u8f68\u8ff9\u5047\u8bbe\u7684\u7ec4\u5408\u7206\u70b8\u968f\u7740\u7c92\u5b50\u548c\u5e27\u7684\u6570\u91cf\u5448\u8d85\u6307\u6570\u7ea7\u589e\u957f\u3002", "method": "\u901a\u8fc7\u4f7f\u7528transformer\u7f16\u7801\u5668\u63a8\u65ad\u8de8\u5e27\u68c0\u6d4b\u4e4b\u95f4\u7684\u8f6f\u5173\u8054\uff0c\u89e3\u51b3\u6807\u7b7e\u9884\u6d4b\u95ee\u9898\uff0c\u4ece\u800c\u6267\u884c\u8f68\u8ff9\u5230\u68c0\u6d4b\u7684\u5173\u8054\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u5bf9\u865a\u5047\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u65b9\u9762\u6709\u6240\u63d0\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u5bf9\u865a\u5047\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u9ad8\u6742\u6ce2\u591a\u7c92\u5b50\u8ddf\u8e2a\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u89e3\u51b3\u65b9\u6848\u3002", "summary_zh": "\u5728\u5608\u6742\u548c\u6df7\u4e71\u7684\u573a\u666f\u4e2d\u8ddf\u8e2a\u591a\u4e2a\u7c92\u5b50\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u8fd9\u662f\u7531\u4e8e\u8f68\u8ff9\u5047\u8bbe\u7684\u7ec4\u5408\u7206\u70b8\uff0c\u5176\u968f\u7740\u7c92\u5b50\u548c\u5e27\u7684\u6570\u91cf\u5448\u8d85\u6307\u6570\u7ea7\u589e\u957f\u3002Transformer\u67b6\u6784\u5728\u62b5\u6297\u8fd9\u79cd\u9ad8\u7ec4\u5408\u8d1f\u8f7d\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u7684\u6539\u8fdb\u3002\u7136\u800c\uff0c\u5728\u8f68\u8ff9\u5047\u8bbe\u96c6\u51cf\u5c11\u7684\u573a\u666f\u4e2d\uff0c\u5176\u6027\u80fd\u4ecd\u7136\u4f4e\u4e8e\u4f20\u7edf\u7684\u8d1d\u53f6\u65af\u6ee4\u6ce2\u65b9\u6cd5\u3002\u8fd9\u8868\u660e\uff0c\u867d\u7136transformer\u64c5\u957f\u7f29\u5c0f\u53ef\u80fd\u7684\u5173\u8054\uff0c\u4f46\u5b83\u4eec\u53ef\u80fd\u65e0\u6cd5\u5728\u5c40\u90e8\u7a00\u758f\u573a\u666f\u4e2d\u8fbe\u5230\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u6700\u4f18\u6027\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u6df7\u5408\u8ddf\u8e2a\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u81ea\u6ce8\u610f\u529b\u5b66\u4e60\u7c92\u5b50\u884c\u4e3a\u6f5c\u5728\u8868\u793a\u7684\u80fd\u529b\u4ee5\u53ca\u8d1d\u53f6\u65af\u6ee4\u6ce2\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u6211\u4eec\u901a\u8fc7\u89e3\u51b3\u6807\u7b7e\u9884\u6d4b\u95ee\u9898\u6765\u6267\u884c\u8f68\u8ff9\u5230\u68c0\u6d4b\u7684\u5173\u8054\uff0c\u4f7f\u7528transformer\u7f16\u7801\u5668\u6765\u63a8\u65ad\u8de8\u5e27\u68c0\u6d4b\u4e4b\u95f4\u7684\u8f6f\u5173\u8054\u3002\u8fd9\u51cf\u5c11\u4e86\u5047\u8bbe\u96c6\uff0c\u4ece\u800c\u80fd\u591f\u5728\u8d1d\u53f6\u65af\u6ee4\u6ce2\u6846\u67b6\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u7c92\u5b50\u8ddf\u8e2a\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u8bc1\u660e\u4e86\u6539\u8fdb\u7684\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u5bf9\u865a\u5047\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u9ad8\u6742\u6ce2\u591a\u7c92\u5b50\u8ddf\u8e2a\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u89e3\u51b3\u65b9\u6848\u3002"}}
