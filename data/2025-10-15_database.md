# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-10-15

## 目录

- [人工智能 (Artificial Intelligence) (1)](#cs-ai)
- [计算语言学 (Computation and Language) (1)](#cs-cl)
- [cs.CR (1)](#cs-cr)
- [cs.DB (9)](#cs-db)
- [机器学习 (Machine Learning) (1)](#cs-lg)

## 人工智能 (Artificial Intelligence) [cs.AI]
### [1] [Scalable and Explainable Enterprise Knowledge Discovery Using Graph-Centric Hybrid Retrieval](https://arxiv.org/abs/2510.10942)
*Nilima Rao, Jagriti Srivastava, Pradeep Kumar Sharma, Hritvik Shrivastava*

Main category: cs.AI

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Modern enterprises manage vast knowledge distributed across heterogeneous systems such as Jira, Git repositories, Confluence, and wikis. Conventional retrieval methods based on keyword search or static embeddings often fail to answer complex queries that require contextual reasoning and multi-hop inference across artifacts. We present a modular hybrid retrieval framework for adaptive enterprise information access that integrates Knowledge Base Language-Augmented Models (KBLam), DeepGraph representations, and embedding-driven semantic search. The framework builds a unified knowledge graph from parsed repositories including code, pull requests, and commit histories, enabling semantic similarity search, structural inference, and multi-hop reasoning. Query analysis dynamically determines the optimal retrieval strategy, supporting both structured and unstructured data sources through independent or fused processing. An interactive interface provides graph visualizations, subgraph exploration, and context-aware query routing to generate concise and explainable answers. Experiments on large-scale Git repositories show that the unified reasoning layer improves answer relevance by up to 80 percent compared with standalone GPT-based retrieval pipelines. By combining graph construction, hybrid reasoning, and interactive visualization, the proposed framework offers a scalable, explainable, and user-centric foundation for intelligent knowledge assistants in enterprise environments.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10942) | **Categories:** cs.AI, cs.DB

---


## 计算语言学 (Computation and Language) [cs.CL]
### [1] [Rethinking Agentic Workflows: Evaluating Inference-Based Test-Time Scaling Strategies in Text2SQL Tasks](https://arxiv.org/abs/2510.10885)
*Jiajing Guo, Kenil Patel, Jorge Piazentin Ono, Wenbin He, Liu Ren*

Main category: cs.CL

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Large language models (LLMs) are increasingly powering Text-to-SQL (Text2SQL) systems, enabling non-expert users to query industrial databases using natural language. While test-time scaling strategies have shown promise in LLM-based solutions, their effectiveness in real-world applications, especially with the latest reasoning models, remains uncertain. In this work, we benchmark six lightweight, industry-oriented test-time scaling strategies and four LLMs, including two reasoning models, evaluating their performance on the BIRD Mini-Dev benchmark. Beyond standard accuracy metrics, we also report inference latency and token consumption, providing insights relevant for practical system deployment. Our findings reveal that Divide-and-Conquer prompting and few-shot demonstrations consistently enhance performance for both general-purpose and reasoning-focused LLMs. However, introducing additional workflow steps yields mixed results, and base model selection plays a critical role. This work sheds light on the practical trade-offs between accuracy, efficiency, and complexity when deploying Text2SQL systems.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10885) | **Categories:** cs.CL, cs.DB

---


## cs.CR [cs.CR]
### [1] [How to Get Actual Privacy and Utility from Privacy Models: the k-Anonymity and Differential Privacy Families](https://arxiv.org/abs/2510.11299)
*Josep Domingo-Ferrer, David Sánchez*

Main category: cs.CR

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Privacy models were introduced in privacy-preserving data publishing and statistical disclosure control with the promise to end the need for costly empirical assessment of disclosure risk. We examine how well this promise is kept by the main privacy models. We find they may fail to provide adequate protection guarantees because of problems in their definition or incur unacceptable trade-offs between privacy protection and utility preservation. Specifically, k-anonymity may not entirely exclude disclosure if enforced with deterministic mechanisms or without constraints on the confidential values. On the other hand, differential privacy (DP) incurs unacceptable utility loss for small budgets and its privacy guarantee becomes meaningless for large budgets. In the latter case, an ex post empirical assessment of disclosure risk becomes necessary, undermining the main appeal of privacy models. Whereas the utility preservation of DP can only be improved by relaxing its privacy guarantees, we argue that a semantic reformulation of k-anonymity can offer more robust privacy without losing utility with respect to traditional syntactic k-anonymity.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.11299) | **Categories:** cs.CR, cs.DB, 68, K.4.1

---


## cs.DB [cs.DB]
### [1] [Real-Time Health Analytics Using Ontology-Driven Complex Event Processing and LLM Reasoning: A Tuberculosis Case Study](https://arxiv.org/abs/2510.09646)
*Ritesh Chandra, Sonali Agarwal, Navjot Singh*

Main category: cs.DB

TL;DR: 该论文提出了一种基于本体的实时分析框架，集成了复杂事件处理（CEP）和大型语言模型（LLM），用于在异构、高速的健康数据流上实现智能健康事件检测和语义推理。


<details>
  <summary>Details</summary>
Motivation: 在大数据环境下，公共卫生分析面临着及时检测关键健康状况的挑战，特别是临床数据量大、速度快、种类繁多。

Method: 该框架利用基本形式本体（BFO）和语义Web规则语言（SWRL）来建模诊断规则和领域知识，使用Apache Kafka和Spark Streaming摄取和处理患者数据，CEP引擎检测临床显著的事件模式，LLM支持自适应推理、事件解释和本体改进，临床信息以资源描述框架（RDF）三元组的形式在图数据库中进行语义结构化。

Result: 使用1000名结核病（TB）患者的数据集进行评估，结果表明该系统具有低延迟事件检测、可扩展推理和高模型性能（在精确率、召回率和F1分数方面）。

Conclusion: 该研究验证了该系统在复杂大数据场景中进行通用、实时健康分析的潜力。

Abstract: 本研究提出了一个基于本体的实时分析框架，该框架集成了复杂事件处理（CEP）和大型语言模型（LLM），旨在实现对异构、高速健康数据流的智能健康事件检测和语义推理。该架构利用基本形式本体（BFO）和语义Web规则语言（SWRL）来建模诊断规则和领域知识。患者数据通过Apache Kafka和Spark Streaming进行摄取和处理，其中CEP引擎检测临床上重要的事件模式。大型语言模型（LLM）支持自适应推理、事件解释和本体完善。临床信息以资源描述框架（RDF）三元组的形式在图数据库中进行语义结构化，从而支持基于SPARQL的查询和知识驱动的决策支持。该框架使用包含1000名结核病（TB）患者的数据集进行评估，结果表明该系统具有低延迟事件检测、可扩展的推理能力和较高的模型性能（在精确率、召回率和F1值方面）。这些结果验证了该系统在复杂的大数据场景中进行通用、实时健康分析的潜力。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.09646) | **Categories:** cs.DB, cs.AI

---

### [2] [Targeted Sequential Pattern Mining with High Average Utility](https://arxiv.org/abs/2510.10115)
*Kai Cao, Yucong Duan, Wensheng Gan*

Main category: cs.DB

TL;DR: 本文提出了一种新的算法TAUSQ-PG，用于挖掘目标高平均效用序列模式，并在效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于频率的模式挖掘方法存在局限性，而基于效用的方法容易产生大量复杂序列，因此需要一种更平衡的指标和用户交互来提高模式的相关性和可解释性。

Method: 提出TAUSQ-PG算法，该算法结合了高效的过滤和剪枝策略、更严格的上限模型以及专门的评估指标和查询标志。

Result: 在不同数据集上的大量对比实验表明，TAUSQ-PG算法能有效控制候选集大小，减少冗余序列生成，显著提高运行时间和内存效率。

Conclusion: TAUSQ-PG算法在挖掘目标高平均效用序列模式方面具有优势，能够有效提高挖掘效率和模式质量。

Abstract: 将效用性纳入目标模式挖掘可以解决传统基于频率的方法的实际局限性。然而，基于效用的方法通常会产生大量冗长而复杂的序列。为了提高模式的相关性和可解释性，平均效用通过同时考虑效用和序列长度，提供了一个更平衡的指标。此外，将用户定义的查询目标纳入挖掘过程，通过仅保留包含用户指定目标的模式，增强了可用性和交互性。为了应对大规模、长序列数据集中与挖掘效率相关的挑战，本研究将平均效用引入到目标序列模式挖掘中。设计了一种新的算法TAUSQ-PG，用于查找目标高平均效用序列模式。它结合了高效的过滤和剪枝策略、更严格的上限模型，以及为该任务量身定制的新的专用评估指标和查询标志。在不同数据集上进行的大量对比实验表明，TAUSQ-PG有效地控制了候选集大小，从而减少了冗余序列的生成，并显著提高了运行时间和内存效率。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10115) | **Categories:** cs.DB

---

### [3] [The Hybrid Multimodal Graph Index (HMGI): A Comprehensive Framework for Integrated Relational and Vector Search](https://arxiv.org/abs/2510.10123)
*Joydeep Chandra, Satyam Kumar Navneet, Yong Zhang*

Main category: cs.DB

TL;DR: 本文提出了混合多模图索引（HMGI），一个用于多模数据高效混合查询的统一框架。


<details>
  <summary>Details</summary>
Motivation: 现有的向量数据库和图数据库在处理复杂多模数据集时存在局限性：向量数据库擅长语义相似度搜索，但缺乏深度关系查询能力；图数据库擅长复杂遍历，但未针对高维向量搜索进行优化。

Method: 本文提出的HMGI框架，利用原生图数据库架构和集成的向量搜索能力（如Neo4j），结合近似最近邻搜索（ANNS）与表达性图遍历查询。关键创新包括：模态感知的嵌入分区以优化索引结构和查询性能；以及一个自适应、低开销的索引更新系统，以支持动态数据摄取。

Result: HMGI旨在复杂、关系密集的查询场景中优于纯向量数据库（如Milvus），并实现混合任务的亚线性查询时间。

Conclusion: HMGI通过将语义相似度搜索与关系上下文直接集成，弥合了向量数据库和图数据库之间的差距，为多模数据的高效混合查询提供了新的解决方案。

Abstract: 复杂多模数据集的激增暴露了专用向量数据库和传统图数据库之间的一个关键差距。虽然向量数据库擅长语义相似度搜索，但它们缺乏深度关系查询的能力。相反，图数据库擅长复杂遍历，但没有针对高维向量搜索进行原生优化。本文介绍了混合多模图索引（HMGI），这是一个旨在通过为多模数据创建高效、混合查询的统一系统来弥合这一差距的新颖框架。HMGI利用原生图数据库架构和集成的向量搜索能力（以Neo4j等平台为例），将近似最近邻搜索（ANNS）与表达性图遍历查询相结合。HMGI框架的关键创新包括：模态感知的嵌入分区，以优化索引结构和查询性能；以及一个自适应、低开销的索引更新系统，以支持动态数据摄取，其灵感来自TigerVector等系统的架构原则。通过将语义相似度搜索直接与关系上下文集成，HMGI旨在复杂、关系密集的查询场景中优于纯向量数据库（如Milvus），并实现混合任务的亚线性查询时间。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10123) | **Categories:** cs.DB, cs.LG

---

### [4] [Efficient Mining of Low-Utility Sequential Patterns](https://arxiv.org/abs/2510.10243)
*Jian Zhu, Zhidong Lin, Wensheng Gan, Ruichu Cai, Zhifeng Hao, Philip S. Yu*

Main category: cs.DB

TL;DR: 本文针对低效用序列模式挖掘问题，提出了三种算法LUSPM_b、LUSPM_s和LUSPM_e，并通过实验验证了LUSPM_s和LUSPM_e的有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有基于效用的序列模式挖掘研究主要集中在高效率用序列模式上，而高效率用序列模式的定义和策略不能直接应用于低效率用序列模式。此外，目前还没有专门用于挖掘低效率用序列模式的算法。

Method: 本文形式化了LUSPM问题，重新定义了序列效用，并引入了一种紧凑的数据结构，称为序列效用链，以有效地记录效用信息。此外，本文提出了三种新的算法LUSPM_b、LUSPM_s和LUSPM_e来发现完整的低效率用序列模式集。LUSPM_b作为详尽的基线，而LUSPM_s和LUSPM_e建立在此基础上，分别通过收缩和扩展操作生成子序列。此外，本文还介绍了最大非互包含序列集，并结合了多种剪枝策略，从而显著减少了LUSPM_s和LUSPM_e中的冗余操作。

Result: 大量的实验结果表明，LUSPM_s和LUSPM_e的性能均优于LUSPM_b，并具有出色的可扩展性。值得注意的是，LUSPM_e实现了卓越的效率，与LUSPM_s相比，需要更少的运行时间和内存消耗。

Conclusion: 本文解决了低效率用序列模式挖掘问题，提出的LUSPM_s和LUSPM_e算法具有良好的性能和可扩展性，LUSPM_e算法效率最高。

Abstract: 从丰富的数据中发现有价值的见解是探索性数据分析的关键任务。序列模式挖掘（SPM）已在各个领域得到广泛应用。近年来，低效用序列模式挖掘（LUSPM）在入侵检测和基因组序列分析等应用中显示出强大的潜力。然而，现有基于效用的SPM研究主要集中在高效率用序列模式上，并且高效率用SPM中使用的定义和策略不能直接应用于LUSPM。此外，尚未开发出专门用于挖掘低效用序列模式的算法。为了解决这些问题，我们形式化了LUSPM问题，重新定义了序列效用，并引入了一种紧凑的数据结构，称为序列效用链，以有效地记录效用信息。此外，我们提出了三种新的算法——LUSPM_b、LUSPM_s和LUSPM_e——来发现完整的低效用序列模式集。LUSPM_b作为详尽的基线，而LUSPM_s和LUSPM_e建立在此基础上，分别通过收缩和扩展操作生成子序列。此外，我们还介绍了最大非互包含序列集，并结合了多种剪枝策略，从而显著减少了LUSPM_s和LUSPM_e中的冗余操作。最后，大量的实验结果表明，LUSPM_s和LUSPM_e的性能均大大优于LUSPM_b，并具有出色的可扩展性。值得注意的是，LUSPM_e实现了卓越的效率，与LUSPM_s相比，需要更少的运行时间和内存消耗。我们的代码可在https://github.com/Zhidong-Lin/LUSPM上找到。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10243) | **Categories:** cs.DB

---

### [5] [Regular Expression Indexing for Log Analysis. Extended Version](https://arxiv.org/abs/2510.10348)
*Ling Zhang, Shaleen Deep, Jignesh M. Patel, Karthikeyan Sankaralingam*

Main category: cs.DB

TL;DR: 本文提出了一种基于n-gram索引策略和高效存储机制的日志数据正则表达式查询系统REI，可实现高达14倍的加速。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决在日志数据上进行正则表达式查询时，现有技术存在的效率问题。

Method: 该论文提出了一种基于n-gram的索引策略和高效的存储机制，用于索引日志数据以加速正则表达式查询。

Result: 实验结果表明，REI系统相比于不使用索引的先进正则表达式处理引擎，速度提升高达14倍，且仅使用了2.1%的额外空间。

Conclusion: 本文提出的REI方法在评估日志数据上的正则表达式查询时，提供了显著的性能提升，并且REI具有模块化设计，可以与现有的正则表达式包一起使用，易于在各种环境中部署。

Abstract: 本文介绍了一种名为REI的新型系统，该系统用于索引日志数据以支持正则表达式查询。我们的主要贡献是一种基于n-gram的索引策略和一种高效的存储机制，与不使用索引的最新正则表达式处理引擎相比，速度提高了14倍，仅使用了2.1%的额外空间。我们进行了详细的研究，分析了索引的空间使用情况和工作负载执行时间的改进，揭示了有趣的见解。具体来说，我们表明，即使是文本处理库中广泛使用的倒排索引等策略的优化实现，也可能导致日志分析任务的正则表达式索引的次优性能。总的来说，本文提出的REI方法在评估日志数据上的正则表达式查询时，提供了显著的提升。REI也是模块化的，可以与现有的正则表达式包一起使用，使其易于在各种环境中部署。REI的代码可在https://github.com/mush-zhang/REI-Regular-Expression-Indexing上找到。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10348) | **Categories:** cs.DB

---

### [6] [AQORA: A Learned Adaptive Query Optimizer for Spark SQL](https://arxiv.org/abs/2510.10580)
*Jiahao He, Yutao Cui, Cuiping Li, Jikang Jiang, Yuheng Hou, Hong Chen*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Recent studies have identified two main approaches to improve query optimization: learned query optimization (LQO), which generates or selects better query plans before execution based on models trained in advance, and adaptive query processing (AQP), which adapts the query plan during execution based on statistical feedback collected at runtime. Although both approaches have shown promise, they also face critical limitations. LQO must commit to a fixed plan without access to actual cardinalities and typically rely on a single end-to-end feedback signal, making learning inefficient. On the other hand, AQP depends heavily on rule-based heuristics and lacks the ability to learn from experience. In this paper, we present AQORA, an adaptive query optimizer with a reinforcement learning architecture that combines the strengths of both LQO and AQP. AQORA addresses the above challenges through four core strategies: (1) realistic feature encoding, (2) query stage-level feedback and intervention, (3) automatic strategy adaptation, and (4) low-cost integration. Experiments show that AQORA reduces end-to-end execution time by up to 90% compared to other learned methods and by up to 70% compared to Spark SQL's default configuration with adaptive query execution.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10580) | **Categories:** cs.DB

---

### [7] [DriftBench: Defining and Generating Data and Query Workload Drift for Benchmarking](https://arxiv.org/abs/2510.10858)
*Guanli Liu, Renata Borovica-Gajic*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Data and workload drift are key to evaluating database components such as caching, cardinality estimation, indexing, and query optimization. Yet, existing benchmarks are static, offering little to no support for modeling drift. This limitation stems from the lack of clear definitions and tools for generating data and workload drift. Motivated by this gap, we propose a unified taxonomy for data and workload drift, grounded in observations from both academia and industry. Building on this foundation, we introduce DriftBench, a lightweight and extensible framework for generating data and workload drift in benchmark inputs. Together, the taxonomy and DriftBench provide a standardized vocabulary and mechanism for modeling and generating drift in benchmarking. We demonstrate their effectiveness through case studies involving data drift, workload drift, and drift-aware cardinality estimation.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10858) | **Categories:** cs.DB

---

### [8] [GrASP: A Generalizable Address-based Semantic Prefetcher for Scalable Transactional and Analytical Workloads](https://arxiv.org/abs/2510.11011)
*Farzaneh Zirak, Farhana Choudhury, Renata Borovica-Gajic*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Data prefetching--loading data into the cache before it is requested--is essential for reducing I/O overhead and improving database performance. While traditional prefetchers focus on sequential patterns, recent learning-based approaches, especially those leveraging data semantics, achieve higher accuracy for complex access patterns. However, these methods often struggle with today's dynamic, ever-growing datasets and require frequent, timely fine-tuning. Privacy constraints may also restrict access to complete datasets, necessitating prefetchers that can learn effectively from samples. To address these challenges, we present GrASP, a learning-based prefetcher designed for both analytical and transactional workloads. GrASP enhances prefetching accuracy and scalability by leveraging logical block address deltas and combining query representations with result encodings. It frames prefetching as a context-aware multi-label classification task, using multi-layer LSTMs to predict delta patterns from embedded context. This delta modeling approach enables GrASP to generalize predictions from small samples to larger, dynamic datasets without requiring extensive retraining. Experiments on real-world datasets and industrial benchmarks demonstrate that GrASP generalizes to datasets 250 times larger than the training data, achieving up to 45% higher hit ratios, 60% lower I/O time, and 55% lower end-to-end query execution latency than existing baselines. On average, GrASP attains a 91.4% hit ratio, a 90.8% I/O time reduction, and a 57.1% execution latency reduction.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.11011) | **Categories:** cs.DB, cs.LG

---

### [9] [Poseidon: A OneGraph Engine](https://arxiv.org/abs/2510.11166)
*Brad Bebee, Ümit V. Çatalyürek, Olaf Hartig, Ankesh Khandelwal, Simone Rondelli, Michael Schmidt, Lefteris Sidirourgos, Bryan Thompson*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: We present the Poseidon engine behind the Neptune Analytics graph database service. Customers interact with Poseidon using the declarative openCypher query language, which enables requests that seamlessly combine traditional querying paradigms (such as graph pattern matching, variable length paths, aggregation) with algorithm invocations and has been syntactically extended to facilitate OneGraph interoperability, such as the disambiguation between globally unique IRIs (as exposed via RDF) vs. local identifiers (as encountered in LPG data). Poseidon supports a broad range of graph workloads, from simple transactions, to top-k beam search algorithms on dynamic graphs, to whole graph analytics requiring multiple full passes over the data. For example, real-time fraud detection, like many other use cases, needs to reflect current committed state of the dynamic graph. If a users cell phone is compromised, then all newer actions by that user become immediately suspect. To address such dynamic graph use cases, Poseidon combines state-of-the-art transaction processing with novel graph data indexing, including lock-free maintenance of adjacency lists, secondary succinct indices, partitioned heaps for data tuple storage with uniform placement, and innovative statistics for cost-based query optimization. The Poseidon engine uses a logical log for durability, enabling rapid evolution of in-memory data structures. Bulk data loads achieve more than 10 million property values per second on many data sets while simple transactions can execute in under 20ms against the storage engine.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.11166) | **Categories:** cs.DB

---


## 机器学习 (Machine Learning) [cs.LG]
### [1] [Aegis: A Correlation-Based Data Masking Advisor for Data Sharing Ecosystems](https://arxiv.org/abs/2510.10810)
*Omar Islam Laskar, Fatemeh Ramezani Khozestani, Ishika Nankani, Sohrab Namazi Nia, Senjuti Basu Roy, Kaustubh Beedkar*

Main category: cs.LG

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Data-sharing ecosystems enable entities -- such as providers, consumers, and intermediaries -- to access, exchange, and utilize data for various downstream tasks and applications. Due to privacy concerns, data providers typically anonymize datasets before sharing them; however, the existence of multiple masking configurations results in masked datasets with varying utility. Consequently, a key challenge lies in efficiently determining the optimal masking configuration that maximizes a dataset's utility. This paper presents AEGIS, a middleware framework for identifying the optimal masking configuration for machine learning datasets that consist of features and a class label. We introduce a utility optimizer that minimizes predictive utility deviation -- a metric based on the changes in feature-label correlations before and after masking. Our framework leverages limited data summaries (such as 1D histograms) or none to estimate the feature-label joint distribution, making it suitable for scenarios where raw data is inaccessible due to privacy restrictions. To achieve this, we propose a joint distribution estimator based on iterative proportional fitting, which allows supporting various feature-label correlation quantification methods such as g3, mutual information, or chi-square. Our experimental evaluation on real-world datasets shows that AEGIS identifies optimal masking configurations over an order of magnitude faster, while the resulting masked datasets achieve predictive performance on downstream ML tasks that is on par with baseline approaches.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.10810) | **Categories:** cs.LG, cs.DB

---
