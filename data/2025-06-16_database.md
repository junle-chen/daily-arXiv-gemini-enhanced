# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-06-16

## 目录

- [cs.DB (4)](#cs-db)

## cs.DB [cs.DB]
### [1] [GPU Acceleration of SQL Analytics on Compressed Data](https://arxiv.org/abs/2506.10092)
*Zezhou Huang, Krystian Sakowski, Hans Lehnert, Wei Cui, Carlo Curino, Matteo Interlandi, Marius Dumitru, Rathijit Sen*

Main category: cs.DB

TL;DR: 该论文提出了一种直接在轻量级压缩数据上运行查询的方法，显著提高了GPU处理大数据集的分析性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决GPU HBM容量有限，无法容纳大型数据集的问题，并且避免解压缩带来的性能开销，该研究旨在探索直接在压缩数据上进行计算的方法。

Method: 该论文提出了一套新的方法，用于直接在轻量级压缩数据上运行查询，包括游程编码（RLE）、索引编码、位宽缩减和字典编码等方案。其创新之处包括在不解压缩的情况下操作多个RLE列，处理异构列编码，并利用PyTorch张量运算实现跨设备的移植性。

Result: 实验结果表明，对于无法放入未压缩GPU内存的生产数据集上的真实查询，与最先进的商业CPU分析系统相比，速度提高了近一个数量级。

Conclusion: 该研究表明，通过直接在轻量级压缩数据上运行查询，可以显著提高GPU在处理大数据集上的分析性能，为更广泛的GPU应用铺平了道路。

Abstract: 由于GPU具有大规模的计算并行性和高带宽内存（HBM），因此非常适合加速（SQL）分析工作负载——当数据集适合GPU HBM时，性能是无与伦比的。不幸的是，与较低带宽的CPU主内存相比，GPU HBM通常仍然很小。除了跨多个GPU的暴力扩展之外，当前加速大型数据集查询的解决方案包括利用数据分区并在GPU HBM中加载较小的数据批次，以及与连接设备（例如CPU）的混合执行。不幸的是，这些方法受到较低主内存和主机到设备互连带宽的限制，引入了额外的I/O开销，或导致更高的成本。当试图在更大的数据集上扩展GPU的应用时，这是一个实质性的问题。数据压缩可以缓解这个瓶颈，但为了避免为昂贵的解压缩/解码付费，理想的解决方案必须包括直接对压缩形式的数据进行操作的计算原语。这是我们论文的重点：一套新的方法，用于直接在轻量级压缩数据上运行查询，使用游程编码（RLE）、索引编码、位宽缩减和字典编码等方案。我们的创新包括在不解压缩的情况下操作多个RLE列，处理异构列编码，并利用PyTorch张量运算实现跨设备的移植性。实验评估表明，对于无法放入未压缩GPU内存的生产数据集上的真实查询，与最先进的商业CPU分析系统相比，速度提高了一个数量级。这项工作为GPU在更广泛的用例中的应用铺平了道路，并且与大多数其他横向扩展或回退机制互补。

</details>

[**[PDF]**](https://arxiv.org/pdf/2506.10092) | **Categories:** cs.DB

---

### [2] [A Unifying Algorithm for Hierarchical Queries](https://arxiv.org/abs/2506.10238)
*Mahmoud Abo Khamis, Jesse Comer, Phokion Kolaitis, Sudeepa Roy, Val Tannen*

Main category: cs.DB

TL;DR: 该论文证明了分层查询定义了概率查询评估、Shapley值计算和bag-set最大化问题在可处理性上的界限，并提出了一个统一的算法。


<details>
  <summary>Details</summary>
Motivation: 分层查询定义了self-join free Boolean conjunctive queries (SJF-BCQ)在可处理性和难处理性之间的界限，针对以下两个广泛研究的问题：(i) 在元组独立的概率数据库上评估SJF-BCQ；(ii) 计算数据库中一个事实的Shapley值，该数据库上SJF-BCQ评估为真。该论文旨在确定分层查询是否也定义了另一个自然算法问题的可处理性和难处理性之间的界限，即“bag-set最大化”问题。

Method: 该论文提出了一个统一的多项式时间算法，该算法作用于一个抽象代数结构，称为“2-monoid”，适用于分层查询的概率查询评估、Shapley值计算和bag-set最大化问题。

Result: 对于非分层查询，bag-set最大化问题是一个NP完全优化问题。对于分层查询，概率查询评估、Shapley值计算和bag-set最大化这三个问题都存在一个统一的多项式时间算法。

Conclusion: 对于分层查询，概率查询评估、Shapley值计算和bag-set最大化这三个问题都存在一个统一的多项式时间算法，该算法作用于一个抽象代数结构，称为“2-monoid”。

Abstract: 分层查询在以下两个广泛研究的关于无自连接布尔合取查询（SJF-BCQ）的问题的可处理性和难处理性之间定义了界限：（i）在元组独立的概率数据库上评估SJF-BCQ；（ii）计算数据库中一个事实的Shapley值，在该数据库上SJF-BCQ的评估结果为真。本文确定了分层查询也定义了另一种自然算法问题的可处理性和难处理性之间的界限，我们称之为“bag-set最大化”问题。与SJF-BCQ $Q$ 相关的bag-set最大化问题是指：给定一个数据库 $\cal D$，找到 $Q$ 在包语义下所能取得的最大值，该数据库 $\cal D'$ 是通过从另一个给定的数据库 $\cal D^r$ 中添加最多 $\theta$ 个事实到 $\cal D$ 而获得的。对于非分层查询，我们证明了 bag-set 最大化问题是一个 NP 完全优化问题。更重要的是，对于分层查询，我们表明所有上述三个问题（概率查询评估、Shapley 值计算和 bag-set 最大化）都接受一个统一的多项式时间算法，该算法作用于一个抽象代数结构，称为“2-monoid”。这三个问题中的每一个都需要针对手头问题量身定制的 2-monoid 的不同实例化。

</details>

[**[PDF]**](https://arxiv.org/pdf/2506.10238) | **Categories:** cs.DB

---

### [3] [A Hybrid Heuristic Framework for Resource-Efficient Querying of Scientific Experiments Data](https://arxiv.org/abs/2506.10422)
*Mayank Patel, Minal Bhise*

Main category: cs.DB

TL;DR: 本文提出了一种轻量级混合框架RAW-HF，通过有效利用有限资源来优化原始数据查询，从而显著减少工作负载执行时间并提高资源利用率。


<details>
  <summary>Details</summary>
Motivation: 传统数据库管理系统（DBMS）和HTAP系统在开始查询执行之前，需要花费大量时间和资源将整个数据集加载到DBMS中。另一方面，原地引擎可能会多次重新解析所需数据，从而增加资源利用率和数据处理成本。此外，过度或不足的资源分配也会增加应用程序的运行成本。

Method: 提出了一种轻量级的资源可用性与工作负载感知混合框架（RAW-HF），以有效利用现有有限资源来优化原始数据查询。

Result: 在实际科学数据集工作负载（如Sloan Digital Sky Survey（SDSS）和Linked Observation Data（LOD））上应用RAW-HF的影响表明，与广泛使用的传统DBMS PostgreSQL相比，工作负载执行时间（WET）减少了90%以上和85%。

Conclusion: 与最先进的混合系统工作负载感知部分加载技术（WA）相比，RAW-HF将CPU、IO资源利用率和WET分别降低了26%、25%和26%，同时将内存利用率提高了33%。与基于机器学习的资源分配技术（如PCC）相比，RAW-HF使用的MUAR技术也具有优势。

Abstract: 科学实验和现代应用程序每天产生大量数据。大多数组织利用内部服务器或云资源来管理应用程序数据和工作负载。传统的数据库管理系统（DBMS）和HTAP系统在开始查询执行之前，需要花费大量时间和资源将整个数据集加载到DBMS中。另一方面，原地引擎可能会多次重新解析所需数据，从而增加资源利用率和数据处理成本。此外，过度或不足的资源分配也会增加应用程序的运行成本。本文提出了一种轻量级的资源可用性与工作负载感知混合框架（RAW-HF），以有效利用现有有限资源来优化原始数据查询。RAW-HF包括一些模块，这些模块有助于优化执行给定工作负载所需的资源，并最大限度地利用现有资源。在实际科学数据集工作负载（如Sloan Digital Sky Survey（SDSS）和Linked Observation Data（LOD））上应用RAW-HF的影响表明，与广泛使用的传统DBMS PostgreSQL相比，工作负载执行时间（WET）减少了90%以上和85%。与最先进的混合系统工作负载感知部分加载技术（WA）相比，总体CPU、IO资源利用率和WET分别降低了26%、25%和26%，同时内存利用率提高了33%。还介绍了RAW-HF使用的MUAR技术与基于机器学习的资源分配技术（如PCC）的比较。

</details>

[**[PDF]**](https://arxiv.org/pdf/2506.10422) | **Categories:** cs.DB, cs.DC, cs.ET, cs.PF

---

### [4] [S3 Mirror: S3Mirror: Making Genomic Data Transfers Fast, Reliable, and Observable with DBOS](https://arxiv.org/abs/2506.10886)
*Steven Vasquez-Grinnell, Alex Poliakov*

Main category: cs.DB

TL;DR: S3Mirror is an open-source application using DBOSTransact that efficiently and reliably transfers large genomic datasets between S3 buckets with real-time observability and failure resilience, outperforming AWS DataSync in speed and cost on DBOS Cloud Pro.


<details>
  <summary>Details</summary>
Motivation: To meet the needs of a large pharmaceutical organization for transferring large genomic sequencing datasets between S3 buckets quickly, reliably, and observably.

Method: The authors used the DBOSTransact durable execution framework.

Result: S3Mirror can run in a variety of environments, including DBOS Cloud Pro where it runs as much as 40x faster than AWS DataSync at a fraction of the cost.

Conclusion: S3Mirror is resilient to failures and allows for real-time filewise observability of ongoing and past transfers.

Abstract: 为了满足大型制药组织的需求，我们创建了 S3Mirror，一个用于在 S3 存储桶之间快速、可靠且可观察地传输大型基因组测序数据集的应用程序。我们使用 DBOSTransact 持久执行框架来实现这些目标，并对应用程序的性能和成本进行了基准测试。S3Mirror 是一个开源的 DBOS Python 应用程序，可以在各种环境中运行，包括 DBOS Cloud Pro，在其中运行速度比 AWS DataSync 快 40 倍，而成本仅为其一小部分。此外，S3Mirror 具有故障恢复能力，并允许对正在进行和过去的传输进行实时文件级可观察性。

</details>

[**[PDF]**](https://arxiv.org/pdf/2506.10886) | **Categories:** cs.DB, q-bio.GN

---
