{"id": "2511.07663", "pdf": "https://arxiv.org/pdf/2511.07663", "abs": "https://arxiv.org/abs/2511.07663", "authors": ["Paritosh Aggarwal", "Bowei Chen", "Anupam Datta", "Benjamin Han", "Boxin Jiang", "Nitish Jindal", "Zihan Li", "Aaron Lin", "Pawel Liskowski", "Jay Tayade", "Dimitris Tsirogiannis", "Nathan Wiegand", "Weicheng Zhao"], "title": "Cortex AISQL: A Production SQL Engine for Unstructured Data", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": null, "summary": "Snowflake's Cortex AISQL is a production SQL engine that integrates native semantic operations directly into SQL. This integration allows users to write declarative queries that combine relational operations with semantic reasoning, enabling them to query both structured and unstructured data effortlessly. However, making semantic operations efficient at production scale poses fundamental challenges. Semantic operations are more expensive than traditional SQL operations, possess distinct latency and throughput characteristics, and their cost and selectivity are unknown during query compilation. Furthermore, existing query engines are not designed to optimize semantic operations. The AISQL query execution engine addresses these challenges through three novel techniques informed by production deployment data from Snowflake customers. First, AI-aware query optimization treats AI inference cost as a first-class optimization objective, reasoning about large language model (LLM) cost directly during query planning to achieve 2-8$\\times$ speedups. Second, adaptive model cascades reduce inference costs by routing most rows through a fast proxy model while escalating uncertain cases to a powerful oracle model, achieving 2-6$\\times$ speedups while maintaining 90-95% of oracle model quality. Third, semantic join query rewriting lowers the quadratic time complexity of join operations to linear through reformulation as multi-label classification tasks, achieving 15-70$\\times$ speedups with often improved prediction quality. AISQL is deployed in production at Snowflake, where it powers diverse customer workloads across analytics, search, and content understanding."}
{"id": "2511.07886", "pdf": "https://arxiv.org/pdf/2511.07886", "abs": "https://arxiv.org/abs/2511.07886", "authors": ["Dechuang Chen", "Sibo Wang", "Qintian Guo"], "title": "ACGraph: An Efficient Asynchronous Out-of-Core Graph Processing Framework", "categories": ["cs.DB", "cs.DC"], "comment": "Accepted by SIGMOD'26", "summary": "Graphs are a ubiquitous data structure in diverse domains such as machine learning, social networks, and data mining. As real-world graphs continue to grow beyond the memory capacity of single machines, out-of-core graph processing systems have emerged as a viable solution. Yet, existing systems that rely on strictly synchronous, iteration-by-iteration execution incur significant overheads. In particular, their scheduling mechanisms lead to I/O inefficiencies, stemming from read and work amplification, and induce costly synchronization stalls hindering sustained disk utilization. To overcome these limitations, we present {\\em ACGraph}, a novel asynchronous graph processing system optimized for SSD-based environments with constrained memory resources. ACGraph employs a dynamic, block-centric priority scheduler that adjusts in real time based on workload, along with an online asynchronous worklist that minimizes redundant disk accesses by efficiently reusing active blocks in memory. Moreover, ACGraph unifies asynchronous I/O with computation in a pipelined execution model that maintains sustained I/O activation, and leverages a highly optimized hybrid storage format to expedite access to low-degree vertices. We implement popular graph algorithms, such as Breadth-First Search (BFS), Weakly Connected Components (WCC), personalized PageRank (PPR), PageRank (PR), and $k$-core on ACGraph and demonstrate that ACGraph substantially outperforms state-of-the-art out-of-core graph processing systems in both runtime and I/O efficiency."}
{"id": "2511.07506", "pdf": "https://arxiv.org/pdf/2511.07506", "abs": "https://arxiv.org/abs/2511.07506", "authors": ["Izaque Esteves", "Regina Braga", "Jos\u00e9 Maria David", "Victor Stroele"], "title": "A Service Suite for Specifying Digital Twins for Industry 5.0", "categories": ["cs.SE", "cs.DB"], "comment": "38 pages, submitted do IEEE Access. It is under review - second rebuttal", "summary": "One of the challenges of predictive maintenance is making decisions based on data in an agile and assertive way. Connected sensors and operational data favor intelligent processing techniques to enrich information and enable decision-making. Digital Twins (DTs) can be used to process information and support decision-making. DTs are a real-time representation of physical machines and generate data that predictive maintenance can use to make assertive and quick decisions. The main contribution of this work is the specification of a suite of services for specifying DTs, called DT-Create, focused on decision support in predictive maintenance. DT-Create suite is based on intelligent techniques, semantic data processing, and self-adaptation. This suite was developed using the Design Science Research (DSR) methodology through two development cycles and evaluated through case studies. The results demonstrate the feasibility of using DT-Create in specifying DTs considering the following aspects: (i) collection, storage, and intelligent processing of data generated by sensors, (ii) enrichment of information through machine learning and ontologies, (iii) use of intelligent techniques to select predictive models that adhere to the available data set, and (iv) decision support and self-adaptation."}
