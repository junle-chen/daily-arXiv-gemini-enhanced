# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-11-27

## 目录

- [cs.DB (8)](#cs-db)
- [cs.DC (3)](#cs-dc)
- [机器学习 (Machine Learning) (1)](#cs-lg)

## cs.DB [cs.DB]
### [1] [Beyond Relational: Semantic-Aware Multi-Modal Analytics with LLM-Native Query Optimization](https://arxiv.org/abs/2511.19830)
*Junhao Zhu, Lu Chen, Xiangyu Ke, Ziquan Fang, Tianyi Li, Yunjun Gao, Christian S. Jensen*

Main category: cs.DB

TL;DR: Nirvana是一个多模态数据分析框架，它结合了可编程语义算子，并利用逻辑和物理查询优化策略，专为LLM驱动的语义查询处理而设计。


<details>
  <summary>Details</summary>
Motivation: 传统关系查询运算符捕获查询语义的能力有限，为了解决这个问题，我们提出了Nirvana，一个多模态数据分析框架，它通过结合可编程语义算子和利用LLM驱动的语义查询处理来克服这些限制。

Method: Nirvana包含一个代理逻辑优化器，它使用自然语言指定的转换规则和基于随机游走的搜索来探索大量的语义等价查询计划。此外，它还引入了一个成本感知的物理优化器，该优化器使用一种新的改进评分指标为每个运算符选择最有效的LLM后端。为了进一步提高效率，Nirvana还结合了计算重用和模型能力假设指导下的评估下推技术。

Result: 在三个真实世界的基准测试中进行的实验评估表明，Nirvana能够将端到端运行时间减少10%--85%，并将系统处理成本平均降低76%，在效率和可扩展性方面均优于最先进的系统。

Conclusion: Nirvana通过结合可编程语义算子，并利用逻辑和物理查询优化策略，显著提高了多模态数据分析的效率和可扩展性，为LLM驱动的语义查询处理开辟了新的可能性。

Abstract: 多模态分析处理有潜力改变电子商务、医疗保健、娱乐等领域的应用。然而，由于传统关系查询运算符捕获查询语义的能力有限，实际应用仍然难以实现。大型语言模型（LLM）等基础模型的出现，为开发灵活的、语义感知的数据分析系统开辟了新的机遇，这些系统超越了关系范式。我们提出了Nirvana，一个多模态数据分析框架，它结合了可编程语义算子，并利用逻辑和物理查询优化策略，专为LLM驱动的语义查询处理而设计。Nirvana解决了两个关键挑战。首先，它包含一个代理逻辑优化器，它使用自然语言指定的转换规则和基于随机游走的搜索来探索大量的语义等价查询计划——远远超出了传统优化器的能力。其次，它引入了一个成本感知的物理优化器，该优化器使用一种新的改进评分指标为每个运算符选择最有效的LLM后端。为了进一步提高效率，Nirvana还结合了计算重用和模型能力假设指导下的评估下推技术。在三个真实世界的基准测试中进行的实验评估表明，Nirvana能够将端到端运行时间减少10%--85%，并将系统处理成本平均降低76%，在效率和可扩展性方面均优于最先进的系统。

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.19830) | **Categories:** cs.DB, cs.AI

---

### [2] [Updatable Balanced Index for Fast On-device Search with Auto-selection Model](https://arxiv.org/abs/2511.20049)
*Yushuai Ji, Sheng Wang, Zhiyu Chen, Yuan Sun, Zhiyong Peng*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Diverse types of edge data, such as 2D geo-locations and 3D point clouds, are collected by sensors like lidar and GPS receivers on edge devices. On-device searches, such as k-nearest neighbor (kNN) search and radius search, are commonly used to enable fast analytics and learning technologies, such as k-means dataset simplification using kNN. To maintain high search efficiency, a representative approach is to utilize a balanced multi-way KD-tree (BMKD-tree). However, the index has shown limited gains, mainly due to substantial construction overhead, inflexibility to real-time insertion, and inconsistent query performance. In this paper, we propose UnIS to address the above limitations. We first accelerate the construction process of the BMKD-tree by utilizing the dataset distribution to predict the splitting hyperplanes. To make the continuously generated data searchable, we propose a selective sub-tree rebuilding scheme to accelerate rebalancing during insertion by reducing the number of data points involved. We then propose an auto-selection model to improve query performance by automatically selecting the optimal search strategy among multiple strategies for an arbitrary query task. Experimental results show that UnIS achieves average speedups of 17.96x in index construction, 1.60x in insertion, 7.15x in kNN search, and 1.09x in radius search compared to the BMKD-tree. We further verify its effectiveness in accelerating dataset simplification on edge devices, achieving a speedup of 217x over Lloyd's algorithm.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.20049) | **Categories:** cs.DB

---

### [3] [Mobility Stream Processing on NebulaStream and MEOS](https://arxiv.org/abs/2511.20084)
*Mariana M. Garcez Duarte, Dwi P. A. Nugroho, Georges Tod, Evert Bevernage, Pieter Moelans, Emine Tas, Esteban Zimanyi, Mahmoud Sakr, Steffen Zeuch, Volker Markl*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: The increasing use of Internet-of-Things (IoT) sensors in moving objects has resulted in vast amounts of spatiotemporal streaming data. To analyze this data in situ, real-time spatiotemporal processing is needed. However, current stream processing systems designed for IoT environments often lack spatiotemporal processing capabilities, and existing spatiotemporal libraries primarily focus on analyzing historical data. This gap makes performing real-time spatiotemporal analytics challenging. In this demonstration, we present NebulaMEOS, which combines MEOS (Mobility Engine Open Source), a spatiotemporal processing library, with NebulaStream, a scalable data management system for IoT applications. By integrating MEOS into NebulaStream, NebulaMEOS utilizes spatiotemporal functionalities to process and analyze streaming data in real-time. We demonstrate NebulaMEOS by querying data streamed from edge devices on trains by the Société Nationale des Chemins de fer Belges (SNCB). Visitors can experience demonstrations of geofencing and geospatial complex event processing, visualizing real-time train operations and environmental impacts.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.20084) | **Categories:** cs.DB

---

### [4] [N2E: A General Framework to Reduce Node-Differential Privacy to Edge-Differential Privacy for Graph Analytics](https://arxiv.org/abs/2511.20125)
*Yihua Hu, Hao Ding, Wei Dong*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Differential privacy (DP) has been widely adopted to protect sensitive information in graph analytics. While edge-DP, which protects privacy at the edge level, has been extensively studied, node-DP, offering stronger protection for entire nodes and their incident edges, remains largely underexplored due to its technical challenges. A natural way to bridge this gap is to develop a general framework for reducing node-DP graph analytical tasks to edge-DP ones, enabling the reuse of existing edge-DP mechanisms. A straightforward solution based on group privacy divides the privacy budget by a given degree upper bound, but this leads to poor utility when the bound is set conservatively large to accommodate worst-case inputs. To address this, we propose node-to-edge (N2E), a general framework that reduces any node-DP graph analytical task to an edge-DP one, with the error dependency on the graph's true maximum degree. N2E introduces two novel techniques: a distance-preserving clipping mechanism that bounds edge distance between neighboring graphs after clipping, and the first node-DP mechanism for maximum degree approximation, enabling tight, privacy-preserving clipping thresholds. By instantiating N2E with existing edge-DP mechanisms, we obtain the first node-DP solutions for tasks such as maximum degree estimation. For edge counting, our method theoretically matches the error of the state-of-the-art, which is provably optimal, and significantly outperforms existing approaches for degree distribution estimation. Experimental results demonstrate that our framework achieves up to a 2.5x reduction in error for edge counting and up to an 80x reduction for degree distribution estimation.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.20125) | **Categories:** cs.DB

---

### [5] [An experimental study of existing tools for outlier detection and cleaning in trajectories](https://arxiv.org/abs/2511.20139)
*Mariana M Garcez Duarte, Mahmoud Sakr*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Outlier detection and cleaning are essential steps in data preprocessing to ensure the integrity and validity of data analyses. This paper focuses on outlier points within individual trajectories, i.e., points that deviate significantly inside a single trajectory. We experiment with ten open-source libraries to comprehensively evaluate available tools, comparing their efficiency and accuracy in identifying and cleaning outliers. This experiment considers the libraries as they are offered to end users, with real-world applicability. We compare existing outlier detection libraries, introduce a method for establishing ground-truth, and aim to guide users in choosing the most appropriate tool for their specific outlier detection needs. Furthermore, we survey the state-of-the-art algorithms for outlier detection and classify them into five types: Statistic-based methods, Sliding window algorithms, Clustering-based methods, Graph-based methods, and Heuristic-based methods. Our research provides insights into these libraries' performance and contributes to developing data preprocessing and outlier detection methodologies.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.20139) | **Categories:** cs.DB

---

### [6] [Forgetting by Pruning: Data Deletion in Join Cardinality Estimation](https://arxiv.org/abs/2511.20293)
*Chaowei He, Yuanjun Liu, Qingzhi Ma, Shenyuan Ren, Xizhao Luo, Lei Zhao, An Liu*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Machine unlearning in learned cardinality estimation (CE) systems presents unique challenges due to the complex distributional dependencies in multi-table relational data. Specifically, data deletion, a core component of machine unlearning, faces three critical challenges in learned CE models: attribute-level sensitivity, inter-table propagation and domain disappearance leading to severe overestimation in multi-way joins. We propose Cardinality Estimation Pruning (CEP), the first unlearning framework specifically designed for multi-table learned CE systems. CEP introduces Distribution Sensitivity Pruning, which constructs semi-join deletion results and computes sensitivity scores to guide parameter pruning, and Domain Pruning, which removes support for value domains entirely eliminated by deletion. We evaluate CEP on state-of-the-art architectures NeuroCard and FACE across IMDB and TPC-H datasets. Results demonstrate CEP consistently achieves the lowest Q-error in multi-table scenarios, particularly under high deletion ratios, often outperforming full retraining. Furthermore, CEP significantly reduces convergence iterations, incurring negligible computational overhead of 0.3%-2.5% of fine-tuning time.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.20293) | **Categories:** cs.DB, cs.AI, cs.LG

---

### [7] [The Case for Intent-Based Query Rewriting](https://arxiv.org/abs/2511.20419)
*Gianna Lisa Nicolai, Patrick Hansert, Sebastian Michel*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: With this work, we describe the concept of intent-based query rewriting and present a first viable solution. The aim is to allow rewrites to alter the structure and syntactic outcome of an original query while keeping the obtainable insights intact. This drastically differs from traditional query rewriting, which typically aims to decrease query evaluation time by using strict equivalence rules and optimization heuristics on the query plan. Rewriting queries to queries that only provide a similar insight but otherwise can be entirely different can remedy inaccessible original data tables due to access control, privacy, or expensive data access regarding monetary cost or remote access. In this paper, we put forward INQURE, a system designed for INtent-based QUery REwriting. It uses access to a large language model (LLM) for the query understanding and human-like derivation of alternate queries. Around the LLM, INQURE employs upfront table filtering and subsequent candidate rewrite pruning and ranking. We report on the results of an evaluation using a benchmark set of over 900 database table schemas and discuss the pros and cons of alternate approaches regarding runtime and quality of the rewrites of a user study.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.20419) | **Categories:** cs.DB

---

### [8] [InferF: Declarative Factorization of AI/ML Inferences over Joins](https://arxiv.org/abs/2511.20489)
*Kanchan Chowdhury, Lixi Zhou, Lulu Xie, Xinwei Fu, Jia Zou*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Real-world AI/ML workflows often apply inference computations to feature vectors joined from multiple datasets. To avoid the redundant AI/ML computations caused by repeated data records in the join's output, factorized ML has been proposed to decompose ML computations into sub-computations to be executed on each normalized dataset. However, there is insufficient discussion on how factorized ML could impact AI/ML inference over multi-way joins. To address the limitations, we propose a novel declarative InferF system, focusing on the factorization of arbitrary inference workflows represented as analyzable expressions over the multi-way joins. We formalize our problem to flexibly push down partial factorized computations to qualified nodes in the join tree to minimize the overall inference computation and join costs and propose two algorithms to resolve the problem: (1) a greedy algorithm based on a per-node cost function that estimates the influence on overall latency if a subset of factorized computations is pushed to a node, and (2) a genetic algorithm for iteratively enumerating and evaluating promising factorization plans. We implement InferF on Velox, an open-sourced database engine from Meta, evaluate it on real-world datasets, observed up to 11.3x speedups, and systematically summarized the factors that determine when factorized ML can benefit AI/ML inference workflows.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.20489) | **Categories:** cs.DB, cs.LG

---


## cs.DC [cs.DC]
### [1] [AVS: A Computational and Hierarchical Storage System for Autonomous Vehicles](https://arxiv.org/abs/2511.19453)
*Yuxin Wang, Yuankai He, Weisong Shi*

Main category: cs.DC

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Autonomous vehicles (AVs) are evolving into mobile computing platforms, equipped with powerful processors and diverse sensors that generate massive heterogeneous data, for example 14 TB per day. Supporting emerging third-party applications calls for a general-purpose, queryable onboard storage system. Yet today's data loggers and storage stacks in vehicles fail to deliver efficient data storage and retrieval. This paper presents AVS, an Autonomous Vehicle Storage system that co-designs computation with a hierarchical layout: modality-aware reduction and compression, hot-cold tiering with daily archival, and a lightweight metadata layer for indexing. The design is grounded with system-level benchmarks on AV data that cover SSD and HDD filesystems and embedded indexing, and is validated on embedded hardware with real L4 autonomous driving traces. The prototype delivers predictable real-time ingest, fast selective retrieval, and substantial footprint reduction under modest resource budgets. The work also outlines observations and next steps toward more scalable and longer deployments to motivate storage as a first-class component in AV stacks.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.19453) | **Categories:** cs.DC, cs.DB, cs.OS, cs.RO

---

### [2] [PolarStore: High-Performance Data Compression for Large-Scale Cloud-Native Databases](https://arxiv.org/abs/2511.19949)
*Qingda Hu, Xinjun Yang, Feifei Li, Junru Li, Ya Lin, Yuqi Zhou, Yicong Zhu, Junwei Zhang, Rongbiao Xie, Ling Zhou, Bin Wu, Wenchao Zhou*

Main category: cs.DC

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: In recent years, resource elasticity and cost optimization have become essential for RDBMSs. While cloud-native RDBMSs provide elastic computing resources via disaggregated computing and storage, storage costs remain a critical user concern. Consequently, data compression emerges as an effective strategy to reduce storage costs. However, existing compression approaches in RDBMSs present a stark trade-off: software-based approaches incur significant performance overheads, while hardware-based alternatives lack the flexibility required for diverse database workloads. In this paper, we present PolarStore, a compressed shared storage system for cloud-native RDBMSs. PolarStore employs a dual-layer compression mechanism that combines in-storage compression in PolarCSD hardware with lightweight compression in software. This design leverages the strengths of both approaches. PolarStore also incorporates database-oriented optimizations to maintain high performance on critical I/O paths. Drawing from large-scale deployment experiences, we also introduce hardware improvements for PolarCSD to ensure host-level stability and propose a compression-aware scheduling scheme to improve cluster-level space efficiency. PolarStore is currently deployed on thousands of storage servers within PolarDB, managing over 100 PB of data. It achieves a compression ratio of 3.55 and reduces storage costs by approximately 60%. Remarkably, these savings are achieved while maintaining performance comparable to uncompressed clusters.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.19949) | **Categories:** cs.DC, cs.DB

---

### [3] [SwitchDelta: Asynchronous Metadata Updating for Distributed Storage with In-Network Data Visibility](https://arxiv.org/abs/2511.19978)
*Junru Li, Qing Wang, Zhe Yang, Shuo Liu, Jiwu Shu, Youyou Lu*

Main category: cs.DC

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Distributed storage systems typically maintain strong consistency between data nodes and metadata nodes by adopting ordered writes: 1) first installing data; 2) then updating metadata to make data visible.We propose SwitchDelta to accelerate ordered writes by moving metadata updates out of the critical path. It buffers in-flight metadata updates in programmable switches to enable data visibility in the network and retain strong consistency. SwitchDelta uses a best-effort data plane design to overcome the resource limitation of switches and designs a novel metadata update protocol to exploit the benefits of in-network data visibility. We evaluate SwitchDelta in three distributed in-memory storage systems: log-structured key-value stores, file systems, and secondary indexes. The evaluation shows that SwitchDelta reduces the latency of write operations by up to 52.4% and boosts the throughput by up to 126.9% under write-heavy workloads.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.19978) | **Categories:** cs.DC, cs.DB

---


## 机器学习 (Machine Learning) [cs.LG]
### [1] [GED-Consistent Disentanglement of Aligned and Unaligned Substructures for Graph Similarity Learning](https://arxiv.org/abs/2511.19837)
*Zhentao Zhan, Xiaoliang Xu, Jingjing Wang, Junmei Wang*

Main category: cs.LG

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Graph Similarity Computation (GSC) is a fundamental graph related task where Graph Edit Distance (GED) serves as a prevalent metric. GED is determined by an optimal alignment between a pair of graphs that partitions each into aligned (zero-cost) and unaligned (cost-incurring) substructures. Due to NP-hard nature of exact GED computation, GED approximations based on Graph Neural Network(GNN) have emerged. Existing GNN-based GED approaches typically learn node embeddings for each graph and then aggregate pairwise node similarities to estimate the final similarity. Despite their effectiveness, we identify a mismatch between this prevalent node-centric matching paradigm and the core principles of GED. This discrepancy leads to two critical limitations: (1) a failure to capture the global structural correspondence for optimal alignment, and (2) a misattribution of edit costs driven by spurious node level signals. To address these limitations, we propose GCGSim, a GED-consistent graph similarity learning framework centering on graph-level matching and substructure-level edit costs. Specifically, we make three core technical contributions. Extensive experiments on four benchmark datasets show that GCGSim achieves state-of-the-art performance. Our comprehensive analyses further validate that the framework effectively learns disentangled and semantically meaningful substructure representations.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.19837) | **Categories:** cs.LG, cs.AI, cs.DB

---
