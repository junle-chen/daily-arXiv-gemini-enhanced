{"id": "2506.14831", "pdf": "https://arxiv.org/pdf/2506.14831", "abs": "https://arxiv.org/abs/2506.14831", "authors": ["C\u00e9line Finet", "Stephane Da Silva Martins", "Jean-Bernard Hayet", "Ioannis Karamouzas", "Javad Amirian", "Sylvie Le H\u00e9garat-Mascle", "Julien Pettr\u00e9", "Emanuel Aldea"], "title": "Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "30 pages", "summary": "With the emergence of powerful data-driven methods in human trajectory\nprediction (HTP), gaining a finer understanding of multi-agent interactions\nlies within hand's reach, with important implications in areas such as\nautonomous navigation and crowd modeling. This survey reviews some of the most\nrecent advancements in deep learning-based multi-agent trajectory prediction,\nfocusing on studies published between 2020 and 2024. We categorize the existing\nmethods based on their architectural design, their input representations, and\ntheir overall prediction strategies, placing a particular emphasis on models\nevaluated using the ETH/UCY benchmark. Furthermore, we highlight key challenges\nand future research directions in the field of multi-agent HTP.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "\u8be5\u8bba\u6587\u6807\u9898\u548c\u6458\u8981\u660e\u786e\u8868\u660e\u5176\u5173\u6ce8\u591a\u667a\u80fd\u4f53\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5c5e\u4e8e\u8f68\u8ff9\u9884\u6d4b\u9886\u57df\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u4e3a\u672a\u6765\u53ef\u80fd\u7ed3\u5408\u5927\u6a21\u578b\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "keywords": ["\u8f68\u8ff9\u9884\u6d4b", "\u591a\u667a\u80fd\u4f53", "\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b", "\u6df1\u5ea6\u5b66\u4e60"]}, "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86 2020-2024 \u5e74\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u7814\u7a76\uff0c\u5e76\u7a81\u51fa\u4e86\u8be5\u9886\u57df\u7684\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u4ee5\u4eba\u4e3a\u672c\u7684\u8f68\u8ff9\u9884\u6d4b (HTP) \u4e2d\u5f3a\u5927\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u51fa\u73b0\uff0c\u66f4\u6df1\u5165\u5730\u4e86\u89e3\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u89e6\u624b\u53ef\u53ca\uff0c\u8fd9\u5bf9\u81ea\u52a8\u5bfc\u822a\u548c\u4eba\u7fa4\u5efa\u6a21\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u6839\u636e\u73b0\u6709\u65b9\u6cd5\u7684\u67b6\u6784\u8bbe\u8ba1\u3001\u8f93\u5165\u8868\u793a\u548c\u6574\u4f53\u9884\u6d4b\u7b56\u7565\u5bf9\u5176\u8fdb\u884c\u5206\u7c7b\uff0c\u7279\u522b\u5173\u6ce8\u4f7f\u7528 ETH/UCY \u57fa\u51c6\u8bc4\u4f30\u7684\u6a21\u578b\u3002", "result": "\u56de\u987e\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86 2020 \u5e74\u81f3 2024 \u5e74\u95f4\u53d1\u8868\u7684\u7814\u7a76\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u591a\u667a\u80fd\u4f53 HTP \u9886\u57df\u7684\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "summary_zh": "\u968f\u7740\u4ee5\u4eba\u4e3a\u672c\u7684\u8f68\u8ff9\u9884\u6d4b (HTP) \u4e2d\u5f3a\u5927\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u51fa\u73b0\uff0c\u66f4\u6df1\u5165\u5730\u4e86\u89e3\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u89e6\u624b\u53ef\u53ca\uff0c\u8fd9\u5bf9\u81ea\u52a8\u5bfc\u822a\u548c\u4eba\u7fa4\u5efa\u6a21\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u672c\u6587\u56de\u987e\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86 2020 \u5e74\u81f3 2024 \u5e74\u95f4\u53d1\u8868\u7684\u7814\u7a76\u3002\u6211\u4eec\u6839\u636e\u73b0\u6709\u65b9\u6cd5\u7684\u67b6\u6784\u8bbe\u8ba1\u3001\u8f93\u5165\u8868\u793a\u548c\u6574\u4f53\u9884\u6d4b\u7b56\u7565\u5bf9\u5176\u8fdb\u884c\u5206\u7c7b\uff0c\u7279\u522b\u5173\u6ce8\u4f7f\u7528 ETH/UCY \u57fa\u51c6\u8bc4\u4f30\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5f3a\u8c03\u4e86\u591a\u667a\u80fd\u4f53 HTP \u9886\u57df\u7684\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.15157", "pdf": "https://arxiv.org/pdf/2506.15157", "abs": "https://arxiv.org/abs/2506.15157", "authors": ["Hanbit Oh", "Andrea M. Salcedo-V\u00e1zquez", "Ixchel G. Ramirez-Alpizar", "Yukiyasu Domae"], "title": "Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS) 2025 accepted", "summary": "Imitation learning (IL) aims to enable robots to perform tasks autonomously\nby observing a few human demonstrations. Recently, a variant of IL, called\nIn-Context IL, utilized off-the-shelf large language models (LLMs) as instant\npolicies that understand the context from a few given demonstrations to perform\na new task, rather than explicitly updating network models with large-scale\ndemonstrations. However, its reliability in the robotics domain is undermined\nby hallucination issues such as LLM-based instant policy, which occasionally\ngenerates poor trajectories that deviate from the given demonstrations. To\nalleviate this problem, we propose a new robust in-context imitation learning\nalgorithm called the robust instant policy (RIP), which utilizes a Student's\nt-regression model to be robust against the hallucinated trajectories of\ninstant policies to allow reliable trajectory generation. Specifically, RIP\ngenerates several candidate robot trajectories to complete a given task from an\nLLM and aggregates them using the Student's t-distribution, which is beneficial\nfor ignoring outliers (i.e., hallucinations); thereby, a robust trajectory\nagainst hallucinations is generated. Our experiments, conducted in both\nsimulated and real-world environments, show that RIP significantly outperforms\nstate-of-the-art IL methods, with at least $26\\%$ improvement in task success\nrates, particularly in low-data scenarios for everyday tasks. Video results\navailable at https://sites.google.com/view/robustinstantpolicy.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "The paper focuses on imitation learning for robot manipulation, leveraging large language models (LLMs) as instant policies. It addresses the issue of hallucination in LLM-generated trajectories and proposes a method to generate robust trajectories. This combines trajectory generation/prediction (robot trajectories) with LLMs.", "keywords": ["trajectory generation", "imitation learning", "large language models", "LLMs", "robot manipulation"]}, "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u77ac\u65f6\u7b56\u7565\uff08RIP\uff09\uff0c\u901a\u8fc7\u5229\u7528Student\u7684t\u56de\u5f52\u6a21\u578b\u62b5\u6297\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e7b\u89c9\uff0c\u4ece\u800c\u63d0\u9ad8\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u77ac\u65f6\u7b56\u7565\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u8f68\u8ff9\u504f\u79bb\u7ed9\u5b9a\u7684\u6f14\u793a\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u5176\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\uff0c\u79f0\u4e3a\u9c81\u68d2\u77ac\u65f6\u7b56\u7565\uff08RIP\uff09\uff0c\u5b83\u5229\u7528Student\u7684t\u56de\u5f52\u6a21\u578b\u6765\u62b5\u6297\u77ac\u65f6\u7b56\u7565\u7684\u5e7b\u89c9\u8f68\u8ff9\uff0c\u4ece\u800c\u5b9e\u73b0\u53ef\u9760\u7684\u8f68\u8ff9\u751f\u6210\u3002", "result": "RIP\u5728\u4efb\u52a1\u6210\u529f\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684IL\u65b9\u6cd5\uff0c\u81f3\u5c11\u63d0\u9ad8\u4e8626%\uff0c\u7279\u522b\u662f\u5728\u65e5\u5e38\u4efb\u52a1\u7684\u4f4e\u6570\u636e\u573a\u666f\u4e2d\u3002", "conclusion": "RIP\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684IL\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u65e5\u5e38\u4efb\u52a1\u7684\u4f4e\u6570\u636e\u573a\u666f\u4e2d\uff0c\u4efb\u52a1\u6210\u529f\u7387\u81f3\u5c11\u63d0\u9ad8\u4e8626%\u3002", "summary_zh": "\u6a21\u4eff\u5b66\u4e60\uff08IL\uff09\u65e8\u5728\u901a\u8fc7\u89c2\u5bdf\u5c11\u91cf\u4eba\u7c7b\u6f14\u793a\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u81ea\u4e3b\u6267\u884c\u4efb\u52a1\u3002\u6700\u8fd1\uff0c\u4e00\u79cdIL\u7684\u53d8\u4f53\uff0c\u79f0\u4e3a\u4e0a\u4e0b\u6587IL\uff0c\u5229\u7528\u73b0\u6210\u7684\uff08off-the-shelf\uff09\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u77ac\u65f6\u7b56\u7565\uff0c\u4ece\u4e00\u4e9b\u7ed9\u5b9a\u7684\u6f14\u793a\u4e2d\u7406\u89e3\u4e0a\u4e0b\u6587\u4ee5\u6267\u884c\u65b0\u4efb\u52a1\uff0c\u800c\u4e0d\u662f\u7528\u5927\u89c4\u6a21\u6f14\u793a\u663e\u5f0f\u66f4\u65b0\u7f51\u7edc\u6a21\u578b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u57fa\u4e8eLLM\u7684\u77ac\u65f6\u7b56\u7565\u7b49\u5e7b\u89c9\u95ee\u9898\uff0c\u5176\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u53ef\u9760\u6027\u53d7\u5230\u635f\u5bb3\uff0c\u8fd9\u4e9b\u95ee\u9898\u5076\u5c14\u4f1a\u4ea7\u751f\u504f\u79bb\u7ed9\u5b9a\u6f14\u793a\u7684\u4e0d\u826f\u8f68\u8ff9\u3002\u4e3a\u4e86\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\uff0c\u79f0\u4e3a\u9c81\u68d2\u77ac\u65f6\u7b56\u7565\uff08RIP\uff09\uff0c\u5b83\u5229\u7528Student\u7684t\u56de\u5f52\u6a21\u578b\u6765\u62b5\u6297\u77ac\u65f6\u7b56\u7565\u7684\u5e7b\u89c9\u8f68\u8ff9\uff0c\u4ece\u800c\u5b9e\u73b0\u53ef\u9760\u7684\u8f68\u8ff9\u751f\u6210\u3002\u5177\u4f53\u6765\u8bf4\uff0cRIP\u751f\u6210\u591a\u4e2a\u5019\u9009\u673a\u5668\u4eba\u8f68\u8ff9\uff0c\u4ee5\u4eceLLM\u5b8c\u6210\u7ed9\u5b9a\u7684\u4efb\u52a1\uff0c\u5e76\u4f7f\u7528Student\u7684t\u5206\u5e03\u805a\u5408\u5b83\u4eec\uff0c\u8fd9\u6709\u5229\u4e8e\u5ffd\u7565\u5f02\u5e38\u503c\uff08\u5373\u5e7b\u89c9\uff09\uff1b\u56e0\u6b64\uff0c\u751f\u6210\u4e86\u9488\u5bf9\u5e7b\u89c9\u7684\u9c81\u68d2\u8f68\u8ff9\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u8fdb\u884c\uff0c\u7ed3\u679c\u8868\u660e\uff0cRIP\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684IL\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u65e5\u5e38\u4efb\u52a1\u7684\u4f4e\u6570\u636e\u573a\u666f\u4e2d\uff0c\u4efb\u52a1\u6210\u529f\u7387\u81f3\u5c11\u63d0\u9ad8\u4e8626%\u3002\u89c6\u9891\u7ed3\u679c\u53ef\u5728https://sites.google.com/view/robustinstantpolicy\u67e5\u770b\u3002"}}
{"id": "2506.15167", "pdf": "https://arxiv.org/pdf/2506.15167", "abs": "https://arxiv.org/abs/2506.15167", "authors": ["Wanzhe Wang", "Jianqiu Peng", "Menghao Hu", "Weihuang Zhong", "Tong Zhang", "Shuai Wang", "Yixin Zhang", "Mingjie Shao", "Wanli Ni"], "title": "LLM Agent for Hyper-Parameter Optimization", "categories": ["cs.IT", "cs.AI", "math.IT"], "comment": "6 pages, 6 figures", "summary": "Hyper-parameters are essential and critical for the performance of\ncommunication algorithms. However, current hyper-parameters tuning methods for\nwarm-start particles swarm optimization with cross and mutation (WS-PSO-CM)\nalgortihm for radio map-enabled unmanned aerial vehicle (UAV) trajectory and\ncommunication are primarily heuristic-based, exhibiting low levels of\nautomation and unsatisfactory performance. In this paper, we design an large\nlanguage model (LLM) agent for automatic hyper-parameters-tuning, where an\niterative framework and model context protocol (MCP) are applied. In\nparticular, the LLM agent is first setup via a profile, which specifies the\nmission, background, and output format. Then, the LLM agent is driven by the\nprompt requirement, and iteratively invokes WS-PSO-CM algorithm for\nexploration. Finally, the LLM agent autonomously terminates the loop and\nreturns a set of hyper-parameters. Our experiment results show that the minimal\nsum-rate achieved by hyper-parameters generated via our LLM agent is\nsignificantly higher than those by both human heuristics and random generation\nmethods. This indicates that an LLM agent with PSO knowledge and WS-PSO-CM\nalgorithm background is useful in finding high-performance hyper-parameters.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "The paper discusses using an LLM agent for hyper-parameter optimization of a UAV trajectory algorithm (WS-PSO-CM), which falls under trajectory prediction and utilizes Large Language Models. The connection to trajectory prediction is through the UAV trajectory optimization, and the connection to large models is explicit through the use of an LLM agent.", "keywords": ["Large Language Model (LLM)", "UAV trajectory", "trajectory", "optimization"]}, "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\uff0c\u7528\u4e8e\u81ea\u52a8\u8c03\u6574WS-PSO-CM\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\uff0c\u4ee5\u63d0\u9ad8\u65e0\u7ebf\u7535\u5730\u56fe\u65e0\u4eba\u673a\u901a\u4fe1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684WS-PSO-CM\u7b97\u6cd5\u8d85\u53c2\u6570\u8c03\u6574\u65b9\u6cd5\u81ea\u52a8\u5316\u7a0b\u5ea6\u4f4e\uff0c\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\uff0c\u7528\u4e8e\u81ea\u52a8\u8d85\u53c2\u6570\u8c03\u6574\uff0c\u91c7\u7528\u4e86\u8fed\u4ee3\u6846\u67b6\u548c\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f53\u751f\u6210\u7684\u8d85\u53c2\u6570\u5b9e\u73b0\u7684\u6700\u5c0f\u548c\u901f\u7387\u663e\u8457\u9ad8\u4e8e\u4eba\u5de5\u542f\u53d1\u5f0f\u548c\u968f\u673a\u751f\u6210\u65b9\u6cd5\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u80fd\u591f\u6709\u6548\u627e\u5230\u9ad8\u6027\u80fd\u8d85\u53c2\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u548c\u968f\u673a\u65b9\u6cd5\u3002", "summary_zh": "\u8d85\u53c2\u6570\u5bf9\u4e8e\u901a\u4fe1\u7b97\u6cd5\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u9488\u5bf9\u65e0\u7ebf\u7535\u5730\u56fe\u65e0\u4eba\u673a\uff08UAV\uff09\u8f68\u8ff9\u548c\u901a\u4fe1\u7684\u5e26\u6709\u4ea4\u53c9\u548c\u53d8\u5f02\u7684warm-start\u7c92\u5b50\u7fa4\u4f18\u5316\uff08WS-PSO-CM\uff09\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\u8c03\u6574\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u542f\u53d1\u5f0f\uff0c\u81ea\u52a8\u5316\u7a0b\u5ea6\u4f4e\uff0c\u6027\u80fd\u4e0d\u5c3d\u5982\u4eba\u610f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\uff0c\u7528\u4e8e\u81ea\u52a8\u8d85\u53c2\u6570\u8c03\u6574\uff0c\u5176\u4e2d\u5e94\u7528\u4e86\u8fed\u4ee3\u6846\u67b6\u548c\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u3002\u7279\u522b\u5730\uff0c\u9996\u5148\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u8bbe\u7f6eLLM\u667a\u80fd\u4f53\uff0c\u8be5\u6587\u4ef6\u6307\u5b9a\u4efb\u52a1\u3001\u80cc\u666f\u548c\u8f93\u51fa\u683c\u5f0f\u3002\u7136\u540e\uff0cLLM\u667a\u80fd\u4f53\u7531\u63d0\u793a\u9700\u6c42\u9a71\u52a8\uff0c\u5e76\u8fed\u4ee3\u5730\u8c03\u7528WS-PSO-CM\u7b97\u6cd5\u8fdb\u884c\u63a2\u7d22\u3002\u6700\u540e\uff0cLLM\u667a\u80fd\u4f53\u81ea\u4e3b\u7ec8\u6b62\u5faa\u73af\u5e76\u8fd4\u56de\u4e00\u7ec4\u8d85\u53c2\u6570\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f53\u751f\u6210\u7684\u8d85\u53c2\u6570\u5b9e\u73b0\u7684\u6700\u5c0f\u548c\u901f\u7387\u663e\u8457\u9ad8\u4e8e\u4eba\u5de5\u542f\u53d1\u5f0f\u548c\u968f\u673a\u751f\u6210\u65b9\u6cd5\u3002\u8fd9\u8868\u660e\u5177\u6709PSO\u77e5\u8bc6\u548cWS-PSO-CM\u7b97\u6cd5\u80cc\u666f\u7684LLM\u667a\u80fd\u4f53\u5728\u5bfb\u627e\u9ad8\u6027\u80fd\u8d85\u53c2\u6570\u65b9\u9762\u975e\u5e38\u6709\u7528\u3002"}}
{"id": "2506.15043", "pdf": "https://arxiv.org/pdf/2506.15043", "abs": "https://arxiv.org/abs/2506.15043", "authors": ["Amir Hossein Baradaran"], "title": "Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Advancements in the defense industry are paramount for ensuring the safety\nand security of nations, providing robust protection against emerging threats.\nAmong these threats, hypersonic missiles pose a significant challenge due to\ntheir extreme speeds and maneuverability, making accurate trajectory prediction\na critical necessity for effective countermeasures. This paper addresses this\nchallenge by employing a novel hybrid deep learning approach, integrating\nConvolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks,\nand Gated Recurrent Units (GRUs). By leveraging the strengths of these\narchitectures, the proposed method successfully predicts the complex\ntrajectories of hypersonic missiles with high accuracy, offering a significant\ncontribution to defense strategies and missile interception technologies. This\nresearch demonstrates the potential of advanced machine learning techniques in\nenhancing the predictive capabilities of defense systems.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f7f\u7528\u4e86CNN-LSTM-GRU\u7b49\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5c5e\u4e8e\u8f68\u8ff9\u9884\u6d4b\u9886\u57df\uff0c\u4e14\u4f7f\u7528\u4e86\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["\u8f68\u8ff9\u9884\u6d4b", "trajectory prediction", "CNN", "LSTM", "GRU", "\u6df1\u5ea6\u5b66\u4e60", "deep learning"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u590d\u6742\u8f68\u8ff9\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u4ee5\u5176\u6781\u9ad8\u7684\u901f\u5ea6\u548c\u673a\u52a8\u6027\u6784\u6210\u4e86\u4e25\u5cfb\u7684\u6311\u6218\uff0c\u56e0\u6b64\u51c6\u786e\u7684\u8f68\u8ff9\u9884\u6d4b\u5bf9\u4e8e\u6709\u6548\u7684\u5bf9\u6297\u63aa\u65bd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u96c6\u6210\u4e86\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3001\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u7f51\u7edc\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u4e86\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u590d\u6742\u8f68\u8ff9\u3002", "conclusion": "\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u53ef\u4ee5\u589e\u5f3a\u9632\u5fa1\u7cfb\u7edf\u7684\u9884\u6d4b\u80fd\u529b\u3002", "summary_zh": "\u56fd\u9632\u5de5\u4e1a\u7684\u8fdb\u6b65\u5bf9\u4e8e\u786e\u4fdd\u56fd\u5bb6\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u5b83\u80fd\u591f\u63d0\u4f9b\u5f3a\u5927\u7684\u4fdd\u62a4\u4ee5\u5e94\u5bf9\u65b0\u5174\u5a01\u80c1\u3002\u5176\u4e2d\uff0c\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7531\u4e8e\u5176\u6781\u9ad8\u7684\u901f\u5ea6\u548c\u673a\u52a8\u6027\u6784\u6210\u4e86\u4e25\u5cfb\u7684\u6311\u6218\uff0c\u56e0\u6b64\u51c6\u786e\u7684\u8f68\u8ff9\u9884\u6d4b\u5bf9\u4e8e\u6709\u6548\u7684\u5bf9\u6297\u63aa\u65bd\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u901a\u8fc7\u91c7\u7528\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u8be5\u65b9\u6cd5\u96c6\u6210\u4e86\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3001\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u7f51\u7edc\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u3002\u901a\u8fc7\u5229\u7528\u8fd9\u4e9b\u67b6\u6784\u7684\u4f18\u52bf\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u5730\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u4e86\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u590d\u6742\u8f68\u8ff9\uff0c\u4e3a\u9632\u5fa1\u7b56\u7565\u548c\u5bfc\u5f39\u62e6\u622a\u6280\u672f\u505a\u51fa\u4e86\u91cd\u5927\u8d21\u732e\u3002\u8fd9\u9879\u7814\u7a76\u8bc1\u660e\u4e86\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u589e\u5f3a\u9632\u5fa1\u7cfb\u7edf\u9884\u6d4b\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.14855", "pdf": "https://arxiv.org/pdf/2506.14855", "abs": "https://arxiv.org/abs/2506.14855", "authors": ["Tommaso Belvedere", "Michael Ziegltrum", "Giulio Turrisi", "Valerio Modugno"], "title": "Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Model Predictive Path Integral control is a powerful sampling-based approach\nsuitable for complex robotic tasks due to its flexibility in handling nonlinear\ndynamics and non-convex costs. However, its applicability in real-time,\nhighfrequency robotic control scenarios is limited by computational demands.\nThis paper introduces Feedback-MPPI (F-MPPI), a novel framework that augments\nstandard MPPI by computing local linear feedback gains derived from sensitivity\nanalysis inspired by Riccati-based feedback used in gradient-based MPC. These\ngains allow for rapid closed-loop corrections around the current state without\nrequiring full re-optimization at each timestep. We demonstrate the\neffectiveness of F-MPPI through simulations and real-world experiments on two\nrobotic platforms: a quadrupedal robot performing dynamic locomotion on uneven\nterrain and a quadrotor executing aggressive maneuvers with onboard\ncomputation. Results illustrate that incorporating local feedback significantly\nimproves control performance and stability, enabling robust, high-frequency\noperation suitable for complex robotic systems.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on Model Predictive Path Integral control, which is related to trajectory planning and control. However, it doesn't explicitly mention or utilize Large Language Models. The connection lies in the potential for LLMs to be used in higher-level decision-making that informs the path planning process, or to learn representations of environments for better path planning. The relevance score is moderate because it's related to trajectory prediction but doesn't involve LLMs directly.", "keywords": ["trajectory prediction", "path planning", "Model Predictive Control", "robotic control"]}, "AI": {"tldr": "F-MPPI\u901a\u8fc7\u589e\u52a0\u5c40\u90e8\u7ebf\u6027\u53cd\u9988\u589e\u76ca\u6765\u589e\u5f3a\u6807\u51c6MPPI\uff0c\u4ece\u800c\u5b9e\u73b0\u9c81\u68d2\u3001\u9ad8\u9891\u7684\u673a\u5668\u4eba\u63a7\u5236\u3002", "motivation": "Model Predictive Path Integral control is a powerful sampling-based approach suitable for complex robotic tasks. However, its applicability in real-time, highfrequency robotic control scenarios is limited by computational demands.", "method": "This paper introduces Feedback-MPPI (F-MPPI), a novel framework that augments standard MPPI by computing local linear feedback gains derived from sensitivity analysis inspired by Riccati-based feedback used in gradient-based MPC.", "result": "Results illustrate that incorporating local feedback significantly improves control performance and stability.", "conclusion": "Incorporating local feedback significantly improves control performance and stability, enabling robust, high-frequency operation suitable for complex robotic systems.", "summary_zh": "\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u673a\u5668\u4eba\u4efb\u52a1\uff0c\u56e0\u4e3a\u5b83\u5728\u5904\u7406\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u548c\u975e\u51f8\u6210\u672c\u65b9\u9762\u5177\u6709\u7075\u6d3b\u6027\u3002\u7136\u800c\uff0c\u7531\u4e8e\u8ba1\u7b97\u9700\u6c42\uff0c\u5b83\u5728\u5b9e\u65f6\u3001\u9ad8\u9891\u673a\u5668\u4eba\u63a7\u5236\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u53d7\u5230\u9650\u5236\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Feedback-MPPI (F-MPPI)\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u8ba1\u7b97\u5c40\u90e8\u7ebf\u6027\u53cd\u9988\u589e\u76ca\u6765\u589e\u5f3a\u6807\u51c6MPPI\uff0c\u8fd9\u4e9b\u589e\u76ca\u6765\u81ea\u7075\u654f\u5ea6\u5206\u6790\uff0c\u7075\u611f\u6765\u81ea\u57fa\u4e8e\u68af\u5ea6\u7684MPC\u4e2d\u4f7f\u7528\u7684\u57fa\u4e8eRiccati\u7684\u53cd\u9988\u3002\u8fd9\u4e9b\u589e\u76ca\u5141\u8bb8\u5728\u5f53\u524d\u72b6\u6001\u4e0b\u8fdb\u884c\u5feb\u901f\u95ed\u73af\u6821\u6b63\uff0c\u800c\u65e0\u9700\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u8fdb\u884c\u5b8c\u5168\u91cd\u65b0\u4f18\u5316\u3002\u6211\u4eec\u901a\u8fc7\u5728\u4e24\u4e2a\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u7684\u6a21\u62df\u548c\u771f\u5b9e\u5b9e\u9a8c\u8bc1\u660e\u4e86F-MPPI\u7684\u6709\u6548\u6027\uff1a\u4e00\u4e2a\u56db\u8db3\u673a\u5668\u4eba\u5728\u4e0d\u5e73\u5766\u5730\u5f62\u4e0a\u6267\u884c\u52a8\u6001\u8fd0\u52a8\uff0c\u4e00\u4e2a\u56db\u65cb\u7ffc\u98de\u884c\u5668\u5728\u673a\u8f7d\u8ba1\u7b97\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u6fc0\u8fdb\u7684\u673a\u52a8\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u5c40\u90e8\u53cd\u9988\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u63a7\u5236\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u9002\u7528\u4e8e\u590d\u6742\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u9c81\u68d2\u3001\u9ad8\u9891\u64cd\u4f5c\u3002"}}
{"id": "2506.14857", "pdf": "https://arxiv.org/pdf/2506.14857", "abs": "https://arxiv.org/abs/2506.14857", "authors": ["Suman Raj", "Swapnil Padhi", "Ruchi Bhoot", "Prince Modi", "Yogesh Simmhan"], "title": "Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired", "categories": ["cs.RO", "cs.CV"], "comment": "16 pages, 7 figures; Accepted as Late-Breaking Results at the\n  IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n  2023", "summary": "Autonomous navigation by drones using onboard sensors combined with machine\nlearning and computer vision algorithms is impacting a number of domains,\nincluding agriculture, logistics, and disaster management. In this paper, we\nexamine the use of drones for assisting visually impaired people (VIPs) in\nnavigating through outdoor urban environments. Specifically, we present a\nperception-based path planning system for local planning around the\nneighborhood of the VIP, integrated with a global planner based on GPS and maps\nfor coarse planning. We represent the problem using a geometric formulation and\npropose a multi DNN based framework for obstacle avoidance of the UAV as well\nas the VIP. Our evaluations conducted on a drone human system in a university\ncampus environment verifies the feasibility of our algorithms in three\nscenarios; when the VIP walks on a footpath, near parked vehicles, and in a\ncrowded street.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper discusses perception-based path planning for UAVs to assist visually impaired people, which involves trajectory prediction and collision avoidance. While it uses DNNs, it doesn't explicitly leverage large language models. The relevance is moderate due to the trajectory prediction aspect.", "keywords": ["trajectory prediction", "path planning", "collision avoidance", "DNN"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a DNN \u6846\u67b6\u7684\u65e0\u4eba\u673a\u8f85\u52a9\u89c6\u969c\u4eba\u58eb\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u5bfc\u822a\u7684\u8def\u5f84\u89c4\u5212\u7cfb\u7edf\u3002", "motivation": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u65e0\u4eba\u673a\u8f85\u52a9\u89c6\u969c\u4eba\u58eb\uff08VIP\uff09\u5728\u6237\u5916\u57ce\u5e02\u73af\u5883\u4e2d\u5bfc\u822a\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u51e0\u4f55\u516c\u5f0f\u8868\u793a\u8be5\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a DNN \u7684\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u548c VIP \u7684\u907f\u969c\u3002", "result": "\u5728\u5927\u5b66\u6821\u56ed\u73af\u5883\u4e2d\u7684\u65e0\u4eba\u673a-\u4eba\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u4e09\u79cd\u573a\u666f\u4e2d\u7684\u53ef\u884c\u6027\uff1b\u5f53 VIP \u5728\u4eba\u884c\u9053\u4e0a\u884c\u8d70\u3001\u9760\u8fd1\u505c\u653e\u7684\u8f66\u8f86\u4ee5\u53ca\u5728\u62e5\u6324\u7684\u8857\u9053\u4e0a\u3002", "conclusion": "\u5728\u5927\u5b66\u6821\u56ed\u73af\u5883\u4e2d\u7684\u65e0\u4eba\u673a-\u4eba\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u4e09\u79cd\u573a\u666f\u4e2d\u7684\u53ef\u884c\u6027\uff1a\u5f53 VIP \u5728\u4eba\u884c\u9053\u4e0a\u884c\u8d70\u3001\u9760\u8fd1\u505c\u653e\u7684\u8f66\u8f86\u4ee5\u53ca\u5728\u62e5\u6324\u7684\u8857\u9053\u4e0a\u3002", "summary_zh": "\u65e0\u4eba\u673a\u7ed3\u5408\u673a\u8f7d\u4f20\u611f\u5668\u3001\u673a\u5668\u5b66\u4e60\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u7b97\u6cd5\u7684\u81ea\u4e3b\u5bfc\u822a\u6b63\u5728\u5f71\u54cd\u519c\u4e1a\u3001\u7269\u6d41\u548c\u707e\u5bb3\u7ba1\u7406\u7b49\u591a\u4e2a\u9886\u57df\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4f7f\u7528\u65e0\u4eba\u673a\u8f85\u52a9\u89c6\u969c\u4eba\u58eb\uff08VIP\uff09\u5728\u6237\u5916\u57ce\u5e02\u73af\u5883\u4e2d\u5bfc\u822a\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u611f\u77e5\u7684\u8def\u5f84\u89c4\u5212\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728 VIP \u9644\u8fd1\u8fdb\u884c\u5c40\u90e8\u89c4\u5212\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e GPS \u548c\u5730\u56fe\u7684\u5168\u5c40\u89c4\u5212\u5668\u8fdb\u884c\u7c97\u7565\u89c4\u5212\u3002\u6211\u4eec\u4f7f\u7528\u51e0\u4f55\u516c\u5f0f\u8868\u793a\u8be5\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a DNN \u7684\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u548c VIP \u7684\u907f\u969c\u3002\u6211\u4eec\u5728\u5927\u5b66\u6821\u56ed\u73af\u5883\u4e2d\u7684\u65e0\u4eba\u673a-\u4eba\u7cfb\u7edf\u4e0a\u8fdb\u884c\u7684\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u4e09\u79cd\u573a\u666f\u4e2d\u7684\u53ef\u884c\u6027\uff1a\u5f53 VIP \u5728\u4eba\u884c\u9053\u4e0a\u884c\u8d70\u3001\u9760\u8fd1\u505c\u653e\u7684\u8f66\u8f86\u4ee5\u53ca\u5728\u62e5\u6324\u7684\u8857\u9053\u4e0a\u3002"}}
{"id": "2506.15050", "pdf": "https://arxiv.org/pdf/2506.15050", "abs": "https://arxiv.org/abs/2506.15050", "authors": ["Tiantian Fan", "Lingjun Liu", "Yu Yue", "Jiaze Chen", "Chengyi Wang", "Qiying Yu", "Chi Zhang", "Zhiqi Lin", "Ruofei Zhu", "Yufeng Yuan", "Xiaochen Zuo", "Bole Ma", "Mofan Zhang", "Gaohong Liu", "Ru Zhang", "Haotian Zhou", "Cong Xie", "Ruidong Zhu", "Zhi Zhang", "Xin Liu", "Mingxuan Wang", "Lin Yan", "Yonghui Wu"], "title": "Truncated Proximal Policy Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Recently, test-time scaling Large Language Models (LLMs) have demonstrated\nexceptional reasoning capabilities across scientific and professional tasks by\ngenerating long chains-of-thought (CoT). As a crucial component for developing\nthese reasoning models, reinforcement learning (RL), exemplified by Proximal\nPolicy Optimization (PPO) and its variants, allows models to learn through\ntrial and error. However, PPO can be time-consuming due to its inherent\non-policy nature, which is further exacerbated by increasing response lengths.\nIn this work, we propose Truncated Proximal Policy Optimization (T-PPO), a\nnovel extension to PPO that improves training efficiency by streamlining policy\nupdate and length-restricted response generation. T-PPO mitigates the issue of\nlow hardware utilization, an inherent drawback of fully synchronized\nlong-generation procedures, where resources often sit idle during the waiting\nperiods for complete rollouts. Our contributions are two-folds. First, we\npropose Extended Generalized Advantage Estimation (EGAE) for advantage\nestimation derived from incomplete responses while maintaining the integrity of\npolicy learning. Second, we devise a computationally optimized mechanism that\nallows for the independent optimization of the policy and value models. By\nselectively filtering prompt and truncated tokens, this mechanism reduces\nredundant computations and accelerates the training process without sacrificing\nconvergence performance. We demonstrate the effectiveness and efficacy of T-PPO\non AIME 2024 with a 32B base model. The experimental results show that T-PPO\nimproves the training efficiency of reasoning LLMs by up to 2.5x and\noutperforms its existing competitors.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on improving the training efficiency of Large Language Models (LLMs) using a modified Proximal Policy Optimization (PPO) algorithm. While it doesn't directly address trajectory prediction, it is relevant to the 'Large Language Models' aspect of the query. The connection is through the use of reinforcement learning for training LLMs, but the paper's core contribution is within the RL and LLM domains, not trajectory prediction.", "keywords": ["Large Language Models", "LLMs", "Proximal Policy Optimization", "PPO", "Reinforcement Learning"]}, "AI": {"tldr": "T-PPO\u901a\u8fc7\u622a\u65ad\u4f18\u5316\u548c\u6269\u5c55\u4f18\u52bf\u4f30\u8ba1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8bad\u7ec3\u7684\u6548\u7387\u3002", "motivation": "\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7531\u4e8e\u5176\u56fa\u6709\u7684on-policy\u6027\u8d28\uff0c\u53ef\u80fd\u975e\u5e38\u8017\u65f6\uff0c\u800c\u54cd\u5e94\u957f\u5ea6\u7684\u589e\u52a0\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u8fd9\u79cd\u60c5\u51b5\u3002\u5b8c\u5168\u540c\u6b65\u7684\u957f\u751f\u6210\u8fc7\u7a0b\u5b58\u5728\u786c\u4ef6\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5728\u7b49\u5f85\u5b8c\u6574rollout\u671f\u95f4\uff0c\u8d44\u6e90\u7ecf\u5e38\u5904\u4e8e\u95f2\u7f6e\u72b6\u6001\u3002", "method": "\u63d0\u51fa\u4e86\u622a\u65ad\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08T-PPO\uff09\uff0c\u901a\u8fc7\u7b80\u5316\u7b56\u7565\u66f4\u65b0\u548c\u957f\u5ea6\u9650\u5236\u7684\u54cd\u5e94\u751f\u6210\u6765\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u6269\u5c55\u5e7f\u4e49\u4f18\u52bf\u4f30\u8ba1\uff08EGAE\uff09\uff0c\u7528\u4e8e\u4ece\u4e0d\u5b8c\u6574\u7684\u54cd\u5e94\u4e2d\u8fdb\u884c\u4f18\u52bf\u4f30\u8ba1\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8ba1\u7b97\u4f18\u5316\u7684\u673a\u5236\uff0c\u5141\u8bb8\u72ec\u7acb\u4f18\u5316\u7b56\u7565\u548c\u4ef7\u503c\u6a21\u578b\u3002", "result": "\u5728AIME 2024\u4e0a\uff0cT-PPO\u5c06\u63a8\u7406LLM\u7684\u8bad\u7ec3\u6548\u7387\u63d0\u9ad8\u4e862.5\u500d\uff0c\u5e76\u4e14\u4f18\u4e8e\u5176\u73b0\u6709\u7684\u7ade\u4e89\u5bf9\u624b\u3002", "conclusion": "T-PPO\u5c06\u63a8\u7406LLM\u7684\u8bad\u7ec3\u6548\u7387\u63d0\u9ad8\u4e862.5\u500d\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u7684\u7ade\u4e89\u5bf9\u624b\u3002", "summary_zh": "\u6700\u8fd1\uff0c\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u901a\u8fc7\u751f\u6210\u957f\u7684\u601d\u7ef4\u94fe\uff08CoT\uff09\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u79d1\u5b66\u548c\u4e13\u4e1a\u4efb\u52a1\u63a8\u7406\u80fd\u529b\u3002\u4f5c\u4e3a\u5f00\u53d1\u8fd9\u4e9b\u63a8\u7406\u6a21\u578b\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\uff0c\u4ee5\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u53ca\u5176\u53d8\u4f53\u4e3a\u4f8b\uff0c\u5141\u8bb8\u6a21\u578b\u901a\u8fc7\u8bd5\u9519\u6765\u5b66\u4e60\u3002\u7136\u800c\uff0cPPO\u7531\u4e8e\u5176\u56fa\u6709\u7684on-policy\u6027\u8d28\uff0c\u53ef\u80fd\u975e\u5e38\u8017\u65f6\uff0c\u800c\u54cd\u5e94\u957f\u5ea6\u7684\u589e\u52a0\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u8fd9\u79cd\u60c5\u51b5\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u622a\u65ad\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08T-PPO\uff09\uff0c\u5b83\u662fPPO\u7684\u4e00\u4e2a\u65b0\u6269\u5c55\uff0c\u901a\u8fc7\u7b80\u5316\u7b56\u7565\u66f4\u65b0\u548c\u957f\u5ea6\u9650\u5236\u7684\u54cd\u5e94\u751f\u6210\u6765\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002T-PPO\u7f13\u89e3\u4e86\u786c\u4ef6\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u8fd9\u662f\u5b8c\u5168\u540c\u6b65\u7684\u957f\u751f\u6210\u7a0b\u5e8f\u7684\u56fa\u6709\u7f3a\u9677\uff0c\u5728\u7b49\u5f85\u5b8c\u6574rollout\u671f\u95f4\uff0c\u8d44\u6e90\u7ecf\u5e38\u5904\u4e8e\u95f2\u7f6e\u72b6\u6001\u3002\u6211\u4eec\u7684\u8d21\u732e\u6709\u4e24\u65b9\u9762\u3002\u9996\u5148\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6269\u5c55\u5e7f\u4e49\u4f18\u52bf\u4f30\u8ba1\uff08EGAE\uff09\uff0c\u7528\u4e8e\u4ece\u4e0d\u5b8c\u6574\u7684\u54cd\u5e94\u4e2d\u8fdb\u884c\u4f18\u52bf\u4f30\u8ba1\uff0c\u540c\u65f6\u4fdd\u6301\u7b56\u7565\u5b66\u4e60\u7684\u5b8c\u6574\u6027\u3002\u5176\u6b21\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8ba1\u7b97\u4f18\u5316\u7684\u673a\u5236\uff0c\u5141\u8bb8\u72ec\u7acb\u4f18\u5316\u7b56\u7565\u548c\u4ef7\u503c\u6a21\u578b\u3002\u901a\u8fc7\u9009\u62e9\u6027\u5730\u8fc7\u6ee4prompt\u548c\u622a\u65ad\u7684tokens\uff0c\u8fd9\u79cd\u673a\u5236\u51cf\u5c11\u4e86\u5197\u4f59\u8ba1\u7b97\uff0c\u5e76\u5728\u4e0d\u727a\u7272\u6536\u655b\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u52a0\u901f\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u3002\u6211\u4eec\u901a\u8fc7\u5728AIME 2024\u4e0a\u4f7f\u752832B\u7684\u57fa\u7840\u6a21\u578b\u8bc1\u660e\u4e86T-PPO\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cT-PPO\u5c06\u63a8\u7406LLM\u7684\u8bad\u7ec3\u6548\u7387\u63d0\u9ad8\u4e862.5\u500d\uff0c\u5e76\u4e14\u4f18\u4e8e\u5176\u73b0\u6709\u7684\u7ade\u4e89\u5bf9\u624b\u3002"}}
{"id": "2506.14968", "pdf": "https://arxiv.org/pdf/2506.14968", "abs": "https://arxiv.org/abs/2506.14968", "authors": ["Rajat Kumar Jenamani", "Tom Silver", "Ben Dodson", "Shiqin Tong", "Anthony Song", "Yuting Yang", "Ziang Liu", "Benjamin Howe", "Aimee Whitneck", "Tapomayukh Bhattacharjee"], "title": "FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization", "categories": ["cs.RO", "cs.AI"], "comment": "RSS 2025 - Outstanding Paper Award & Outstanding Systems Paper Award\n  Finalist", "summary": "Physical caregiving robots hold promise for improving the quality of life of\nmillions worldwide who require assistance with feeding. However, in-home meal\nassistance remains challenging due to the diversity of activities (e.g.,\neating, drinking, mouth wiping), contexts (e.g., socializing, watching TV),\nfood items, and user preferences that arise during deployment. In this work, we\npropose FEAST, a flexible mealtime-assistance system that can be personalized\nin-the-wild to meet the unique needs of individual care recipients. Developed\nin collaboration with two community researchers and informed by a formative\nstudy with a diverse group of care recipients, our system is guided by three\nkey tenets for in-the-wild personalization: adaptability, transparency, and\nsafety. FEAST embodies these principles through: (i) modular hardware that\nenables switching between assisted feeding, drinking, and mouth-wiping, (ii)\ndiverse interaction methods, including a web interface, head gestures, and\nphysical buttons, to accommodate diverse functional abilities and preferences,\nand (iii) parameterized behavior trees that can be safely and transparently\nadapted using a large language model. We evaluate our system based on the\npersonalization requirements identified in our formative study, demonstrating\nthat FEAST offers a wide range of transparent and safe adaptations and\noutperforms a state-of-the-art baseline limited to fixed customizations. To\ndemonstrate real-world applicability, we conduct an in-home user study with two\ncare recipients (who are community researchers), feeding them three meals each\nacross three diverse scenarios. We further assess FEAST's ecological validity\nby evaluating with an Occupational Therapist previously unfamiliar with the\nsystem. In all cases, users successfully personalize FEAST to meet their\nindividual needs and preferences. Website: https://emprise.cs.cornell.edu/feast", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u7684\u662f\u4e00\u4e2a\u8f85\u52a9\u8fdb\u98df\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u53c2\u6570\u5316\u884c\u4e3a\u6811\u7684\u8c03\u6574\uff0c\u4ee5\u5b9e\u73b0\u4e2a\u6027\u5316\u3002\u867d\u7136\u4e3b\u8981\u76ee\u6807\u4e0d\u662f\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u5b83\u786e\u5b9e\u5229\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u8c03\u6574\u673a\u5668\u4eba\u7684\u884c\u4e3a\uff0c\u8fd9\u4e0e\u5927\u6a21\u578b\u76f8\u5173\u3002\u8f68\u8ff9\u9884\u6d4b\u5e76\u975e\u8bba\u6587\u7684\u6838\u5fc3\u5185\u5bb9\u3002", "keywords": ["large language model", "LLM", "personalization"]}, "AI": {"tldr": "FEAST\u662f\u4e00\u4e2a\u7075\u6d3b\u7684\u81b3\u98df\u8f85\u52a9\u7cfb\u7edf\uff0c\u53ef\u4ee5\u901a\u8fc7\u6a21\u5757\u5316\u786c\u4ef6\u3001\u591a\u6837\u5316\u7684\u4ea4\u4e92\u65b9\u5f0f\u548c\u53c2\u6570\u5316\u7684\u884c\u4e3a\u6811\u8fdb\u884c\u4e2a\u6027\u5316\u5b9a\u5236\uff0c\u4ee5\u6ee1\u8db3\u4e2a\u4f53\u62a4\u7406\u5bf9\u8c61\u7684\u72ec\u7279\u9700\u6c42\u3002", "motivation": "\u7531\u4e8e\u6d3b\u52a8\u3001\u73af\u5883\u3001\u98df\u7269\u79cd\u7c7b\u548c\u7528\u6237\u504f\u597d\u7684\u591a\u6837\u6027\uff0c\u5c45\u5bb6\u81b3\u98df\u8f85\u52a9\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "FEAST\u662f\u4e00\u79cd\u7075\u6d3b\u7684\u81b3\u98df\u8f85\u52a9\u7cfb\u7edf\uff0c\u53ef\u4ee5\u901a\u8fc7\u6a21\u5757\u5316\u786c\u4ef6\u3001\u591a\u6837\u5316\u7684\u4ea4\u4e92\u65b9\u5f0f\u548c\u53c2\u6570\u5316\u7684\u884c\u4e3a\u6811\u8fdb\u884c\u4e2a\u6027\u5316\u5b9a\u5236\u3002", "result": "FEAST\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u900f\u660e\u548c\u5b89\u5168\u7684\u8c03\u6574\uff0c\u5e76\u4e14\u4f18\u4e8e\u4ec5\u9650\u4e8e\u56fa\u5b9a\u5b9a\u5236\u7684\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u7528\u6237\u53ef\u4ee5\u6210\u529f\u5730\u4e2a\u6027\u5316FEAST\u4ee5\u6ee1\u8db3\u4ed6\u4eec\u7684\u4e2a\u4eba\u9700\u6c42\u548c\u504f\u597d\u3002", "summary_zh": "\u7269\u7406\u62a4\u7406\u673a\u5668\u4eba\u6709\u671b\u6539\u5584\u5168\u7403\u6570\u767e\u4e07\u9700\u8981\u5582\u98df\u5e2e\u52a9\u7684\u4eba\u7684\u751f\u6d3b\u8d28\u91cf\u3002\u7136\u800c\uff0c\u7531\u4e8e\u90e8\u7f72\u671f\u95f4\u51fa\u73b0\u7684\u5404\u79cd\u6d3b\u52a8\uff08\u4f8b\u5982\uff0c\u5403\u996d\u3001\u559d\u6c34\u3001\u64e6\u5634\uff09\u3001\u73af\u5883\uff08\u4f8b\u5982\uff0c\u793e\u4ea4\u3001\u770b\u7535\u89c6\uff09\u3001\u98df\u7269\u79cd\u7c7b\u548c\u7528\u6237\u504f\u597d\uff0c\u5c45\u5bb6\u81b3\u98df\u8f85\u52a9\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86FEAST\uff0c\u8fd9\u662f\u4e00\u79cd\u7075\u6d3b\u7684\u81b3\u98df\u8f85\u52a9\u7cfb\u7edf\uff0c\u53ef\u4ee5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8fdb\u884c\u4e2a\u6027\u5316\u5b9a\u5236\uff0c\u4ee5\u6ee1\u8db3\u4e2a\u4f53\u62a4\u7406\u5bf9\u8c61\u7684\u72ec\u7279\u9700\u6c42\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4e0e\u4e24\u4f4d\u793e\u533a\u7814\u7a76\u5458\u5408\u4f5c\u5f00\u53d1\uff0c\u5e76\u4ee5\u5bf9\u4e0d\u540c\u62a4\u7406\u5bf9\u8c61\u7fa4\u4f53\u7684\u524d\u671f\u7814\u7a76\u4e3a\u57fa\u7840\uff0c\u4ee5\u9002\u5e94\u6027\u3001\u900f\u660e\u6027\u548c\u5b89\u5168\u6027\u8fd9\u4e09\u4e2a\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8fdb\u884c\u4e2a\u6027\u5316\u5b9a\u5236\u7684\u5173\u952e\u539f\u5219\u4e3a\u6307\u5bfc\u3002FEAST\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u4f53\u73b0\u4e86\u8fd9\u4e9b\u539f\u5219\uff1a\uff08i\uff09\u6a21\u5757\u5316\u786c\u4ef6\uff0c\u53ef\u4ee5\u5728\u8f85\u52a9\u5582\u98df\u3001\u996e\u6c34\u548c\u64e6\u5634\u4e4b\u95f4\u5207\u6362\uff0c\uff08ii\uff09\u591a\u6837\u5316\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u5305\u62ecWeb\u754c\u9762\u3001\u5934\u90e8\u624b\u52bf\u548c\u7269\u7406\u6309\u94ae\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u7684\u529f\u80fd\u80fd\u529b\u548c\u504f\u597d\uff0c\u4ee5\u53ca\uff08iii\uff09\u53ef\u4ee5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u900f\u660e\u5730\u8c03\u6574\u7684\u53c2\u6570\u5316\u884c\u4e3a\u6811\u3002\u6211\u4eec\u6839\u636e\u524d\u671f\u7814\u7a76\u4e2d\u786e\u5b9a\u7684\u4e2a\u6027\u5316\u9700\u6c42\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u8868\u660eFEAST\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u900f\u660e\u548c\u5b89\u5168\u7684\u8c03\u6574\uff0c\u5e76\u4e14\u4f18\u4e8e\u4ec5\u9650\u4e8e\u56fa\u5b9a\u5b9a\u5236\u7684\u73b0\u6709\u6280\u672f\u3002\u4e3a\u4e86\u8bc1\u660e\u5176\u5b9e\u9645\u5e94\u7528\u6027\uff0c\u6211\u4eec\u4e0e\u4e24\u4f4d\u62a4\u7406\u5bf9\u8c61\uff08\u4ed6\u4eec\u662f\u793e\u533a\u7814\u7a76\u5458\uff09\u8fdb\u884c\u4e86\u4e00\u9879\u5bb6\u5ead\u7528\u6237\u7814\u7a76\uff0c\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u573a\u666f\u4e2d\uff0c\u6bcf\u4eba\u5582\u98df\u4e09\u9910\u3002\u6211\u4eec\u8fd8\u901a\u8fc7\u4e0e\u4e00\u4f4d\u4ee5\u524d\u4e0d\u719f\u6089\u8be5\u7cfb\u7edf\u7684\u804c\u4e1a\u6cbb\u7597\u5e08\u8fdb\u884c\u8bc4\u4f30\uff0c\u6765\u8bc4\u4f30FEAST\u7684\u751f\u6001\u6709\u6548\u6027\u3002\u5728\u6240\u6709\u60c5\u51b5\u4e0b\uff0c\u7528\u6237\u90fd\u53ef\u4ee5\u6210\u529f\u5730\u4e2a\u6027\u5316FEAST\u4ee5\u6ee1\u8db3\u4ed6\u4eec\u7684\u4e2a\u4eba\u9700\u6c42\u548c\u504f\u597d\u3002\u7f51\u7ad9\uff1ahttps://emprise.cs.cornell.edu/feast"}}
{"id": "2506.15096", "pdf": "https://arxiv.org/pdf/2506.15096", "abs": "https://arxiv.org/abs/2506.15096", "authors": ["Zihe Ji", "Huangxuan Lin", "Yue Gao"], "title": "DyNaVLM: Zero-Shot Vision-Language Navigation System with Dynamic Viewpoints and Self-Refining Graph Memory", "categories": ["cs.RO"], "comment": null, "summary": "We present DyNaVLM, an end-to-end vision-language navigation framework using\nVision-Language Models (VLM). In contrast to prior methods constrained by fixed\nangular or distance intervals, our system empowers agents to freely select\nnavigation targets via visual-language reasoning. At its core lies a\nself-refining graph memory that 1) stores object locations as executable\ntopological relations, 2) enables cross-robot memory sharing through\ndistributed graph updates, and 3) enhances VLM's decision-making via retrieval\naugmentation. Operating without task-specific training or fine-tuning, DyNaVLM\ndemonstrates high performance on GOAT and ObjectNav benchmarks. Real-world\ntests further validate its robustness and generalization. The system's three\ninnovations: dynamic action space formulation, collaborative graph memory, and\ntraining-free deployment, establish a new paradigm for scalable embodied robot,\nbridging the gap between discrete VLN tasks and continuous real-world\nnavigation.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on vision-language navigation, which involves navigating through an environment based on visual and language input. This is related to trajectory prediction as the agent needs to predict its future trajectory to reach the goal. The paper explicitly mentions Vision-Language Models (VLMs), a type of Large Language Model. While not directly addressing trajectory prediction in the traditional sense, the navigation aspect and the use of VLMs contribute to the relevance.", "keywords": ["vision-language navigation", "VLMs", "navigation", "Vision-Language Models"]}, "AI": {"tldr": "DyNaVLM \u662f\u4e00\u79cd\u65b0\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u5b83\u4f7f\u7528\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u548c\u534f\u4f5c\u56fe\u8bb0\u5fc6\u6765\u5b9e\u73b0\u9ad8\u6548\u7684\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u5bfc\u822a\uff0c\u65e0\u9700\u4efb\u4f55\u8bad\u7ec3\u3002", "motivation": "\u5148\u524d\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u65b9\u6cd5\u53d7\u9650\u4e8e\u56fa\u5b9a\u7684\u89d2\u5ea6\u6216\u8ddd\u79bb\u95f4\u9694\u3002", "method": "DyNaVLM \u662f\u4e00\u79cd\u7aef\u5230\u7aef\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u5b83\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u5e76\u5141\u8bb8\u667a\u80fd\u4f53\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u81ea\u7531\u9009\u62e9\u5bfc\u822a\u76ee\u6807\u3002\u8be5\u6846\u67b6\u7684\u6838\u5fc3\u662f\u4e00\u4e2a\u81ea\u5b8c\u5584\u7684\u56fe\u8bb0\u5fc6\uff0c\u5b83\u53ef\u4ee5\u5c06\u5bf9\u8c61\u4f4d\u7f6e\u5b58\u50a8\u4e3a\u53ef\u6267\u884c\u7684\u62d3\u6251\u5173\u7cfb\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u56fe\u66f4\u65b0\u5b9e\u73b0\u8de8\u673a\u5668\u4eba\u5185\u5b58\u5171\u4eab\uff0c\u5e76\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u6765\u589e\u5f3a VLM \u7684\u51b3\u7b56\u80fd\u529b\u3002", "result": "DyNaVLM \u5728 GOAT \u548c ObjectNav \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u6027\u80fd\u3002\u771f\u5b9e\u4e16\u754c\u7684\u6d4b\u8bd5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u3001\u534f\u4f5c\u56fe\u8bb0\u5fc6\u548c\u65e0\u8bad\u7ec3\u90e8\u7f72\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u5177\u8eab\u673a\u5668\u4eba\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u8303\u4f8b\uff0c\u5f25\u5408\u4e86\u79bb\u6563 VLN \u4efb\u52a1\u548c\u8fde\u7eed\u771f\u5b9e\u4e16\u754c\u5bfc\u822a\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "summary_zh": "\u6211\u4eec\u63d0\u51fa\u4e86 DyNaVLM\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u7684\u7aef\u5230\u7aef\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\u3002\u4e0e\u5148\u524d\u53d7\u56fa\u5b9a\u89d2\u5ea6\u6216\u8ddd\u79bb\u95f4\u9694\u7ea6\u675f\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u81ea\u7531\u9009\u62e9\u5bfc\u822a\u76ee\u6807\u3002\u5b83\u7684\u6838\u5fc3\u5728\u4e8e\u4e00\u4e2a\u81ea\u5b8c\u5584\u7684\u56fe\u8bb0\u5fc6\uff0c\u8be5\u8bb0\u5fc6 1) \u5c06\u5bf9\u8c61\u4f4d\u7f6e\u5b58\u50a8\u4e3a\u53ef\u6267\u884c\u7684\u62d3\u6251\u5173\u7cfb\uff0c2) \u901a\u8fc7\u5206\u5e03\u5f0f\u56fe\u66f4\u65b0\u5b9e\u73b0\u8de8\u673a\u5668\u4eba\u5185\u5b58\u5171\u4eab\uff0c\u4ee5\u53ca 3) \u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u6765\u589e\u5f3a VLM \u7684\u51b3\u7b56\u80fd\u529b\u3002DyNaVLM \u65e0\u9700\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u8bad\u7ec3\u6216\u5fae\u8c03\u5373\u53ef\u8fd0\u884c\uff0c\u5728 GOAT \u548c ObjectNav \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u6027\u80fd\u3002\u771f\u5b9e\u4e16\u754c\u7684\u6d4b\u8bd5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u8be5\u7cfb\u7edf\u7684\u4e09\u9879\u521b\u65b0\uff1a\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u516c\u5f0f\u3001\u534f\u4f5c\u56fe\u8bb0\u5fc6\u548c\u65e0\u8bad\u7ec3\u90e8\u7f72\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u5177\u8eab\u673a\u5668\u4eba\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u8303\u4f8b\uff0c\u5f25\u5408\u4e86\u79bb\u6563 VLN \u4efb\u52a1\u548c\u8fde\u7eed\u771f\u5b9e\u4e16\u754c\u5bfc\u822a\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2506.15065", "pdf": "https://arxiv.org/pdf/2506.15065", "abs": "https://arxiv.org/abs/2506.15065", "authors": ["Trishna Chakraborty", "Udita Ghosh", "Xiaopan Zhang", "Fahim Faisal Niloy", "Yue Dong", "Jiachen Li", "Amit K. Roy-Chowdhury", "Chengyu Song"], "title": "HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Large language models (LLMs) are increasingly being adopted as the cognitive\ncore of embodied agents. However, inherited hallucinations, which stem from\nfailures to ground user instructions in the observed physical environment, can\nlead to navigation errors, such as searching for a refrigerator that does not\nexist. In this paper, we present the first systematic study of hallucinations\nin LLM-based embodied agents performing long-horizon tasks under scene-task\ninconsistencies. Our goal is to understand to what extent hallucinations occur,\nwhat types of inconsistencies trigger them, and how current models respond. To\nachieve these goals, we construct a hallucination probing set by building on an\nexisting benchmark, capable of inducing hallucination rates up to 40x higher\nthan base prompts. Evaluating 12 models across two simulation environments, we\nfind that while models exhibit reasoning, they fail to resolve scene-task\ninconsistencies-highlighting fundamental limitations in handling infeasible\ntasks. We also provide actionable insights on ideal model behavior for each\nscenario, offering guidance for developing more robust and reliable planning\nstrategies.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on the use of Large Language Models (LLMs) in embodied agents, specifically addressing the issue of hallucinations leading to navigation errors. While it doesn't directly focus on trajectory prediction algorithms, the navigation aspect and the use of LLMs place it within a relevant scope. The connection to trajectory prediction is indirect, as navigation errors can impact the predicted trajectory. The paper's emphasis is more on LLM limitations in embodied agents rather than the trajectory prediction itself.", "keywords": ["Large Language Models", "LLMs", "embodied agents", "navigation", "hallucinations"]}, "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u57fa\u4e8e LLM \u7684\u5177\u8eab\u4ee3\u7406\u5728\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u60c5\u51b5\u4e0b\u6267\u884c\u957f\u65f6\u7a0b\u4efb\u52a1\u65f6\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u5177\u8eab\u4ee3\u7406\u7684\u8ba4\u77e5\u6838\u5fc3\uff0c\u4f46\u7531\u4e8e\u672a\u80fd\u5c06\u7528\u6237\u6307\u4ee4\u4e0e\u89c2\u5bdf\u5230\u7684\u7269\u7406\u73af\u5883\u8054\u7cfb\u8d77\u6765\u800c\u5bfc\u81f4\u7684\u5e7b\u89c9\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bfc\u822a\u9519\u8bef\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5e7b\u89c9\u63a2\u6d4b\u96c6\uff0c\u80fd\u591f\u8bf1\u5bfc\u6bd4\u57fa\u672c\u63d0\u793a\u9ad8\u51fa 40 \u500d\u7684\u5e7b\u89c9\u7387\u3002", "result": "\u5728\u4e24\u4e2a\u6a21\u62df\u73af\u5883\u4e2d\u8bc4\u4f30\u4e86 12 \u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u8868\u73b0\u51fa\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u672a\u80fd\u89e3\u51b3\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "conclusion": "\u6a21\u578b\u5728\u5904\u7406\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u65f6\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u5177\u8eab\u4ee3\u7406\u7684\u8ba4\u77e5\u6838\u5fc3\u3002\u7136\u800c\uff0c\u7531\u4e8e\u672a\u80fd\u5c06\u7528\u6237\u6307\u4ee4\u4e0e\u89c2\u5bdf\u5230\u7684\u7269\u7406\u73af\u5883\u8054\u7cfb\u8d77\u6765\u800c\u5bfc\u81f4\u7684\u5e7b\u89c9\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bfc\u822a\u9519\u8bef\uff0c\u4f8b\u5982\u641c\u7d22\u4e0d\u5b58\u5728\u7684\u51b0\u7bb1\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u9996\u6b21\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u57fa\u4e8e LLM \u7684\u5177\u8eab\u4ee3\u7406\u5728\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u60c5\u51b5\u4e0b\u6267\u884c\u957f\u65f6\u7a0b\u4efb\u52a1\u65f6\u7684\u5e7b\u89c9\u95ee\u9898\u3002\u6211\u4eec\u7684\u76ee\u6807\u662f\u4e86\u89e3\u5e7b\u89c9\u53d1\u751f\u7684\u7a0b\u5ea6\uff0c\u54ea\u4e9b\u7c7b\u578b\u7684\u4e0d\u4e00\u81f4\u4f1a\u89e6\u53d1\u5e7b\u89c9\uff0c\u4ee5\u53ca\u5f53\u524d\u6a21\u578b\u5982\u4f55\u54cd\u5e94\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e9b\u76ee\u6807\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5e7b\u89c9\u63a2\u6d4b\u96c6\uff0c\u8be5\u63a2\u6d4b\u96c6\u5efa\u7acb\u5728\u73b0\u6709\u57fa\u51c6\u4e4b\u4e0a\uff0c\u80fd\u591f\u8bf1\u5bfc\u6bd4\u57fa\u672c\u63d0\u793a\u9ad8\u51fa 40 \u500d\u7684\u5e7b\u89c9\u7387\u3002\u901a\u8fc7\u5728\u4e24\u4e2a\u6a21\u62df\u73af\u5883\u4e2d\u8bc4\u4f30 12 \u4e2a\u6a21\u578b\uff0c\u6211\u4eec\u53d1\u73b0\u6a21\u578b\u8868\u73b0\u51fa\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u672a\u80fd\u89e3\u51b3\u573a\u666f\u4efb\u52a1\u4e0d\u4e00\u81f4\u95ee\u9898\u2014\u2014\u7a81\u663e\u4e86\u5904\u7406\u4e0d\u53ef\u884c\u4efb\u52a1\u7684\u6839\u672c\u5c40\u9650\u6027\u3002\u6211\u4eec\u8fd8\u4e3a\u6bcf\u79cd\u573a\u666f\u63d0\u4f9b\u4e86\u7406\u60f3\u6a21\u578b\u884c\u4e3a\u7684\u53ef\u884c\u89c1\u89e3\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u66f4\u53ef\u9760\u7684\u89c4\u5212\u7b56\u7565\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2506.15313", "pdf": "https://arxiv.org/pdf/2506.15313", "abs": "https://arxiv.org/abs/2506.15313", "authors": ["Leonid Ivanov", "Vasily Yuryev", "Dmitry Yudin"], "title": "MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint. Submitted. 12 pages, 4 figures", "summary": "In autonomous driving, high-definition (HD) maps and semantic maps in\nbird's-eye view (BEV) are essential for accurate localization, planning, and\ndecision-making. This paper introduces an enhanced End-to-End model named MapFM\nfor online vectorized HD map generation. We show significantly boost feature\nrepresentation quality by incorporating powerful foundation model for encoding\ncamera images. To further enrich the model's understanding of the environment\nand improve prediction quality, we integrate auxiliary prediction heads for\nsemantic segmentation in the BEV representation. This multi-task learning\napproach provides richer contextual supervision, leading to a more\ncomprehensive scene representation and ultimately resulting in higher accuracy\nand improved quality of the predicted vectorized HD maps. The source code is\navailable at https://github.com/LIvanoff/MapFM.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u4f7f\u7528\u57fa\u7840\u6a21\u578b\uff08foundation model\uff09\u8fdb\u884c\u9ad8\u6e05\u5730\u56fe\uff08HD map\uff09\u751f\u6210\uff0c\u800c\u9ad8\u6e05\u5730\u56fe\u5bf9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u8f68\u8ff9\u9884\u6d4b\u548c\u8def\u5f84\u89c4\u5212\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u8bba\u6587\u672c\u8eab\u6ca1\u6709\u76f4\u63a5\u8fdb\u884c\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u5b83\u5229\u7528\u5927\u6a21\u578b\u6765\u6539\u8fdb\u5730\u56fe\u6784\u5efa\uff0c\u95f4\u63a5\u5f71\u54cd\u8f68\u8ff9\u9884\u6d4b\u7684\u6027\u80fd\u3002\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["foundation model", "HD mapping", "autonomous driving"]}, "AI": {"tldr": "MapFM \u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u548c\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u5728\u7ebf\u77e2\u91cf\u5316\u9ad8\u6e05\u5730\u56fe\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002", "motivation": "\u9ad8\u6e05\u5730\u56fe\u548c\u9e1f\u77b0\u56fe\u4e2d\u7684\u8bed\u4e49\u5730\u56fe\u5bf9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u7cbe\u786e\u5b9a\u4f4d\u3001\u89c4\u5212\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a MapFM \u7684\u589e\u5f3a\u578b\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u7ebf\u77e2\u91cf\u5316\u9ad8\u6e05\u5730\u56fe\u751f\u6210\u3002", "result": "\u901a\u8fc7\u7ed3\u5408\u5f3a\u5927\u7684\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u76f8\u673a\u56fe\u50cf\u7f16\u7801\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7279\u5f81\u8868\u793a\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u591a\u4efb\u52a1\u5b66\u4e60\u548c\u4e0a\u4e0b\u6587\u76d1\u7763\uff0cMapFM \u63d0\u9ad8\u4e86\u9884\u6d4b\u77e2\u91cf\u5316\u9ad8\u6e05\u5730\u56fe\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002", "summary_zh": "\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\uff0c\u9ad8\u6e05\uff08HD\uff09\u5730\u56fe\u548c\u9e1f\u77b0\uff08BEV\uff09\u89c6\u56fe\u4e2d\u7684\u8bed\u4e49\u5730\u56fe\u5bf9\u4e8e\u7cbe\u786e\u5b9a\u4f4d\u3001\u89c4\u5212\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a MapFM \u7684\u589e\u5f3a\u578b\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u7ebf\u77e2\u91cf\u5316\u9ad8\u6e05\u5730\u56fe\u751f\u6210\u3002\u6211\u4eec\u901a\u8fc7\u7ed3\u5408\u5f3a\u5927\u7684\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u76f8\u673a\u56fe\u50cf\u7f16\u7801\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7279\u5f81\u8868\u793a\u8d28\u91cf\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u4e30\u5bcc\u6a21\u578b\u5bf9\u73af\u5883\u7684\u7406\u89e3\u5e76\u63d0\u9ad8\u9884\u6d4b\u8d28\u91cf\uff0c\u6211\u4eec\u96c6\u6210\u4e86\u8f85\u52a9\u9884\u6d4b\u5934\uff0c\u7528\u4e8e\u5728 BEV \u8868\u793a\u4e2d\u8fdb\u884c\u8bed\u4e49\u5206\u5272\u3002\u8fd9\u79cd\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u76d1\u7763\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u66f4\u5168\u9762\u7684\u573a\u666f\u8868\u793a\uff0c\u5e76\u6700\u7ec8\u63d0\u9ad8\u4e86\u9884\u6d4b\u77e2\u91cf\u5316\u9ad8\u6e05\u5730\u56fe\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002\u6e90\u4ee3\u7801\u53ef\u5728 https://github.com/LIvanoff/MapFM \u83b7\u53d6\u3002"}}
{"id": "2506.15447", "pdf": "https://arxiv.org/pdf/2506.15447", "abs": "https://arxiv.org/abs/2506.15447", "authors": ["David Leprich", "Mario Rosenfelder", "Mario Hermle", "Jingshan Chen", "Peter Eberhard"], "title": "Model Predictive Path-Following Control for a Quadrotor", "categories": ["eess.SY", "cs.RO", "cs.SY", "93-XX"], "comment": "15 pages, 11 figures, submitted to PAMM 2025", "summary": "Automating drone-assisted processes is a complex task. Many solutions rely on\ntrajectory generation and tracking, whereas in contrast, path-following control\nis a particularly promising approach, offering an intuitive and natural\napproach to automate tasks for drones and other vehicles. While different\nsolutions to the path-following problem have been proposed, most of them lack\nthe capability to explicitly handle state and input constraints, are formulated\nin a conservative two-stage approach, or are only applicable to linear systems.\nTo address these challenges, the paper is built upon a Model Predictive\nControl-based path-following framework and extends its application to the\nCrazyflie quadrotor, which is investigated in hardware experiments. A cascaded\ncontrol structure including an underlying attitude controller is included in\nthe Model Predictive Path-Following Control formulation to meet the challenging\nreal-time demands of quadrotor control. The effectiveness of the proposed\nmethod is demonstrated through real-world experiments, representing, to the\nbest of the authors' knowledge, a novel application of this MPC-based\npath-following approach to the quadrotor. Additionally, as an extension to the\noriginal method, to allow for deviations of the path in cases where the precise\nfollowing of the path might be overly restrictive, a corridor path-following\napproach is presented.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u65e0\u4eba\u673a\u7684\u8def\u5f84\u8ddf\u8e2a\u63a7\u5236\uff0c\u4f7f\u7528\u4e86\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u65b9\u6cd5\u3002\u867d\u7136\u6d89\u53ca\u8def\u5f84\u89c4\u5212\u548c\u63a7\u5236\uff0c\u4f46\u4e3b\u8981\u96c6\u4e2d\u5728\u63a7\u5236\u7b97\u6cd5\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\u4e0a\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u6709\u4e00\u5b9a\u5173\u8054\uff0c\u4f46\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u5927\u6a21\u578b\u3002\u5173\u952e\u8bcd'path-following'\u548c'Model Predictive Control'\u4e0e\u8f68\u8ff9\u9884\u6d4b\u76f8\u5173\u3002", "keywords": ["path-following", "Model Predictive Control", "trajectory generation"]}, "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8eCrazyflie\u56db\u65cb\u7ffc\u98de\u884c\u5668\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u6269\u5c55\u5230\u8d70\u5eca\u8def\u5f84\u8ddf\u8e2a\u3002", "motivation": "\u73b0\u6709\u7684\u8def\u5f84\u8ddf\u8e2a\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u663e\u5f0f\u5904\u7406\u72b6\u6001\u548c\u8f93\u5165\u7ea6\u675f\u7684\u80fd\u529b\uff0c\u901a\u5e38\u91c7\u7528\u4fdd\u5b88\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u6216\u8005\u4ec5\u9002\u7528\u4e8e\u7ebf\u6027\u7cfb\u7edf\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u5904\u7406\u7ea6\u675f\u5e76\u5728\u56db\u65cb\u7ffc\u98de\u884c\u5668\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u8def\u5f84\u8ddf\u8e2a\u7684\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u7684\u8def\u5f84\u8ddf\u8e2a\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eCrazyflie\u56db\u65cb\u7ffc\u98de\u884c\u5668\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u5e95\u5c42\u7684\u59ff\u6001\u63a7\u5236\u5668\uff0c\u4ee5\u6ee1\u8db3\u56db\u65cb\u7ffc\u63a7\u5236\u7684\u5b9e\u65f6\u6027\u9700\u6c42\u3002", "result": "\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u57fa\u4e8eMPC\u7684\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u5728\u56db\u65cb\u7ffc\u98de\u884c\u5668\u4e0a\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u4f5c\u4e3a\u539f\u59cb\u65b9\u6cd5\u7684\u6269\u5c55\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8d70\u5eca\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u5141\u8bb8\u5728\u8def\u5f84\u7cbe\u786e\u8ddf\u8e2a\u53ef\u80fd\u8fc7\u4e8e\u4e25\u683c\u7684\u60c5\u51b5\u4e0b\u504f\u79bb\u8def\u5f84\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u56db\u65cb\u7ffc\u98de\u884c\u5668\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8d70\u5eca\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u5141\u8bb8\u5728\u8def\u5f84\u8ddf\u8e2a\u8fc7\u4e8e\u4e25\u683c\u7684\u60c5\u51b5\u4e0b\u504f\u79bb\u8def\u5f84\u3002", "summary_zh": "\u65e0\u4eba\u673a\u8f85\u52a9\u6d41\u7a0b\u7684\u81ea\u52a8\u5316\u662f\u4e00\u4e2a\u590d\u6742\u7684\u4efb\u52a1\u3002\u8bb8\u591a\u89e3\u51b3\u65b9\u6848\u4f9d\u8d56\u4e8e\u8f68\u8ff9\u751f\u6210\u548c\u8ddf\u8e2a\uff0c\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u8def\u5f84\u8ddf\u8e2a\u63a7\u5236\u662f\u4e00\u79cd\u7279\u522b\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u5b83\u4e3a\u65e0\u4eba\u673a\u548c\u5176\u4ed6\u8f66\u8f86\u7684\u81ea\u52a8\u5316\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u76f4\u89c2\u548c\u81ea\u7136\u7684\u65b9\u6cd5\u3002\u867d\u7136\u5df2\u7ecf\u63d0\u51fa\u4e86\u4e0d\u540c\u7684\u8def\u5f84\u8ddf\u8e2a\u95ee\u9898\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b83\u4eec\u4e2d\u7684\u5927\u591a\u6570\u7f3a\u4e4f\u663e\u5f0f\u5904\u7406\u72b6\u6001\u548c\u8f93\u5165\u7ea6\u675f\u7684\u80fd\u529b\uff0c\u4ee5\u4fdd\u5b88\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u5236\u5b9a\uff0c\u6216\u8005\u4ec5\u9002\u7528\u4e8e\u7ebf\u6027\u7cfb\u7edf\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u672c\u6587\u5efa\u7acb\u5728\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u8def\u5f84\u8ddf\u8e2a\u6846\u67b6\u4e4b\u4e0a\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u6269\u5c55\u5230Crazyflie\u56db\u65cb\u7ffc\u98de\u884c\u5668\uff0c\u5e76\u5728\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u8fdb\u884c\u4e86\u7814\u7a76\u3002\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u8ddf\u8e2a\u63a7\u5236\u516c\u5f0f\u4e2d\u5305\u542b\u4e00\u4e2a\u5305\u542b\u5e95\u5c42\u59ff\u6001\u63a7\u5236\u5668\u7684\u7ea7\u8054\u63a7\u5236\u7ed3\u6784\uff0c\u4ee5\u6ee1\u8db3\u56db\u65cb\u7ffc\u63a7\u5236\u7684\u5177\u6709\u6311\u6218\u6027\u7684\u5b9e\u65f6\u9700\u6c42\u3002\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u636e\u4f5c\u8005\u6240\u77e5\uff0c\u8fd9\u4ee3\u8868\u4e86\u8fd9\u79cd\u57fa\u4e8eMPC\u7684\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u5728\u56db\u65cb\u7ffc\u98de\u884c\u5668\u4e0a\u7684\u65b0\u9896\u5e94\u7528\u3002\u6b64\u5916\uff0c\u4f5c\u4e3a\u5bf9\u539f\u59cb\u65b9\u6cd5\u7684\u6269\u5c55\uff0c\u4e3a\u4e86\u5141\u8bb8\u5728\u8def\u5f84\u7cbe\u786e\u8ddf\u8e2a\u53ef\u80fd\u8fc7\u4e8e\u4e25\u683c\u7684\u60c5\u51b5\u4e0b\u504f\u79bb\u8def\u5f84\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8d70\u5eca\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u3002"}}
