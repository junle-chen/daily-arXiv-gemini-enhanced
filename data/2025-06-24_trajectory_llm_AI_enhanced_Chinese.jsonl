{"id": "2506.15868", "pdf": "https://arxiv.org/pdf/2506.15868", "abs": "https://arxiv.org/abs/2506.15868", "authors": ["Mingyue Lei", "Zewei Zhou", "Hongchen Li", "Jia Hu", "Jiaqi Ma"], "title": "CooperRisk: A Driving Risk Quantification Pipeline with Multi-Agent Cooperative Perception and Prediction", "categories": ["cs.RO"], "comment": "IROS2025", "summary": "Risk quantification is a critical component of safe autonomous driving,\nhowever, constrained by the limited perception range and occlusion of\nsingle-vehicle systems in complex and dense scenarios. Vehicle-to-everything\n(V2X) paradigm has been a promising solution to sharing complementary\nperception information, nevertheless, how to ensure the risk interpretability\nwhile understanding multi-agent interaction with V2X remains an open question.\nIn this paper, we introduce the first V2X-enabled risk quantification pipeline,\nCooperRisk, to fuse perception information from multiple agents and quantify\nthe scenario driving risk in future multiple timestamps. The risk is\nrepresented as a scenario risk map to ensure interpretability based on risk\nseverity and exposure, and the multi-agent interaction is captured by the\nlearning-based cooperative prediction model. We carefully design a\nrisk-oriented transformer-based prediction model with multi-modality and\nmulti-agent considerations. It aims to ensure scene-consistent future behaviors\nof multiple agents and avoid conflicting predictions that could lead to overly\nconservative risk quantification and cause the ego vehicle to become overly\nhesitant to drive. Then, the temporal risk maps could serve to guide a model\npredictive control planner. We evaluate the CooperRisk pipeline in a real-world\nV2X dataset V2XPnP, and the experiments demonstrate its superior performance in\nrisk quantification, showing a 44.35% decrease in conflict rate between the ego\nvehicle and background traffic participants.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\uff08driving risk quantification, prediction model\uff09\uff0c\u5e76\u5229\u7528\u4e86transformer\u6a21\u578b\u8fdb\u884c\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u5efa\u6a21\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46transformer\u67b6\u6784\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bc6\u5207\u76f8\u5173\uff0c\u4e14\u8bba\u6587\u6d89\u53ca\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\uff0c\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["trajectory prediction", "risk quantification", "multi-agent interaction", "transformer", "V2X", "cooperative perception", "driving risk"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.15710", "pdf": "https://arxiv.org/pdf/2506.15710", "abs": "https://arxiv.org/abs/2506.15710", "authors": ["Siru Ouyang", "Xinyu Zhu", "Zilin Xiao", "Minhao Jiang", "Yu Meng", "Jiawei Han"], "title": "RAST: Reasoning Activation in LLMs via Small-model Transfer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a powerful approach for improving the\nreasoning capabilities of large language models (LLMs), as evidenced by recent\nsuccesses such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale\nremains intimidatingly resource-intensive, requiring multiple model copies and\nextensive GPU workloads. On the other hand, while being powerful, recent\nstudies suggest that RL does not fundamentally endow models with new knowledge;\nrather, it primarily reshapes the model's output distribution to activate\nreasoning capabilities latent in the base model. Building on this insight, we\nhypothesize that the changes in output probabilities induced by RL are largely\nmodel-size invariant, opening the door to a more efficient paradigm: training a\nsmall model with RL and transferring its induced probability shifts to larger\nbase models. To verify our hypothesis, we conduct a token-level analysis of\ndecoding trajectories and find high alignment in RL-induced output\ndistributions across model scales, validating our hypothesis. Motivated by\nthis, we propose RAST, a simple yet effective method that transfers reasoning\nbehaviors by injecting RL-induced probability adjustments from a small\nRL-trained model into larger models. Experiments across multiple mathematical\nreasoning benchmarks show that RAST substantially and consistently enhances the\nreasoning capabilities of base models while requiring significantly lower GPU\nmemory than direct RL training, sometimes even yielding better performance than\nthe RL-trained counterparts. Our findings offer new insights into the nature of\nRL-driven reasoning and practical strategies for scaling its benefits without\nincurring its full computational cost. The project page of RAST is available at\nhttps://ozyyshr.github.io/RAST/.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper focuses on improving the reasoning capabilities of large language models (LLMs) using reinforcement learning. While it doesn't directly address trajectory prediction, it is highly relevant to the 'Large Language Models' aspect of the prompt, and the techniques for improving reasoning *could* potentially be applied in the future to trajectory prediction tasks that require reasoning about the environment and possible future states.  The reinforcement learning aspect also hints at a potential connection to sequential decision making, which is relevant to trajectory prediction.", "keywords": ["Large Language Models", "LLMs", "Reinforcement Learning", "reasoning capabilities", "foundation models"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.17111", "pdf": "https://arxiv.org/pdf/2506.17111", "abs": "https://arxiv.org/abs/2506.17111", "authors": ["Lina Berrayana", "Sean Rooney", "Luis Garc\u00e9s-Erice", "Ioana Giurgiu"], "title": "Are Bias Evaluation Methods Biased ?", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Workshop GEM", "summary": "The creation of benchmarks to evaluate the safety of Large Language Models is\none of the key activities within the trusted AI community. These benchmarks\nallow models to be compared for different aspects of safety such as toxicity,\nbias, harmful behavior etc. Independent benchmarks adopt different approaches\nwith distinct data sets and evaluation methods. We investigate how robust such\nbenchmarks are by using different approaches to rank a set of representative\nmodels for bias and compare how similar are the overall rankings. We show that\ndifferent but widely used bias evaluations methods result in disparate model\nrankings. We conclude with recommendations for the community in the usage of\nsuch benchmarks.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper focuses on evaluating the bias of Large Language Models. While it doesn't directly address trajectory prediction, it's highly relevant to the field of Large Language Models, a key area of interest.", "keywords": ["Large Language Models", "LLMs", "bias", "evaluation", "benchmarks"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.15828", "pdf": "https://arxiv.org/pdf/2506.15828", "abs": "https://arxiv.org/abs/2506.15828", "authors": ["Emanuele Musumeci", "Michele Brienza", "Francesco Argenziano", "Vincenzo Suriani", "Daniele Nardi", "Domenico D. Bloisi"], "title": "Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Classical planning in AI and Robotics addresses complex tasks by shifting\nfrom imperative to declarative approaches (e.g., PDDL). However, these methods\noften fail in real scenarios due to limited robot perception and the need to\nground perceptions to planning predicates. This often results in heavily\nhard-coded behaviors that struggle to adapt, even with scenarios where goals\ncan be achieved through relaxed planning. Meanwhile, Large Language Models\n(LLMs) lead to planning systems that leverage commonsense reasoning but often\nat the cost of generating unfeasible and/or unsafe plans. To address these\nlimitations, we present an approach integrating classical planning with LLMs,\nleveraging their ability to extract commonsense knowledge and ground actions.\nWe propose a hierarchical formulation that enables robots to make unfeasible\ntasks tractable by defining functionally equivalent goals through gradual\nrelaxation. This mechanism supports partial achievement of the intended\nobjective, suited to the agent's specific context. Our method demonstrates its\nability to adapt and execute tasks effectively within environments modeled\nusing 3D Scene Graphs through comprehensive qualitative and quantitative\nevaluations. We also show how this method succeeds in complex scenarios where\nother benchmark methods are more likely to fail. Code, dataset, and additional\nmaterial are released to the community.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper integrates Large Language Models (LLMs) with classical planning for robotic tasks. While it doesn't explicitly focus on trajectory prediction, the planning aspect and the use of LLMs suggest a moderate relevance, especially considering the planning involves generating action sequences within a 3D scene, which could implicitly involve trajectory considerations. The core focus is on feasible plan generation rather than specifically predicting trajectories, hence the score is not higher.", "keywords": ["Large Language Models", "LLMs", "planning", "3D Scene Planning", "robotics", "commonsense reasoning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.15854", "pdf": "https://arxiv.org/pdf/2506.15854", "abs": "https://arxiv.org/abs/2506.15854", "authors": ["Abdolazim Rezaei", "Mehdi Sookhak", "Ahmad Patooghy"], "title": "Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Connected and Autonomous Vehicles (CAVs) rely on a range of devices that\noften process privacy-sensitive data. Among these, roadside units play a\ncritical role particularly through the use of AI-equipped (AIE) cameras for\napplications such as violation detection. However, the privacy risks associated\nwith captured imagery remain a major concern, as such data can be misused for\nidentity theft, profiling, or unauthorized commercial purposes. While\ntraditional techniques such as face blurring and obfuscation have been applied\nto mitigate privacy risks, individual privacy remains at risk, as individuals\ncan still be tracked using other features such as their clothing. This paper\nintroduces a novel privacy-preserving framework that leverages feedback-based\nreinforcement learning (RL) and vision-language models (VLMs) to protect\nsensitive visual information captured by AIE cameras. The main idea is to\nconvert images into semantically equivalent textual descriptions, ensuring that\nscene-relevant information is retained while visual privacy is preserved. A\nhierarchical RL strategy is employed to iteratively refine the generated text,\nenhancing both semantic accuracy and privacy. Evaluation results demonstrate\nsignificant improvements in both privacy protection and textual quality, with\nthe Unique Word Count increasing by approximately 77\\% and Detail Density by\naround 50\\% compared to existing approaches.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on privacy preservation in connected and autonomous vehicles using vision-language models (VLMs) to transform images into text. While it doesn't directly address trajectory prediction, the context of autonomous vehicles implies a connection to trajectory planning and prediction. The use of VLMs also links it to large language models, although the paper primarily uses them for vision-to-text transformation rather than trajectory-related tasks.", "keywords": ["vision-language models", "autonomous vehicles", "privacy preservation"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.15695", "pdf": "https://arxiv.org/pdf/2506.15695", "abs": "https://arxiv.org/abs/2506.15695", "authors": ["Xinxing Ren", "Qianbo Zang", "Zekun Guo"], "title": "SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in large language models (LLMs) have shown impressive\nperformance in mathematical reasoning and code generation. However, LLMs still\nstruggle in the simulation domain, particularly in generating Simulink models,\nwhich are essential tools in engineering and scientific research. Our\npreliminary experiments indicate that LLM agents often fail to produce reliable\nand complete Simulink simulation code from text-only inputs, likely due to the\nlack of Simulink-specific data in their pretraining. To address this challenge,\nwe propose SimuGen, a multimodal agent-based framework that automatically\ngenerates accurate Simulink simulation code by leveraging both the visual\nSimulink diagram and domain knowledge. SimuGen coordinates several specialized\nagents, including an investigator, unit test reviewer, code generator,\nexecutor, debug locator, and report writer, supported by a domain-specific\nknowledge base. This collaborative and modular design enables interpretable,\nrobust, and reproducible Simulink simulation generation. Our source code is\npublicly available at https://github.com/renxinxing123/SimuGen_beta.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on using Large Language Models (LLMs) for generating Simulink models, which are used in engineering and scientific research. While not directly related to trajectory prediction, the use of LLMs is a central theme, and Simulink models could potentially be used in trajectory prediction contexts. Therefore, there is a moderate level of relevance.", "keywords": ["Large Language Models", "LLMs", "simulation"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.15945", "pdf": "https://arxiv.org/pdf/2506.15945", "abs": "https://arxiv.org/abs/2506.15945", "authors": ["Kowndinya Boyalakuntla", "Abdeslam Boularias", "Jingjin Yu"], "title": "KARL: Kalman-Filter Assisted Reinforcement Learner for Dynamic Object Tracking and Grasping", "categories": ["cs.RO"], "comment": null, "summary": "We present Kalman-filter Assisted Reinforcement Learner (KARL) for dynamic\nobject tracking and grasping over eye-on-hand (EoH) systems, significantly\nexpanding such systems capabilities in challenging, realistic environments. In\ncomparison to the previous state-of-the-art, KARL (1) incorporates a novel\nsix-stage RL curriculum that doubles the system's motion range, thereby greatly\nenhancing the system's grasping performance, (2) integrates a robust Kalman\nfilter layer between the perception and reinforcement learning (RL) control\nmodules, enabling the system to maintain an uncertain but continuous 6D pose\nestimate even when the target object temporarily exits the camera's\nfield-of-view or undergoes rapid, unpredictable motion, and (3) introduces\nmechanisms to allow retries to gracefully recover from unavoidable policy\nexecution failures. Extensive evaluations conducted in both simulation and\nreal-world experiments qualitatively and quantitatively corroborate KARL's\nadvantage over earlier systems, achieving higher grasp success rates and faster\nrobot execution speed. Source code and supplementary materials for KARL will be\nmade available at: https://github.com/arc-l/karl.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on dynamic object tracking and grasping, which is related to trajectory prediction. While it doesn't directly involve large language models, the Kalman filter is used for state estimation, which can be considered a form of trajectory prediction. The reinforcement learning aspect also touches upon predicting future states based on actions.", "keywords": ["dynamic object tracking", "Kalman filter", "reinforcement learning", "motion prediction", "pose estimation"]}, "AI": {"tldr": "KARL\u901a\u8fc7\u7ed3\u5408\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u773c\u624b\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8ddf\u8e2a\u548c\u6293\u53d6\u7269\u4f53\u7684\u6027\u80fd\u3002", "motivation": "\u6269\u5c55\u773c\u624b (EoH) \u7cfb\u7edf\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u80fd\u529b\u3002", "method": "KARL \u7ed3\u5408\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u516d\u9636\u6bb5 RL \u8bfe\u7a0b\uff0c\u5e76\u5728\u611f\u77e5\u548c\u5f3a\u5316\u5b66\u4e60 (RL) \u63a7\u5236\u6a21\u5757\u4e4b\u95f4\u96c6\u6210\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5c42\uff0c\u5e76\u5f15\u5165\u4e86\u5141\u8bb8\u91cd\u8bd5\u7684\u673a\u5236\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u8fdb\u884c\u7684\u5927\u91cf\u8bc4\u4f30\u5b9a\u6027\u548c\u5b9a\u91cf\u5730\u8bc1\u5b9e\u4e86 KARL \u76f8\u5bf9\u4e8e\u65e9\u671f\u7cfb\u7edf\u7684\u4f18\u52bf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6293\u53d6\u6210\u529f\u7387\u548c\u66f4\u5feb\u7684\u673a\u5668\u4eba\u6267\u884c\u901f\u5ea6\u3002", "conclusion": "KARL\u5728\u52a8\u6001\u7269\u4f53\u8ddf\u8e2a\u548c\u6293\u53d6\u65b9\u9762\u4f18\u4e8e\u65e9\u671f\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6293\u53d6\u6210\u529f\u7387\u548c\u66f4\u5feb\u7684\u673a\u5668\u4eba\u6267\u884c\u901f\u5ea6\u3002", "summary_zh": "\u6211\u4eec\u63d0\u51fa\u4e86\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u8f85\u52a9\u5f3a\u5316\u5b66\u4e60\u5668 (KARL)\uff0c\u7528\u4e8e\u773c\u624b (EoH) \u7cfb\u7edf\u4e0a\u7684\u52a8\u6001\u7269\u4f53\u8ddf\u8e2a\u548c\u6293\u53d6\uff0c\u663e\u7740\u6269\u5c55\u4e86\u6b64\u7c7b\u7cfb\u7edf\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u80fd\u529b\u3002\u4e0e\u4e4b\u524d\u7684\u6700\u5148\u8fdb\u6280\u672f\u76f8\u6bd4\uff0cKARL (1) \u7ed3\u5408\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u516d\u9636\u6bb5 RL \u8bfe\u7a0b\uff0c\u8be5\u8bfe\u7a0b\u4f7f\u7cfb\u7edf\u7684\u8fd0\u52a8\u8303\u56f4\u589e\u52a0\u4e86\u4e00\u500d\uff0c\u4ece\u800c\u5927\u5927\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u6293\u53d6\u6027\u80fd\uff0c(2) \u5728\u611f\u77e5\u548c\u5f3a\u5316\u5b66\u4e60 (RL) \u63a7\u5236\u6a21\u5757\u4e4b\u95f4\u96c6\u6210\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5c42\uff0c\u4f7f\u7cfb\u7edf\u5373\u4f7f\u5728\u76ee\u6807\u7269\u4f53\u6682\u65f6\u9000\u51fa\u76f8\u673a\u89c6\u91ce\u6216\u7ecf\u5386\u5feb\u901f\u3001\u4e0d\u53ef\u9884\u6d4b\u7684\u8fd0\u52a8\u65f6\uff0c\u4e5f\u80fd\u4fdd\u6301\u4e0d\u786e\u5b9a\u4f46\u8fde\u7eed\u7684 6D \u59ff\u52bf\u4f30\u8ba1\uff0c\u4ee5\u53ca (3) \u5f15\u5165\u4e86\u5141\u8bb8\u91cd\u8bd5\u7684\u673a\u5236\uff0c\u4ee5\u4fbf\u4ece\u4e0d\u53ef\u907f\u514d\u7684\u7b56\u7565\u6267\u884c\u5931\u8d25\u4e2d\u4f18\u96c5\u5730\u6062\u590d\u3002\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u8fdb\u884c\u7684\u5927\u91cf\u8bc4\u4f30\u5b9a\u6027\u548c\u5b9a\u91cf\u5730\u8bc1\u5b9e\u4e86 KARL \u76f8\u5bf9\u4e8e\u65e9\u671f\u7cfb\u7edf\u7684\u4f18\u52bf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6293\u53d6\u6210\u529f\u7387\u548c\u66f4\u5feb\u7684\u673a\u5668\u4eba\u6267\u884c\u901f\u5ea6\u3002KARL \u7684\u6e90\u4ee3\u7801\u548c\u8865\u5145\u6750\u6599\u5c06\u5728\u4ee5\u4e0b\u7f51\u5740\u63d0\u4f9b\uff1ahttps://github.com/arc-l/karl\u3002"}}
{"id": "2506.15700", "pdf": "https://arxiv.org/pdf/2506.15700", "abs": "https://arxiv.org/abs/2506.15700", "authors": ["Minjae Cho", "Hiroyasu Tsukamoto", "Huy Trong Tran"], "title": "Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Control contraction metrics (CCMs) provide a framework to co-synthesize a\ncontroller and a corresponding contraction metric -- a positive-definite\nRiemannian metric under which a closed-loop system is guaranteed to be\nincrementally exponentially stable. However, the synthesized controller only\nensures that all the trajectories of the system converge to one single\ntrajectory and, as such, does not impose any notion of optimality across an\nentire trajectory. Furthermore, constructing CCMs requires a known dynamics\nmodel and non-trivial effort in solving an infinite-dimensional convex\nfeasibility problem, which limits its scalability to complex systems featuring\nhigh dimensionality with uncertainty. To address these issues, we propose to\nintegrate CCMs into reinforcement learning (RL), where CCMs provide\ndynamics-informed feedback for learning control policies that minimize\ncumulative tracking error under unknown dynamics. We show that our algorithm,\ncalled contraction actor-critic (CAC), formally enhances the capability of CCMs\nto provide a set of contracting policies with the long-term optimality of RL in\na fully automated setting. Given a pre-trained dynamics model, CAC\nsimultaneously learns a contraction metric generator (CMG) -- which generates a\ncontraction metric -- and uses an actor-critic algorithm to learn an optimal\ntracking policy guided by that metric. We demonstrate the effectiveness of our\nalgorithm relative to established baselines through extensive empirical\nstudies, including simulated and real-world robot experiments, and provide a\ntheoretical rationale for incorporating contraction theory into RL.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u8def\u5f84\u8ddf\u8e2a\uff08path tracking\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u7279\u522b\u662f\u7ed3\u5408\u63a7\u5236\u6536\u7f29\u5ea6\u91cf\uff08CCMs\uff09\u6765\u63d0\u9ad8\u8def\u5f84\u8ddf\u8e2a\u7684\u9c81\u68d2\u6027\u3002 \u867d\u7136\u6d89\u53ca\u8def\u5f84\u8ddf\u8e2a\uff0c\u4f46\u4e0e\u8f68\u8ff9\u9884\u6d4b\u7684\u5173\u8054\u6027\u8f83\u5f31\uff0c\u4e14\u6ca1\u6709\u6d89\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u3002\u5f3a\u5316\u5b66\u4e60\u5728\u8f68\u8ff9\u9884\u6d4b\u4e2d\u6709\u6240\u5e94\u7528\uff0c\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["path tracking", "reinforcement learning", "robot experiments"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16163", "pdf": "https://arxiv.org/pdf/2506.16163", "abs": "https://arxiv.org/abs/2506.16163", "authors": ["Hao Li", "Gengrui Zhang", "Petter Holme", "Shuyue Hu", "Zhen Wang"], "title": "Large Language Models are Near-Optimal Decision-Makers with a Non-Human Learning Behavior", "categories": ["cs.AI"], "comment": null, "summary": "Human decision-making belongs to the foundation of our society and\ncivilization, but we are on the verge of a future where much of it will be\ndelegated to artificial intelligence. The arrival of Large Language Models\n(LLMs) has transformed the nature and scope of AI-supported decision-making;\nhowever, the process by which they learn to make decisions, compared to humans,\nremains poorly understood. In this study, we examined the decision-making\nbehavior of five leading LLMs across three core dimensions of real-world\ndecision-making: uncertainty, risk, and set-shifting. Using three\nwell-established experimental psychology tasks designed to probe these\ndimensions, we benchmarked LLMs against 360 newly recruited human participants.\nAcross all tasks, LLMs often outperformed humans, approaching near-optimal\nperformance. Moreover, the processes underlying their decisions diverged\nfundamentally from those of humans. On the one hand, our finding demonstrates\nthe ability of LLMs to manage uncertainty, calibrate risk, and adapt to\nchanges. On the other hand, this disparity highlights the risks of relying on\nthem as substitutes for human judgment, calling for further inquiry.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on the decision-making capabilities of Large Language Models (LLMs) and compares their performance to humans. While it doesn't explicitly mention trajectory prediction, the decision-making aspect is relevant to trajectory planning and control, especially if LLMs are used to make decisions within a trajectory prediction framework. The primary focus is on LLMs, hence the score is not 1.0.", "keywords": ["Large Language Models", "LLMs", "decision-making", "artificial intelligence", "foundation models"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16143", "pdf": "https://arxiv.org/pdf/2506.16143", "abs": "https://arxiv.org/abs/2506.16143", "authors": ["Stephane Ngnepiepaye Wembe", "Vincent Rousseau", "Johann Laconte", "Roland Lenain"], "title": "From Theory to Practice: Identifying the Optimal Approach for Offset Point Tracking in the Context of Agricultural Robotics", "categories": ["cs.RO"], "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "summary": "Modern agriculture faces escalating challenges: increasing demand for food,\nlabor shortages, and the urgent need to reduce environmental impact.\nAgricultural robotics has emerged as a promising response to these pressures,\nenabling the automation of precise and suitable field operations. In\nparticular, robots equipped with implements for tasks such as weeding or sowing\nmust interact delicately and accurately with the crops and soil. Unlike robots\nin other domains, these agricultural platforms typically use rigidly mounted\nimplements, where the implement's position is more critical than the robot's\ncenter in determining task success. Yet, most control strategies in the\nliterature focus on the vehicle body, often neglecting the acctual working\npoint of the system. This is particularly important when considering new\nagriculture practices where crops row are not necessary straights. This paper\npresents a predictive control strategy targeting the implement's reference\npoint. The method improves tracking performance by anticipating the motion of\nthe implement, which, due to its offset from the vehicle's center of rotation,\nis prone to overshooting during turns if not properly accounted for.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper discusses a predictive control strategy for agricultural robots, focusing on tracking the implement's reference point. While it doesn't explicitly mention Large Language Models, the \"predictive control strategy\" aligns with the broader concept of trajectory prediction. The paper focuses on improving tracking performance by anticipating the motion of the implement. Therefore, there is a moderate relevance to trajectory prediction but no relevance to large language models.", "keywords": ["predictive control", "trajectory prediction", "tracking"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16211", "pdf": "https://arxiv.org/pdf/2506.16211", "abs": "https://arxiv.org/abs/2506.16211", "authors": ["Puhao Li", "Yingying Wu", "Ziheng Xi", "Wanlin Li", "Yuzhe Huang", "Zhiyuan Zhang", "Yinghan Chen", "Jianan Wang", "Song-Chun Zhu", "Tengyu Liu", "Siyuan Huang"], "title": "ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models", "categories": ["cs.RO"], "comment": "Website: https://controlvla.github.io", "summary": "Learning real-world robotic manipulation is challenging, particularly when\nlimited demonstrations are available. Existing methods for few-shot\nmanipulation often rely on simulation-augmented data or pre-built modules like\ngrasping and pose estimation, which struggle with sim-to-real gaps and lack\nextensibility. While large-scale imitation pre-training shows promise, adapting\nthese general-purpose policies to specific tasks in data-scarce settings\nremains unexplored. To achieve this, we propose ControlVLA, a novel framework\nthat bridges pre-trained VLA models with object-centric representations via a\nControlNet-style architecture for efficient fine-tuning. Specifically, to\nintroduce object-centric conditions without overwriting prior knowledge,\nControlVLA zero-initializes a set of projection layers, allowing them to\ngradually adapt the pre-trained manipulation policies. In real-world\nexperiments across 6 diverse tasks, including pouring cubes and folding\nclothes, our method achieves a 76.7% success rate while requiring only 10-20\ndemonstrations -- a significant improvement over traditional approaches that\nrequire more than 100 demonstrations to achieve comparable success. Additional\nexperiments highlight ControlVLA's extensibility to long-horizon tasks and\nrobustness to unseen objects and backgrounds.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper discusses pre-trained Vision-Language-Action (VLA) models for robotic manipulation, which implicitly involves action prediction and control. While not directly addressing trajectory prediction in the classical sense (e.g., predicting pedestrian trajectories), it uses large pre-trained models (VLAs) for action execution, suggesting a connection to both large models and a form of action/trajectory planning. The 'action' component of VLA models is relevant to trajectory prediction, though the focus is on manipulation rather than explicit trajectory forecasting.", "keywords": ["Large Language Models", "Vision-Language-Action Models", "Pre-trained Models", "Action prediction", "Robotic Manipulation"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16219", "pdf": "https://arxiv.org/pdf/2506.16219", "abs": "https://arxiv.org/abs/2506.16219", "authors": ["Amine Tourki", "Paul Prevel", "Nils Einecke", "Tim Puphal", "Alexandre Alahi"], "title": "Probabilistic Collision Risk Estimation for Pedestrian Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Intelligent devices for supporting persons with vision impairment are\nbecoming more widespread, but they are lacking behind the advancements in\nintelligent driver assistant system. To make a first step forward, this work\ndiscusses the integration of the risk model technology, previously used in\nautonomous driving and advanced driver assistance systems, into an assistance\ndevice for persons with vision impairment. The risk model computes a\nprobabilistic collision risk given object trajectories which has previously\nbeen shown to give better indications of an object's collision potential\ncompared to distance or time-to-contact measures in vehicle scenarios. In this\nwork, we show that the risk model is also superior in warning persons with\nvision impairment about dangerous objects. Our experiments demonstrate that the\nwarning accuracy of the risk model is 67% while both distance and\ntime-to-contact measures reach only 51% accuracy for real-world data.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on probabilistic collision risk estimation based on object trajectories, which is related to trajectory prediction. While it doesn't directly involve large language models, the risk model utilizes trajectory information for prediction, placing it within the broader scope of trajectory prediction. The application to pedestrian navigation further strengthens this connection.", "keywords": ["trajectory prediction", "collision risk estimation", "pedestrian navigation", "object trajectories"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16301", "pdf": "https://arxiv.org/pdf/2506.16301", "abs": "https://arxiv.org/abs/2506.16301", "authors": ["Nadine Imholz", "Maurice Brunner", "Nicolas Baumann", "Edoardo Ghignone", "Michele Magno"], "title": "M-Predictive Spliner: Enabling Spatiotemporal Multi-Opponent Overtaking for Autonomous Racing", "categories": ["cs.RO"], "comment": null, "summary": "Unrestricted multi-agent racing presents a significant research challenge,\nrequiring decision-making at the limits of a robot's operational capabilities.\nWhile previous approaches have either ignored spatiotemporal information in the\ndecision-making process or been restricted to single-opponent scenarios, this\nwork enables arbitrary multi-opponent head-to-head racing while considering the\nopponents' future intent. The proposed method employs a KF-based multi-opponent\ntracker to effectively perform opponent ReID by associating them across\nobservations. Simultaneously, spatial and velocity GPR is performed on all\nobserved opponent trajectories, providing predictive information to compute the\novertaking maneuvers. This approach has been experimentally validated on a\nphysical 1:10 scale autonomous racing car, achieving an overtaking success rate\nof up to 91.65% and demonstrating an average 10.13%-point improvement in safety\nat the same speed as the previous SotA. These results highlight its potential\nfor high-performance autonomous racing.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u81ea\u4e3b\u8d5b\u8f66\u4e2d\u7684\u8f68\u8ff9\u9884\u6d4b\u548c\u884c\u4e3a\u51b3\u7b56\uff0c\u7279\u522b\u662f\u8d85\u8f66\u573a\u666f\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u6d89\u53ca\u5230\u4e86\u5bf9\u624b\u8f68\u8ff9\u7684\u9884\u6d4b\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u9886\u57df\u76f8\u5173\u3002\u5173\u952e\u8bcd\u4e2d\u5305\u542b\u201c\u8f68\u8ff9\u9884\u6d4b\u201d\u7684\u76f8\u5173\u6982\u5ff5\uff0c\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["trajectory prediction", "opponent trajectory", "predictive information", "KF-based multi-opponent tracker"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16336", "pdf": "https://arxiv.org/pdf/2506.16336", "abs": "https://arxiv.org/abs/2506.16336", "authors": ["Yiou Huang"], "title": "Goal-conditioned Hierarchical Reinforcement Learning for Sample-efficient and Safe Autonomous Driving at Intersections", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Reinforcement learning (RL) exhibits remarkable potential in addressing\nautonomous driving tasks. However, it is difficult to train a sample-efficient\nand safe policy in complex scenarios. In this article, we propose a novel\nhierarchical reinforcement learning (HRL) framework with a goal-conditioned\ncollision prediction (GCCP) module. In the hierarchical structure, the GCCP\nmodule predicts collision risks according to different potential subgoals of\nthe ego vehicle. A high-level decision-maker choose the best safe subgoal. A\nlow-level motion-planner interacts with the environment according to the\nsubgoal. Compared to traditional RL methods, our algorithm is more\nsample-efficient, since its hierarchical structure allows reusing the policies\nof subgoals across similar tasks for various navigation scenarios. In\nadditional, the GCCP module's ability to predict both the ego vehicle's and\nsurrounding vehicles' future actions according to different subgoals, ensures\nthe safety of the ego vehicle throughout the decision-making process.\nExperimental results demonstrate that the proposed method converges to an\noptimal policy faster and achieves higher safety than traditional RL methods.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u6d89\u53ca\u81ea\u4e3b\u9a7e\u9a76\u4e2d\u7684\u8f68\u8ff9\u9884\u6d4b\uff0c\u7279\u522b\u662f\u901a\u8fc7goal-conditioned collision prediction\u6a21\u5757\u9884\u6d4b\u8f66\u8f86\u672a\u6765\u8f68\u8ff9\uff0c\u5e76\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u51b3\u7b56\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5176\u76ee\u6807\u662f\u9884\u6d4b\u672a\u6765\u8f68\u8ff9\u5e76\u505a\u51fa\u51b3\u7b56\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u76f8\u5173\u3002", "keywords": ["trajectory prediction", "autonomous driving", "collision prediction", "reinforcement learning", "motion planning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16386", "pdf": "https://arxiv.org/pdf/2506.16386", "abs": "https://arxiv.org/abs/2506.16386", "authors": ["Leesai Park", "Keunwoo Jang", "Sanghyun Kim"], "title": "CSC-MPPI: A Novel Constrained MPPI Framework with DBSCAN for Reliable Obstacle Avoidance", "categories": ["cs.RO"], "comment": null, "summary": "This paper proposes Constrained Sampling Cluster Model Predictive Path\nIntegral (CSC-MPPI), a novel constrained formulation of MPPI designed to\nenhance trajectory optimization while enforcing strict constraints on system\nstates and control inputs. Traditional MPPI, which relies on a probabilistic\nsampling process, often struggles with constraint satisfaction and generates\nsuboptimal trajectories due to the weighted averaging of sampled trajectories.\nTo address these limitations, the proposed framework integrates a primal-dual\ngradient-based approach and Density-Based Spatial Clustering of Applications\nwith Noise (DBSCAN) to steer sampled input trajectories into feasible regions\nwhile mitigating risks associated with weighted averaging. First, to ensure\nthat sampled trajectories remain within the feasible region, the primal-dual\ngradient method is applied to iteratively shift sampled inputs while enforcing\nstate and control constraints. Then, DBSCAN groups the sampled trajectories,\nenabling the selection of representative control inputs within each cluster.\nFinally, among the representative control inputs, the one with the lowest cost\nis chosen as the optimal action. As a result, CSC-MPPI guarantees constraint\nsatisfaction, improves trajectory selection, and enhances robustness in complex\nenvironments. Simulation and real-world experiments demonstrate that CSC-MPPI\noutperforms traditional MPPI in obstacle avoidance, achieving improved\nreliability and efficiency. The experimental videos are available at\nhttps://cscmppi.github.io", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on trajectory optimization and obstacle avoidance using a constrained MPPI framework. While it does not directly involve large language models, it falls under the broader category of trajectory prediction and path planning for mobile objects. The use of MPPI and DBSCAN for trajectory optimization indicates relevance to trajectory prediction.", "keywords": ["trajectory optimization", "obstacle avoidance", "MPPI", "path planning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16493", "pdf": "https://arxiv.org/pdf/2506.16493", "abs": "https://arxiv.org/abs/2506.16493", "authors": ["Mehreen Naeem", "Andrew Melnik", "Michael Beetz"], "title": "Grounding Language Models with Semantic Digital Twins for Robotic Planning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We introduce a novel framework that integrates Semantic Digital Twins (SDTs)\nwith Large Language Models (LLMs) to enable adaptive and goal-driven robotic\ntask execution in dynamic environments. The system decomposes natural language\ninstructions into structured action triplets, which are grounded in contextual\nenvironmental data provided by the SDT. This semantic grounding allows the\nrobot to interpret object affordances and interaction rules, enabling action\nplanning and real-time adaptability. In case of execution failures, the LLM\nutilizes error feedback and SDT insights to generate recovery strategies and\niteratively revise the action plan. We evaluate our approach using tasks from\nthe ALFRED benchmark, demonstrating robust performance across various household\nscenarios. The proposed framework effectively combines high-level reasoning\nwith semantic environment understanding, achieving reliable task completion in\nthe face of uncertainty and failure.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on using LLMs and Semantic Digital Twins for robotic planning. While it doesn't directly address trajectory prediction, the robotic planning aspect can involve trajectory generation and adaptation. The use of LLMs is a strong indicator of relevance.", "keywords": ["Large Language Models", "LLMs", "robotic planning", "action planning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2506.16209", "pdf": "https://arxiv.org/pdf/2506.16209", "abs": "https://arxiv.org/abs/2506.16209", "authors": ["Annajoyce Mariani", "Kira Maag", "Hanno Gottschalk"], "title": "VideoGAN-based Trajectory Proposal for Automated Vehicles", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Being able to generate realistic trajectory options is at the core of\nincreasing the degree of automation of road vehicles. While model-driven,\nrule-based, and classical learning-based methods are widely used to tackle\nthese tasks at present, they can struggle to effectively capture the complex,\nmultimodal distributions of future trajectories. In this paper we investigate\nwhether a generative adversarial network (GAN) trained on videos of bird's-eye\nview (BEV) traffic scenarios can generate statistically accurate trajectories\nthat correctly capture spatial relationships between the agents. To this end,\nwe propose a pipeline that uses low-resolution BEV occupancy grid videos as\ntraining data for a video generative model. From the generated videos of\ntraffic scenarios we extract abstract trajectory data using single-frame object\ndetection and frame-to-frame object matching. We particularly choose a GAN\narchitecture for the fast training and inference times with respect to\ndiffusion models. We obtain our best results within 100 GPU hours of training,\nwith inference times under 20\\,ms. We demonstrate the physical realism of the\nproposed trajectories in terms of distribution alignment of spatial and dynamic\nparameters with respect to the ground truth videos from the Waymo Open Motion\nDataset.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on trajectory prediction for automated vehicles using a GAN, which is a generative model. While it doesn't directly involve large language models, it falls under the broader umbrella of trajectory prediction and uses a generative model, showing some relevance.", "keywords": ["trajectory prediction", "automated vehicles", "GAN", "generative adversarial network", "motion prediction"]}, "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u4ece\u9e1f\u77b0\u56fe\u4ea4\u901a\u573a\u666f\u89c6\u9891\u4e2d\u751f\u6210\u903c\u771f\u8f68\u8ff9\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6a21\u578b\u3001\u89c4\u5219\u548c\u7ecf\u5178\u5b66\u4e60\u7684\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5730\u6355\u6349\u672a\u6765\u8f68\u8ff9\u7684\u590d\u6742\u3001\u591a\u6a21\u6001\u5206\u5e03\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u6c34\u7ebf\uff0c\u4f7f\u7528\u4f4e\u5206\u8fa8\u7387\u9e1f\u77b0\u56fe\u5360\u7528\u7f51\u683c\u89c6\u9891\u4f5c\u4e3a\u89c6\u9891\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u4ece\u751f\u6210\u7684\u4ea4\u901a\u573a\u666f\u89c6\u9891\u4e2d\u4f7f\u7528\u5355\u5e27\u5bf9\u8c61\u68c0\u6d4b\u548c\u5e27\u5230\u5e27\u5bf9\u8c61\u5339\u914d\u63d0\u53d6\u62bd\u8c61\u8f68\u8ff9\u6570\u636e\u3002", "result": "\u8be5\u8bba\u6587\u5728100 GPU\u5c0f\u65f6\u5185\u83b7\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\uff0c\u63a8\u7406\u65f6\u95f4\u4f4e\u4e8e20\u6beb\u79d2\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u8f68\u8ff9\u5728\u7a7a\u95f4\u548c\u52a8\u6001\u53c2\u6570\u7684\u5206\u5e03\u4e0a\u4e0eWaymo Open Motion\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u89c6\u9891\u5bf9\u9f50\u3002", "conclusion": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u4f7f\u7528\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u4ece\u9e1f\u77b0\u56fe\u4ea4\u901a\u573a\u666f\u89c6\u9891\u4e2d\u751f\u6210\u7684\u8f68\u8ff9\u5728\u7a7a\u95f4\u548c\u52a8\u6001\u53c2\u6570\u7684\u5206\u5e03\u4e0a\u4e0eWaymo Open Motion\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u89c6\u9891\u5bf9\u9f50\uff0c\u5177\u6709\u7269\u7406\u771f\u5b9e\u6027\u3002", "summary_zh": "\u80fd\u591f\u751f\u6210\u903c\u771f\u7684\u8f68\u8ff9\u9009\u9879\u662f\u63d0\u9ad8\u9053\u8def\u8f66\u8f86\u81ea\u52a8\u5316\u7a0b\u5ea6\u7684\u6838\u5fc3\u3002\u867d\u7136\u76ee\u524d\u57fa\u4e8e\u6a21\u578b\u3001\u57fa\u4e8e\u89c4\u5219\u548c\u57fa\u4e8e\u7ecf\u5178\u5b66\u4e60\u7684\u65b9\u6cd5\u88ab\u5e7f\u6cdb\u7528\u4e8e\u89e3\u51b3\u8fd9\u4e9b\u4efb\u52a1\uff0c\u4f46\u5b83\u4eec\u53ef\u80fd\u96be\u4ee5\u6709\u6548\u5730\u6355\u6349\u672a\u6765\u8f68\u8ff9\u7684\u590d\u6742\u3001\u591a\u6a21\u6001\u5206\u5e03\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u5728\u9e1f\u77b0\u56fe\uff08BEV\uff09\u4ea4\u901a\u573a\u666f\u89c6\u9891\u4e0a\u8bad\u7ec3\u7684\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u662f\u5426\u53ef\u4ee5\u751f\u6210\u7edf\u8ba1\u4e0a\u51c6\u786e\u7684\u8f68\u8ff9\uff0c\u4ece\u800c\u6b63\u786e\u6355\u83b7\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u7a7a\u95f4\u5173\u7cfb\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u6c34\u7ebf\uff0c\u8be5\u6d41\u6c34\u7ebf\u4f7f\u7528\u4f4e\u5206\u8fa8\u7387BEV\u5360\u7528\u7f51\u683c\u89c6\u9891\u4f5c\u4e3a\u89c6\u9891\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\u3002\u4ece\u751f\u6210\u7684\u4ea4\u901a\u573a\u666f\u89c6\u9891\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u5355\u5e27\u5bf9\u8c61\u68c0\u6d4b\u548c\u5e27\u5230\u5e27\u5bf9\u8c61\u5339\u914d\u63d0\u53d6\u62bd\u8c61\u8f68\u8ff9\u6570\u636e\u3002\u6211\u4eec\u7279\u522b\u9009\u62e9\u4e86\u4e00\u79cdGAN\u67b6\u6784\uff0c\u4ee5\u4fbf\u76f8\u5bf9\u4e8e\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u5feb\u901f\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u3002\u6211\u4eec\u5728100\u4e2aGPU\u5c0f\u65f6\u7684\u8bad\u7ec3\u65f6\u95f4\u5185\u83b7\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\uff0c\u63a8\u7406\u65f6\u95f4\u4f4e\u4e8e20\u6beb\u79d2\u3002\u6211\u4eec\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u8f68\u8ff9\u5728\u7a7a\u95f4\u548c\u52a8\u6001\u53c2\u6570\u7684\u5206\u5e03\u4e0a\u4e0eWaymo Open Motion\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u89c6\u9891\u5bf9\u9f50\uff0c\u5177\u6709\u7269\u7406\u771f\u5b9e\u6027\u3002"}}
{"id": "2506.16546", "pdf": "https://arxiv.org/pdf/2506.16546", "abs": "https://arxiv.org/abs/2506.16546", "authors": ["Liyang Yu", "Tianyi Wang", "Junfeng Jiao", "Fengwu Shan", "Hongqing Chu", "Bingzhao Gao"], "title": "BIDA: A Bi-level Interaction Decision-making Algorithm for Autonomous Vehicles in Dynamic Traffic Scenarios", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures, 4 tables, accepted for IEEE Intelligent Vehicles\n  (IV) Symposium 2025", "summary": "In complex real-world traffic environments, autonomous vehicles (AVs) need to\ninteract with other traffic participants while making real-time and\nsafety-critical decisions accordingly. The unpredictability of human behaviors\nposes significant challenges, particularly in dynamic scenarios, such as\nmulti-lane highways and unsignalized T-intersections. To address this gap, we\ndesign a bi-level interaction decision-making algorithm (BIDA) that integrates\ninteractive Monte Carlo tree search (MCTS) with deep reinforcement learning\n(DRL), aiming to enhance interaction rationality, efficiency and safety of AVs\nin dynamic key traffic scenarios. Specifically, we adopt three types of DRL\nalgorithms to construct a reliable value network and policy network, which\nguide the online deduction process of interactive MCTS by assisting in value\nupdate and node selection. Then, a dynamic trajectory planner and a trajectory\ntracking controller are designed and implemented in CARLA to ensure smooth\nexecution of planned maneuvers. Experimental evaluations demonstrate that our\nBIDA not only enhances interactive deduction and reduces computational costs,\nbut also outperforms other latest benchmarks, which exhibits superior safety,\nefficiency and interaction rationality under varying traffic conditions.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u51b3\u7b56\u7b97\u6cd5\uff0c\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\u548c\u5f3a\u5316\u5b66\u4e60\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5b83\u89e3\u51b3\u4e86\u52a8\u6001\u4ea4\u901a\u573a\u666f\u4e2d\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u7684\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u9886\u57df\u5bc6\u5207\u76f8\u5173\u3002\u76f8\u5173\u6027\u8f83\u9ad8\uff0c\u4f46\u672a\u76f4\u63a5\u6d89\u53ca\u5927\u6a21\u578b\u3002", "keywords": ["trajectory prediction", "autonomous vehicles", "decision-making", "reinforcement learning", "Monte Carlo tree search"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
