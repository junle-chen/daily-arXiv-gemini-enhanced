{"id": "2510.10454", "pdf": "https://arxiv.org/pdf/2510.10454", "abs": "https://arxiv.org/abs/2510.10454", "authors": ["Sihang Zeng", "Yujuan Fu", "Sitong Zhou", "Zixuan Yu", "Lucas Jing Liu", "Jun Wen", "Matthew Thompson", "Ruth Etzioni", "Meliha Yetisgen"], "title": "Traj-CoA: Patient Trajectory Modeling via Chain-of-Agents for Lung Cancer Risk Prediction", "categories": ["cs.AI"], "comment": "Accepted by NeurIPS 2025 GenAI4Health Workshop", "summary": "Large language models (LLMs) offer a generalizable approach for modeling\npatient trajectories, but suffer from the long and noisy nature of electronic\nhealth records (EHR) data in temporal reasoning. To address these challenges,\nwe introduce Traj-CoA, a multi-agent system involving chain-of-agents for\npatient trajectory modeling. Traj-CoA employs a chain of worker agents to\nprocess EHR data in manageable chunks sequentially, distilling critical events\ninto a shared long-term memory module, EHRMem, to reduce noise and preserve a\ncomprehensive timeline. A final manager agent synthesizes the worker agents'\nsummary and the extracted timeline in EHRMem to make predictions. In a\nzero-shot one-year lung cancer risk prediction task based on five-year EHR\ndata, Traj-CoA outperforms baselines of four categories. Analysis reveals that\nTraj-CoA exhibits clinically aligned temporal reasoning, establishing it as a\npromisingly robust and generalizable approach for modeling complex patient\ntrajectories.", "relevance_analysis": {"relevance_score": 0.9, "explanation": "This paper is highly relevant as it combines trajectory modeling (patient trajectory) with large language models. The abstract explicitly mentions using LLMs for modeling patient trajectories and proposes a novel architecture (Traj-CoA) to address challenges related to EHR data. It also highlights the use of a multi-agent system, which is often associated with LLM applications.", "keywords": ["trajectory modeling", "large language models", "LLMs", "patient trajectory", "temporal reasoning", "multi-agent system"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10086", "pdf": "https://arxiv.org/pdf/2510.10086", "abs": "https://arxiv.org/abs/2510.10086", "authors": ["Feifei Liu", "Haozhe Wang", "Zejun Wei", "Qirong Lu", "Yiyang Wen", "Xiaoyu Tang", "Jingyan Jiang", "Zhijian He"], "title": "Beyond ADE and FDE: A Comprehensive Evaluation Framework for Safety-Critical Prediction in Multi-Agent Autonomous Driving Scenarios", "categories": ["cs.RO"], "comment": null, "summary": "Current evaluation methods for autonomous driving prediction models rely\nheavily on simplistic metrics such as Average Displacement Error (ADE) and\nFinal Displacement Error (FDE). While these metrics offer basic performance\nassessments, they fail to capture the nuanced behavior of prediction modules\nunder complex, interactive, and safety-critical driving scenarios. For\ninstance, existing benchmarks do not distinguish the influence of nearby versus\ndistant agents, nor systematically test model robustness across varying\nmulti-agent interactions. This paper addresses this critical gap by proposing a\nnovel testing framework that evaluates prediction performance under diverse\nscene structures, saying, map context, agent density and spatial distribution.\nThrough extensive empirical analysis, we quantify the differential impact of\nagent proximity on target trajectory prediction and identify scenario-specific\nfailure cases that are not exposed by traditional metrics. Our findings\nhighlight key vulnerabilities in current state-of-the-art prediction models and\ndemonstrate the importance of scenario-aware evaluation. The proposed framework\nlays the groundwork for rigorous, safety-driven prediction validation,\ncontributing significantly to the identification of failure-prone corner cases\nand the development of robust, certifiable prediction systems for autonomous\nvehicles.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper focuses on evaluating trajectory prediction models for autonomous driving. While it doesn't directly involve large language models, it's highly relevant to trajectory prediction. The emphasis on safety-critical scenarios and multi-agent interactions strengthens the connection to the trajectory prediction domain.", "keywords": ["trajectory prediction", "autonomous driving", "multi-agent", "prediction models", "evaluation framework"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10154", "pdf": "https://arxiv.org/pdf/2510.10154", "abs": "https://arxiv.org/abs/2510.10154", "authors": ["LinFeng Li", "Jian Zhao", "Yuan Xie", "Xin Tan", "Xuelong Li"], "title": "CompassNav: Steering From Path Imitation To Decision Understanding In Navigation", "categories": ["cs.RO"], "comment": null, "summary": "The dominant paradigm for training Large Vision-Language Models (LVLMs) in\nnavigation relies on imitating expert trajectories. This approach reduces the\ncomplex navigation task to a sequence-to-sequence replication of a single\ncorrect path, fundamentally limiting the agent's ability to explore and\ngeneralize. In this work, we argue for and introduce a new paradigm: a shift\nfrom Path Imitation to Decision Understanding. The goal of this paradigm is to\nbuild agents that do not just follow, but truly understand how to navigate. We\nmaterialize this through two core contributions: first, we introduce\nCompass-Data-22k, a novel 22k-trajectory dataset.Its Reinforcement Fine-Tuning\n(RFT) subset provides a panoramic view of the decision landscape by annotating\nall feasible actions with A* geodesic distances. Second, we design a novel\ngap-aware hybrid reward function that dynamically adapts its feedback to\ndecision certainty, shifting between decisive signals for optimal actions and\nnuanced scores to encourage exploration. Integrated into an SFT-then-RFT\nrecipe, our CompassNav agent is trained not to memorize static routes, but to\ndevelop an internal ``compass'' that constantly intuits the direction to the\ngoal by evaluating the relative quality of all possible moves. This approach\nenables our 7B agent to set a new state-of-the-art on Goal navigation\nbenchmarks, outperforming even larger proprietary models, and achieve robust\nreal-world goal navigation on a physical robot.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u5728\u5bfc\u822a\u4efb\u52a1\u4e2d\u4f7f\u7528\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b(LVLMs)\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u8303\u5f0f\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u662f\u5bfc\u822a\u4efb\u52a1\u672c\u8eab\u4e0e\u8def\u5f84\u89c4\u5212\u548c\u79fb\u52a8\u7269\u4f53\u7684\u8f68\u8ff9\u5bc6\u5207\u76f8\u5173\u3002\u6b64\u5916\uff0c\u8bba\u6587\u4e2d\u63d0\u5230\u4e86\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u4e5f\u4e0e\u5927\u6a21\u578b\u4e3b\u9898\u76f8\u5173\u3002\u7efc\u5408\u8003\u8651\uff0c\u8be5\u8bba\u6587\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["Large Vision-Language Models", "LVLMs", "navigation", "Reinforcement Fine-Tuning", "RFT", "path imitation", "decision understanding", "goal navigation"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.09981", "pdf": "https://arxiv.org/pdf/2510.09981", "abs": "https://arxiv.org/abs/2510.09981", "authors": ["Fan Zuo", "Donglin Zhou", "Jingqin Gao", "Kaan Ozbay"], "title": "Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Accurate, scalable traffic monitoring is critical for real-time and long-term\ntransportation management, particularly during disruptions such as natural\ndisasters, large construction projects, or major policy changes like New York\nCity's first-in-the-nation congestion pricing program. However, widespread\nsensor deployment remains limited due to high installation, maintenance, and\ndata management costs. While traffic cameras offer a cost-effective\nalternative, existing video analytics struggle with dynamic camera viewpoints\nand massive data volumes from large camera networks. This study presents an\nend-to-end AI-based framework leveraging existing traffic camera infrastructure\nfor high-resolution, longitudinal analysis at scale. A fine-tuned YOLOv11\nmodel, trained on localized urban scenes, extracts multimodal traffic density\nand classification metrics in real time. To address inconsistencies from\nnon-stationary pan-tilt-zoom cameras, we introduce a novel graph-based\nviewpoint normalization method. A domain-specific large language model was also\nintegrated to process massive data from a 24/7 video stream to generate\nfrequent, automated summaries of evolving traffic patterns, a task far\nexceeding manual capabilities. We validated the system using over 9 million\nimages from roughly 1,000 traffic cameras during the early rollout of NYC\ncongestion pricing in 2025. Results show a 9% decline in weekday passenger\nvehicle density within the Congestion Relief Zone, early truck volume\nreductions with signs of rebound, and consistent increases in pedestrian and\ncyclist activity at corridor and zonal scales. Experiments showed that\nexample-based prompts improved LLM's numerical accuracy and reduced\nhallucinations. These findings demonstrate the framework's potential as a\npractical, infrastructure-ready solution for large-scale, policy-relevant\ntraffic monitoring with minimal human intervention.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper focuses on traffic monitoring using AI and large language models. While it doesn't directly address trajectory prediction, the analysis of traffic patterns and vehicle movement implicitly involves understanding trajectories. The use of a domain-specific large language model is a significant aspect of the paper, increasing its relevance to the specified themes.", "keywords": ["Large Language Model", "traffic monitoring", "AI", "YOLOv11", "traffic patterns"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10603", "pdf": "https://arxiv.org/pdf/2510.10603", "abs": "https://arxiv.org/abs/2510.10603", "authors": ["WenTao Liu", "Siyu Song", "Hao Hao", "Aimin Zhou"], "title": "EA4LLM: A Gradient-Free Approach to Large Language Model Optimization via Evolutionary Algorithms", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, large language models (LLMs) have made remarkable progress,\nwith model optimization primarily relying on gradient-based optimizers such as\nAdam. However, these gradient-based methods impose stringent hardware\nrequirements, demanding high-concurrency, high-memory GPUs. Moreover, they\nrequire all neural network operations to be differentiable, thereby excluding\nmany promising non-differentiable architectures from practical use. To address\nthese limitations, we propose a method for optimizing LLMs using evolutionary\nalgorithms (EA4LLM) and, for the first time, successfully demonstrate its\ncapability to train a 1-billion-parameter LLM from the pre-trained stage. We\nconduct extensive experiments and provide key insights into how evolutionary\nalgorithms can effectively optimize neural networks. Our work challenges the\nprevailing assumption that gradient-based optimization is the only viable\napproach for training neural networks. It also holds significant potential to\nreduce the computational cost of training large language models, thereby\nenabling groups with limited computational resources to participate in deep\nlearning research.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\uff0c\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u5176\u7814\u7a76\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\u53ef\u80fd\u5bf9\u672a\u6765\u8f68\u8ff9\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u5927\u6a21\u578b\u5e94\u7528\u6709\u6f5c\u5728\u4ef7\u503c\u3002\u6458\u8981\u4e2d\u660e\u786e\u63d0\u5230\u4e86LLM\u7684\u4f18\u5316\u3002", "keywords": ["Large Language Models", "LLMs", "optimization", "evolutionary algorithms"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10731", "pdf": "https://arxiv.org/pdf/2510.10731", "abs": "https://arxiv.org/abs/2510.10731", "authors": ["Yongxi Cao", "Julian F. Schumann", "Jens Kober", "Joni Pajarinen", "Arkady Zgonnikov"], "title": "Controllable Generative Trajectory Prediction via Weak Preference Alignment", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Deep generative models such as conditional variational autoencoders (CVAEs)\nhave shown great promise for predicting trajectories of surrounding agents in\nautonomous vehicle planning. State-of-the-art models have achieved remarkable\naccuracy in such prediction tasks. Besides accuracy, diversity is also crucial\nfor safe planning because human behaviors are inherently uncertain and\nmultimodal. However, existing methods generally lack a scheme to generate\ncontrollably diverse trajectories, which is arguably more useful than randomly\ndiversified trajectories, to the end of safe planning. To address this, we\npropose PrefCVAE, an augmented CVAE framework that uses weakly labeled\npreference pairs to imbue latent variables with semantic attributes. Using\naverage velocity as an example attribute, we demonstrate that PrefCVAE enables\ncontrollable, semantically meaningful predictions without degrading baseline\naccuracy. Our results show the effectiveness of preference supervision as a\ncost-effective way to enhance sampling-based generative models.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u8f68\u8ff9\u9884\u6d4b\uff0c\u7279\u522b\u662f\u4f7f\u7528\u751f\u6210\u6a21\u578b\u8fdb\u884c\u53ef\u63a7\u7684\u8f68\u8ff9\u9884\u6d4b\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u4f7f\u7528\u4e86\u751f\u6210\u6a21\u578b\uff08CVAE\uff09\uff0c\u4e0e\u5927\u578b\u6a21\u578b\u7684\u751f\u6210\u6027\u8d28\u6709\u4e00\u5b9a\u5173\u8054\u3002\u56e0\u6b64\u76f8\u5173\u6027\u8f83\u9ad8\u3002", "keywords": ["trajectory prediction", "generative models", "CVAE", "autonomous vehicle planning", "controllable trajectory generation"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10865", "pdf": "https://arxiv.org/pdf/2510.10865", "abs": "https://arxiv.org/abs/2510.10865", "authors": ["Ahmed Alanazi", "Duy Ho", "Yugyung Lee"], "title": "GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments", "categories": ["cs.RO", "cs.AI", "I.2.9; I.2.8"], "comment": "17 pages, 5 figures, 8 tables", "summary": "Robots navigating dynamic, cluttered, and semantically complex environments\nmust integrate perception, symbolic reasoning, and spatial planning to\ngeneralize across diverse layouts and object categories. Existing methods often\nrely on static priors or limited memory, constraining adaptability under\npartial observability and semantic ambiguity. We present GRIP, Grid-based Relay\nwith Intermediate Planning, a unified, modular framework with three scalable\nvariants: GRIP-L (Lightweight), optimized for symbolic navigation via semantic\noccupancy grids; GRIP-F (Full), supporting multi-hop anchor chaining and\nLLM-based introspection; and GRIP-R (Real-World), enabling physical robot\ndeployment under perceptual uncertainty. GRIP integrates dynamic 2D grid\nconstruction, open-vocabulary object grounding, co-occurrence-aware symbolic\nplanning, and hybrid policy execution using behavioral cloning, D* search, and\ngrid-conditioned control. Empirical results on AI2-THOR and RoboTHOR benchmarks\nshow that GRIP achieves up to 9.6% higher success rates and over $2\\times$\nimprovement in path efficiency (SPL and SAE) on long-horizon tasks. Qualitative\nanalyses reveal interpretable symbolic plans in ambiguous scenes. Real-world\ndeployment on a Jetbot further validates GRIP's generalization under sensor\nnoise and environmental variation. These results position GRIP as a robust,\nscalable, and explainable framework bridging simulation and real-world\nnavigation.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper presents GRIP, a framework for robot navigation in dynamic environments. While the core focus is on robot planning and navigation, it incorporates LLM-based introspection (GRIP-F variant) and deals with planning in dynamic environments which relates to trajectory prediction. The integration of LLMs and planning in dynamic environments makes it relevant to both trajectory prediction and large language models.", "keywords": ["dynamic environments", "planning", "LLM", "navigation", "robot"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.09782", "pdf": "https://arxiv.org/pdf/2510.09782", "abs": "https://arxiv.org/abs/2510.09782", "authors": ["Yufa Zhou", "Yixiao Wang", "Xunjian Yin", "Shuyan Zhou", "Anru R. Zhang"], "title": "The Geometry of Reasoning: Flowing Logics in Representation Space", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "comment": "Code: https://github.com/MasterZhou1/Reasoning-Flow", "summary": "We study how large language models (LLMs) ``think'' through their\nrepresentation space. We propose a novel geometric framework that models an\nLLM's reasoning as flows -- embedding trajectories evolving where logic goes.\nWe disentangle logical structure from semantics by employing the same natural\ndeduction propositions with varied semantic carriers, allowing us to test\nwhether LLMs internalize logic beyond surface form. This perspective connects\nreasoning with geometric quantities such as position, velocity, and curvature,\nenabling formal analysis in representation and concept spaces. Our theory\nestablishes: (1) LLM reasoning corresponds to smooth flows in representation\nspace, and (2) logical statements act as local controllers of these flows'\nvelocities. Using learned representation proxies, we design controlled\nexperiments to visualize and quantify reasoning flows, providing empirical\nvalidation of our theoretical framework. Our work serves as both a conceptual\nfoundation and practical tools for studying reasoning phenomenon, offering a\nnew lens for interpretability and formal analysis of LLMs' behavior.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on the reasoning process of Large Language Models (LLMs) and models this reasoning as 'flows' in the representation space. While it doesn't directly address trajectory prediction, the concept of 'flows' and 'trajectories' in the embedding space shares conceptual similarities with trajectory prediction. The paper explicitly mentions LLMs, increasing its relevance.", "keywords": ["Large Language Models", "LLMs", "representation space", "flows", "reasoning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.09963", "pdf": "https://arxiv.org/pdf/2510.09963", "abs": "https://arxiv.org/abs/2510.09963", "authors": ["Chaoran Wang", "Jingyuan Sun", "Yanhui Zhang", "Mingyu Zhang", "Changju Wu"], "title": "LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots", "categories": ["cs.RO"], "comment": "It contains 8 pages, 7 figures and 4 tables. This paper is submitted\n  to ICRA 2026", "summary": "We introduce a novel framework for automatic behavior tree (BT) construction\nin heterogeneous multi-robot systems, designed to address the challenges of\nadaptability and robustness in dynamic environments. Traditional robots are\nlimited by fixed functional attributes and cannot efficiently reconfigure their\nstrategies in response to task failures or environmental changes. To overcome\nthis limitation, we leverage large language models (LLMs) to generate and\nextend BTs dynamically, combining the reasoning and generalization power of\nLLMs with the modularity and recovery capability of BTs. The proposed framework\nconsists of four interconnected modules task initialization, task assignment,\nBT update, and failure node detection which operate in a closed loop. Robots\ntick their BTs during execution, and upon encountering a failure node, they can\neither extend the tree locally or invoke a centralized virtual coordinator\n(Alex) to reassign subtasks and synchronize BTs across peers. This design\nenables long-term cooperative execution in heterogeneous teams. We validate the\nframework on 60 tasks across three simulated scenarios and in a real-world cafe\nenvironment with a robotic arm and a wheeled-legged robot. Results show that\nour method consistently outperforms baseline approaches in task success rate,\nrobustness, and scalability, demonstrating its effectiveness for multi-robot\ncollaboration in complex scenarios.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u52a8\u6001\u6784\u5efa\u884c\u4e3a\u6811\uff08BT\uff09\uff0c\u7528\u4e8e\u5f02\u6784\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u534f\u8c03\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46BT\u7684\u6784\u5efa\u548c\u4f18\u5316\u4e0e\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u548c\u884c\u4e3a\u51b3\u7b56\u5bc6\u5207\u76f8\u5173\uff0c\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002\u8bba\u6587\u660e\u786e\u4f7f\u7528\u4e86LLM\uff0c\u6240\u4ee5\u4e0e\u5927\u6a21\u578b\u76f8\u5173\u3002", "keywords": ["Large Language Models", "LLMs", "behavior tree", "multi-robot systems", "dynamic environments", "task assignment"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.09667", "pdf": "https://arxiv.org/pdf/2510.09667", "abs": "https://arxiv.org/abs/2510.09667", "authors": ["Huaihai Lyu", "Chaofan Chen", "Senwei Xie", "Pengwei Wang", "Xiansheng Chen", "Shanghang Zhang", "Changsheng Xu"], "title": "OmniSAT: Compact Action Token, Faster Auto Regression", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Existing Vision-Language-Action (VLA) models can be broadly categorized into\ndiffusion-based and auto-regressive (AR) approaches: diffusion models capture\ncontinuous action distributions but rely on computationally heavy iterative\ndenoising. In contrast, AR models enable efficient optimization and flexible\nsequence construction, making them better suited for large-scale pretraining.\nTo further improve AR efficiency, particularly when action chunks induce\nextended and high-dimensional sequences, prior work applies entropy-guided and\ntoken-frequency techniques to shorten the sequence length. However, such\ncompression struggled with \\textit{poor reconstruction or inefficient\ncompression}. Motivated by this, we introduce an Omni Swift Action Tokenizer,\nwhich learns a compact, transferable action representation. Specifically, we\nfirst normalize value ranges and temporal horizons to obtain a consistent\nrepresentation with B-Spline encoding. Then, we apply multi-stage residual\nquantization to the position, rotation, and gripper subspaces, producing\ncompressed discrete tokens with coarse-to-fine granularity for each part. After\npre-training on the large-scale dataset Droid, the resulting discrete\ntokenization shortens the training sequence by 6.8$\\times$, and lowers the\ntarget entropy. To further explore the potential of OmniSAT, we develop a\ncross-embodiment learning strategy that builds on the unified action-pattern\nspace and jointly leverages robot and human demonstrations. It enables scalable\nauxiliary supervision from heterogeneous egocentric videos. Across diverse\nreal-robot and simulation experiments, OmniSAT encompasses higher compression\nwhile preserving reconstruction quality, enabling faster AR training\nconvergence and model performance.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on improving the efficiency of auto-regressive models for Vision-Language-Action (VLA) tasks, particularly in robotics. While it doesn't explicitly mention trajectory prediction, the action sequences being modeled could involve predicting future states or movements. The use of auto-regressive models and large-scale pretraining aligns with the large language model theme, albeit in a robotics context. The connection to trajectory prediction is indirect, depending on the specific actions being modeled. The keyword 'action' is relevant, and the description involves sequence modeling which could be applied to trajectory prediction.", "keywords": ["auto-regressive models", "large-scale pretraining", "action", "sequence construction", "VLA models"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10046", "pdf": "https://arxiv.org/pdf/2510.10046", "abs": "https://arxiv.org/abs/2510.10046", "authors": ["Mingke Lu", "Shuaikang Wang", "Meng Guo"], "title": "LOMORO: Long-term Monitoring of Dynamic Targets with Minimum Robotic Fleet under Resource Constraints", "categories": ["cs.RO"], "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2025)", "summary": "Long-term monitoring of numerous dynamic targets can be tedious for a human\noperator and infeasible for a single robot, e.g., to monitor wild flocks,\ndetect intruders, search and rescue. Fleets of autonomous robots can be\neffective by acting collaboratively and concurrently. However, the online\ncoordination is challenging due to the unknown behaviors of the targets and the\nlimited perception of each robot. Existing work often deploys all robots\navailable without minimizing the fleet size, or neglects the constraints on\ntheir resources such as battery and memory. This work proposes an online\ncoordination scheme called LOMORO for collaborative target monitoring, path\nrouting and resource charging. It includes three core components: (I) the\nmodeling of multi-robot task assignment problem under the constraints on\nresources and monitoring intervals; (II) the resource-aware task coordination\nalgorithm iterates between the high-level assignment of dynamic targets and the\nlow-level multi-objective routing via the Martin's algorithm; (III) the online\nadaptation algorithm in case of unpredictable target behaviors and robot\nfailures. It ensures the explicitly upper-bounded monitoring intervals for all\ntargets and the lower-bounded resource levels for all robots, while minimizing\nthe average number of active robots. The proposed methods are validated\nextensively via large-scale simulations against several baselines, under\ndifferent road networks, robot velocities, charging rates and monitoring\nintervals.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u4f7f\u7528\u673a\u5668\u4eba\u8230\u961f\u8fdb\u884c\u52a8\u6001\u76ee\u6807\u7684\u957f\u671f\u76d1\u63a7\uff0c\u6d89\u53ca\u5230\u8def\u5f84\u89c4\u5212\u548c\u4efb\u52a1\u5206\u914d\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\uff0c\u4f46\u662f\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u3002\u8bba\u6587\u4e2d\u63d0\u53ca\u4e86\u52a8\u6001\u76ee\u6807\u7684\u672a\u77e5\u884c\u4e3a\uff0c\u53ef\u80fd\u9700\u8981\u9884\u6d4b\uff0c\u4f46\u91cd\u70b9\u5728\u4e8e\u673a\u5668\u4eba\u534f\u540c\u548c\u8d44\u6e90\u7ea6\u675f\u3002", "keywords": ["path routing", "dynamic targets", "multi-robot task assignment", "monitoring"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10125", "pdf": "https://arxiv.org/pdf/2510.10125", "abs": "https://arxiv.org/abs/2510.10125", "authors": ["Yanjiang Guo", "Lucy Xiaoyang Shi", "Jianyu Chen", "Chelsea Finn"], "title": "Ctrl-World: A Controllable Generative World Model for Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "17 pages", "summary": "Generalist robot policies can now perform a wide range of manipulation\nskills, but evaluating and improving their ability with unfamiliar objects and\ninstructions remains a significant challenge. Rigorous evaluation requires a\nlarge number of real-world rollouts, while systematic improvement demands\nadditional corrective data with expert labels. Both of these processes are\nslow, costly, and difficult to scale. World models offer a promising, scalable\nalternative by enabling policies to rollout within imagination space. However,\na key challenge is building a controllable world model that can handle\nmulti-step interactions with generalist robot policies. This requires a world\nmodel compatible with modern generalist policies by supporting multi-view\nprediction, fine-grained action control, and consistent long-horizon\ninteractions, which is not achieved by previous works. In this paper, we make a\nstep forward by introducing a controllable multi-view world model that can be\nused to evaluate and improve the instruction-following ability of generalist\nrobot policies. Our model maintains long-horizon consistency with a\npose-conditioned memory retrieval mechanism and achieves precise action control\nthrough frame-level action conditioning. Trained on the DROID dataset (95k\ntrajectories, 564 scenes), our model generates spatially and temporally\nconsistent trajectories under novel scenarios and new camera placements for\nover 20 seconds. We show that our method can accurately rank policy performance\nwithout real-world robot rollouts. Moreover, by synthesizing successful\ntrajectories in imagination and using them for supervised fine-tuning, our\napproach can improve policy success by 44.7\\%.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper describes a controllable generative world model for robot manipulation. While it does not explicitly use or mention Large Language Models (LLMs), it does involve trajectory prediction and generation within a simulated environment. The mention of 'trajectories' and 'long-horizon consistency' points to a connection with trajectory prediction. The 'world model' concept is related to models that predict future states, which can be seen as a form of trajectory prediction. However, the absence of LLMs lowers the overall relevance score.", "keywords": ["trajectory prediction", "world model", "robot manipulation", "long-horizon consistency", "trajectories"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10047", "pdf": "https://arxiv.org/pdf/2510.10047", "abs": "https://arxiv.org/abs/2510.10047", "authors": ["Ruohao Li", "Hongjun Liu", "Leyi Zhao", "Zisu Li", "Jiawei Li", "Jiajun Jiang", "Linning Xu", "Chen Zhao", "Mingming Fan", "Chen Liang"], "title": "SwarmSys: Decentralized Swarm-Inspired Agents for Scalable and Adaptive Reasoning", "categories": ["cs.AI"], "comment": "14 pages, 7 figures", "summary": "Large language model (LLM) agents have shown remarkable reasoning abilities.\nHowever, existing multi-agent frameworks often rely on fixed roles or\ncentralized control, limiting scalability and adaptability in long-horizon\nreasoning. We introduce SwarmSys, a closed-loop framework for distributed\nmulti-agent reasoning inspired by swarm intelligence. Coordination in SwarmSys\nemerges through iterative interactions among three specialized roles,\nExplorers, Workers, and Validators, that continuously cycle through\nexploration, exploitation, and validation. To enable scalable and adaptive\ncollaboration, we integrate adaptive agent and event profiles, embedding-based\nprobabilistic matching, and a pheromone-inspired reinforcement mechanism,\nsupporting dynamic task allocation and self-organizing convergence without\nglobal supervision. Across symbolic reasoning, research synthesis, and\nscientific programming tasks, SwarmSys consistently outperforms baselines,\nimproving both accuracy and reasoning stability. These findings highlight\nswarm-inspired coordination as a promising paradigm for scalable, robust, and\nadaptive multi-agent reasoning, suggesting that coordination scaling may rival\nmodel scaling in advancing LLM intelligence.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on multi-agent reasoning using large language models, drawing inspiration from swarm intelligence. While it doesn't directly address trajectory prediction, the concepts of decentralized agents, adaptive reasoning, and coordination could potentially be applied to trajectory prediction scenarios involving multiple interacting agents (e.g., autonomous vehicles or pedestrian crowds). The core focus is on LLMs and multi-agent systems, making it moderately relevant.", "keywords": ["Large language model (LLM)", "multi-agent reasoning", "swarm intelligence", "agents", "reasoning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10217", "pdf": "https://arxiv.org/pdf/2510.10217", "abs": "https://arxiv.org/abs/2510.10217", "authors": ["Hyogo Hiruma", "Hiroshi Ito", "Tetsuya Ogata"], "title": "UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 6 figures", "summary": "Training robots to operate effectively in environments with uncertain states,\nsuch as ambiguous object properties or unpredictable interactions, remains a\nlongstanding challenge in robotics. Imitation learning methods typically rely\non successful examples and often neglect failure scenarios where uncertainty is\nmost pronounced. To address this limitation, we propose the Uncertainty-driven\nForesight Recurrent Neural Network (UF-RNN), a model that combines standard\ntime-series prediction with an active \"Foresight\" module. This module performs\ninternal simulations of multiple future trajectories and refines the hidden\nstate to minimize predicted variance, enabling the model to selectively explore\nactions under high uncertainty. We evaluate UF-RNN on a door-opening task in\nboth simulation and a real-robot setting, demonstrating that, despite the\nabsence of explicit failure demonstrations, the model exhibits robust\nadaptation by leveraging self-induced chaotic dynamics in its latent space.\nWhen guided by the Foresight module, these chaotic properties stimulate\nexploratory behaviors precisely when the environment is ambiguous, yielding\nimproved success rates compared to conventional stochastic RNN baselines. These\nfindings suggest that integrating uncertainty-driven foresight into imitation\nlearning pipelines can significantly enhance a robot's ability to handle\nunpredictable real-world conditions.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on motion generation and prediction for robots in uncertain environments. It uses a recurrent neural network (RNN) to predict future trajectories and adapt to uncertainty. While it doesn't directly involve large language models, it does deal with trajectory prediction and motion planning, making it somewhat relevant.", "keywords": ["trajectory prediction", "motion generation", "RNN", "uncertainty", "robotics", "time-series prediction"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10379", "pdf": "https://arxiv.org/pdf/2510.10379", "abs": "https://arxiv.org/abs/2510.10379", "authors": ["Rohan Gupta", "Trevor Asbery", "Zain Merchant", "Abrar Anwar", "Jesse Thomason"], "title": "RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": null, "summary": "Coordinating heterogeneous robot fleets to achieve multiple goals is\nchallenging in multi-robot systems. We introduce an open-source and extensible\nframework for centralized multi-robot task planning and scheduling that\nleverages LLMs to enable fleets of heterogeneous robots to accomplish multiple\ntasks. RobotFleet provides abstractions for planning, scheduling, and execution\nacross robots deployed as containerized services to simplify fleet scaling and\nmanagement. The framework maintains a shared declarative world state and\ntwo-way communication for task execution and replanning. By modularizing each\nlayer of the autonomy stack and using LLMs for open-world reasoning, RobotFleet\nlowers the barrier to building scalable multi-robot systems. The code can be\nfound here: https://github.com/therohangupta/robot-fleet.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on multi-robot task planning using LLMs. While it doesn't directly address trajectory prediction, the task planning aspect often involves predicting future states and trajectories implicitly. The use of LLMs is a strong indicator of relevance.", "keywords": ["Large Language Models", "LLMs", "multi-robot task planning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10421", "pdf": "https://arxiv.org/pdf/2510.10421", "abs": "https://arxiv.org/abs/2510.10421", "authors": ["Junbin Yuan", "Brady Moon", "Muqing Cao", "Sebastian Scherer"], "title": "Hierarchical Planning for Long-Horizon Multi-Target Tracking Under Target Motion Uncertainty", "categories": ["cs.RO"], "comment": "8 pages, 7 figures. Accepted to IEEE Robotics and Automation Letters\n  (RAL), 2025", "summary": "Achieving persistent tracking of multiple dynamic targets over a large\nspatial area poses significant challenges for a single-robot system with\nconstrained sensing capabilities. As the robot moves to track different\ntargets, the ones outside the field of view accumulate uncertainty, making them\nprogressively harder to track. An effective path planning algorithm must manage\nuncertainty over a long horizon and account for the risk of permanently losing\ntrack of targets that remain unseen for too long. However, most existing\napproaches rely on short planning horizons and assume small, bounded\nenvironments, resulting in poor tracking performance and target loss in\nlarge-scale scenarios. In this paper, we present a hierarchical planner for\ntracking multiple moving targets with an aerial vehicle. To address the\nchallenge of tracking non-static targets, our method incorporates motion models\nand uncertainty propagation during path execution, allowing for more informed\ndecision-making. We decompose the multi-target tracking task into sub-tasks of\nsingle target search and detection, and our proposed pipeline consists a novel\nlow-level coverage planner that enables searching for a target in an evolving\nbelief area, and an estimation method to assess the likelihood of success for\neach sub-task, making it possible to convert the active target tracking task to\na Markov decision process (MDP) that we solve with a tree-based algorithm to\ndetermine the sequence of sub-tasks. We validate our approach in simulation,\ndemonstrating its effectiveness compared to existing planners for active target\ntracking tasks, and our proposed planner outperforms existing approaches,\nachieving a reduction of 11-70% in final uncertainty across different\nenvironments.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u591a\u76ee\u6807\u8ddf\u8e2a\u548c\u8def\u5f84\u89c4\u5212\uff0c\u6d89\u53ca\u76ee\u6807\u8fd0\u52a8\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u5bc6\u5207\u76f8\u5173\u3002\u4f46\u8bba\u6587\u4e2d\u6ca1\u6709\u63d0\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u56e0\u6b64\u76f8\u5173\u6027\u5f97\u5206\u4e2d\u7b49\u3002", "keywords": ["target tracking", "motion models", "uncertainty propagation", "path planning", "Markov decision process", "trajectory prediction"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10494", "pdf": "https://arxiv.org/pdf/2510.10494", "abs": "https://arxiv.org/abs/2510.10494", "authors": ["Martina G. Vilas", "Safoora Yousefi", "Besmira Nushi", "Eric Horvitz", "Vidhisha Balachandran"], "title": "Tracing the Traces: Latent Temporal Signals for Efficient and Accurate Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Reasoning models improve their problem-solving ability through inference-time\nscaling, allocating more compute via longer token budgets. Identifying which\nreasoning traces are likely to succeed remains a key opportunity: reliably\npredicting productive paths can substantially reduce wasted computation and\nimprove overall efficiency. We introduce Latent-Trajectory signals that\ncharacterize the temporal evolution of a model's internal representations\nduring the generation of intermediate reasoning tokens. By measuring the\noverall change in latent representations between the start and end of\nreasoning, the change accumulated across intermediate steps, and the extent to\nwhich these changes advance toward the final state, we show that these signals\npredict solution accuracy more reliably than both cross-layer metrics and\noutput-based confidence measures. When used to guide answer selection across\nmultiple sampled generations, Latent-Trajectory signals make test-time scaling\nmore effective and efficient than majority voting, reducing token usage by up\nto 70% while preserving and even improving accuracy by 2.6% on average.\nMoreover, these predictive signals often emerge early in the reasoning trace,\nenabling early selection and allocation of compute to the most promising\ncandidates. Our findings contribute not only practical strategies for\ninference-time efficiency, but also a deeper interpretability perspective on\nhow reasoning processes are represented and differentiated in latent space.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper discusses using latent representations to predict the success of reasoning traces in large language models, which can be seen as predicting the 'trajectory' of the model's reasoning process. While it doesn't directly predict physical trajectories, the concept of tracing and predicting the evolution of internal representations shares conceptual similarities with trajectory prediction. It is closely related to large language models.", "keywords": ["reasoning traces", "latent representations", "large language models", "inference-time efficiency"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10567", "pdf": "https://arxiv.org/pdf/2510.10567", "abs": "https://arxiv.org/abs/2510.10567", "authors": ["Alexander Langmann", "Yevhenii Tokarev", "Mattia Piccinini", "Korbinian Moller", "Johannes Betz"], "title": "Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving", "categories": ["cs.RO"], "comment": "8 pages, submitted to the IEEE ICRA 2026, Vienna, Austria", "summary": "Sampling-based trajectory planners are widely used for agile autonomous\ndriving due to their ability to generate fast, smooth, and kinodynamically\nfeasible trajectories. However, their behavior is often governed by a cost\nfunction with manually tuned, static weights, which forces a tactical\ncompromise that is suboptimal across the wide range of scenarios encountered in\na race. To address this shortcoming, we propose using a Reinforcement Learning\n(RL) agent as a high-level behavioral selector that dynamically switches the\ncost function parameters of an analytical, low-level trajectory planner during\nruntime. We show the effectiveness of our approach in simulation in an\nautonomous racing environment where our RL-based planner achieved 0% collision\nrate while reducing overtaking time by up to 60% compared to state-of-the-art\nstatic planners. Our new agent now dynamically switches between aggressive and\nconservative behaviors, enabling interactive maneuvers unattainable with static\nconfigurations. These results demonstrate that integrating reinforcement\nlearning as a high-level selector resolves the inherent trade-off between\nsafety and competitiveness in autonomous racing planners. The proposed\nmethodology offers a pathway toward adaptive yet interpretable motion planning\nfor broader autonomous driving applications.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on motion planning and trajectory generation for autonomous driving using reinforcement learning. While it involves trajectory planning, it doesn't directly involve large language models. The connection to trajectory prediction is present but not central, and the RL aspect is more prominent.", "keywords": ["trajectory planning", "motion planning", "autonomous driving"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10030", "pdf": "https://arxiv.org/pdf/2510.10030", "abs": "https://arxiv.org/abs/2510.10030", "authors": ["Henan Wang", "Hanxin Zhu", "Xinliang Gong", "Tianyu He", "Xin Li", "Zhibo Chen"], "title": "P-4DGS: Predictive 4D Gaussian Splatting with 90$\\times$ Compression", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has garnered significant attention due to its\nsuperior scene representation fidelity and real-time rendering performance,\nespecially for dynamic 3D scene reconstruction (\\textit{i.e.}, 4D\nreconstruction). However, despite achieving promising results, most existing\nalgorithms overlook the substantial temporal and spatial redundancies inherent\nin dynamic scenes, leading to prohibitive memory consumption. To address this,\nwe propose P-4DGS, a novel dynamic 3DGS representation for compact 4D scene\nmodeling. Inspired by intra- and inter-frame prediction techniques commonly\nused in video compression, we first design a 3D anchor point-based\nspatial-temporal prediction module to fully exploit the spatial-temporal\ncorrelations across different 3D Gaussian primitives. Subsequently, we employ\nan adaptive quantization strategy combined with context-based entropy coding to\nfurther reduce the size of the 3D anchor points, thereby achieving enhanced\ncompression efficiency. To evaluate the rate-distortion performance of our\nproposed P-4DGS in comparison with other dynamic 3DGS representations, we\nconduct extensive experiments on both synthetic and real-world datasets.\nExperimental results demonstrate that our approach achieves state-of-the-art\nreconstruction quality and the fastest rendering speed, with a remarkably low\nstorage footprint (around \\textbf{1MB} on average), achieving up to\n\\textbf{40$\\times$} and \\textbf{90$\\times$} compression on synthetic and\nreal-world scenes, respectively.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on dynamic 3D scene reconstruction and compression using 3D Gaussian Splatting. While not explicitly mentioning trajectory prediction, the 'predictive' aspect in the title and the mention of 'spatial-temporal prediction module' in the abstract suggest a connection to predicting the evolution of the 3D scene over time, which is related to trajectory prediction. However, the paper does not involve large language models.", "keywords": ["dynamic 3D scene reconstruction", "spatial-temporal prediction", "4D reconstruction"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10637", "pdf": "https://arxiv.org/pdf/2510.10637", "abs": "https://arxiv.org/abs/2510.10637", "authors": ["Haoyu Zhao", "Cheng Zeng", "Linghao Zhuang", "Yaxi Zhao", "Shengke Xue", "Hao Wang", "Xingyue Zhao", "Zhongyu Li", "Kehan Li", "Siteng Huang", "Mingxiu Chen", "Xin Li", "Deli Zhao", "Hua Zou"], "title": "High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting", "categories": ["cs.RO"], "comment": "13 pages, 6 figures", "summary": "The scalability of robotic learning is fundamentally bottlenecked by the\nsignificant cost and labor of real-world data collection. While simulated data\noffers a scalable alternative, it often fails to generalize to the real world\ndue to significant gaps in visual appearance, physical properties, and object\ninteractions. To address this, we propose RoboSimGS, a novel Real2Sim2Real\nframework that converts multi-view real-world images into scalable,\nhigh-fidelity, and physically interactive simulation environments for robotic\nmanipulation. Our approach reconstructs scenes using a hybrid representation:\n3D Gaussian Splatting (3DGS) captures the photorealistic appearance of the\nenvironment, while mesh primitives for interactive objects ensure accurate\nphysics simulation. Crucially, we pioneer the use of a Multi-modal Large\nLanguage Model (MLLM) to automate the creation of physically plausible,\narticulated assets. The MLLM analyzes visual data to infer not only physical\nproperties (e.g., density, stiffness) but also complex kinematic structures\n(e.g., hinges, sliding rails) of objects. We demonstrate that policies trained\nentirely on data generated by RoboSimGS achieve successful zero-shot\nsim-to-real transfer across a diverse set of real-world manipulation tasks.\nFurthermore, data from RoboSimGS significantly enhances the performance and\ngeneralization capabilities of SOTA methods. Our results validate RoboSimGS as\na powerful and scalable solution for bridging the sim-to-real gap.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper is related to Large Language Models as it uses a Multi-modal Large Language Model (MLLM) to automate the creation of physically plausible, articulated assets. While the main focus isn't trajectory prediction, the robotic manipulation tasks could potentially involve some form of trajectory planning or prediction for the robot's movements. Therefore, there's a moderate level of relevance.", "keywords": ["Large Language Model", "MLLM", "robotic manipulation"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10642", "pdf": "https://arxiv.org/pdf/2510.10642", "abs": "https://arxiv.org/abs/2510.10642", "authors": ["Jianke Zhang", "Yucheng Hu", "Yanjiang Guo", "Xiaoyu Chen", "Yichen Liu", "Wenna Chen", "Chaochao Lu", "Jianyu Chen"], "title": "UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Building generalist robot policies that can handle diverse tasks in\nopen-ended environments is a central challenge in robotics. To leverage\nknowledge from large-scale pretraining, prior work has typically built\ngeneralist policies either on top of vision-language understanding models\n(VLMs) or generative models. However, both semantic understanding from\nvision-language pretraining and visual dynamics modeling from visual-generation\npretraining are crucial for embodied robots. Recent unified models of\ngeneration and understanding have demonstrated strong capabilities in both\ncomprehension and generation through large-scale pretraining. We posit that\nrobotic policy learning can likewise benefit from the combined strengths of\nunderstanding, planning and continuous future representation learning. Building\non this insight, we introduce UniCoD, which acquires the ability to dynamically\nmodel high-dimensional visual features through pretraining on over 1M\ninternet-scale instructional manipulation videos. Subsequently, UniCoD is\nfine-tuned on data collected from the robot embodiment, enabling the learning\nof mappings from predictive representations to action tokens. Extensive\nexperiments show our approach consistently outperforms baseline methods in\nterms of 9\\% and 12\\% across simulation environments and real-world\nout-of-distribution tasks.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u5229\u7528\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b(UniCoD)\u6765\u589e\u5f3a\u673a\u5668\u4eba\u7b56\u7565\uff0c\u6d89\u53ca\u8fde\u7eed\u672a\u6765\u8868\u793a\u5b66\u4e60\uff0c\u8fd9\u4e0e\u8f68\u8ff9\u9884\u6d4b\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\uff0c\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u673a\u5668\u4eba\u7b56\u7565\u7684\u5b66\u4e60\u548c\u52a8\u4f5c\u89c4\u5212\u4e0e\u8f68\u8ff9\u9884\u6d4b\u5bc6\u5207\u76f8\u5173\u3002\u540c\u65f6\uff0c\u8bba\u6587\u63d0\u5230\u4e86\u5229\u7528\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u56e0\u6b64\u4e0e\u5927\u6a21\u578b\u4e5f\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["large-scale pretraining", "unified models", "continuous future representation learning", "robot policy"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10644", "pdf": "https://arxiv.org/pdf/2510.10644", "abs": "https://arxiv.org/abs/2510.10644", "authors": ["Yi Zhang", "Yushen Long", "Yun Ni", "Liping Huang", "Xiaohong Wang", "Jun Liu"], "title": "Hierarchical Optimization via LLM-Guided Objective Evolution for Mobility-on-Demand Systems", "categories": ["cs.AI"], "comment": null, "summary": "Online ride-hailing platforms aim to deliver efficient mobility-on-demand\nservices, often facing challenges in balancing dynamic and spatially\nheterogeneous supply and demand. Existing methods typically fall into two\ncategories: reinforcement learning (RL) approaches, which suffer from data\ninefficiency, oversimplified modeling of real-world dynamics, and difficulty\nenforcing operational constraints; or decomposed online optimization methods,\nwhich rely on manually designed high-level objectives that lack awareness of\nlow-level routing dynamics. To address this issue, we propose a novel hybrid\nframework that integrates large language model (LLM) with mathematical\noptimization in a dynamic hierarchical system: (1) it is training-free,\nremoving the need for large-scale interaction data as in RL, and (2) it\nleverages LLM to bridge cognitive limitations caused by problem decomposition\nby adaptively generating high-level objectives. Within this framework, LLM\nserves as a meta-optimizer, producing semantic heuristics that guide a\nlow-level optimizer responsible for constraint enforcement and real-time\ndecision execution. These heuristics are refined through a closed-loop\nevolutionary process, driven by harmony search, which iteratively adapts the\nLLM prompts based on feasibility and performance feedback from the optimization\nlayer. Extensive experiments based on scenarios derived from both the New York\nand Chicago taxi datasets demonstrate the effectiveness of our approach,\nachieving an average improvement of 16% compared to state-of-the-art baselines.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u51fa\u884c\u5373\u670d\u52a1\uff08Mobility-on-Demand\uff09\u7cfb\u7edf\u4e2d\u7684\u4f18\u5316\u95ee\u9898\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u51fa\u884c\u5373\u670d\u52a1\u7cfb\u7edf\u901a\u5e38\u5305\u542b\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u7684\u7ec4\u6210\u90e8\u5206\u3002\u8bba\u6587\u660e\u786e\u4f7f\u7528\u4e86LLM\u6765\u6307\u5bfc\u4f18\u5316\u8fc7\u7a0b\uff0c\u56e0\u6b64\u4e0e\u5927\u6a21\u578b\u76f8\u5173\u3002\u76f8\u5173\u6027\u5904\u4e8e\u4e2d\u7b49\u6c34\u5e73\u3002", "keywords": ["Large Language Model", "LLM", "Mobility-on-Demand", "optimization", "ride-hailing"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10886", "pdf": "https://arxiv.org/pdf/2510.10886", "abs": "https://arxiv.org/abs/2510.10886", "authors": ["Yashom Dighe", "Youngjin Kim", "Karthik Dantu"], "title": "QuayPoints: A Reasoning Framework to Bridge the Information Gap Between Global and Local Planning in Autonomous Racing", "categories": ["cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Autonomous racing requires tight integration between perception, planning and\ncontrol to minimize latency as well as timely decision making. A standard\nautonomy pipeline comprising a global planner, local planner, and controller\nloses information as the higher-level racing context is sequentially propagated\ndownstream into specific task-oriented context. In particular, the global\nplanner's understanding of optimality is typically reduced to a sparse set of\nwaypoints, leaving the local planner to make reactive decisions with limited\ncontext. This paper investigates whether additional global insights,\nspecifically time-optimality information, can be meaningfully passed to the\nlocal planner to improve downstream decisions. We introduce a framework that\npreserves essential global knowledge and conveys it to the local planner\nthrough QuayPoints regions where deviations from the optimal raceline result in\nsignificant compromises to optimality. QuayPoints enable local planners to make\nmore informed global decisions when deviating from the raceline, such as during\nstrategic overtaking. To demonstrate this, we integrate QuayPoints into an\nexisting planner and show that it consistently overtakes opponents traveling at\nup to 75% of the ego vehicle's speed across four distinct race tracks.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on autonomous racing, which involves trajectory planning and prediction for vehicles. While it doesn't directly use large language models, it addresses the problem of information flow and decision making in a hierarchical planning system, a concept that could potentially be relevant to how LLMs are used in robotics or autonomous systems. Keywords like 'planning', 'autonomous racing', and 'global planner' suggest a connection to trajectory prediction, although a weak one to LLMs.", "keywords": ["trajectory planning", "autonomous racing", "global planner", "local planner"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10893", "pdf": "https://arxiv.org/pdf/2510.10893", "abs": "https://arxiv.org/abs/2510.10893", "authors": ["Dikshant Shehmar", "Matthew E. Taylor", "Ehsan Hashemi"], "title": "An Adaptive Transition Framework for Game-Theoretic Based Takeover", "categories": ["cs.RO"], "comment": null, "summary": "The transition of control from autonomous systems to human drivers is\ncritical in automated driving systems, particularly due to the out-of-the-loop\n(OOTL) circumstances that reduce driver readiness and increase reaction times.\nExisting takeover strategies are based on fixed time-based transitions, which\nfail to account for real-time driver performance variations. This paper\nproposes an adaptive transition strategy that dynamically adjusts the control\nauthority based on both the time and tracking ability of the driver trajectory.\nShared control is modeled as a cooperative differential game, where control\nauthority is modulated through time-varying objective functions instead of\nblending control torques directly. To ensure a more natural takeover, a\ndriver-specific state-tracking matrix is introduced, allowing the transition to\nalign with individual control preferences. Multiple transition strategies are\nevaluated using a cumulative trajectory error metric. Human-in-the-loop control\nscenarios of the standardized ISO lane change maneuvers demonstrate that\nadaptive transitions reduce trajectory deviations and driver control effort\ncompared to conventional strategies. Experiments also confirm that continuously\nadjusting control authority based on real-time deviations enhances vehicle\nstability while reducing driver effort during takeover.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5230\u4eba\u7c7b\u9a7e\u9a76\u5458\u7684\u63a7\u5236\u6743\u79fb\u4ea4\uff0c\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\uff08driver trajectory, trajectory deviations\uff09\u548c\u63a7\u5236\u7b56\u7565\uff0c\u4f46\u6ca1\u6709\u63d0\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u76f8\u5173\u6027\u4e2d\u7b49\u3002", "keywords": ["trajectory prediction", "driver trajectory", "trajectory deviations", "automated driving systems"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10960", "pdf": "https://arxiv.org/pdf/2510.10960", "abs": "https://arxiv.org/abs/2510.10960", "authors": ["Dong Hu", "Fenqing Hu", "Lidong Yang", "Chao Huang"], "title": "Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving", "categories": ["cs.RO"], "comment": null, "summary": "Ensuring safety in autonomous driving (AD) remains a significant challenge,\nespecially in highly dynamic and complex traffic environments where diverse\nagents interact and unexpected hazards frequently emerge. Traditional\nreinforcement learning (RL) methods often struggle to balance safety,\nefficiency, and adaptability, as they primarily focus on reward maximization\nwithout explicitly modeling risk or safety constraints. To address these\nlimitations, this study proposes a novel game-theoretic risk-shaped RL (GTR2L)\nframework for safe AD. GTR2L incorporates a multi-level game-theoretic world\nmodel that jointly predicts the interactive behaviors of surrounding vehicles\nand their associated risks, along with an adaptive rollout horizon that adjusts\ndynamically based on predictive uncertainty. Furthermore, an uncertainty-aware\nbarrier mechanism enables flexible modulation of safety boundaries. A dedicated\nrisk modeling approach is also proposed, explicitly capturing both epistemic\nand aleatoric uncertainty to guide constrained policy optimization and enhance\ndecision-making in complex environments. Extensive evaluations across diverse\nand safety-critical traffic scenarios show that GTR2L significantly outperforms\nstate-of-the-art baselines, including human drivers, in terms of success rate,\ncollision and violation reduction, and driving efficiency. The code is\navailable at https://github.com/DanielHu197/GTR2L.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on autonomous driving safety using reinforcement learning and game-theoretic modeling to predict the behavior of surrounding vehicles. While it involves predicting the behavior of other agents (which is related to trajectory prediction), it does not explicitly mention or utilize Large Language Models. The core focus is on risk assessment and safe decision-making in autonomous driving, making it somewhat relevant but not highly so.", "keywords": ["trajectory prediction", "autonomous driving", "reinforcement learning", "behavior prediction"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.10976", "pdf": "https://arxiv.org/pdf/2510.10976", "abs": "https://arxiv.org/abs/2510.10976", "authors": ["Wentao Wang", "Heqing Zou", "Tianze Luo", "Rui Huang", "Yutian Zhao", "Zhuochen Wang", "Hansheng Zhang", "Chengwei Qin", "Yan Wang", "Lin Zhao", "Huaijian Zhang"], "title": "Video-STR: Reinforcing MLLMs in Video Spatio-Temporal Reasoning with Relation Graph", "categories": ["cs.AI", "68T05", "I.2.10"], "comment": null, "summary": "Recent progress in Multimodal Large Language Models (MLLMs) has demonstrated\nstrong semantic understanding capabilities, but struggles to perform precise\nspatio-temporal understanding. Existing spatio-temporal methods primarily focus\non the video itself, while overlooking the physical information within the\nvideo, such as multi-object layouts and motion. Such limitations restrict the\nuse of MLLMs in downstream applications that demand high precision, including\nembodied intelligence and VR. To address this issue, we present Video-STR, a\nnovel graph-based reinforcement method for precise Video Spatio-Temporal\nReasoning. Building upon the capacity of Reinforcement Learning with Verifiable\nReward (RLVR) to improve model abilities, we introduce a reasoning mechanism\nusing graph-based Group Relative Policy Optimization (GRPO) method to guide the\nmodel in inferring the underlying spatio-temporal topology of scenarios during\nthe thinking process. To resolve the lack of spatio-temporal training data, we\nconstruct the STV-205k dataset with 205k question-answering pairs, covering\ndynamic multi-object scenes in both indoor and outdoor environments, to support\nthe model training. Experiments show that Video-STR achieves state-of-the-art\nresults on various benchmarks, outperforming the base model by 13% on\nSTI-Bench, and demonstrating the effectiveness of our approach and dataset.\nCode, model, and data will be released.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on improving spatio-temporal reasoning capabilities of Multimodal Large Language Models (MLLMs) using a graph-based reinforcement method. While it doesn't directly address trajectory prediction, the spatio-temporal reasoning aspect, especially in dynamic multi-object scenes, has overlaps with trajectory prediction. The use of MLLMs is also a relevant factor.", "keywords": ["Multimodal Large Language Models", "MLLMs", "spatio-temporal reasoning", "reinforcement learning", "graph-based", "dynamic multi-object scenes"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.11041", "pdf": "https://arxiv.org/pdf/2510.11041", "abs": "https://arxiv.org/abs/2510.11041", "authors": ["Shiyao Zhang", "Liwei Deng", "Shuyu Zhang", "Weijie Yuan", "Hong Zhang"], "title": "Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy", "categories": ["cs.RO"], "comment": "Accepted by IEEE RA-L", "summary": "In future intelligent transportation systems, autonomous cooperative planning\n(ACP), becomes a promising technique to increase the effectiveness and security\nof multi-vehicle interactions. However, multiple uncertainties cannot be fully\naddressed for existing ACP strategies, e.g. perception, planning, and\ncommunication uncertainties. To address these, a novel deep reinforcement\nlearning-based autonomous cooperative planning (DRLACP) framework is proposed\nto tackle various uncertainties on cooperative motion planning schemes.\nSpecifically, the soft actor-critic (SAC) with the implementation of gate\nrecurrent units (GRUs) is adopted to learn the deterministic optimal\ntime-varying actions with imperfect state information occurred by planning,\ncommunication, and perception uncertainties. In addition, the real-time actions\nof autonomous vehicles (AVs) are demonstrated via the Car Learning to Act\n(CARLA) simulation platform. Evaluation results show that the proposed DRLACP\nlearns and performs cooperative planning effectively, which outperforms other\nbaseline methods under different scenarios with imperfect AV state information.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on autonomous cooperative planning for vehicles using deep reinforcement learning. It touches upon trajectory planning and uncertainty, but does not explicitly involve large language models. The use of GRUs hints at sequence modeling, which is relevant to trajectory prediction.", "keywords": ["autonomous cooperative planning", "trajectory planning", "uncertainty", "deep reinforcement learning", "GRU"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.11083", "pdf": "https://arxiv.org/pdf/2510.11083", "abs": "https://arxiv.org/abs/2510.11083", "authors": ["Tianyi Tan", "Yinan Zheng", "Ruiming Liang", "Zexu Wang", "Kexin Zheng", "Jinliang Zheng", "Jianxiong Li", "Xianyuan Zhan", "Jingjing Liu"], "title": "Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling", "categories": ["cs.RO", "cs.AI"], "comment": "26 pages, 6 figures. Accepted at NeurIPS 2025", "summary": "Modeling interactive driving behaviors in complex scenarios remains a\nfundamental challenge for autonomous driving planning. Learning-based\napproaches attempt to address this challenge with advanced generative models,\nremoving the dependency on over-engineered architectures for representation\nfusion. However, brute-force implementation by simply stacking transformer\nblocks lacks a dedicated mechanism for modeling interactive behaviors that are\ncommon in real driving scenarios. The scarcity of interactive driving data\nfurther exacerbates this problem, leaving conventional imitation learning\nmethods ill-equipped to capture high-value interactive behaviors. We propose\nFlow Planner, which tackles these problems through coordinated innovations in\ndata modeling, model architecture, and learning scheme. Specifically, we first\nintroduce fine-grained trajectory tokenization, which decomposes the trajectory\ninto overlapping segments to decrease the complexity of whole trajectory\nmodeling. With a sophisticatedly designed architecture, we achieve efficient\ntemporal and spatial fusion of planning and scene information, to better\ncapture interactive behaviors. In addition, the framework incorporates flow\nmatching with classifier-free guidance for multi-modal behavior generation,\nwhich dynamically reweights agent interactions during inference to maintain\ncoherent response strategies, providing a critical boost for interactive\nscenario understanding. Experimental results on the large-scale nuPlan dataset\nand challenging interactive interPlan dataset demonstrate that Flow Planner\nachieves state-of-the-art performance among learning-based approaches while\neffectively modeling interactive behaviors in complex driving scenarios.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5b66\u4e60\u4ea4\u4e92\u884c\u4e3a\u6765\u8fdb\u884c\u8f68\u8ff9\u9884\u6d4b\u3002\u6458\u8981\u4e2d\u63d0\u5230\u4e86\u4f7f\u7528\u751f\u6210\u6a21\u578b\u6765\u89e3\u51b3\u4ea4\u4e92\u884c\u4e3a\u5efa\u6a21\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86Flow Planner\u6846\u67b6\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u4f7f\u7528\u4e86transformer\u7ed3\u6784\u548c\u751f\u6210\u6a21\u578b\uff0c\u5e76\u4e14\u4e0e\u8f68\u8ff9\u9884\u6d4b\u9ad8\u5ea6\u76f8\u5173\u3002\u56e0\u6b64\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["trajectory prediction", "autonomous driving", "interactive behavior modeling", "generative models", "transformer", "flow matching", "trajectory tokenization"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
