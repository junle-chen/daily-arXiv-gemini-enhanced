# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-09-27

## 目录

- [机器学习 (Machine Learning) (1)](#cs-lg)

## 机器学习 (Machine Learning) [cs.LG]
### [1] [Sig2Model: A Boosting-Driven Model for Updatable Learned Indexes](https://arxiv.org/abs/2509.20781)
*Alireza Heidari, Amirhossein Ahmad, Wei Zhang, Ying Xiong*

Main category: cs.LG

TL;DR: Sig2Model通过sigmoid函数近似、主动更新训练和神经联合优化，显著降低了学习索引在动态更新时的重训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有学习索引在动态更新频繁的实际应用中，由于全局模型重训练导致性能下降，无法有效解决重训练成本问题。

Method: 提出Sig2Model，利用sigmoid boosting近似动态调整索引模型，通过高斯混合模型进行主动更新训练，并采用神经联合优化框架持续优化sigmoid集成和GMM参数。

Result: 实验结果表明，Sig2Model将重训练成本降低了高达20倍，实现了高达3倍的QPS提升，并减少了高达1000倍的内存使用。

Conclusion: Sig2Model通过其创新技术，显著提高了学习索引在动态数据集上的性能和效率。

Abstract: 学习索引（LIs）通过使用机器学习模型来近似排序数据的累积分布函数（CDF），代表了传统索引结构的一种范式转变。虽然LIs在静态数据集上实现了显著的效率，但其性能在动态更新下会降低：维护CDF不变性（F(k)之和等于1）需要全局模型重训练，这会阻塞查询并限制每秒查询数（QPS）指标。当前的方法未能有效解决这些重训练成本，使得它们不适用于具有频繁更新的实际工作负载。在本文中，我们提出了一种高效且自适应的学习索引Sig2Model，它通过三个关键技术最大限度地降低重训练成本：（1）一种sigmoid boosting近似技术，通过使用局部sigmoid函数近似数据分布中由更新引起的偏移来动态调整索引模型，同时保持有界误差保证并推迟完全重训练；（2）通过高斯混合模型（GMM）进行主动更新训练，识别高更新概率区域以进行战略占位符分配，从而加速更新；（3）一种神经联合优化框架，通过基于梯度的学习不断优化sigmoid集成和GMM参数。我们针对最先进的可更新学习索引在真实和合成工作负载上评估了Sig2Model，结果表明Sig2Model将重训练成本降低了高达20倍，实现了高达3倍的QPS提升，并减少了高达1000倍的内存使用。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.20781) | **Categories:** cs.LG, cs.DB, cs.PF

---
