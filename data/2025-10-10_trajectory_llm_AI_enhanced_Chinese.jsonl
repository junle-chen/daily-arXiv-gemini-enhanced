{"id": "2510.06717", "pdf": "https://arxiv.org/pdf/2510.06717", "abs": "https://arxiv.org/abs/2510.06717", "authors": ["Yuanfei Lin", "Sebastian Illing", "Matthias Althoff"], "title": "SanDRA: Safe Large-Language-Model-Based Decision Making for Automated Vehicles Using Reachability Analysis", "categories": ["cs.RO"], "comment": "@2025 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Large language models have been widely applied to knowledge-driven\ndecision-making for automated vehicles due to their strong generalization and\nreasoning capabilities. However, the safety of the resulting decisions cannot\nbe ensured due to possible hallucinations and the lack of integrated vehicle\ndynamics. To address this issue, we propose SanDRA, the first safe\nlarge-language-model-based decision making framework for automated vehicles\nusing reachability analysis. Our approach starts with a comprehensive\ndescription of the driving scenario to prompt large language models to generate\nand rank feasible driving actions. These actions are translated into temporal\nlogic formulas that incorporate formalized traffic rules, and are subsequently\nintegrated into reachability analysis to eliminate unsafe actions. We validate\nour approach in both open-loop and closed-loop driving environments using\noff-the-shelf and finetuned large language models, showing that it can provide\nprovably safe and, where possible, legally compliant driving actions, even\nunder high-density traffic conditions. To ensure transparency and facilitate\nfuture research, all code and experimental setups are publicly available at\ngithub.com/CommonRoad/SanDRA.", "relevance_analysis": {"relevance_score": 0.95, "explanation": "This paper is highly relevant as it directly combines Large Language Models (LLMs) with decision-making for automated vehicles, focusing on safe driving actions. It uses LLMs to generate driving actions and reachability analysis to ensure safety, which falls under the umbrella of trajectory prediction/planning for autonomous vehicles. The paper explicitly mentions LLMs and their application in automated vehicle decision-making.", "keywords": ["Large Language Models", "LLMs", "automated vehicles", "decision making", "reachability analysis", "driving actions", "trajectory prediction", "safe driving"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06291", "pdf": "https://arxiv.org/pdf/2510.06291", "abs": "https://arxiv.org/abs/2510.06291", "authors": ["Zhiyang Zhang", "Ningcong Chen", "Xin Zhang", "Yanhua Li", "Shen Su", "Hui Lu", "Jun Luo"], "title": "Traj-Transformer: Diffusion Models with Transformer for GPS Trajectory Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The widespread use of GPS devices has driven advances in spatiotemporal data\nmining, enabling machine learning models to simulate human decision making and\ngenerate realistic trajectories, addressing both data collection costs and\nprivacy concerns. Recent studies have shown the promise of diffusion models for\nhigh-quality trajectory generation. However, most existing methods rely on\nconvolution based architectures (e.g. UNet) to predict noise during the\ndiffusion process, which often results in notable deviations and the loss of\nfine-grained street-level details due to limited model capacity. In this paper,\nwe propose Trajectory Transformer, a novel model that employs a transformer\nbackbone for both conditional information embedding and noise prediction. We\nexplore two GPS coordinate embedding strategies, location embedding and\nlongitude-latitude embedding, and analyze model performance at different\nscales. Experiments on two real-world datasets demonstrate that Trajectory\nTransformer significantly enhances generation quality and effectively\nalleviates the deviation issues observed in prior approaches.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "\u8be5\u8bba\u6587\u6807\u9898\u548c\u6458\u8981\u90fd\u660e\u786e\u63d0\u5230\u4e86\u8f68\u8ff9\u751f\u6210\uff08trajectory generation\uff09\u548cTransformer\u6a21\u578b\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46Transformer\u67b6\u6784\u662f\u8bb8\u591a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7840\uff0c\u5e76\u4e14\u8bba\u6587\u4e2d\u4f7f\u7528\u4e86Transformer\u6765\u89e3\u51b3\u8f68\u8ff9\u751f\u6210\u95ee\u9898\uff0c\u56e0\u6b64\u5177\u6709\u8f83\u9ad8\u7684\u76f8\u5173\u6027\u3002", "keywords": ["trajectory generation", "Transformer", "diffusion models", "GPS trajectory", "spatiotemporal data"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06504", "pdf": "https://arxiv.org/pdf/2510.06504", "abs": "https://arxiv.org/abs/2510.06504", "authors": ["Qingxuan Wu", "Zhiyang Dou", "Chuan Guo", "Yiming Huang", "Qiao Feng", "Bing Zhou", "Jian Wang", "Lingjie Liu"], "title": "Text2Interact: High-Fidelity and Diverse Text-to-Two-Person Interaction Generation", "categories": ["cs.CV"], "comment": null, "summary": "Modeling human-human interactions from text remains challenging because it\nrequires not only realistic individual dynamics but also precise,\ntext-consistent spatiotemporal coupling between agents. Currently, progress is\nhindered by 1) limited two-person training data, inadequate to capture the\ndiverse intricacies of two-person interactions; and 2) insufficiently\nfine-grained text-to-interaction modeling, where language conditioning\ncollapses rich, structured prompts into a single sentence embedding. To address\nthese limitations, we propose our Text2Interact framework, designed to generate\nrealistic, text-aligned human-human interactions through a scalable\nhigh-fidelity interaction data synthesizer and an effective spatiotemporal\ncoordination pipeline. First, we present InterCompose, a scalable\nsynthesis-by-composition pipeline that aligns LLM-generated interaction\ndescriptions with strong single-person motion priors. Given a prompt and a\nmotion for an agent, InterCompose retrieves candidate single-person motions,\ntrains a conditional reaction generator for another agent, and uses a neural\nmotion evaluator to filter weak or misaligned samples-expanding interaction\ncoverage without extra capture. Second, we propose InterActor, a\ntext-to-interaction model with word-level conditioning that preserves\ntoken-level cues (initiation, response, contact ordering) and an adaptive\ninteraction loss that emphasizes contextually relevant inter-person joint\npairs, improving coupling and physical plausibility for fine-grained\ninteraction modeling. Extensive experiments show consistent gains in motion\ndiversity, fidelity, and generalization, including out-of-distribution\nscenarios and user studies. We will release code and models to facilitate\nreproducibility.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u4ea4\u4e92\u63cf\u8ff0\uff0c\u5e76\u5c06\u5176\u4e0e\u5355\u4eba\u8fd0\u52a8\u5148\u9a8c\u5bf9\u9f50\uff0c\u4ee5\u751f\u6210\u903c\u771f\u7684\u4eba\u4e0e\u4eba\u4e4b\u95f4\u7684\u4ea4\u4e92\u3002\u867d\u7136\u4e3b\u8981\u5173\u6ce8\u751f\u6210\uff0c\u4f46\u5176\u4e2d\u6d89\u53ca\u5bf9\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u4eba\u7269\u8fd0\u52a8\u8f68\u8ff9\u7684\u5efa\u6a21\u548c\u9884\u6d4b\uff0c\u56e0\u6b64\u4e0e\u8f68\u8ff9\u9884\u6d4b\u6709\u4e00\u5b9a\u76f8\u5173\u6027\uff0c\u5e76\u4e14\u660e\u786e\u4f7f\u7528\u4e86LLM\u3002", "keywords": ["Large Language Models", "LLM", "interaction", "motion", "text-to-interaction", "spatiotemporal"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06913", "pdf": "https://arxiv.org/pdf/2510.06913", "abs": "https://arxiv.org/abs/2510.06913", "authors": ["Ke Guo", "Haochen Liu", "Xiaojun Wu", "Chen Lv"], "title": "DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Realistic traffic simulation is critical for the development of autonomous\ndriving systems and urban mobility planning, yet existing imitation learning\napproaches often fail to model realistic traffic behaviors. Behavior cloning\nsuffers from covariate shift, while Generative Adversarial Imitation Learning\n(GAIL) is notoriously unstable in multi-agent settings. We identify a key\nsource of this instability: irrelevant interaction misguidance, where a\ndiscriminator penalizes an ego vehicle's realistic behavior due to unrealistic\ninteractions among its neighbors. To address this, we propose Decomposed\nMulti-agent GAIL (DecompGAIL), which explicitly decomposes realism into ego-map\nand ego-neighbor components, filtering out misleading neighbor: neighbor and\nneighbor: map interactions. We further introduce a social PPO objective that\naugments ego rewards with distance-weighted neighborhood rewards, encouraging\noverall realism across agents. Integrated into a lightweight SMART-based\nbackbone, DecompGAIL achieves state-of-the-art performance on the WOMD Sim\nAgents 2025 benchmark.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u4ea4\u901a\u884c\u4e3a\u5efa\u6a21\u548c\u4eff\u771f\uff0c\u4f7f\u7528\u4e86\u751f\u6210\u5bf9\u6297\u6a21\u4eff\u5b66\u4e60\uff08GAIL\uff09\u65b9\u6cd5\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5176\u7814\u7a76\u9886\u57df\u4e0e\u8f68\u8ff9\u9884\u6d4b\u5bc6\u5207\u76f8\u5173\uff0c\u7279\u522b\u662f\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u548c\u4ea4\u901a\u884c\u4e3a\u5efa\u6a21\u3002\u5173\u952e\u8bcd\u8868\u660e\u5176\u4e0e\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e0b\u7684\u884c\u4e3a\u5b66\u4e60\u6709\u5173\u3002", "keywords": ["trajectory prediction", "imitation learning", "multi-agent", "traffic behaviors", "Generative Adversarial Imitation Learning", "autonomous driving"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06351", "pdf": "https://arxiv.org/pdf/2510.06351", "abs": "https://arxiv.org/abs/2510.06351", "authors": ["Kaleb Ben Naveed", "Devansh R. Agrawal", "Dimitra Panagou"], "title": "A Formal gatekeeper Framework for Safe Dual Control with Active Exploration", "categories": ["cs.RO"], "comment": "Submitted to American Control Conference (ACC) 2026", "summary": "Planning safe trajectories under model uncertainty is a fundamental\nchallenge. Robust planning ensures safety by considering worst-case\nrealizations, yet ignores uncertainty reduction and leads to overly\nconservative behavior. Actively reducing uncertainty on-the-fly during a\nnominal mission defines the dual control problem. Most approaches address this\nby adding a weighted exploration term to the cost, tuned to trade off the\nnominal objective and uncertainty reduction, but without formal consideration\nof when exploration is beneficial. Moreover, safety is enforced in some methods\nbut not in others. We propose a framework that integrates robust planning with\nactive exploration under formal guarantees as follows: The key innovation and\ncontribution is that exploration is pursued only when it provides a verifiable\nimprovement without compromising safety. To achieve this, we utilize our\nearlier work on gatekeeper as an architecture for safety verification, and\nextend it so that it generates both safe and informative trajectories that\nreduce uncertainty and the cost of the mission, or keep it within a\nuser-defined budget. The methodology is evaluated via simulation case studies\non the online dual control of a quadrotor under parametric uncertainty.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on safe trajectory planning under uncertainty, which is related to trajectory prediction. It mentions planning safe trajectories and active exploration for uncertainty reduction. However, it doesn't directly involve large language models. The connection to trajectory prediction is moderately strong due to the focus on planning and safety.", "keywords": ["trajectory planning", "safe trajectories", "uncertainty reduction", "active exploration"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06357", "pdf": "https://arxiv.org/pdf/2510.06357", "abs": "https://arxiv.org/abs/2510.06357", "authors": ["Grayson Byrd", "Corban Rivera", "Bethany Kemp", "Meghan Booker", "Aurora Schmidt", "Celso M de Melo", "Lalithkumar Seenivasan", "Mathias Unberath"], "title": "Constrained Natural Language Action Planning for Resilient Embodied Systems", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Replicating human-level intelligence in the execution of embodied tasks\nremains challenging due to the unconstrained nature of real-world environments.\nNovel use of large language models (LLMs) for task planning seeks to address\nthe previously intractable state/action space of complex planning tasks, but\nhallucinations limit their reliability, and thus, viability beyond a research\ncontext. Additionally, the prompt engineering required to achieve adequate\nsystem performance lacks transparency, and thus, repeatability. In contrast to\nLLM planning, symbolic planning methods offer strong reliability and\nrepeatability guarantees, but struggle to scale to the complexity and ambiguity\nof real-world tasks. We introduce a new robotic planning method that augments\nLLM planners with symbolic planning oversight to improve reliability and\nrepeatability, and provide a transparent approach to defining hard constraints\nwith considerably stronger clarity than traditional prompt engineering.\nImportantly, these augmentations preserve the reasoning capabilities of LLMs\nand retain impressive generalization in open-world environments. We demonstrate\nour approach in simulated and real-world environments. On the ALFWorld planning\nbenchmark, our approach outperforms current state-of-the-art methods, achieving\na near-perfect 99% success rate. Deployment of our method to a real-world\nquadruped robot resulted in 100% task success compared to 50% and 30% for pure\nLLM and symbolic planners across embodied pick and place tasks. Our approach\npresents an effective strategy to enhance the reliability, repeatability and\ntransparency of LLM-based robot planners while retaining their key strengths:\nflexibility and generalizability to complex real-world environments. We hope\nthat this work will contribute to the broad goal of building resilient embodied\nintelligent systems.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\uff0c\u5e76\u7ed3\u5408\u7b26\u53f7\u89c4\u5212\u6765\u63d0\u9ad8\u53ef\u9760\u6027\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u4efb\u52a1\u89c4\u5212\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u8f68\u8ff9\u9884\u6d4b\u7684\u4e00\u79cd\u9ad8\u5c42\u62bd\u8c61\u3002\u56e0\u6b64\uff0c\u8bba\u6587\u4e0e\u5927\u6a21\u578b\u5bc6\u5207\u76f8\u5173\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u6709\u4e00\u5b9a\u5173\u8054\u3002", "keywords": ["large language models", "LLMs", "task planning", "robotic planning", "embodied systems"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06410", "pdf": "https://arxiv.org/pdf/2510.06410", "abs": "https://arxiv.org/abs/2510.06410", "authors": ["Aochong Oliver Li", "Tanya Goyal"], "title": "Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?", "categories": ["cs.AI"], "comment": null, "summary": "Reasoning LLMs are trained to verbalize their reasoning process, yielding\nstrong gains on complex tasks. This transparency also opens a promising\ndirection: multiple reasoners can directly collaborate on each other's thinking\nwithin a shared trajectory, yielding better inference efficiency and\nexploration. A key prerequisite, however, is the ability to assess the\nusefulness and build on another model's partial thinking -- we call this\noff-trajectory reasoning. Our paper investigates a critical question: can\nstandard solo-reasoning training pipelines deliver desired off-trajectory\nbehaviors? We propose twin tests that capture the two extremes of the\noff-trajectory spectrum, namely Recoverability, which tests whether LLMs can\nbacktrack from \"distractions\" induced by misleading reasoning traces, and\nGuidability, which tests their ability to build upon correct reasoning from\nstronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and\nreveals a counterintuitive finding -- \"stronger\" LLMs on benchmarks are often\nmore fragile under distraction. Moreover, all models tested fail to effectively\nleverage guiding steps from collaborators on problems beyond their inherent\ncapabilities with solve rates remaining under 9.2%. Finally, we conduct control\nstudies to isolate the effects of three factors in post-training on these\nbehaviors: the choice of distillation teacher, the use of RL, and data\nselection strategy. Our results provide actionable insights for training\nnatively strong reasoning collaborators; e.g., we find that suboptimal\nrecoverability behaviors of teacher models are transferred to distilled\nstudents even if the distillation trajectories are correct. Taken together,\nthis work lays the groundwork for evaluating multi-model collaborations in\nshared reasoning trajectories and highlights the limitations of off-the-shelf\nreasoning LLMs.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u6a21\u578b\u5728\u63a8\u7406\u8f68\u8ff9\u4e0a\u7684\u534f\u4f5c\u80fd\u529b\u3002\u867d\u7136\u6807\u9898\u4e2d\u5305\u542b\"Trajectory\"\uff0c\u4f46\u8fd9\u91cc\u7684\"Trajectory\"\u6307\u7684\u662f\u63a8\u7406\u8f68\u8ff9\uff0c\u800c\u975e\u7269\u7406\u8f68\u8ff9\u6216\u8fd0\u52a8\u8f68\u8ff9\uff0c\u56e0\u6b64\u4e0e\u8f68\u8ff9\u9884\u6d4b\u7684\u76f4\u63a5\u76f8\u5173\u6027\u8f83\u4f4e\u3002\u4f46\u8bba\u6587\u7684\u6838\u5fc3\u5185\u5bb9\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u5bc6\u5207\u76f8\u5173\u3002", "keywords": ["LLMs", "Large Language Models", "reasoning", "reasoning trajectory", "foundation models"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06633", "pdf": "https://arxiv.org/pdf/2510.06633", "abs": "https://arxiv.org/abs/2510.06633", "authors": ["Kruthika Gangaraju", "Tanmayi Inaparthy", "Jiaqi Yang", "Yihao Zheng", "Fengpei Yuan"], "title": "Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care", "categories": ["cs.RO"], "comment": null, "summary": "People living with dementia (PLWDs) face progressively declining abilities in\nmedication management-from simple forgetfulness to complete task breakdown-yet\nmost assistive technologies fail to adapt to these changing needs. This\none-size-fits-all approach undermines autonomy, accelerates dependence, and\nincreases caregiver burden. Occupational therapy principles emphasize matching\nassistance levels to individual capabilities: minimal reminders for those who\nmerely forget, spatial guidance for those who misplace items, and comprehensive\nmultimodal support for those requiring step-by-step instruction. However,\nexisting robotic systems lack this adaptive, graduated response framework\nessential for maintaining PLWD independence. We present an adaptive multimodal\nrobotic framework using the Pepper robot that dynamically adjusts assistance\nbased on real-time assessment of user needs. Our system implements a\nhierarchical intervention model progressing from (1) simple verbal reminders,\nto (2) verbal + gestural cues, to (3) full multimodal guidance combining\nphysical navigation to medication locations with step-by-step verbal and\ngestural instructions. Powered by LLM-driven interaction strategies and\nmultimodal sensing, the system continuously evaluates task states to provide\njust-enough assistance-preserving autonomy while ensuring medication adherence.\nWe conducted a preliminary study with healthy adults and dementia care\nstakeholders in a controlled lab setting, evaluating the system's usability,\ncomprehensibility, and appropriateness of adaptive feedback mechanisms. This\nwork contributes: (1) a theoretically grounded adaptive assistance framework\ntranslating occupational therapy principles into HRI design, (2) a multimodal\nrobotic implementation that preserves PLWD dignity through graduated support,\nand (3) empirical insights into stakeholder perceptions of adaptive robotic\ncare.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper describes a robotic system for medication management that adapts its assistance level based on user needs, powered by LLM-driven interaction strategies. While the primary focus is not trajectory prediction, the robotic navigation aspect and use of LLMs contribute to a moderate relevance. The system uses multimodal guidance which may involve path planning. The LLM component is a key factor in the relevance.", "keywords": ["LLM", "Large Language Models", "multimodal guidance", "robotic navigation"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06534", "pdf": "https://arxiv.org/pdf/2510.06534", "abs": "https://arxiv.org/abs/2510.06534", "authors": ["Jiahe Jin", "Abhijay Paladugu", "Chenyan Xiong"], "title": "Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agentic search leverages large language models (LLMs) to interpret complex\nuser information needs and execute a multi-step process of planning, searching,\nand synthesizing information to provide answers. This paradigm introduces\nunique challenges for LLMs' reasoning and agentic capabilities when interacting\nwith retrieval systems and the broader web. In this paper, we propose a\nreasoning-driven LLM-based pipeline to study effective reasoning behavior\npatterns in agentic search. Using this pipeline, we analyze successful agentic\nsearch trajectories and identify four beneficial reasoning behaviors:\nInformation Verification, Authority Evaluation, Adaptive Search, and Error\nRecovery. Based on these findings, we propose a technique called Behavior\nPriming to train more effective agentic search models. It synthesizes agentic\nsearch trajectories that exhibit these four behaviors and integrates them into\nthe agentic search model through supervised fine-tuning (SFT), followed by\nstandard reinforcement learning (RL). Experiments on three benchmarks (GAIA,\nWebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in\nLlama3.2-3B and Qwen3-1.7B compared to directly training agentic search models\nwith RL. Crucially, we demonstrate that the desired reasoning behaviors in the\nSFT data, rather than the correctness of the final answer, is the critical\nfactor for achieving strong final performance after RL: fine-tuning on\ntrajectories with desirable reasoning behaviors but incorrect answers leads to\nbetter performance than fine-tuning on trajectories with correct answers. Our\nanalysis further reveals the underlying mechanism: the introduced reasoning\nbehaviors endow models with more effective exploration (higher pass@k and\nentropy) and test-time scaling (longer trajectories) capabilities, providing a\nstrong foundation for RL. Our code will be released as open source.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on using Large Language Models (LLMs) for agentic search, analyzing reasoning behaviors and improving performance through behavior priming. While it involves trajectories of agentic search, it doesn't directly deal with trajectory prediction in the sense of predicting the future path of moving objects. However, the analysis of search trajectories and the use of LLMs make it somewhat relevant.", "keywords": ["Large Language Models", "LLMs", "agentic search", "trajectories", "reasoning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07077", "pdf": "https://arxiv.org/pdf/2510.07077", "abs": "https://arxiv.org/abs/2510.07077", "authors": ["Kento Kawaharazuka", "Jihoon Oh", "Jun Yamada", "Ingmar Posner", "Yuke Zhu"], "title": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted to IEEE Access, website: https://vla-survey.github.io", "summary": "Amid growing efforts to leverage advances in large language models (LLMs) and\nvision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models\nhave recently gained significant attention. By unifying vision, language, and\naction data at scale, which have traditionally been studied separately, VLA\nmodels aim to learn policies that generalise across diverse tasks, objects,\nembodiments, and environments. This generalisation capability is expected to\nenable robots to solve novel downstream tasks with minimal or no additional\ntask-specific data, facilitating more flexible and scalable real-world\ndeployment. Unlike previous surveys that focus narrowly on action\nrepresentations or high-level model architectures, this work offers a\ncomprehensive, full-stack review, integrating both software and hardware\ncomponents of VLA systems. In particular, this paper provides a systematic\nreview of VLAs, covering their strategy and architectural transition,\narchitectures and building blocks, modality-specific processing techniques, and\nlearning paradigms. In addition, to support the deployment of VLAs in\nreal-world robotic applications, we also review commonly used robot platforms,\ndata collection strategies, publicly available datasets, data augmentation\nmethods, and evaluation benchmarks. Throughout this comprehensive survey, this\npaper aims to offer practical guidance for the robotics community in applying\nVLAs to real-world robotic systems. All references categorized by training\napproach, evaluation method, modality, and dataset are available in the table\non our project website: https://vla-survey.github.io .", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper reviews Vision-Language-Action (VLA) models for robotics, which leverage large language models (LLMs) and vision-language models (VLMs). While it doesn't directly focus on trajectory prediction, the action component of VLA models could potentially involve trajectory generation or prediction as part of robotic tasks. The strong connection to LLMs earns it a moderate relevance score.", "keywords": ["large language models", "LLMs", "vision-language models", "VLMs", "robotics", "action"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07133", "pdf": "https://arxiv.org/pdf/2510.07133", "abs": "https://arxiv.org/abs/2510.07133", "authors": ["Tony Zhang", "Burak Kantarci", "Umair Siddique"], "title": "A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Ensuring the safety of self-driving cars remains a major challenge due to the\ncomplexity and unpredictability of real-world driving environments. Traditional\ntesting methods face significant limitations, such as the oracle problem, which\nmakes it difficult to determine whether a system's behavior is correct, and the\ninability to cover the full range of scenarios an autonomous vehicle may\nencounter. In this paper, we introduce a digital twin-driven metamorphic\ntesting framework that addresses these challenges by creating a virtual replica\nof the self-driving system and its operating environment. By combining digital\ntwin technology with AI-based image generative models such as Stable Diffusion,\nour approach enables the systematic generation of realistic and diverse driving\nscenes. This includes variations in weather, road topology, and environmental\nfeatures, all while maintaining the core semantics of the original scenario.\nThe digital twin provides a synchronized simulation environment where changes\ncan be tested in a controlled and repeatable manner. Within this environment,\nwe define three metamorphic relations inspired by real-world traffic rules and\nvehicle behavior. We validate our framework in the Udacity self-driving\nsimulator and demonstrate that it significantly enhances test coverage and\neffectiveness. Our method achieves the highest true positive rate (0.719), F1\nscore (0.689), and precision (0.662) compared to baseline approaches. This\npaper highlights the value of integrating digital twins with AI-powered\nscenario generation to create a scalable, automated, and high-fidelity testing\nsolution for autonomous vehicle safety.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper discusses autonomous driving systems and uses generative models (Stable Diffusion, an AI-based image generative model) to create driving scenarios for testing. While it doesn't directly focus on trajectory prediction, autonomous driving inherently involves it. The use of generative models, though not explicitly a large language model, contributes to the relevance. The connection to trajectory prediction is implicit within the context of autonomous driving.", "keywords": ["autonomous driving", "generative model", "Stable Diffusion", "digital twin", "driving scenarios"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07134", "pdf": "https://arxiv.org/pdf/2510.07134", "abs": "https://arxiv.org/abs/2510.07134", "authors": ["Jiahang Liu", "Yunpeng Qi", "Jiazhao Zhang", "Minghan Li", "Shaoan Wang", "Kui Wu", "Hanjing Ye", "Hong Zhang", "Zhibo Chen", "Fangwei Zhong", "Zhizheng Zhang", "He Wang"], "title": "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Project page: https://pku-epic.github.io/TrackVLA-plus-plus-Web/", "summary": "Embodied Visual Tracking (EVT) is a fundamental ability that underpins\npractical applications, such as companion robots, guidance robots and service\nassistants, where continuously following moving targets is essential. Recent\nadvances have enabled language-guided tracking in complex and unstructured\nscenes. However, existing approaches lack explicit spatial reasoning and\neffective temporal memory, causing failures under severe occlusions or in the\npresence of similar-looking distractors. To address these challenges, we\npresent TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances\nembodied visual tracking with two key modules, a spatial reasoning mechanism\nand a Target Identification Memory (TIM). The reasoning module introduces a\nChain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative\nposition and encodes it as a compact polar-coordinate token for action\nprediction. Guided by these spatial priors, the TIM employs a gated update\nstrategy to preserve long-horizon target memory, ensuring spatiotemporal\nconsistency and mitigating target loss during extended occlusions. Extensive\nexperiments show that TrackVLA++ achieves state-of-the-art performance on\npublic benchmarks across both egocentric and multi-camera settings. On the\nchallenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading\napproach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong\nzero-shot generalization, enabling robust real-world tracking in dynamic and\noccluded scenarios.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u5177\u8eab\u89c6\u89c9\u8ffd\u8e2a\uff08Embodied Visual Tracking\uff09\uff0c\u76ee\u6807\u662f\u8fde\u7eed\u8ddf\u8e2a\u79fb\u52a8\u76ee\u6807\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u8ddf\u8e2a\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u9884\u6d4b\u77ed\u671f\u8f68\u8ff9\u7684\u4e00\u79cd\u5f62\u5f0f\u3002\u8bba\u6587\u4e2d\u4f7f\u7528\u4e86\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\uff0c\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u5927\u578b\u6a21\u578b\uff0c\u7279\u522b\u662f\u5f53\u5b83\u96c6\u6210\u4e86\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u65f6\u3002\u7136\u800c\uff0c\u5b83\u4e0e\u4f20\u7edf\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8054\u7cfb\u5e76\u4e0d\u76f4\u63a5\uff0c\u800c\u4e14\u8bba\u6587\u7684\u91cd\u70b9\u5728\u4e8e\u89c6\u89c9\u548c\u7a7a\u95f4\u63a8\u7406\uff0c\u800c\u975e\u8bed\u8a00\u5efa\u6a21\u3002\u56e0\u6b64\uff0c\u76f8\u5173\u6027\u4e2d\u7b49\u3002", "keywords": ["Embodied Visual Tracking", "VLA models", "Vision-Language-Action", "tracking", "action prediction"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07181", "pdf": "https://arxiv.org/pdf/2510.07181", "abs": "https://arxiv.org/abs/2510.07181", "authors": ["Yi Han", "Cheng Chi", "Enshen Zhou", "Shanyu Rong", "Jingkun An", "Pengwei Wang", "Zhongyuan Wang", "Lu Sheng", "Shanghang Zhang"], "title": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "9 pages, 6 figures", "summary": "Vision-Language Models (VLMs) have shown remarkable capabilities in spatial\nreasoning, yet they remain fundamentally limited to qualitative precision and\nlack the computational precision required for real-world robotics. Current\napproaches fail to leverage metric cues from depth sensors and camera\ncalibration, instead reducing geometric problems to pattern recognition tasks\nthat cannot deliver the centimeter-level accuracy essential for robotic\nmanipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel\nframework that transforms VLMs from perceptual estimators to geometric\ncomputers by enabling them to generate and execute precise geometric\ncomputations through external tools. Rather than attempting to internalize\ncomplex geometric operations within neural networks, TIGeR empowers models to\nrecognize geometric reasoning requirements, synthesize appropriate\ncomputational code, and invoke specialized libraries for exact calculations. To\nsupport this paradigm, we introduce TIGeR-300K, a comprehensive\ntool-invocation-oriented dataset covering point transformations, pose\nestimation, trajectory generation, and spatial compatibility verification,\ncomplete with tool invocation sequences and intermediate computations. Through\na two-stage training pipeline combining supervised fine-tuning (SFT) and\nreinforcement fine-tuning (RFT) with our proposed hierarchical reward design,\nTIGeR achieves SOTA performance on geometric reasoning benchmarks while\ndemonstrating centimeter-level precision in real-world robotic manipulation\ntasks.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper integrates Vision-Language Models (VLMs) with geometric reasoning for robotics. While the primary focus is on robotics and geometric reasoning using VLMs, the abstract mentions \"trajectory generation\" as one of the tasks supported by their framework and dataset. This connects to the trajectory prediction aspect, although it's not the central theme. The use of VLMs also contributes to the relevance.", "keywords": ["Vision-Language Models", "VLMs", "trajectory generation", "geometric reasoning"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07210", "pdf": "https://arxiv.org/pdf/2510.07210", "abs": "https://arxiv.org/abs/2510.07210", "authors": ["Donald Pfaffmann", "Matthias Klusch", "Marcel Steinmetz"], "title": "HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We present a novel hybrid learning-assisted planning method, named HyPlan,\nfor solving the collision-free navigation problem for self-driving cars in\npartially observable traffic environments. HyPlan combines methods for\nmulti-agent behavior prediction, deep reinforcement learning with proximal\npolicy optimization and approximated online POMDP planning with heuristic\nconfidence-based vertical pruning to reduce its execution time without\ncompromising safety of driving. Our experimental performance analysis on the\nCARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealed\nthat HyPlan may navigate safer than selected relevant baselines and perform\nsignificantly faster than considered alternative online POMDP planners.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u6d89\u53ca\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u4f7f\u7528\u4e86\u884c\u4e3a\u9884\u6d4b\u65b9\u6cd5\uff0c\u56e0\u6b64\u4e0e\u8f68\u8ff9\u9884\u6d4b\u76f8\u5173\u3002\u4f46\u8bba\u6587\u4e2d\u672a\u4f7f\u7528\u6216\u63d0\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u6240\u4ee5\u76f8\u5173\u6027\u4e0d\u9ad8\u3002", "keywords": ["trajectory prediction", "behavior prediction", "autonomous driving"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07092", "pdf": "https://arxiv.org/pdf/2510.07092", "abs": "https://arxiv.org/abs/2510.07092", "authors": ["Riccardo Mereu", "Aidan Scannell", "Yuxin Hou", "Yi Zhao", "Aditya Jitta", "Antonio Dominguez", "Luigi Acerbi", "Amos Storkey", "Paul Chang"], "title": "Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "6 pages, 3 figures, 1X world model challenge technical report", "summary": "World models are a powerful paradigm in AI and robotics, enabling agents to\nreason about the future by predicting visual observations or compact latent\nstates. The 1X World Model Challenge introduces an open-source benchmark of\nreal-world humanoid interaction, with two complementary tracks: sampling,\nfocused on forecasting future image frames, and compression, focused on\npredicting future discrete latent codes. For the sampling track, we adapt the\nvideo generation foundation model Wan-2.2 TI2V-5B to video-state-conditioned\nfuture frame prediction. We condition the video generation on robot states\nusing AdaLN-Zero, and further post-train the model using LoRA. For the\ncompression track, we train a Spatio-Temporal Transformer model from scratch.\nOur models achieve 23.0 dB PSNR in the sampling task and a Top-500 CE of 6.6386\nin the compression task, securing 1st place in both challenges.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u6d89\u53ca\u4e16\u754c\u6a21\u578b\uff0c\u5176\u4e2d\u5305\u542b\u9884\u6d4b\u672a\u6765\u56fe\u50cf\u5e27\uff0c\u8fd9\u4e0e\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u9884\u6d4b\u672a\u6765\u884c\u4e3a\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002\u6b64\u5916\uff0c\u8bba\u6587\u4f7f\u7528\u4e86\u89c6\u9891\u751f\u6210\u57fa\u7840\u6a21\u578b\uff08foundation model\uff09\uff0c\u8fd9\u4e0e\u5927\u6a21\u578b\u76f8\u5173\u3002\u4f46\u662f\uff0c\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u4eba\u578b\u673a\u5668\u4eba\u7684\u4e16\u754c\u5efa\u6a21\uff0c\u4e0e\u4f20\u7edf\u7684\u8f68\u8ff9\u9884\u6d4b\u4efb\u52a1\uff08\u5982\u884c\u4eba\u6216\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\uff09\u5173\u8054\u8f83\u5f31\uff0c\u4e14\u5927\u6a21\u578b\u4e3b\u8981\u7528\u4e8e\u56fe\u50cf\u751f\u6210\uff0c\u4e0e\u8bed\u8a00\u6a21\u578b\u5173\u8054\u4e0d\u5927\u3002", "keywords": ["World Model", "video generation foundation model", "future frame prediction", "foundation models"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.06225", "pdf": "https://arxiv.org/pdf/2510.06225", "abs": "https://arxiv.org/abs/2510.06225", "authors": ["Gang Li", "Jie Lin", "Yining Tang", "Ziteng Wang", "Yirui Huang", "Junyu Zhang", "Shuang Luo", "Chao Wu", "Yike Guo"], "title": "Generalized Multi-agent Social Simulation Framework", "categories": ["physics.soc-ph", "cs.AI"], "comment": null, "summary": "Multi-agent social interaction has clearly benefited from Large Language\nModels. However, current simulation systems still face challenges such as\ndifficulties in scaling to diverse scenarios and poor reusability due to a lack\nof modular design. To address these issues, we designed and developed a\nmodular, object-oriented framework that organically integrates various base\nclasses through a hierarchical structure, harvesting scalability and\nreusability. We inherited the framework to realize common derived classes.\nAdditionally, a memory summarization mechanism is proposed to filter and\ndistill relevant information from raw memory data, prioritizing contextually\nsalient events and interactions. By selecting and combining some necessary\nderived classes, we customized a specific simulated environment. Utilizing this\nsimulated environment, we successfully simulated human interactions on social\nmedia, replicating real-world online social behaviors. The source code for the\nproject will be released and evolve.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper discusses multi-agent social simulation and integrates Large Language Models. While it doesn't explicitly mention trajectory prediction, the simulation of social interactions could potentially involve predicting agent movements or behaviors. The use of LLMs is a key aspect of the paper, increasing its relevance.", "keywords": ["Large Language Models", "multi-agent social simulation"]}, "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
