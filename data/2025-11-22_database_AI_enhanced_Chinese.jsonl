{"id": "2511.16131", "pdf": "https://arxiv.org/pdf/2511.16131", "abs": "https://arxiv.org/abs/2511.16131", "authors": ["Xuan-Quang Phan", "Tan-Ha Mai", "Thai-Duy Dinh", "Minh-Thuan Nguyen", "Lam-Son L\u00ea"], "title": "AskDB: An LLM Agent for Natural Language Interaction with Relational Databases", "categories": ["cs.DB", "cs.AI"], "comment": "15 pages, 10 figures", "summary": "Interacting with relational databases remains challenging for users across different expertise levels, particularly when composing complex analytical queries or performing administrative tasks. Existing systems typically address either natural language querying or narrow aspects of database administration, lacking a unified and intelligent interface for general-purpose database interaction. We introduce AskDB, a large language model powered agent designed to bridge this gap by supporting both data analysis and administrative operations over SQL databases through natural language. Built on Gemini 2, AskDB integrates two key innovations: a dynamic schema-aware prompting mechanism that effectively incorporates database metadata, and a task decomposition framework that enables the agent to plan and execute multi-step actions. These capabilities allow AskDB to autonomously debug derived SQL, retrieve contextual information via real-time web search, and adaptively refine its responses. We evaluate AskDB on a widely used Text-to-SQL benchmark and a curated set of DBA tasks, demonstrating strong performance in both analytical and administrative scenarios. Our results highlight the potential of AskDB as a unified and intelligent agent for relational database systems, offering an intuitive and accessible experience for end users.", "AI": {"tldr": "AskDB \u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fdAgent\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u652f\u6301SQL\u6570\u636e\u5e93\u7684\u6570\u636e\u5206\u6790\u548c\u7ba1\u7406\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u7edf\u4e00\u7684\u667a\u80fd\u754c\u9762\uff0c\u96be\u4ee5\u652f\u6301\u901a\u7528\u6570\u636e\u5e93\u4ea4\u4e92\uff0c\u7279\u522b\u662f\u590d\u6742\u5206\u6790\u67e5\u8be2\u548c\u7ba1\u7406\u4efb\u52a1\u3002", "method": "AskDB\u57fa\u4e8eGemini 2\uff0c\u96c6\u6210\u4e86\u52a8\u6001\u6a21\u5f0f\u611f\u77e5\u63d0\u793a\u673a\u5236\u548c\u4efb\u52a1\u5206\u89e3\u6846\u67b6\uff0c\u5b9e\u73b0\u81ea\u4e3b\u8c03\u8bd5SQL\u3001\u68c0\u7d22\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u81ea\u9002\u5e94\u4f18\u5316\u3002", "result": "\u5728Text-to-SQL\u57fa\u51c6\u6d4b\u8bd5\u548cDBA\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5206\u6790\u548c\u7ba1\u7406\u573a\u666f\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "AskDB\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684\u667a\u80fdAgent\uff0c\u4e3a\u5173\u7cfb\u6570\u636e\u5e93\u7cfb\u7edf\u63d0\u4f9b\u4e86\u76f4\u89c2\u6613\u7528\u7684\u4f53\u9a8c\u3002", "summary_zh": "\u4e0e\u5173\u7cfb\u6570\u636e\u5e93\u4ea4\u4e92\u5bf9\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7684\u7528\u6237\u6765\u8bf4\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5728\u7f16\u5199\u590d\u6742\u7684\u5206\u6790\u67e5\u8be2\u6216\u6267\u884c\u7ba1\u7406\u4efb\u52a1\u65f6\u3002\u73b0\u6709\u7684\u7cfb\u7edf\u901a\u5e38\u53ea\u5173\u6ce8\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u6216\u6570\u636e\u5e93\u7ba1\u7406\u7684\u72ed\u7a84\u65b9\u9762\uff0c\u7f3a\u4e4f\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u667a\u80fd\u7684\u754c\u9762\u6765\u8fdb\u884c\u901a\u7528\u6570\u636e\u5e93\u4ea4\u4e92\u3002\u6211\u4eec\u4ecb\u7ecd\u4e86AskDB\uff0c\u4e00\u4e2a\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684Agent\uff0c\u65e8\u5728\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u652f\u6301SQL\u6570\u636e\u5e93\u4e0a\u7684\u6570\u636e\u5206\u6790\u548c\u7ba1\u7406\u64cd\u4f5c\uff0c\u4ece\u800c\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002AskDB\u5efa\u7acb\u5728Gemini 2\u4e4b\u4e0a\uff0c\u96c6\u6210\u4e86\u4e24\u9879\u5173\u952e\u521b\u65b0\uff1a\u4e00\u79cd\u52a8\u6001\u7684\u3001\u6a21\u5f0f\u611f\u77e5\u7684\u63d0\u793a\u673a\u5236\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u6574\u5408\u6570\u636e\u5e93\u5143\u6570\u636e\uff1b\u4ee5\u53ca\u4e00\u4e2a\u4efb\u52a1\u5206\u89e3\u6846\u67b6\uff0c\u4f7fAgent\u80fd\u591f\u8ba1\u5212\u548c\u6267\u884c\u591a\u6b65\u9aa4\u64cd\u4f5c\u3002\u8fd9\u4e9b\u80fd\u529b\u4f7fAskDB\u80fd\u591f\u81ea\u4e3b\u8c03\u8bd5\u6d3e\u751f\u7684SQL\uff0c\u901a\u8fc7\u5b9e\u65f6\u7f51\u7edc\u641c\u7d22\u68c0\u7d22\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5e76\u81ea\u9002\u5e94\u5730\u6539\u8fdb\u5176\u54cd\u5e94\u3002\u6211\u4eec\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684Text-to-SQL\u57fa\u51c6\u548c\u4e00\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684DBA\u4efb\u52a1\u96c6\u4e0a\u8bc4\u4f30\u4e86AskDB\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5206\u6790\u548c\u7ba1\u7406\u573a\u666f\u4e2d\u7684\u5f3a\u5927\u6027\u80fd\u3002\u6211\u4eec\u7684\u7ed3\u679c\u7a81\u663e\u4e86AskDB\u4f5c\u4e3a\u5173\u7cfb\u6570\u636e\u5e93\u7cfb\u7edf\u7684\u7edf\u4e00\u548c\u667a\u80fdAgent\u7684\u6f5c\u529b\uff0c\u4e3a\u7ec8\u7aef\u7528\u6237\u63d0\u4f9b\u4e86\u76f4\u89c2\u548c\u53ef\u8bbf\u95ee\u7684\u4f53\u9a8c\u3002"}}
{"id": "2511.16134", "pdf": "https://arxiv.org/pdf/2511.16134", "abs": "https://arxiv.org/abs/2511.16134", "authors": ["Marijan Soric", "C\u00e9cile Gracianne", "Ioana Manolescu", "Pierre Senellart"], "title": "Benchmarking Table Extraction from Heterogeneous Scientific Extraction Documents", "categories": ["cs.DB"], "comment": null, "summary": "Table Extraction (TE) consists in extracting tables from PDF documents, in a structured format which can be automatically processed. While numerous TE tools exist, the variety of methods and techniques makes it difficult for users to choose an appropriate one. We propose a novel benchmark for assessing end-to-end TE methods (from PDF to the final table). We contribute an analysis of TE evaluation metrics, and the design of a rigorous evaluation process, which allows scoring each TE sub-task as well as end-to-end TE, and captures model uncertainty. Along with a prior dataset, our benchmark comprises two new heterogeneous datasets of 37k samples. We run our benchmark on diverse models, including off-the-shelf libraries, software tools, large vision language models, and approaches based on computer vision. The results demonstrate that TE remains challenging: current methods suffer from a lack of generalizability when facing heterogeneous data, and from limitations in robustness and interpretability.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.16138", "pdf": "https://arxiv.org/pdf/2511.16138", "abs": "https://arxiv.org/abs/2511.16138", "authors": ["Weiping Yu", "Ye Jiarui", "He Mengke", "Junfeng Liu", "Siqiang Luo"], "title": "On 10x Better Scalability: KV Stores Scale Up KV Cache", "categories": ["cs.DB"], "comment": null, "summary": "Large language models (LLMs) rely on Key-Value (KV) cache to reduce time- to-first-token (TTFT) latency, but existing disk-based KV cache systems using file-per-object layouts suffer from severe scalability bottlenecks due to file system metadata overhead, I/O inefficiency, and poor spatial locality. This paper presents SGLANG-LSM, a database-inspired system that leverages Log-Structured Merge- tree (LSM-tree) architectures for scalable KV cache management. SGLANG-LSM implements a layered system design with three coordinated components: (1) a prefix-preserving storage engine that maintains token sequence locality while efficiently storing large KV cache tensors through key-value separation, (2) an adaptive controller that dynamically optimizes LSM-tree configurations based on shifting workload characteristics, and (3) runtime services including batch opera- tions and automatic resource management for production deployment. Evaluation on large-scale dynamic workloads demonstrates that SGLANG-LSM significantly improves cache hits by up to 143% and reduces TTFT by up to 24% compared to state-of-the-art systems, representing the first systematic application of database storage architectures to large-scale LLM cache management.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.16366", "pdf": "https://arxiv.org/pdf/2511.16366", "abs": "https://arxiv.org/abs/2511.16366", "authors": ["Gustavo Laranja Thomaello", "Thomaz Yeiden Busnardo Aguena", "Eric Trevelato Costa", "Rafael Bas\u00e1glia Rosante", "Thiago Rodrigo Ramos", "Daiane Aparecida Zuanetti", "Edgar Dutra Zanotto"], "title": "From Patents to Dataset: Scraping for Oxide Glass Compositions and Properties", "categories": ["cs.DB", "cond-mat.mtrl-sci"], "comment": null, "summary": "In this work, we present web scraping techniques to extract in- formation from patent tables, clean and structure them for future use in predictive machine learning models to develop new glasses. We extracted compositions and three properties relevant to the development of new glasses and structured them into a database to be used together with information from other available datasets. We also analyzed the consistency of the information obtained and what it adds to the existing databases. The extracted liquidus temperatures comprise 5,696 compositions; the second subset includes 4,298 refractive indexes and, finally, 1,771 compositions with Abbe numbers. The extraction performed here increases the available information by approximately 10.4% for liquidus temperature, 6.6% for refractive index, and 4.9% for Abbe number. The impact extends beyond quantity: the newly extracted data introduce compositions with property values that are more diverse than those in existing databases, thereby expanding the accessible compositional and property space for glass modeling applications. We emphasize that the compositions of the new database contain relatively more titanium, magnesium, zirconium, niobium, iron, tin, and yttrium oxides than those of the existing bases.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.16455", "pdf": "https://arxiv.org/pdf/2511.16455", "abs": "https://arxiv.org/abs/2511.16455", "authors": ["Pei Mu", "Anderson Chaves Carniel", "Antonio Barbalace", "Amir Shaikhha"], "title": "[Experiment, Analysis, and Benchmark] Systematic Evaluation of Plan-based Adaptive Query Processing", "categories": ["cs.DB"], "comment": null, "summary": "Unreliable cardinality estimation remains a critical performance bottleneck in database management systems (DBMSs). Adaptive Query Processing (AQP) strategies address this limitation by providing a more robust query execution mechanism. Specifically, plan-based AQP achieves this by incrementally refining cardinality using feedback from the execution of sub-plans. However, the actual reason behind the improvements of plan-based AQP, especially across different storage architectures (on-disk vs. in-memory DBMSs), remains unexplored.\n  This paper presents the first comprehensive analysis of state-of-the-art plan-based AQP. We implement and evaluate this strategy on both on-disk and in-memory DBMSs across two benchmarks. Our key findings reveal that while plan-based AQP provides overall speedups in both environments, the sources of improvement differ significantly. In the on-disk DBMS, PostgreSQL, performance gains primarily come from the query plan reorderings, but not the cardinality updating mechanism; in fact, updating cardinalities introduces measurable overhead. Conversely, in the in-memory DBMS, DuckDB, cardinality refinement drives significant performance improvements for most queries. We also observe significant performance benefits of the plan-based AQP compared to a state-of-the-art related-based AQP method. These observations provide crucial insights for researchers on when and why plan-based AQP is effective, and ultimately guide database system developers on the tradeoffs between the implementation effort and performance improvements.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.16402", "pdf": "https://arxiv.org/pdf/2511.16402", "abs": "https://arxiv.org/abs/2511.16402", "authors": ["Jacopo Tagliabue", "Federico Bianchi", "Ciro Greco"], "title": "Trustworthy AI in the Agentic Lakehouse: from Concurrency to Governance", "categories": ["cs.AI", "cs.DB"], "comment": "AAAI26, pre-print of paper accepted at the Trustworthy Agentic AI Workshop", "summary": "Even as AI capabilities improve, most enterprises do not consider agents trustworthy enough to work on production data. In this paper, we argue that the path to trustworthy agentic workflows begins with solving the infrastructure problem first: traditional lakehouses are not suited for agent access patterns, but if we design one around transactions, governance follows. In particular, we draw an operational analogy to MVCC in databases and show why a direct transplant fails in a decoupled, multi-language setting. We then propose an agent-first design, Bauplan, that reimplements data and compute isolation in the lakehouse. We conclude by sharing a reference implementation of a self-healing pipeline in Bauplan, which seamlessly couples agent reasoning with all the desired guarantees for correctness and trust.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
