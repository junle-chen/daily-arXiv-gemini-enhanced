{"id": "2512.03278", "pdf": "https://arxiv.org/pdf/2512.03278", "abs": "https://arxiv.org/abs/2512.03278", "authors": ["Michael Theologitis", "Dan Suciu"], "title": "Thucy: An LLM-based Multi-Agent System for Claim Verification across Relational Databases", "categories": ["cs.DB", "cs.AI"], "comment": "Accepted at AAAI 2026 Workshop on LLM-based Multi-Agent Systems (LaMAS)", "summary": "In today's age, it is becoming increasingly difficult to decipher truth from lies. Every day, politicians, media outlets, and public figures make conflicting claims$\\unicode{x2014}$often about topics that can, in principle, be verified against structured data. For instance, statements about crime rates, economic growth or healthcare can all be verified against official public records and structured datasets. Building a system that can automatically do that would have sounded like science fiction just a few years ago. Yet, with the extraordinary progress in LLMs and agentic AI, this is now within reach. Still, there remains a striking gap between what is technically possible and what is being demonstrated by recent work. Most existing verification systems operate only on small, single-table databases$\\unicode{x2014}$typically a few hundred rows$\\unicode{x2014}$that conveniently fit within an LLM's context window.\n  In this paper we report our progress on Thucy, the first cross-database, cross-table multi-agent claim verification system that also provides concrete evidence for each verification verdict. Thucy remains completely agnostic to the underlying data sources before deployment and must therefore autonomously discover, inspect, and reason over all available relational databases to verify claims. Importantly, Thucy also reports the exact SQL queries that support its verdict (whether the claim is accurate or not) offering full transparency to expert users familiar with SQL. When evaluated on the TabFact dataset$\\unicode{x2014}$the standard benchmark for fact verification over structured data$\\unicode{x2014}$Thucy surpasses the previous state of the art by 5.6 percentage points in accuracy (94.3% vs. 88.7%).", "AI": {"tldr": "Thucy\u662f\u4e00\u4e2a\u8de8\u6570\u636e\u5e93\u3001\u8de8\u8868\u683c\u7684\u591a\u667a\u80fd\u4f53\u58f0\u660e\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u5b83\u80fd\u4e3a\u6bcf\u4e2a\u9a8c\u8bc1\u7ed3\u8bba\u63d0\u4f9b\u5177\u4f53\u7684\u8bc1\u636e\uff0c\u5e76\u5728TabFact\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002", "motivation": "\u5f53\u524d\u96be\u4ee5\u8fa8\u522b\u771f\u5047\u4fe1\u606f\uff0c\u5c24\u5176\u662f\u5728\u53ef\u4ee5\u6839\u636e\u7ed3\u6784\u5316\u6570\u636e\u9a8c\u8bc1\u7684\u58f0\u660e\u4e0a\u3002\u73b0\u6709\u9a8c\u8bc1\u7cfb\u7edf\u901a\u5e38\u53ea\u80fd\u5728\u5c0f\u578b\u5355\u8868\u6570\u636e\u5e93\u4e0a\u8fd0\u884c\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "Thucy\u7cfb\u7edf\u81ea\u4e3b\u53d1\u73b0\u3001\u68c0\u67e5\u548c\u63a8\u7406\u6240\u6709\u53ef\u7528\u7684\u5173\u7cfb\u6570\u636e\u5e93\u6765\u9a8c\u8bc1\u58f0\u660e\uff0c\u5e76\u62a5\u544a\u652f\u6301\u5176\u7ed3\u8bba\u7684SQL\u67e5\u8be2\u3002", "result": "\u5728TabFact\u6570\u636e\u96c6\u4e0a\uff0cThucy\u7684\u51c6\u786e\u7387\u8d85\u8fc7\u4e86\u4e4b\u524d\u7684state of the art 5.6\u4e2a\u767e\u5206\u70b9\uff0894.3% vs. 88.7%\uff09\u3002", "conclusion": "Thucy\u662f\u7b2c\u4e00\u4e2a\u8de8\u6570\u636e\u5e93\u3001\u8de8\u8868\u683c\u7684\u591a\u667a\u80fd\u4f53\u58f0\u660e\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u5b83\u901a\u8fc7\u63d0\u4f9b\u900f\u660e\u7684SQL\u67e5\u8be2\u6765\u652f\u6301\u5176\u9a8c\u8bc1\u7ed3\u679c\uff0c\u5e76\u5728\u4e8b\u5b9e\u6838\u67e5\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002", "summary_zh": "\u5f53\u4eca\u65f6\u4ee3\uff0c\u8fa8\u522b\u771f\u5047\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\u3002\u653f\u5ba2\u3001\u5a92\u4f53\u548c\u516c\u4f17\u4eba\u7269\u6bcf\u5929\u90fd\u5728\u53d1\u8868\u76f8\u4e92\u77db\u76fe\u7684\u58f0\u660e\uff0c\u8fd9\u4e9b\u58f0\u660e\u901a\u5e38\u662f\u5173\u4e8e\u539f\u5219\u4e0a\u53ef\u4ee5\u6839\u636e\u7ed3\u6784\u5316\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u7684\u4e3b\u9898\u3002\u4f8b\u5982\uff0c\u5173\u4e8e\u72af\u7f6a\u7387\u3001\u7ecf\u6d4e\u589e\u957f\u6216\u533b\u7597\u4fdd\u5065\u7684\u58f0\u660e\u90fd\u53ef\u4ee5\u6839\u636e\u5b98\u65b9\u516c\u5171\u8bb0\u5f55\u548c\u7ed3\u6784\u5316\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u81ea\u52a8\u6267\u884c\u6b64\u64cd\u4f5c\u7684\u7cfb\u7edf\u5728\u51e0\u5e74\u524d\u542c\u8d77\u6765\u8fd8\u50cf\u662f\u79d1\u5e7b\u5c0f\u8bf4\u3002\u7136\u800c\uff0c\u968f\u7740LLM\u548cAgentic AI\u7684\u975e\u51e1\u8fdb\u6b65\uff0c\u73b0\u5728\u5df2\u7ecf\u89e6\u624b\u53ef\u53ca\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5728\u6280\u672f\u4e0a\u53ef\u884c\u7684\u548c\u6700\u8fd1\u7684\u5de5\u4f5c\u6240\u5c55\u793a\u7684\u4e4b\u95f4\u4ecd\u7136\u5b58\u5728\u663e\u7740\u5dee\u8ddd\u3002\u5927\u591a\u6570\u73b0\u6709\u7684\u9a8c\u8bc1\u7cfb\u7edf\u4ec5\u5728\u5c0f\u578b\u5355\u8868\u6570\u636e\u5e93\u4e0a\u8fd0\u884c\uff0c\u8fd9\u4e9b\u6570\u636e\u5e93\u901a\u5e38\u53ea\u6709\u51e0\u767e\u884c\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5730\u653e\u5165LLM\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u62a5\u544a\u4e86\u6211\u4eec\u5728Thucy\u4e0a\u7684\u8fdb\u5c55\uff0cThucy\u662f\u7b2c\u4e00\u4e2a\u8de8\u6570\u636e\u5e93\u3001\u8de8\u8868\u7684\u591a\u667a\u80fd\u4f53\u58f0\u660e\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u5b83\u8fd8\u4e3a\u6bcf\u4e2a\u9a8c\u8bc1\u7ed3\u8bba\u63d0\u4f9b\u5177\u4f53\u7684\u8bc1\u636e\u3002Thucy\u5728\u90e8\u7f72\u4e4b\u524d\u5b8c\u5168\u4e0d\u77e5\u9053\u5e95\u5c42\u6570\u636e\u6e90\uff0c\u56e0\u6b64\u5fc5\u987b\u81ea\u4e3b\u53d1\u73b0\u3001\u68c0\u67e5\u548c\u63a8\u7406\u6240\u6709\u53ef\u7528\u7684\u5173\u7cfb\u6570\u636e\u5e93\u6765\u9a8c\u8bc1\u58f0\u660e\u3002\u91cd\u8981\u7684\u662f\uff0cThucy\u8fd8\u4f1a\u62a5\u544a\u652f\u6301\u5176\u7ed3\u8bba\uff08\u65e0\u8bba\u58f0\u660e\u662f\u5426\u51c6\u786e\uff09\u7684\u786e\u5207SQL\u67e5\u8be2\uff0c\u4ece\u800c\u4e3a\u719f\u6089SQL\u7684\u4e13\u5bb6\u7528\u6237\u63d0\u4f9b\u5b8c\u5168\u7684\u900f\u660e\u5ea6\u3002\u5f53\u5728TabFact\u6570\u636e\u96c6\uff08\u7ed3\u6784\u5316\u6570\u636e\u4e0a\u4e8b\u5b9e\u9a8c\u8bc1\u7684\u6807\u51c6\u57fa\u51c6\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0cThucy\u5728\u51c6\u786e\u7387\u65b9\u9762\u8d85\u8fc7\u4e86\u4e4b\u524d\u7684state of the art 5.6\u4e2a\u767e\u5206\u70b9\uff0894.3% vs. 88.7%\uff09\u3002"}}
{"id": "2512.03389", "pdf": "https://arxiv.org/pdf/2512.03389", "abs": "https://arxiv.org/abs/2512.03389", "authors": ["Shu Chen", "Deepti Raghavan", "U\u011fur \u00c7etintemel"], "title": "Continuous Prompts: LLM-Augmented Pipeline Processing over Unstructured Streams", "categories": ["cs.DB"], "comment": null, "summary": "Monitoring unstructured streams increasingly requires persistent, semantics-aware computation, yet today's LLM frameworks remain stateless and one-shot, limiting their usefulness for long-running analytics. We introduce Continuous Prompts (CPs), the first framework that brings LLM reasoning into continuous stream processing. CPs extend RAG to streaming settings, define continuous semantic operators, and provide multiple implementations, primarily focusing on LLM-based approaches but also reporting one embedding-based variants. Furthermore, we study two LLM-centric optimizations, tuple batching and operator fusion, to significantly improve efficiency while managing accuracy loss.\n  Because these optimizations inherently trade accuracy for speed, we present a dynamic optimization framework that uses lightweight shadow executions and cost-aware multi-objective Bayesian optimization (MOBO) to learn throughput-accuracy frontiers and adapt plans under probing budgets.\n  We implement CPs in the VectraFlow stream processing system. Using operator-level microbenchmarks and streaming pipelines on real datasets, we show that VectraFlow can adapt to workload dynamics, navigate accuracy-efficiency trade-offs, and sustain persistent semantic queries over evolving unstructured streams.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2512.03401", "pdf": "https://arxiv.org/pdf/2512.03401", "abs": "https://arxiv.org/abs/2512.03401", "authors": ["Ryoto Miyamoto", "Akira Kasuga"], "title": "Enterprise Data Science Platform: A Unified Architecture for Federated Data Access", "categories": ["cs.DB"], "comment": "10 pages, 2 figures, 3 tables, WS-D2ET @ IEEE BigData 2025", "summary": "Organizations struggle to share data across departments that have adopted different data analytics platforms. If n datasets must serve m environments, up to n*m replicas can emerge, increasing inconsistency and cost. Traditional warehouses copy data into vendor-specific stores; cross-platform access is hard. This study proposes the Enterprise Data Science Platform (EDSP), which builds on data lakehouse architecture and follows a Write-Once, Read-Anywhere principle. EDSP enables federated data access for multi-query engine environments, targeting data science workloads with periodic data updates and query response times ranging from seconds to minutes. By providing centralized data management with federated access from multiple query engines to the same data sources, EDSP eliminates data duplication and vendor lock-in inherent in traditional data warehouses. The platform employs a four-layer architecture: Data Preparation, Data Store, Access Interface, and Query Engines. This design enforces separation of concerns and reduces the need for data migration when integrating additional analytical environments. Experimental results demonstrate that major cloud data warehouses and programming environments can directly query EDSP-managed datasets. We implemented and deployed EDSP in production, confirming interoperability across multiple query engines. For data sharing across different analytical environments, EDSP achieves a 33-44% reduction in operational steps compared with conventional approaches requiring data migration. Although query latency may increase by up to a factor of 2.6 compared with native tables, end-to-end completion times remain on the order of seconds, maintaining practical performance for analytical use cases. Based on our production experience, EDSP provides practical design guidelines for addressing the data-silo problem in multi-query engine environments.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2512.03790", "pdf": "https://arxiv.org/pdf/2512.03790", "abs": "https://arxiv.org/abs/2512.03790", "authors": ["Iris Beerepoot", "Vinicius Stein Dani", "Xixi Lu"], "title": "ExOAR: Expert-Guided Object and Activity Recognition from Textual Data", "categories": ["cs.DB", "cs.CY"], "comment": "Accepted manuscript (on August 22, 2025) to the 2nd International Workshop on Generative AI for Process Mining (GenAI4PM 2025), held in conjunction with the 7th International Conference on Process Mining (ICPM 2025)", "summary": "Object-centric process mining requires structured data, but extracting it from unstructured text remains a challenge. We introduce ExOAR (Expert-Guided Object and Activity Recognition), an interactive method that combines large language models (LLMs) with human verification to identify objects and activities from textual data. ExOAR guides users through consecutive stages in which an LLM generates candidate object types, activities, and object instances based on contextual input, such as a user's profession, and textual data. Users review and refine these suggestions before proceeding to the next stage. Implemented as a practical tool, ExOAR is initially validated through a demonstration and then evaluated with real-world Active Window Tracking data from five users. Our results show that ExOAR can effectively bridge the gap between unstructured textual data and the structured log with clear semantics needed for object-centric process analysis, while it maintains flexibility and human oversight.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2512.03906", "pdf": "https://arxiv.org/pdf/2512.03906", "abs": "https://arxiv.org/abs/2512.03906", "authors": ["Alberto Ronzoni", "Anina Antony", "Anjana M R", "Francesca De Leo", "Jesna Jose", "Mattia Freda", "Nandini Narayanankutty", "Rafflesia Khan", "Raji RV", "Thomas Diacci"], "title": "IBM Multilevel Process Mining vs de facto Object-Centric Process Mining approaches", "categories": ["cs.DB"], "comment": null, "summary": "The academic evolution of process mining is moving toward object centric process mining, marking a significant shift in how processes are modeled and analyzed. IBM has developed its own distinctive approach called Multilevel Process Mining. This paper provides a description of the two approaches and presents a comparative analysis of their respective advantages and limitations. IBM leveraged this comparison to drive the evolution of IBM Process Mining product, creating the new Organizational Mining feature, an innovation that combines the best of the two approaches. Demonstrate the potential of this novel, innovative and distinct methodology with an example.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2512.03669", "pdf": "https://arxiv.org/pdf/2512.03669", "abs": "https://arxiv.org/abs/2512.03669", "authors": ["Zuan Wang", "Juntao Lu", "Jiazhuang Wu", "Youliang Tian", "Wei Song", "Qiuxian Li", "Duo Zhang"], "title": "Towards Privacy-Preserving Range Queries with Secure Learned Spatial Index over Encrypted Data", "categories": ["cs.CR", "cs.DB"], "comment": "IEEE TrustCom-2025", "summary": "With the growing reliance on cloud services for large-scale data management, preserving the security and privacy of outsourced datasets has become increasingly critical. While encrypting data and queries can prevent direct content exposure, recent research reveals that adversaries can still infer sensitive information via access pattern and search path analysis. However, existing solutions that offer strong access pattern privacy often incur substantial performance overhead. In this paper, we propose a novel privacy-preserving range query scheme over encrypted datasets, offering strong security guarantees while maintaining high efficiency. To achieve this, we develop secure learned spatial index (SLS-INDEX), a secure learned index that integrates the Paillier cryptosystem with a hierarchical prediction architecture and noise-injected buckets, enabling data-aware query acceleration in the encrypted domain. To further obfuscate query execution paths, SLS-INDEXbased Range Queries (SLRQ) employs a permutation-based secure bucket prediction protocol. Additionally, we introduce a secure point extraction protocol that generates candidate results to reduce the overhead of secure computation. We provide formal security analysis under realistic leakage functions and implement a prototype to evaluate its practical performance. Extensive experiments on both real-world and synthetic datasets demonstrate that SLRQ significantly outperforms existing solutions in query efficiency while ensuring dataset, query, result, and access pattern privacy.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
