{"id": "2510.16388", "pdf": "https://arxiv.org/pdf/2510.16388", "abs": "https://arxiv.org/abs/2510.16388", "authors": ["Doriana Armenise", "Ginevra Battello", "Andrea Brunello", "Lorenza Driul", "Angelo Montanari", "Elisa Rizzante", "Nicola Saccomanno", "Andrea Salvador", "Serena Xodo", "Silvia Zermano"], "title": "Unified Peripartum Database with Natural-Language-to-SQL Capabilities at Udine University Hospital: Design and Prototype", "categories": ["cs.DB", "H.2; H.4.0"], "comment": null, "summary": "The fragmentation of obstetric information across electronic health record\nmodules, device repositories, and laboratory systems, as it is common in\nhospitals, hinders both intrapartum care and reproducible research. In this\nwork, we present a practical blueprint for transforming heterogeneous\nperipartum records into computable, queryable assets by designing and\nprototyping a unified peripartum relational database with\nnatural-language-to-SQL (NL2SQL) capabilities at the Obstetrics Clinic of Udine\nUniversity Hospital. Requirements were co-defined with clinicians and\nformalized as an Entity-Relationship diagram, from which the logical schema and\nSQL implementation of the database were then derived. The latter integrates\nheterogeneous sources to connect maternal anamnestic and longitudinal history,\ncurrent-pregnancy findings, intrapartum course, and delivery and neonatal\noutcomes. The NL2SQL layer enables clinicians to pose natural-language queries\nto the system, lowering barriers to audit and exploratory analysis."}
{"id": "2510.16470", "pdf": "https://arxiv.org/pdf/2510.16470", "abs": "https://arxiv.org/abs/2510.16470", "authors": ["Elham Khabiri", "Jeffrey O. Kephart", "Fenno F. Heath III", "Srideepika Jayaraman", "Fateh A. Tipu", "Yingjie Li", "Dhruv Shah", "Achille Fokoue", "Anu Bhamidipaty"], "title": "Declarative Techniques for NL Queries over Heterogeneous Data", "categories": ["cs.DB", "cs.AI", "cs.SE"], "comment": null, "summary": "In many industrial settings, users wish to ask questions in natural language,\nthe answers to which require assembling information from diverse structured\ndata sources. With the advent of Large Language Models (LLMs), applications can\nnow translate natural language questions into a set of API calls or database\ncalls, execute them, and combine the results into an appropriate natural\nlanguage response. However, these applications remain impractical in realistic\nindustrial settings because they do not cope with the data source heterogeneity\nthat typifies such environments. In this work, we simulate the heterogeneity of\nreal industry settings by introducing two extensions of the popular Spider\nbenchmark dataset that require a combination of database and API calls. Then,\nwe introduce a declarative approach to handling such data heterogeneity and\ndemonstrate that it copes with data source heterogeneity significantly better\nthan state-of-the-art LLM-based agentic or imperative code generation systems.\nOur augmented benchmarks are available to the research community."}
{"id": "2510.17089", "pdf": "https://arxiv.org/pdf/2510.17089", "abs": "https://arxiv.org/abs/2510.17089", "authors": ["Christian Imenkamp", "Andrea Maldonado", "Hendrik Reiter", "Martin Werner", "Wilhelm Hasselbring", "Agnes Koschmider", "Andrea Burattin"], "title": "AVOCADO: The Streaming Process Mining Challenge", "categories": ["cs.DB"], "comment": "12 pages, 4 figures", "summary": "Streaming process mining deals with the real-time analysis of streaming data.\nEvent streams require algorithms capable of processing data incrementally. To\nsystematically address the complexities of this domain, we propose AVOCADO, a\nstandardized challenge framework that provides clear structural divisions:\nseparating the concept and instantiation layers of challenges in streaming\nprocess mining for algorithm evaluation. The AVOCADO evaluates algorithms on\nstreaming-specific metrics like accuracy, Mean Absolute Error (MAE), Root Mean\nSquare Error (RMSE), Processing Latency, and robustness. This initiative seeks\nto foster innovation and community-driven discussions to advance the field of\nstreaming process mining. We present this framework as a foundation and invite\nthe community to contribute to its evolution by suggesting new challenges, such\nas integrating metrics for system throughput and memory consumption, and\nexpanding the scope to address real-world stream complexities like out-of-order\nevent arrival."}
{"id": "2510.17301", "pdf": "https://arxiv.org/pdf/2510.17301", "abs": "https://arxiv.org/abs/2510.17301", "authors": ["Panos Kalnis. Shuo Shang", "Christian S. Jensen"], "title": "Comprehending Spatio-temporal Data via Cinematic Storytelling using Large Language Models", "categories": ["cs.DB", "cs.AI"], "comment": "5 pages", "summary": "Spatio-temporal data captures complex dynamics across both space and time,\nyet traditional visualizations are complex, require domain expertise and often\nfail to resonate with broader audiences. Here, we propose MapMuse, a\nstorytelling-based framework for interpreting spatio-temporal datasets,\ntransforming them into compelling, narrative-driven experiences. We utilize\nlarge language models and employ retrieval augmented generation (RAG) and\nagent-based techniques to generate comprehensive stories. Drawing on principles\ncommon in cinematic storytelling, we emphasize clarity, emotional connection,\nand audience-centric design. As a case study, we analyze a dataset of taxi\ntrajectories. Two perspectives are presented: a captivating story based on a\nheat map that visualizes millions of taxi trip endpoints to uncover urban\nmobility patterns; and a detailed narrative following a single long taxi\njourney, enriched with city landmarks and temporal shifts. By portraying\nlocations as characters and movement as plot, we argue that data storytelling\ndrives insight, engagement, and action from spatio-temporal information. The\ncase study illustrates how MapMuse can bridge the gap between data complexity\nand human understanding. The aim of this short paper is to provide a glimpse to\nthe potential of the cinematic storytelling technique as an effective\ncommunication tool for spatio-temporal data, as well as to describe open\nproblems and opportunities for future research."}
{"id": "2510.17326", "pdf": "https://arxiv.org/pdf/2510.17326", "abs": "https://arxiv.org/abs/2510.17326", "authors": ["Kun Yu", "Jiabao Jin", "Xiaoyao Zhong", "Peng Cheng", "Lei Chen", "Zhitao Shen", "Jingkuan Song", "Hengtao Shen", "Xuemin Lin"], "title": "Approximate Nearest Neighbor Search of Large Scale Vectors on Distributed Storage", "categories": ["cs.DB"], "comment": null, "summary": "Approximate Nearest Neighbor Search (ANNS) in high-dimensional space is an\nessential operator in many online services, such as information retrieval and\nrecommendation. Indices constructed by the state-of-the-art ANNS algorithms\nmust be stored in single machine's memory or disk for high recall rate and\nthroughput, suffering from substantial storage cost, constraint of limited\nscale and single point of failure. While distributed storage can provide a\ncost-effective and robust solution, there is no efficient and effective\nalgorithms for indexing vectors in distributed storage scenarios. In this\npaper, we present a new graph-cluster hybrid indexing and search system which\nsupports Distributed Storage Approximate Nearest Neighbor Search, called DSANN.\nDSANN can efficiently index, store, search billion-scale vector database in\ndistributed storage and guarantee the high availability of index service. DSANN\nemploys the concurrent index construction method to significantly reduces the\ncomplexity of index building. Then, DSANN applies Point Aggregation Graph to\nleverage the structural information of graph to aggregate similar vectors,\noptimizing storage efficiency and improving query throughput via asynchronous\nI/O in distributed storage. Through extensive experiments, we demonstrate DSANN\ncan efficiently and effectively index, store and search large-scale vector\ndatasets in distributed storage scenarios."}
{"id": "2510.17586", "pdf": "https://arxiv.org/pdf/2510.17586", "abs": "https://arxiv.org/abs/2510.17586", "authors": ["Boyan Li", "Chong Chen", "Zhujun Xue", "Yinan Mei", "Yuyu Luo"], "title": "DeepEye-SQL: A Software-Engineering-Inspired Text-to-SQL Framework", "categories": ["cs.DB"], "comment": null, "summary": "Large language models (LLMs) have advanced Text-to-SQL, yet existing\nsolutions still fall short of system-level reliability. The limitation is not\nmerely in individual modules - e.g., schema linking, reasoning, and\nverification - but more critically in the lack of structured orchestration that\nenforces correctness across the entire workflow. This gap motivates a paradigm\nshift: treating Text-to-SQL not as free-form language generation but as a\nsoftware-engineering problem that demands structured, verifiable orchestration.\nWe present DeepEye-SQL, a software-engineering-inspired framework that reframes\nText-to-SQL as the development of a small software program, executed through a\nverifiable process guided by the Software Development Life Cycle (SDLC).\nDeepEye-SQL integrates four synergistic stages: it grounds ambiguous user\nintent through semantic value retrieval and robust schema linking; enhances\nfault tolerance with N-version SQL generation using diverse reasoning\nparadigms; ensures deterministic verification via a tool-chain of unit tests\nand targeted LLM-guided revision; and introduces confidence-aware selection\nthat clusters execution results to estimate confidence and then takes a\nhigh-confidence shortcut or runs unbalanced pairwise adjudication in\nlow-confidence cases, yielding a calibrated, quality-gated output. This\nSDLC-aligned workflow transforms ad hoc query generation into a disciplined\nengineering process. Using ~30B open-source LLMs without any fine-tuning,\nDeepEye-SQL achieves 73.5% execution accuracy on BIRD-Dev and 89.8% on\nSpider-Test, outperforming state-of-the-art solutions. This highlights that\nprincipled orchestration, rather than LLM scaling alone, is key to achieving\nsystem-level reliability in Text-to-SQL."}
{"id": "2510.17748", "pdf": "https://arxiv.org/pdf/2510.17748", "abs": "https://arxiv.org/abs/2510.17748", "authors": ["William Zhang", "Wan Shen Lim", "Andrew Pavlo"], "title": "This is Going to Sound Crazy, But What If We Used Large Language Models to Boost Automatic Database Tuning Algorithms By Leveraging Prior History? We Will Find Better Configurations More Quickly Than Retraining From Scratch!", "categories": ["cs.DB"], "comment": "Accepted to SIGMOD2026", "summary": "Tuning database management systems (DBMSs) is challenging due to trillions of\npossible configurations and evolving workloads. Recent advances in tuning have\nled to breakthroughs in optimizing over the possible configurations. However,\ndue to their design and inability to leverage query-level historical insights,\nexisting automated tuners struggle to adapt and re-optimize the DBMS when the\nenvironment changes (e.g., workload drift, schema transfer).\n  This paper presents the Booster framework that assists existing tuners in\nadapting to environment changes (e.g., drift, cross-schema transfer). Booster\nstructures historical artifacts into query-configuration contexts, prompts\nlarge language models (LLMs) to suggest configurations for each query based on\nrelevant contexts, and then composes the query-level suggestions into a\nholistic configuration with beam search. With multiple OLAP workloads, we\nevaluate Booster's ability to assist different state-of-the-art tuners (e.g.,\ncost-/machine learning-/LLM-based) in adapting to environment changes. By\ncomposing recommendations derived from query-level insights, Booster assists\ntuners in discovering configurations that are up to 74% better and in up to\n4.7x less time than the alternative approach of continuing to tune from\nhistorical configurations."}
{"id": "2510.16872", "pdf": "https://arxiv.org/pdf/2510.16872", "abs": "https://arxiv.org/abs/2510.16872", "authors": ["Shaolei Zhang", "Ju Fan", "Meihao Fan", "Guoliang Li", "Xiaoyong Du"], "title": "DeepAnalyze: Agentic Large Language Models for Autonomous Data Science", "categories": ["cs.AI", "cs.CL", "cs.DB"], "comment": "Code: https://github.com/ruc-datalab/DeepAnalyze Model:\n  https://huggingface.co/RUC-DataLab/DeepAnalyze-8B", "summary": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language models (LLMs). Recent workflow-based\ndata agents have shown promising results on specific data tasks but remain\nfundamentally limited in achieving fully autonomous data science due to their\nreliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,\nthe first agentic LLM designed for autonomous data science, capable of\nautomatically completing the end-toend pipeline from data sources to\nanalyst-grade deep research reports. To tackle high-complexity data science\ntasks, we propose a curriculum-based agentic training paradigm that emulates\nthe learning trajectory of human data scientists, enabling LLMs to\nprogressively acquire and integrate multiple capabilities in real-world\nenvironments. We also introduce a data-grounded trajectory synthesis framework\nthat constructs high-quality training data. Through agentic training,\nDeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data\nquestion answering and specialized analytical tasks to open-ended data\nresearch. Experiments demonstrate that, with only 8B parameters, DeepAnalyze\noutperforms previous workflow-based agents built on most advanced proprietary\nLLMs. The model, code, and training data of DeepAnalyze are open-sourced,\npaving the way toward autonomous data science."}
