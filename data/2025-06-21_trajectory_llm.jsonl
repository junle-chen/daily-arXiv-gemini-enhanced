{"id": "2506.14831", "pdf": "https://arxiv.org/pdf/2506.14831", "abs": "https://arxiv.org/abs/2506.14831", "authors": ["C\u00e9line Finet", "Stephane Da Silva Martins", "Jean-Bernard Hayet", "Ioannis Karamouzas", "Javad Amirian", "Sylvie Le H\u00e9garat-Mascle", "Julien Pettr\u00e9", "Emanuel Aldea"], "title": "Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "30 pages", "summary": "With the emergence of powerful data-driven methods in human trajectory prediction (HTP), gaining a finer understanding of multi-agent interactions lies within hand's reach, with important implications in areas such as autonomous navigation and crowd modeling. This survey reviews some of the most recent advancements in deep learning-based multi-agent trajectory prediction, focusing on studies published between 2020 and 2024. We categorize the existing methods based on their architectural design, their input representations, and their overall prediction strategies, placing a particular emphasis on models evaluated using the ETH/UCY benchmark. Furthermore, we highlight key challenges and future research directions in the field of multi-agent HTP.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "\u8be5\u8bba\u6587\u7684\u6807\u9898\u548c\u6458\u8981\u660e\u786e\u6307\u51fa\u5176\u5173\u6ce8\u591a\u667a\u80fd\u4f53\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u5bf9\u76f8\u5173\u65b9\u6cd5\u8fdb\u884c\u4e86\u7efc\u8ff0\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u8f68\u8ff9\u9884\u6d4b\u672c\u8eab\u662f\u6838\u5fc3\u4e3b\u9898\uff0c\u56e0\u6b64\u5177\u6709\u8f83\u9ad8\u7684\u76f8\u5173\u6027\u3002", "keywords": ["trajectory prediction", "human trajectory prediction", "multi-agent", "deep learning"]}}
{"id": "2506.15157", "pdf": "https://arxiv.org/pdf/2506.15157", "abs": "https://arxiv.org/abs/2506.15157", "authors": ["Hanbit Oh", "Andrea M. Salcedo-V\u00e1zquez", "Ixchel G. Ramirez-Alpizar", "Yukiyasu Domae"], "title": "Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025 accepted", "summary": "Imitation learning (IL) aims to enable robots to perform tasks autonomously by observing a few human demonstrations. Recently, a variant of IL, called In-Context IL, utilized off-the-shelf large language models (LLMs) as instant policies that understand the context from a few given demonstrations to perform a new task, rather than explicitly updating network models with large-scale demonstrations. However, its reliability in the robotics domain is undermined by hallucination issues such as LLM-based instant policy, which occasionally generates poor trajectories that deviate from the given demonstrations. To alleviate this problem, we propose a new robust in-context imitation learning algorithm called the robust instant policy (RIP), which utilizes a Student's t-regression model to be robust against the hallucinated trajectories of instant policies to allow reliable trajectory generation. Specifically, RIP generates several candidate robot trajectories to complete a given task from an LLM and aggregates them using the Student's t-distribution, which is beneficial for ignoring outliers (i.e., hallucinations); thereby, a robust trajectory against hallucinations is generated. Our experiments, conducted in both simulated and real-world environments, show that RIP significantly outperforms state-of-the-art IL methods, with at least $26\\%$ improvement in task success rates, particularly in low-data scenarios for everyday tasks. Video results available at https://sites.google.com/view/robustinstantpolicy.", "relevance_analysis": {"relevance_score": 0.8, "explanation": "\u8be5\u8bba\u6587\u4f7f\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u673a\u5668\u4eba\u64cd\u4f5c\u8f68\u8ff9\uff0c\u5e76\u4f7f\u7528Student's t-regression\u6a21\u578b\u6765\u63d0\u9ad8\u8f68\u8ff9\u7684\u9c81\u68d2\u6027\u3002\u867d\u7136\u4e3b\u8981\u5173\u6ce8\u673a\u5668\u4eba\u64cd\u4f5c\uff0c\u4f46\u4e5f\u6d89\u53ca\u4e86\u8f68\u8ff9\u751f\u6210\u548c\u5229\u7528LLM\u8fdb\u884c\u8f68\u8ff9\u89c4\u5212\uff0c\u56e0\u6b64\u5177\u6709\u8f83\u9ad8\u7684\u76f8\u5173\u6027\u3002", "keywords": ["large language models", "LLMs", "trajectory generation", "imitation learning", "robot manipulation"]}}
{"id": "2506.15043", "pdf": "https://arxiv.org/pdf/2506.15043", "abs": "https://arxiv.org/abs/2506.15043", "authors": ["Amir Hossein Baradaran"], "title": "Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Advancements in the defense industry are paramount for ensuring the safety and security of nations, providing robust protection against emerging threats. Among these threats, hypersonic missiles pose a significant challenge due to their extreme speeds and maneuverability, making accurate trajectory prediction a critical necessity for effective countermeasures. This paper addresses this challenge by employing a novel hybrid deep learning approach, integrating Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks, and Gated Recurrent Units (GRUs). By leveraging the strengths of these architectures, the proposed method successfully predicts the complex trajectories of hypersonic missiles with high accuracy, offering a significant contribution to defense strategies and missile interception technologies. This research demonstrates the potential of advanced machine learning techniques in enhancing the predictive capabilities of defense systems.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper focuses on trajectory prediction of hypersonic missiles using deep learning models (CNN, LSTM, GRU). While it doesn't directly involve large language models, the core topic is trajectory prediction, which is a relevant area. The use of deep learning also makes it potentially relevant to future applications involving large models.", "keywords": ["trajectory prediction", "deep learning", "CNN", "LSTM", "GRU", "missile trajectory"]}}
{"id": "2506.15167", "pdf": "https://arxiv.org/pdf/2506.15167", "abs": "https://arxiv.org/abs/2506.15167", "authors": ["Wanzhe Wang", "Jianqiu Peng", "Menghao Hu", "Weihuang Zhong", "Tong Zhang", "Shuai Wang", "Yixin Zhang", "Mingjie Shao", "Wanli Ni"], "title": "LLM Agent for Hyper-Parameter Optimization", "categories": ["cs.IT", "cs.AI"], "comment": "6 pages, 6 figures", "summary": "Hyper-parameters are essential and critical for the performance of communication algorithms. However, current hyper-parameters tuning methods for warm-start particles swarm optimization with cross and mutation (WS-PSO-CM) algortihm for radio map-enabled unmanned aerial vehicle (UAV) trajectory and communication are primarily heuristic-based, exhibiting low levels of automation and unsatisfactory performance. In this paper, we design an large language model (LLM) agent for automatic hyper-parameters-tuning, where an iterative framework and model context protocol (MCP) are applied. In particular, the LLM agent is first setup via a profile, which specifies the mission, background, and output format. Then, the LLM agent is driven by the prompt requirement, and iteratively invokes WS-PSO-CM algorithm for exploration. Finally, the LLM agent autonomously terminates the loop and returns a set of hyper-parameters. Our experiment results show that the minimal sum-rate achieved by hyper-parameters generated via our LLM agent is significantly higher than those by both human heuristics and random generation methods. This indicates that an LLM agent with PSO knowledge and WS-PSO-CM algorithm background is useful in finding high-performance hyper-parameters.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "The paper discusses using an LLM agent to optimize hyper-parameters for a UAV trajectory algorithm (WS-PSO-CM) which is related to trajectory prediction. Although the main focus is on hyper-parameter optimization using LLMs, the application context involves UAV trajectory planning, making it relevant.", "keywords": ["Large Language Model (LLM)", "UAV trajectory", "trajectory", "WS-PSO-CM algorithm"]}}
{"id": "2506.14857", "pdf": "https://arxiv.org/pdf/2506.14857", "abs": "https://arxiv.org/abs/2506.14857", "authors": ["Suman Raj", "Swapnil Padhi", "Ruchi Bhoot", "Prince Modi", "Yogesh Simmhan"], "title": "Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired", "categories": ["cs.RO", "cs.CV"], "comment": "16 pages, 7 figures; Accepted as Late-Breaking Results at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023", "summary": "Autonomous navigation by drones using onboard sensors combined with machine learning and computer vision algorithms is impacting a number of domains, including agriculture, logistics, and disaster management. In this paper, we examine the use of drones for assisting visually impaired people (VIPs) in navigating through outdoor urban environments. Specifically, we present a perception-based path planning system for local planning around the neighborhood of the VIP, integrated with a global planner based on GPS and maps for coarse planning. We represent the problem using a geometric formulation and propose a multi DNN based framework for obstacle avoidance of the UAV as well as the VIP. Our evaluations conducted on a drone human system in a university campus environment verifies the feasibility of our algorithms in three scenarios; when the VIP walks on a footpath, near parked vehicles, and in a crowded street.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper discusses perception-based path planning for UAVs assisting visually impaired people. While it focuses on path planning and obstacle avoidance, which are related to trajectory prediction, it doesn't explicitly involve large language models. The use of DNNs is mentioned, but not in the context of LLMs.", "keywords": ["path planning", "obstacle avoidance", "DNN", "UAV", "autonomous navigation"]}}
{"id": "2506.14865", "pdf": "https://arxiv.org/pdf/2506.14865", "abs": "https://arxiv.org/abs/2506.14865", "authors": ["Xuemin Chi", "Hakan Girgin", "Tobias L\u00f6w", "Yangyang Xie", "Teng Xue", "Jihao Huang", "Cheng Hu", "Zhitao Liu", "Sylvain Calinon"], "title": "Efficient and Real-Time Motion Planning for Robotics Using Projection-Based Optimization", "categories": ["cs.RO"], "comment": "submitted to IROS 2025", "summary": "Generating motions for robots interacting with objects of various shapes is a complex challenge, further complicated by the robot geometry and multiple desired behaviors. While current robot programming tools (such as inverse kinematics, collision avoidance, and manipulation planning) often treat these problems as constrained optimization, many existing solvers focus on specific problem domains or do not exploit geometric constraints effectively. We propose an efficient first-order method, Augmented Lagrangian Spectral Projected Gradient Descent (ALSPG), which leverages geometric projections via Euclidean projections, Minkowski sums, and basis functions. We show that by using geometric constraints rather than full constraints and gradients, ALSPG significantly improves real-time performance. Compared to second-order methods like iLQR, ALSPG remains competitive in the unconstrained case. We validate our method through toy examples and extensive simulations, and demonstrate its effectiveness on a 7-axis Franka robot, a 6-axis P-Rob robot and a 1:10 scale car in real-world experiments. Source codes, experimental data and videos are available on the project webpage: https://sites.google.com/view/alspg-oc", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on motion planning for robotics, which is related to trajectory prediction. While it doesn't directly involve large language models, the underlying optimization techniques could potentially be used in conjunction with LLMs for more complex robotic tasks. The connection is indirect but present.", "keywords": ["motion planning", "trajectory prediction", "robotics", "optimization"]}}
{"id": "2506.14975", "pdf": "https://arxiv.org/pdf/2506.14975", "abs": "https://arxiv.org/abs/2506.14975", "authors": ["Jeffrey Mao", "Raghuram Cauligi Srinivas", "Steven Nogar", "Giuseppe Loianno"], "title": "Time-Optimized Safe Navigation in Unstructured Environments through Learning Based Depth Completion", "categories": ["cs.RO"], "comment": null, "summary": "Quadrotors hold significant promise for several applications such as agriculture, search and rescue, and infrastructure inspection. Achieving autonomous operation requires systems to navigate safely through complex and unfamiliar environments. This level of autonomy is particularly challenging due to the complexity of such environments and the need for real-time decision making especially for platforms constrained by size, weight, and power (SWaP), which limits flight time and precludes the use of bulky sensors like Light Detection and Ranging (LiDAR) for mapping. Furthermore, computing globally optimal, collision-free paths and translating them into time-optimized, safe trajectories in real time adds significant computational complexity. To address these challenges, we present a fully onboard, real-time navigation system that relies solely on lightweight onboard sensors. Our system constructs a dense 3D map of the environment using a novel visual depth estimation approach that fuses stereo and monocular learning-based depth, yielding longer-range, denser, and less noisy depth maps than conventional stereo methods. Building on this map, we introduce a novel planning and trajectory generation framework capable of rapidly computing time-optimal global trajectories. As the map is incrementally updated with new depth information, our system continuously refines the trajectory to maintain safety and optimality. Both our planner and trajectory generator outperforms state-of-the-art methods in terms of computational efficiency and guarantee obstacle-free trajectories. We validate our system through robust autonomous flight experiments in diverse indoor and outdoor environments, demonstrating its effectiveness for safe navigation in previously unknown settings.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b89\u5168\u5bfc\u822a\uff0c\u6d89\u53ca\u8def\u5f84\u89c4\u5212\u548c\u8f68\u8ff9\u751f\u6210\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u76f8\u5173\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u6df1\u5ea6\u8865\u5168\u4efb\u52a1\u4f7f\u7528\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4e3a\u672a\u6765\u7ed3\u5408\u5927\u6a21\u578b\u8fdb\u884c\u8f68\u8ff9\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002", "keywords": ["trajectory generation", "navigation", "path planning", "depth completion"]}}
{"id": "2506.15624", "pdf": "https://arxiv.org/pdf/2506.15624", "abs": "https://arxiv.org/abs/2506.15624", "authors": ["Lyle Goodyear", "Rachel Guo", "Ramesh Johari"], "title": "The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games", "categories": ["cs.AI"], "comment": "27 pages, 20 figures", "summary": "Large Language Models (LLMs) have shown promise as decision-makers in dynamic settings, but their stateless nature necessitates creating a natural language representation of history. We present a unifying framework for systematically constructing natural language \"state\" representations for prompting LLM agents in repeated multi-agent games. Previous work on games with LLM agents has taken an ad hoc approach to encoding game history, which not only obscures the impact of state representation on agents' behavior, but also limits comparability between studies. Our framework addresses these gaps by characterizing methods of state representation along three axes: action informativeness (i.e., the extent to which the state representation captures actions played); reward informativeness (i.e., the extent to which the state representation describes rewards obtained); and prompting style (or natural language compression, i.e., the extent to which the full text history is summarized).\n  We apply this framework to a dynamic selfish routing game, chosen because it admits a simple equilibrium both in theory and in human subject experiments \\cite{rapoport_choice_2009}. Despite the game's relative simplicity, we find that there are key dependencies of LLM agent behavior on the natural language state representation. In particular, we observe that representations which provide agents with (1) summarized, rather than complete, natural language representations of past history; (2) information about regrets, rather than raw payoffs; and (3) limited information about others' actions lead to behavior that more closely matches game theoretic equilibrium predictions, and with more stable game play by the agents. By contrast, other representations can exhibit either large deviations from equilibrium, higher variation in dynamic game play over time, or both.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8fd9\u7bc7\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u8def\u7531\u535a\u5f08\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u72b6\u6001\u8868\u793a\u5bf9LLM agent\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u867d\u7136\u6d89\u53ca\u52a8\u6001\u73af\u5883\u548c\u51b3\u7b56\uff0c\u4f46\u66f4\u4fa7\u91cd\u4e8e\u535a\u5f08\u8bba\u548cLLM agent\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u7684\u76f4\u63a5\u5173\u8054\u6027\u8f83\u5f31\u3002\u4e0d\u8fc7\uff0c\u8def\u7531\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u8def\u5f84\u9009\u62e9\u95ee\u9898\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002", "keywords": ["Large Language Models", "LLM Agent", "Dynamic Routing", "State Representation"]}}
{"id": "2506.15096", "pdf": "https://arxiv.org/pdf/2506.15096", "abs": "https://arxiv.org/abs/2506.15096", "authors": ["Zihe Ji", "Huangxuan Lin", "Yue Gao"], "title": "DyNaVLM: Zero-Shot Vision-Language Navigation System with Dynamic Viewpoints and Self-Refining Graph Memory", "categories": ["cs.RO"], "comment": null, "summary": "We present DyNaVLM, an end-to-end vision-language navigation framework using Vision-Language Models (VLM). In contrast to prior methods constrained by fixed angular or distance intervals, our system empowers agents to freely select navigation targets via visual-language reasoning. At its core lies a self-refining graph memory that 1) stores object locations as executable topological relations, 2) enables cross-robot memory sharing through distributed graph updates, and 3) enhances VLM's decision-making via retrieval augmentation. Operating without task-specific training or fine-tuning, DyNaVLM demonstrates high performance on GOAT and ObjectNav benchmarks. Real-world tests further validate its robustness and generalization. The system's three innovations: dynamic action space formulation, collaborative graph memory, and training-free deployment, establish a new paradigm for scalable embodied robot, bridging the gap between discrete VLN tasks and continuous real-world navigation.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper describes a vision-language navigation system that utilizes Vision-Language Models (VLMs) for robot navigation. While it doesn't explicitly mention trajectory prediction, navigation inherently involves predicting future paths. The use of VLMs connects it to the large language model domain. The focus is more on navigation and visual-language reasoning than pure trajectory prediction.", "keywords": ["vision-language navigation", "VLM", "navigation", "robot navigation"]}}
{"id": "2506.15672", "pdf": "https://arxiv.org/pdf/2506.15672", "abs": "https://arxiv.org/abs/2506.15672", "authors": ["Yao Zhang", "Chenyang Lin", "Shijie Tang", "Haokun Chen", "Shijie Zhou", "Yunpu Ma", "Volker Tresp"], "title": "SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence", "categories": ["cs.AI", "cs.MA"], "comment": "41 pages", "summary": "The rapid progress of Large Language Models has advanced agentic systems in decision-making, coordination, and task execution. Yet, existing agentic system generation frameworks lack full autonomy, missing from-scratch agent generation, self-optimizing agent functionality, and collaboration, limiting adaptability and scalability. We propose SwarmAgentic, a framework for fully automated agentic system generation that constructs agentic systems from scratch and jointly optimizes agent functionality and collaboration as interdependent components through language-driven exploration. To enable efficient search over system-level structures, SwarmAgentic maintains a population of candidate systems and evolves them via feedback-guided updates, drawing inspiration from Particle Swarm Optimization (PSO). We evaluate our method on six real-world, open-ended, and exploratory tasks involving high-level planning, system-level coordination, and creative reasoning. Given only a task description and an objective function, SwarmAgentic outperforms all baselines, achieving a +261.8% relative improvement over ADAS on the TravelPlanner benchmark, highlighting the effectiveness of full automation in structurally unconstrained tasks. This framework marks a significant step toward scalable and autonomous agentic system design, bridging swarm intelligence with fully automated system multi-agent generation. Our code is publicly released at https://yaoz720.github.io/SwarmAgentic/.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on automated agentic system generation using Large Language Models and swarm intelligence. While it doesn't directly address trajectory prediction, the mention of agentic systems, decision-making, coordination, and task execution suggests potential applications in areas where agents need to navigate and interact with dynamic environments, which is related to trajectory prediction. The core focus, however, is on the generation and optimization of multi-agent systems using LLMs.", "keywords": ["Large Language Models", "agentic systems", "multi-agent", "swarm intelligence"]}}
{"id": "2506.14802", "pdf": "https://arxiv.org/pdf/2506.14802", "abs": "https://arxiv.org/abs/2506.14802", "authors": ["Zuochen Ye"], "title": "ss-Mamba: Semantic-Spline Selective State-Space Model", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose ss-Mamba, a novel foundation model that enhances time series forecasting by integrating semantic-aware embeddings and adaptive spline-based temporal encoding within a selective state-space modeling framework. Building upon the recent success of Transformer architectures, ss-Mamba adopts the Mamba selective state space model as an efficient alternative that achieves comparable performance while significantly reducing computational complexity from quadratic to linear time. Semantic index embeddings, initialized from pretrained language models, allow effective generalization to previously unseen series through meaningful semantic priors. Additionally, spline-based Kolmogorov-Arnold Networks (KAN) dynamically and interpretably capture complex seasonalities and non-stationary temporal effects, providing a powerful enhancement over conventional temporal feature encodings. Extensive experimental evaluations confirm that ss-Mamba delivers superior accuracy, robustness, and interpretability, demonstrating its capability as a versatile and computationally efficient alternative to traditional Transformer-based models in time-series forecasting.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on time series forecasting using a novel foundation model (ss-Mamba) that integrates semantic embeddings from pretrained language models. While it doesn't directly address trajectory prediction, time series forecasting is a related area. The use of pretrained language models connects it to the large language model domain. The connection to trajectory prediction is indirect but present.", "keywords": ["foundation model", "time series forecasting", "pretrained language models"]}}
{"id": "2506.15220", "pdf": "https://arxiv.org/pdf/2506.15220", "abs": "https://arxiv.org/abs/2506.15220", "authors": ["Changli Tang", "Yixuan Li", "Yudong Yang", "Jimin Zhuang", "Guangzhi Sun", "Wei Li", "Zejun Ma", "Chao Zhang"], "title": "video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models", "categories": ["cs.CV", "cs.CL", "cs.SD"], "comment": null, "summary": "Videos contain a wealth of information, and generating detailed and accurate descriptions in natural language is a key aspect of video understanding. In this paper, we present video-SALMONN 2, an advanced audio-visual large language model (LLM) with low-rank adaptation (LoRA) designed for enhanced video (with paired audio) captioning through directed preference optimisation (DPO). We propose new metrics to evaluate the completeness and accuracy of video descriptions, which are optimised using DPO. To further improve training, we propose a novel multi-round DPO (MrDPO) approach, which involves periodically updating the DPO reference model, merging and re-initialising the LoRA module as a proxy for parameter updates after each training round (1,000 steps), and incorporating guidance from ground-truth video captions to stabilise the process. Experimental results show that MrDPO significantly enhances video-SALMONN 2's captioning accuracy, reducing the captioning error rates by 28\\%. The final video-SALMONN 2 model, with just 7 billion parameters, surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioning tasks, while maintaining highly competitive performance to the state-of-the-art on widely used video question-answering benchmarks among models of similar size. Codes are available at \\href{https://github.com/bytedance/video-SALMONN-2}{https://github.com/bytedance/video-SALMONN-2}.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on video captioning using a large language model (video-SALMONN 2). While it doesn't directly address trajectory prediction, the use of LLMs for video understanding and the potential for describing dynamic scenes could indirectly relate to predicting future states or actions. The core focus, however, is on captioning performance.", "keywords": ["Large Language Models", "LLMs", "video captioning", "audio-visual"]}}
{"id": "2506.15065", "pdf": "https://arxiv.org/pdf/2506.15065", "abs": "https://arxiv.org/abs/2506.15065", "authors": ["Trishna Chakraborty", "Udita Ghosh", "Xiaopan Zhang", "Fahim Faisal Niloy", "Yue Dong", "Jiachen Li", "Amit K. Roy-Chowdhury", "Chengyu Song"], "title": "HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Large language models (LLMs) are increasingly being adopted as the cognitive core of embodied agents. However, inherited hallucinations, which stem from failures to ground user instructions in the observed physical environment, can lead to navigation errors, such as searching for a refrigerator that does not exist. In this paper, we present the first systematic study of hallucinations in LLM-based embodied agents performing long-horizon tasks under scene-task inconsistencies. Our goal is to understand to what extent hallucinations occur, what types of inconsistencies trigger them, and how current models respond. To achieve these goals, we construct a hallucination probing set by building on an existing benchmark, capable of inducing hallucination rates up to 40x higher than base prompts. Evaluating 12 models across two simulation environments, we find that while models exhibit reasoning, they fail to resolve scene-task inconsistencies-highlighting fundamental limitations in handling infeasible tasks. We also provide actionable insights on ideal model behavior for each scenario, offering guidance for developing more robust and reliable planning strategies.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eab\u667a\u80fd\u4f53\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662fLLM\u4ea7\u751f\u7684\u5e7b\u89c9\u95ee\u9898\u53ca\u5176\u5bf9\u5bfc\u822a\u7684\u5f71\u54cd\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\u7b97\u6cd5\u7684\u6539\u8fdb\uff0c\u4f46\u5b83\u63a2\u8ba8\u4e86LLM\u5728\u73af\u5883\u611f\u77e5\u548c\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u8fd9\u4e0e\u8f68\u8ff9\u9884\u6d4b\u4efb\u52a1\u4e2d\u667a\u80fd\u4f53\u7406\u89e3\u73af\u5883\u548c\u89c4\u5212\u8def\u5f84\u7684\u80fd\u529b\u5bc6\u5207\u76f8\u5173\u3002\u53ef\u4ee5\u8ba4\u4e3a\u8be5\u8bba\u6587\u662fLLM\u5728\u5177\u8eab\u667a\u80fd\u4f53\u9886\u57df\u5e94\u7528\u7684\u4e00\u4e2a\u76f8\u5173\u7814\u7a76\uff0c\u95f4\u63a5\u5f71\u54cd\u4e86\u8f68\u8ff9\u9884\u6d4b\u3002", "keywords": ["Large Language Models", "LLMs", "embodied agents", "hallucinations", "navigation"]}}
{"id": "2506.15313", "pdf": "https://arxiv.org/pdf/2506.15313", "abs": "https://arxiv.org/abs/2506.15313", "authors": ["Leonid Ivanov", "Vasily Yuryev", "Dmitry Yudin"], "title": "MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint. Submitted. 12 pages, 4 figures", "summary": "In autonomous driving, high-definition (HD) maps and semantic maps in bird's-eye view (BEV) are essential for accurate localization, planning, and decision-making. This paper introduces an enhanced End-to-End model named MapFM for online vectorized HD map generation. We show significantly boost feature representation quality by incorporating powerful foundation model for encoding camera images. To further enrich the model's understanding of the environment and improve prediction quality, we integrate auxiliary prediction heads for semantic segmentation in the BEV representation. This multi-task learning approach provides richer contextual supervision, leading to a more comprehensive scene representation and ultimately resulting in higher accuracy and improved quality of the predicted vectorized HD maps. The source code is available at https://github.com/LIvanoff/MapFM.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper utilizes a foundation model (a type of large model) for HD map generation, which is relevant to autonomous driving planning. While the primary focus isn't directly on trajectory prediction, HD maps are crucial for accurate trajectory prediction in autonomous vehicles. Therefore, there is an indirect connection. The paper uses a foundation model, which falls under the large language model umbrella, although it's applied to a vision task.", "keywords": ["foundation model", "HD map", "autonomous driving", "semantic segmentation", "BEV"]}}
{"id": "2506.15447", "pdf": "https://arxiv.org/pdf/2506.15447", "abs": "https://arxiv.org/abs/2506.15447", "authors": ["David Leprich", "Mario Rosenfelder", "Mario Hermle", "Jingshan Chen", "Peter Eberhard"], "title": "Model Predictive Path-Following Control for a Quadrotor", "categories": ["eess.SY", "cs.RO"], "comment": "15 pages, 11 figures, submitted to PAMM 2025", "summary": "Automating drone-assisted processes is a complex task. Many solutions rely on trajectory generation and tracking, whereas in contrast, path-following control is a particularly promising approach, offering an intuitive and natural approach to automate tasks for drones and other vehicles. While different solutions to the path-following problem have been proposed, most of them lack the capability to explicitly handle state and input constraints, are formulated in a conservative two-stage approach, or are only applicable to linear systems. To address these challenges, the paper is built upon a Model Predictive Control-based path-following framework and extends its application to the Crazyflie quadrotor, which is investigated in hardware experiments. A cascaded control structure including an underlying attitude controller is included in the Model Predictive Path-Following Control formulation to meet the challenging real-time demands of quadrotor control. The effectiveness of the proposed method is demonstrated through real-world experiments, representing, to the best of the authors' knowledge, a novel application of this MPC-based path-following approach to the quadrotor. Additionally, as an extension to the original method, to allow for deviations of the path in cases where the precise following of the path might be overly restrictive, a corridor path-following approach is presented.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on path-following control for a quadrotor, which is related to trajectory prediction and path planning. It uses Model Predictive Control (MPC), a technique often used in trajectory optimization. However, it doesn't involve large language models. The connection to trajectory prediction is through the path-following aspect, where the drone attempts to predict and follow a desired path.", "keywords": ["trajectory generation", "path-following control", "Model Predictive Control", "path planning"]}}
{"id": "2506.15635", "pdf": "https://arxiv.org/pdf/2506.15635", "abs": "https://arxiv.org/abs/2506.15635", "authors": ["Karmesh Yadav", "Yusuf Ali", "Gunshi Gupta", "Yarin Gal", "Zsolt Kira"], "title": "FindingDory: A Benchmark to Evaluate Memory in Embodied Agents", "categories": ["cs.CV", "cs.RO"], "comment": "Our dataset and code will be made available at: https://findingdory-benchmark.github.io/", "summary": "Large vision-language models have recently demonstrated impressive performance in planning and control tasks, driving interest in their application to real-world robotics. However, deploying these models for reasoning in embodied contexts is limited by their ability to incorporate long-term experience collected across multiple days and represented by vast collections of images. Current VLMs typically struggle to process more than a few hundred images concurrently, highlighting the need for more efficient mechanisms to handle long-term memory in embodied settings. To effectively evaluate these models for long-horizon control, a benchmark must specifically target scenarios where memory is crucial for success. Existing long-video QA benchmarks overlook embodied challenges like object manipulation and navigation, which demand low-level skills and fine-grained reasoning over past interactions. Moreover, effective memory integration in embodied agents involves both recalling relevant historical information and executing actions based on that information, making it essential to study these aspects together rather than in isolation. In this work, we introduce a new benchmark for long-range embodied tasks in the Habitat simulator. This benchmark evaluates memory-based capabilities across 60 tasks requiring sustained engagement and contextual awareness in an environment. The tasks can also be procedurally extended to longer and more challenging versions, enabling scalable evaluation of memory and reasoning. We also present baselines that integrate state-of-the-art VLMs with low level navigation policies, assessing their performance on these memory-intensive tasks and highlight areas for improvement.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on evaluating memory in embodied agents using large vision-language models (VLMs) for planning and control tasks within a simulated environment. While it doesn't directly address trajectory prediction, the embodied navigation aspect and the use of VLMs connect to the broader theme of predicting agent behavior and utilizing large models for decision-making. The paper uses Habitat simulator which often involves trajectory planning.", "keywords": ["Large vision-language models", "VLMs", "embodied agents", "planning", "control", "navigation", "Habitat simulator"]}}
{"id": "2506.15190", "pdf": "https://arxiv.org/pdf/2506.15190", "abs": "https://arxiv.org/abs/2506.15190", "authors": ["Jiyi Wang", "Jingyang Ke", "Bo Dai", "Anqi Wu"], "title": "Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors", "categories": ["cs.LG", "q-bio.NC"], "comment": "9 pages and 4 figures for the main text", "summary": "Animals flexibly recombine a finite set of core motor primitives to meet diverse task demands, but existing behavior-segmentation methods oversimplify this process by imposing discrete syllables under restrictive generative assumptions. To reflect the animal behavior generation procedure, we introduce skill-based imitation learning (SKIL) for behavior understanding, a reinforcement learning-based imitation framework that (1) infers interpretable skill sets, i.e., latent basis functions of behavior, by leveraging representation learning on transition probabilities, and (2) parameterizes policies as dynamic mixtures of these skills. We validate our approach on a simple grid world, a discrete labyrinth, and unconstrained videos of freely moving animals. Across tasks, it identifies reusable skill components, learns continuously evolving compositional policies, and generates realistic trajectories beyond the capabilities of traditional discrete models. By exploiting generative behavior modeling with compositional representations, our method offers a concise, principled account of how complex animal behaviors emerge from dynamic combinations of fundamental motor primitives.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u4eff\u5b66\u4e60\u6765\u5b66\u4e60\u52a8\u7269\u884c\u4e3a\u4e2d\u7684\u8fd0\u52a8\u539f\u8bed\uff0c\u5e76\u751f\u6210\u8f68\u8ff9\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u662f\u6d89\u53ca\u5230\u4e86\u8f68\u8ff9\u751f\u6210\u3001\u52a8\u4f5c\u9884\u6d4b\uff08\u901a\u8fc7\u5b66\u4e60\u8fd0\u52a8\u539f\u8bed\uff09\u4ee5\u53carepresentation learning\uff0c\u56e0\u6b64\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\u3002\u5173\u952e\u8bcdskill\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u79cd\u52a8\u4f5c\u7b56\u7565\u6216\u8005\u8fd0\u52a8\u57fa\u5143\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u76f8\u5173\u3002", "keywords": ["trajectory generation", "imitation learning", "reinforcement learning", "skill", "motor primitives", "behavior understanding"]}}
{"id": "2506.14851", "pdf": "https://arxiv.org/pdf/2506.14851", "abs": "https://arxiv.org/abs/2506.14851", "authors": ["Yifei Liu", "Zuo Gan", "Zhenghao Gan", "Weiye Wang", "Chen Chen", "Yizhou Shan", "Xusheng Chen", "Zhenhua Han", "Yifei Zhu", "Shixuan Sun", "Minyi Guo"], "title": "Efficient Serving of LLM Applications with Probabilistic Demand Modeling", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Applications based on Large Language Models (LLMs) contains a series of tasks to address real-world problems with boosted capability, which have dynamic demand volumes on diverse backends. Existing serving systems treat the resource demands of LLM applications as a blackbox, compromising end-to-end efficiency due to improper queuing order and backend warm up latency. We find that the resource demands of LLM applications can be modeled in a general and accurate manner with Probabilistic Demand Graph (PDGraph). We then propose Hermes, which leverages PDGraph for efficient serving of LLM applications. Confronting probabilistic demand description, Hermes applies the Gittins policy to determine the scheduling order that can minimize the average application completion time. It also uses the PDGraph model to help prewarm cold backends at proper moments. Experiments with diverse LLM applications confirm that Hermes can effectively improve the application serving efficiency, reducing the average completion time by over 70% and the P95 completion time by over 80%.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper focuses on efficient serving of LLM applications. While it deals with Large Language Models, it does not directly address trajectory prediction. However, the techniques for efficient serving could potentially be applied to trajectory prediction models that utilize LLMs.", "keywords": ["Large Language Models", "LLM applications", "Probabilistic Demand Modeling", "serving systems"]}}
