{"id": "2510.02865", "pdf": "https://arxiv.org/pdf/2510.02865", "abs": "https://arxiv.org/abs/2510.02865", "authors": ["Niko S. Snell", "Rayen C. Lee"], "title": "A New Normalization Form for Limited Distinct Attributes", "categories": ["cs.DB"], "comment": "11 pages", "summary": "In modern databases, the practice of data normalization continues to be\nimportant in improving data integrity, minimizing redundancies, and eliminating\nanomalies. However, since its inception and consequent improvements, there have\nbeen no attempts to document a method which constrains the values of attributes\ncapable of only possessing a limited quantity of values. These non-limited\ndistinct attributes pose a problem throughout many relational databases as they\nhave the potential to cause data anomalies and query inaccuracies. Thus, a new\ndatabase normalization method, Limited Distinct Normal Form (LDNF), is\nnecessary in order to improve upon the currently established data normalization\nprocess. In brief, LDNF is a method which turns non-limited distinct attributes\ninto limited distinct attributes by forcing the attributes to conform to a\nlimited quantity of values. Utilizing LDNF in tandem with existing normal forms\nfulfills a need in normalization that is otherwise not present when only using\ncurrent methods. A formal approach to LDNF is therefore proposed."}
{"id": "2510.03203", "pdf": "https://arxiv.org/pdf/2510.03203", "abs": "https://arxiv.org/abs/2510.03203", "authors": ["Yann Collet", "Nick Terrell", "W. Felix Handte", "Danielle Rozenblit", "Victor Zhang", "Kevin Zhang", "Yaelle Goldschlag", "Jennifer Lee", "Daniel Riegel", "Stan Angelov", "Nadav Rotem"], "title": "OpenZL: A Graph-Based Model for Compression", "categories": ["cs.IR", "cs.DB"], "comment": null, "summary": "Research in general-purpose lossless compression over the last decade has\nlargely found improvements in compression ratio that come at great cost to\nresource utilization and processing throughput. However, most production\nworkloads require high throughput and low resource utilization, so most\nresearch systems have seen little adoption. Instead, real world improvements in\ncompression are increasingly often realized by building application-specific\ncompressors which can exploit knowledge about the structure and semantics of\nthe data being compressed. These systems easily outperform even the best\ngeneric compressors, but application-specific compression schemes are not\nwithout drawbacks. They are inherently limited in applicability and are\ndifficult to maintain and deploy.\n  We show that these challenges can be overcome with a new way of thinking\nabout compression. We propose the ``graph model'' of compression, a new\ntheoretical framework for representing compression as a directed acyclic graph\nof modular codecs. This motivates OpenZL, an implementation of this model that\ncompresses data into a self-describing wire format, any configuration of which\ncan be decompressed by a universal decoder. OpenZL's design enables rapid\ndevelopment of tailored compressors with minimal code, its universal decoder\neliminates deployment lag, and its investment in a well-vetted standard\ncomponent library minimizes security risks. Experimental results demonstrate\nthat OpenZL achieves superior compression ratios and speeds compared to\nstate-of-the-art general-purpose compressors on a variety of real-world\ndatasets. Internal deployments at Meta have also shown consistent improvements\nin size and/or speed, with development timelines reduced from months to days.\nOpenZL thus represents an advance in practical, scalable, and maintainable data\ncompression for modern data-intensive applications."}
