{"id": "2510.07833", "pdf": "https://arxiv.org/pdf/2510.07833", "abs": "https://arxiv.org/abs/2510.07833", "authors": ["Santatra Hagamalala Bernardin", "Riad Mokadem", "Franck Morvan", "Hasinarivo Ramanana", "Hasimandimby Rakotoarivelo"], "title": "TCDRM: A Tenant Budget-Aware Data Replication Framework for Multi-Cloud Computing", "categories": ["cs.DB"], "comment": null, "summary": "Multi-cloud computing systems face significant challenges in ensuring\nacceptable performance while adhering to tenant budget requirements. This paper\nproposes a tenant budget-aware (tenant-centric) data replication framework for\nMulti-Cloud Computing (TCDRM). The proposed strategy dynamically creates data\nreplicas based on predefined thresholds for response time, economic budget of\nthe tenant and data popularity. TCDRM employs a heuristic replica placement\nalgorithm that leverages the diverse pricing structures of multiple cloud\nproviders. The TCDRM strategy aims to maintain the required performance without\nexceeding the tenant's budget by taking advantage of the capabilities offered\nby multicloud environments. The middleware considered acts as an intermediary\nbetween tenants and multiple cloud providers, facilitating intelligent replica\nplacement decisions. To achieve this, the proposed TCDRM strategy defines\nstrict thresholds for tenant budget and response time. A performance evaluation\nis conducted to validate the effectiveness of the strategy. The results show\nthat our approach effectively meets tenant performance objectives while\nrespecting their economic constraints. Bandwidth consumption is reduced by up\nto 78% compared to non-replicated approaches, and average response time for\ncomplex queries is decreased by 51%, all while adhering to tenant budget\nlimitations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u591a\u4e91\u73af\u5883\u7684\u79df\u6237\u9884\u7b97\u611f\u77e5\u6570\u636e\u590d\u5236\u6846\u67b6\uff08TCDRM\uff09\uff0c\u65e8\u5728\u6ee1\u8db3\u79df\u6237\u6027\u80fd\u9700\u6c42\u7684\u540c\u65f6\uff0c\u9075\u5b88\u5176\u7ecf\u6d4e\u9884\u7b97\u7ea6\u675f\u3002", "motivation": "\u591a\u4e91\u8ba1\u7b97\u7cfb\u7edf\u5728\u786e\u4fdd\u53ef\u63a5\u53d7\u7684\u6027\u80fd\u5e76\u9075\u5b88\u79df\u6237\u9884\u7b97\u8981\u6c42\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79df\u6237\u9884\u7b97\u611f\u77e5\u7684\u6570\u636e\u590d\u5236\u6846\u67b6\uff08TCDRM\uff09\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u54cd\u5e94\u65f6\u95f4\u3001\u79df\u6237\u7ecf\u6d4e\u9884\u7b97\u548c\u6570\u636e\u6d41\u884c\u5ea6\u7684\u9884\u5b9a\u4e49\u9608\u503c\u52a8\u6001\u521b\u5efa\u6570\u636e\u526f\u672c\uff0c\u5e76\u91c7\u7528\u542f\u53d1\u5f0f\u526f\u672c\u653e\u7f6e\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u6ee1\u8db3\u4e86\u79df\u6237\u7684\u6027\u80fd\u76ee\u6807\uff0c\u540c\u65f6\u5c0a\u91cd\u5176\u7ecf\u6d4e\u7ea6\u675f\u3002\u4e0e\u975e\u590d\u5236\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5e26\u5bbd\u6d88\u8017\u964d\u4f4e\u4e86\u9ad8\u8fbe78%\uff0c\u590d\u6742\u67e5\u8be2\u7684\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u51cf\u5c11\u4e8651%\uff0c\u5e76\u4e14\u90fd\u7b26\u5408\u79df\u6237\u7684\u9884\u7b97\u9650\u5236\u3002", "conclusion": "TCDRM\u7b56\u7565\u80fd\u591f\u5229\u7528\u591a\u4e91\u73af\u5883\u63d0\u4f9b\u7684\u80fd\u529b\uff0c\u5728\u4e0d\u8d85\u51fa\u79df\u6237\u9884\u7b97\u7684\u60c5\u51b5\u4e0b\uff0c\u7ef4\u6301\u6240\u9700\u7684\u6027\u80fd\u3002", "summary_zh": "\u591a\u4e91\u8ba1\u7b97\u7cfb\u7edf\u5728\u786e\u4fdd\u53ef\u63a5\u53d7\u7684\u6027\u80fd\u5e76\u9075\u5b88\u79df\u6237\u9884\u7b97\u8981\u6c42\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u591a\u4e91\u8ba1\u7b97\u7684\u79df\u6237\u9884\u7b97\u611f\u77e5\uff08\u4ee5\u79df\u6237\u4e3a\u4e2d\u5fc3\uff09\u6570\u636e\u590d\u5236\u6846\u67b6\uff08TCDRM\uff09\u3002\u6240\u63d0\u51fa\u7684\u7b56\u7565\u57fa\u4e8e\u54cd\u5e94\u65f6\u95f4\u3001\u79df\u6237\u7ecf\u6d4e\u9884\u7b97\u548c\u6570\u636e\u6d41\u884c\u5ea6\u7684\u9884\u5b9a\u4e49\u9608\u503c\u52a8\u6001\u521b\u5efa\u6570\u636e\u526f\u672c\u3002TCDRM \u91c7\u7528\u4e86\u4e00\u79cd\u542f\u53d1\u5f0f\u526f\u672c\u653e\u7f6e\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u4e86\u591a\u4e2a\u4e91\u63d0\u4f9b\u5546\u7684\u4e0d\u540c\u5b9a\u4ef7\u7ed3\u6784\u3002TCDRM \u7b56\u7565\u65e8\u5728\u901a\u8fc7\u5229\u7528\u591a\u4e91\u73af\u5883\u63d0\u4f9b\u7684\u80fd\u529b\uff0c\u5728\u4e0d\u8d85\u51fa\u79df\u6237\u9884\u7b97\u7684\u60c5\u51b5\u4e0b\uff0c\u7ef4\u6301\u6240\u9700\u7684\u6027\u80fd\u3002\u6240\u8003\u8651\u7684\u4e2d\u95f4\u4ef6\u5145\u5f53\u79df\u6237\u548c\u591a\u4e2a\u4e91\u63d0\u4f9b\u5546\u4e4b\u95f4\u7684\u4e2d\u4ecb\uff0c\u4fc3\u8fdb\u667a\u80fd\u526f\u672c\u653e\u7f6e\u51b3\u7b56\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u6240\u63d0\u51fa\u7684 TCDRM \u7b56\u7565\u4e3a\u79df\u6237\u9884\u7b97\u548c\u54cd\u5e94\u65f6\u95f4\u5b9a\u4e49\u4e86\u4e25\u683c\u7684\u9608\u503c\u3002\u901a\u8fc7\u6027\u80fd\u8bc4\u4f30\u6765\u9a8c\u8bc1\u8be5\u7b56\u7565\u7684\u6709\u6548\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6709\u6548\u5730\u6ee1\u8db3\u4e86\u79df\u6237\u7684\u6027\u80fd\u76ee\u6807\uff0c\u540c\u65f6\u5c0a\u91cd\u5176\u7ecf\u6d4e\u7ea6\u675f\u3002\u4e0e\u975e\u590d\u5236\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5e26\u5bbd\u6d88\u8017\u964d\u4f4e\u4e86\u9ad8\u8fbe 78%\uff0c\u590d\u6742\u67e5\u8be2\u7684\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u51cf\u5c11\u4e86 51%\uff0c\u5e76\u4e14\u90fd\u7b26\u5408\u79df\u6237\u7684\u9884\u7b97\u9650\u5236\u3002"}}
{"id": "2510.07963", "pdf": "https://arxiv.org/pdf/2510.07963", "abs": "https://arxiv.org/abs/2510.07963", "authors": ["Nhu Ngoc Hoang", "Ngoc Hoa Pham", "Viet Phuong Hoang", "Esteban Zim\u00e1nyi"], "title": "MobilityDuck: Mobility Data Management with DuckDB", "categories": ["cs.DB"], "comment": null, "summary": "The analytics of spatiotemporal data is increasingly important for mobility\nanalytics. Despite extensive research on moving object databases (MODs), few\nsystems are ready on production or lightweight enough for analytics. MobilityDB\nis a notable system that extends PostgreSQL with spatiotemporal data, but it\ninherits complexity of the architecture as well. In this paper, we present\nMobilityDuck, a DuckDB extension that integrates the MEOS library to provide\nsupport spatiotemporal and other temporal data types in DuckDB. MobilityDuck\nleverages DuckDB's lightweight, columnar, in-memory executable properties to\ndeliver efficient analytics. To the best of our knowledge, no existing\nin-memory or embedded analytical system offers native spatiotemporal types and\ncontinuous trajectory operators as MobilityDuck does. We evaluate MobilityDuck\nusing the BerlinMOD-Hanoi benchmark dataset and compare its performance to\nMobilityDB. Our results show that MobilityDuck preserves the expressiveness of\nspatiotemporal queries while benefiting from DuckDB's in-memory, columnar\narchitecture.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07983", "pdf": "https://arxiv.org/pdf/2510.07983", "abs": "https://arxiv.org/abs/2510.07983", "authors": ["Xianghong Xu", "Rong Kang", "Xiao He", "Lei Zhang", "Jianjun Chen", "Tieying Zhang"], "title": "ZeroCard: Cardinality Estimation with Zero Dependence on Target Databases -- No Data, No Query, No Retraining", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Cardinality estimation is a fundamental task in database systems and plays a\ncritical role in query optimization. Despite significant advances in\nlearning-based cardinality estimation methods, most existing approaches remain\ndifficult to generalize to new datasets due to their strong dependence on raw\ndata or queries, thus limiting their practicality in real scenarios. To\novercome these challenges, we argue that semantics in the schema may benefit\ncardinality estimation, and leveraging such semantics may alleviate these\ndependencies. To this end, we introduce ZeroCard, the first semantics-driven\ncardinality estimation method that can be applied without any dependence on raw\ndata access, query logs, or retraining on the target database. Specifically, we\npropose to predict data distributions using schema semantics, thereby avoiding\nraw data dependence. Then, we introduce a query template-agnostic\nrepresentation method to alleviate query dependence. Finally, we construct a\nlarge-scale query dataset derived from real-world tables and pretrain ZeroCard\non it, enabling it to learn cardinality from schema semantics and predicate\nrepresentations. After pretraining, ZeroCard's parameters can be frozen and\napplied in an off-the-shelf manner. We conduct extensive experiments to\ndemonstrate the distinct advantages of ZeroCard and show its practical\napplications in query optimization. Its zero-dependence property significantly\nfacilitates deployment in real-world scenarios.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.08489", "pdf": "https://arxiv.org/pdf/2510.08489", "abs": "https://arxiv.org/abs/2510.08489", "authors": ["Immanuel Trummer"], "title": "Implementing Semantic Join Operators Efficiently", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Semantic query processing engines often support semantic joins, enabling\nusers to match rows that satisfy conditions specified in natural language. Such\njoin conditions can be evaluated using large language models (LLMs) that solve\nnovel tasks without task-specific training.\n  Currently, many semantic query processing engines implement semantic joins\nvia nested loops, invoking the LLM to evaluate the join condition on row pairs.\nInstead, this paper proposes a novel algorithm, inspired by the block nested\nloops join operator implementation in traditional database systems. The\nproposed algorithm integrates batches of rows from both input tables into a\nsingle prompt. The goal of the LLM invocation is to identify all matching row\npairs in the current input. The paper introduces formulas that can be used to\noptimize the size of the row batches, taking into account constraints on the\nsize of the LLM context window (limiting both input and output size). An\nadaptive variant of the proposed algorithm refers to cases in which the size of\nthe output is difficult to estimate. A formal analysis of asymptotic processing\ncosts, as well as empirical results, demonstrates that the proposed approach\nreduces costs significantly and performs well compared to join implementations\nused by recent semantic query processing engines.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07422", "pdf": "https://arxiv.org/pdf/2510.07422", "abs": "https://arxiv.org/abs/2510.07422", "authors": ["R\u00e9mi Morvan"], "title": "Homomorphism Problems in Graph Databases and Automatic Structures", "categories": ["cs.LO", "cs.DB", "cs.FL"], "comment": "Ph.D. thesis defended on 3 July 2025 at Universit\\'e de Bordeaux", "summary": "This thesis investigates the central role of homomorphism problems\n(structure-preserving maps) in two complementary domains: database querying\nover finite, graph-shaped data, and constraint solving over (potentially\ninfinite) structures. Building on the well-known equivalence between\nconjunctive query evaluation and homomorphism existence, the first part focuses\non conjunctive regular path queries, a standard extension of conjunctive\nqueries that incorporates regular-path predicates. We study the fundamental\nproblem of query minimization under two measures: the number of atoms\n(constraints) and the tree-width of the query graph. In both cases, we prove\nthe problem to be decidable, and provide efficient algorithms for a large\nfragment of queries used in practice. The second part of the thesis lifts\nhomomorphism problems to automatic structures, which are infinite structures\ndescribable by finite automata. We highlight a dichotomy, between homomorphism\nproblems over automatic structures that are decidable in non-deterministic\nlogarithmic space, and those that are undecidable (proving to be the more\ncommon case). In contrast to this prevalence of undecidability, we then focus\non the language-theoretic properties of these structures, and show, relying on\na novel algebraic language theory, that for any well-behaved logic (a\npseudovariety), whether an automatic structure can be described in this logic\nis decidable.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07513", "pdf": "https://arxiv.org/pdf/2510.07513", "abs": "https://arxiv.org/abs/2510.07513", "authors": ["Qinghua Liu", "Sam Heshmati", "Zheda Mai", "Zubin Abraham", "John Paparrizos", "Liu Ren"], "title": "MLLM4TS: Leveraging Vision and Multimodal Language Models for General Time-Series Analysis", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DB"], "comment": null, "summary": "Effective analysis of time series data presents significant challenges due to\nthe complex temporal dependencies and cross-channel interactions in\nmultivariate data. Inspired by the way human analysts visually inspect time\nseries to uncover hidden patterns, we ask: can incorporating visual\nrepresentations enhance automated time-series analysis? Recent advances in\nmultimodal large language models have demonstrated impressive generalization\nand visual understanding capability, yet their application to time series\nremains constrained by the modality gap between continuous numerical data and\ndiscrete natural language. To bridge this gap, we introduce MLLM4TS, a novel\nframework that leverages multimodal large language models for general\ntime-series analysis by integrating a dedicated vision branch. Each time-series\nchannel is rendered as a horizontally stacked color-coded line plot in one\ncomposite image to capture spatial dependencies across channels, and a\ntemporal-aware visual patch alignment strategy then aligns visual patches with\ntheir corresponding time segments. MLLM4TS fuses fine-grained temporal details\nfrom the numerical data with global contextual information derived from the\nvisual representation, providing a unified foundation for multimodal\ntime-series analysis. Extensive experiments on standard benchmarks demonstrate\nthe effectiveness of MLLM4TS across both predictive tasks (e.g.,\nclassification) and generative tasks (e.g., anomaly detection and forecasting).\nThese results underscore the potential of integrating visual modalities with\npretrained language models to achieve robust and generalizable time-series\nanalysis.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.07653", "pdf": "https://arxiv.org/pdf/2510.07653", "abs": "https://arxiv.org/abs/2510.07653", "authors": ["Jiawen Chen", "Jinwei Zhang", "Dongshen Peng", "Yutong Song", "Aitong Ruan", "Yun Li", "Didong Li"], "title": "Large-scale spatial variable gene atlas for spatial transcriptomics", "categories": ["stat.AP", "cs.DB", "q-bio.GN", "q-bio.TO", "stat.CO", "62P10", "J.3"], "comment": null, "summary": "Spatial variable genes (SVGs) reveal critical information about tissue\narchitecture, cellular interactions, and disease microenvironments. As spatial\ntranscriptomics (ST) technologies proliferate, accurately identifying SVGs\nacross diverse platforms, tissue types, and disease contexts has become both a\nmajor opportunity and a significant computational challenge. Here, we present a\ncomprehensive benchmarking study of 20 state-of-the-art SVG detection methods\nusing human slides from STimage-1K4M, a large-scale resource of ST data\ncomprising 662 slides from more than 18 tissue types. We evaluate each method\nacross a range of biologically and technically meaningful criteria, including\nrecovery of pathologist-annotated domain-specific markers, cross-slide\nreproducibility, scalability to high-resolution data, and robustness to\ntechnical variation. Our results reveal marked differences in performance\ndepending on tissue type, spatial resolution, and study design. Beyond\nbenchmarking, we construct the first cross-tissue atlas of SVGs, enabling\ncomparative analysis of spatial gene programs across cancer and normal tissues.\nWe observe similarities between pairs of tissues that reflect developmental and\nfunctional relationships, such as high overlap between thymus and lymph node,\nand uncover spatial gene programs associated with metastasis, immune\ninfiltration, and tissue-of-origin identity in cancer. Together, our work\ndefines a framework for evaluating and interpreting spatial gene expression and\nestablishes a reference resource for the ST community.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2510.08385", "pdf": "https://arxiv.org/pdf/2510.08385", "abs": "https://arxiv.org/abs/2510.08385", "authors": ["Sofia Kirsanova", "Yao-Yi Chiang", "Weiwei Duan"], "title": "Detecting Legend Items on Historical Maps Using GPT-4o with In-Context Learning", "categories": ["cs.CV", "cs.AI", "cs.DB", "cs.IR", "H.2.8; H.3.3; I.2.10; I.4.8"], "comment": null, "summary": "Historical map legends are critical for interpreting cartographic symbols.\nHowever, their inconsistent layouts and unstructured formats make automatic\nextraction challenging. Prior work focuses primarily on segmentation or general\noptical character recognition (OCR), with few methods effectively matching\nlegend symbols to their corresponding descriptions in a structured manner. We\npresent a method that combines LayoutLMv3 for layout detection with GPT-4o\nusing in-context learning to detect and link legend items and their\ndescriptions via bounding box predictions. Our experiments show that GPT-4 with\nstructured JSON prompts outperforms the baseline, achieving 88% F-1 and 85%\nIoU, and reveal how prompt design, example counts, and layout alignment affect\nperformance. This approach supports scalable, layout-aware legend parsing and\nimproves the indexing and searchability of historical maps across various\nvisual styles.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
