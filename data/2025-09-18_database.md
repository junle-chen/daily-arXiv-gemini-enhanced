# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-09-18

## 目录

- [cs.DB (1)](#cs-db)
- [cs.DC (1)](#cs-dc)

## cs.DB [cs.DB]
### [1] [ScaleDoc: Scaling LLM-based Predicates over Large Document Collections](https://arxiv.org/abs/2509.12610)
*Hengrui Zhang, Yulong Hui, Yihao Liu, Huanchen Zhang*

Main category: cs.DB

TL;DR: ScaleDoc通过离线生成文档语义表示和在线训练轻量级代理模型过滤文档，显著降低了LLM的调用次数，提高了大规模语义分析的效率。


<details>
  <summary>Details</summary>
Motivation: 现代工作负载越来越多地涉及非结构化文档，这需要超越传统基于值的谓词的语义理解。大型语言模型 (LLM) 虽然展示了强大的零样本能力，但其高昂的推理成本导致了不可接受的开销。

Method: ScaleDoc将谓词执行解耦为离线表示阶段和优化的在线过滤阶段。离线阶段利用LLM为每个文档生成语义表示。在线阶段，针对每个查询，它在这些表示上训练一个轻量级代理模型来过滤掉大多数文档，仅将模糊的案例转发给LLM进行最终决策。此外，ScaleDoc提出了两个核心创新：(1) 基于对比学习的框架，训练代理模型以生成可靠的谓词决策分数；(2) 自适应级联机制，确定有效的过滤策略，同时满足特定的准确性目标。

Result: 在三个数据集上的评估表明，ScaleDoc实现了超过2倍的端到端加速，并将昂贵的LLM调用减少了高达85%，从而使大规模语义分析变得实用且高效。

Conclusion: ScaleDoc通过离线表示和在线过滤，有效降低了LLM的调用次数，提高了大规模语义分析的效率，使其更具实用性。

Abstract: 谓词是数据分析系统中的基础组件。然而，现代工作负载越来越多地涉及非结构化文档，这需要超越传统基于值的谓词的语义理解。鉴于海量文档和临时查询，虽然大型语言模型 (LLM) 展示了强大的零样本能力，但其高昂的推理成本导致了不可接受的开销。因此，我们引入了 ScaleDoc，这是一个新颖的系统，它通过将谓词执行解耦为离线表示阶段和优化的在线过滤阶段来解决这个问题。在离线阶段，ScaleDoc 利用 LLM 为每个文档生成语义表示。在线阶段，针对每个查询，它在这些表示上训练一个轻量级代理模型来过滤掉大多数文档，仅将模糊的案例转发给 LLM 进行最终决策。此外，ScaleDoc 提出了两个核心创新，以实现显著的效率：(1) 基于对比学习的框架，训练代理模型以生成可靠的谓词决策分数；(2) 自适应级联机制，确定有效的过滤策略，同时满足特定的准确性目标。我们在三个数据集上的评估表明，ScaleDoc 实现了超过 2 倍的端到端加速，并将昂贵的 LLM 调用减少了高达 85%，从而使大规模语义分析变得实用且高效。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.12610) | **Categories:** cs.DB, cs.AI, cs.LG

---


## cs.DC [cs.DC]
### [1] [Exploring Distributed Vector Databases Performance on HPC Platforms: A Study with Qdrant](https://arxiv.org/abs/2509.12384)
*Seth Ockerman, Amal Gueroudji, Song Young Oh, Robert Underwood, Nicholas Chia, Kyle Chard, Robert Ross, Shivaram Venkataraman*

Main category: cs.DC

TL;DR: 本文研究了在高性能计算（HPC）系统上分布式向量数据库的性能，并为未来的研究和优化提供指导。


<details>
  <summary>Details</summary>
Motivation: 向量数据库在现代人工智能工作流程中发挥着核心作用，但对于驱动大规模科学的高性能计算（HPC）系统中向量数据库的性能特征知之甚少。

Method: 本文在Argonne Leadership Computing Facility的Polaris超级计算机上，构建了一个来自BV-BRC的真实生物文本工作负载，并使用Qwen3-Embedding-4B从peS2o语料库生成嵌入，选择Qdrant来评估插入、索引构建和查询延迟，最多使用32个worker。

Result: 本文对分布式向量数据库在HPC平台上的性能进行了初步的表征，总结了实践经验。

Conclusion: 本文旨在通过表征向量数据库在HPC平台上的性能，为未来的研究和优化提供指导。

Abstract: 向量数据库已经迅速普及，可以在文本、图像和视频等数据上实现高效的相似性搜索。它们现在在现代人工智能工作流程中发挥着核心作用，通过检索增强生成，帮助大型语言模型将模型输出建立在外部文献的基础上。尽管它们很重要，但对于驱动大规模科学的高性能计算（HPC）系统中向量数据库的性能特征知之甚少。这项工作对Argonne Leadership Computing Facility的Polaris超级计算机上分布式向量数据库的性能进行了实证研究。我们构建了一个来自BV-BRC的真实生物文本工作负载，并使用Qwen3-Embedding-4B从peS2o语料库生成嵌入。我们选择Qdrant来评估插入、索引构建和查询延迟，最多使用32个worker。根据我们经验中的实际教训，这项工作朝着表征HPC平台上向量数据库的性能迈出了第一步，以指导未来的研究和优化。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.12384) | **Categories:** cs.DC, cs.DB

---
