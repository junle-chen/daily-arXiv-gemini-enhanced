# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-10-22

## 目录

- [人工智能 (Artificial Intelligence) (1)](#cs-ai)
- [cs.DB (7)](#cs-db)

## 人工智能 (Artificial Intelligence) [cs.AI]
### [1] [DeepAnalyze: Agentic Large Language Models for Autonomous Data Science](https://arxiv.org/abs/2510.16872)
*Shaolei Zhang, Ju Fan, Meihao Fan, Guoliang Li, Xiaoyong Du*

Main category: cs.AI

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Autonomous data science, from raw data sources to analyst-grade deep research reports, has been a long-standing challenge, and is now becoming feasible with the emergence of powerful large language models (LLMs). Recent workflow-based data agents have shown promising results on specific data tasks but remain fundamentally limited in achieving fully autonomous data science due to their reliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B, the first agentic LLM designed for autonomous data science, capable of automatically completing the end-toend pipeline from data sources to analyst-grade deep research reports. To tackle high-complexity data science tasks, we propose a curriculum-based agentic training paradigm that emulates the learning trajectory of human data scientists, enabling LLMs to progressively acquire and integrate multiple capabilities in real-world environments. We also introduce a data-grounded trajectory synthesis framework that constructs high-quality training data. Through agentic training, DeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data question answering and specialized analytical tasks to open-ended data research. Experiments demonstrate that, with only 8B parameters, DeepAnalyze outperforms previous workflow-based agents built on most advanced proprietary LLMs. The model, code, and training data of DeepAnalyze are open-sourced, paving the way toward autonomous data science.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.16872) | **Categories:** cs.AI, cs.CL, cs.DB

---


## cs.DB [cs.DB]
### [1] [Unified Peripartum Database with Natural-Language-to-SQL Capabilities at Udine University Hospital: Design and Prototype](https://arxiv.org/abs/2510.16388)
*Doriana Armenise, Ginevra Battello, Andrea Brunello, Lorenza Driul, Angelo Montanari, Elisa Rizzante, Nicola Saccomanno, Andrea Salvador, Serena Xodo, Silvia Zermano*

Main category: cs.DB

TL;DR: 本文提出了一种将异构围产期记录转换为可计算、可查询资产的实用蓝图，通过设计和原型化一个统一的围产期关系数据库，该数据库具有自然语言到SQL（NL2SQL）功能。


<details>
  <summary>Details</summary>
Motivation: 医院中常见的产科信息在电子健康记录模块、设备存储库和实验室系统中的碎片化，阻碍了分娩期间的护理和可重复的研究。

Method: 通过与临床医生共同定义需求，并将其形式化为实体关系图，从中推导出数据库的逻辑模式和SQL实现，从而将异构围产期记录转换为可计算、可查询的资产。

Result: 该数据库集成了异构来源，连接了母亲的既往史和纵向病史、当前妊娠发现、分娩过程以及分娩和新生儿结局。NL2SQL层使临床医生能够向系统提出自然语言查询，降低了审计和探索性分析的门槛。

Conclusion: 本文展示了一种将异构围产期记录转换为可计算、可查询资产的实用蓝图，并设计和原型化了一个统一的围产期关系数据库，具有自然语言到SQL（NL2SQL）功能。

Abstract: 医院中常见的产科信息在电子健康记录模块、设备存储库和实验室系统中的碎片化，阻碍了分娩期间的护理和可重复的研究。在这项工作中，我们提出了一个实用的蓝图，通过在乌迪内大学医院妇产科诊所设计和原型化一个具有自然语言到SQL（NL2SQL）功能的统一围产期关系数据库，将异构围产期记录转换为可计算、可查询的资产。需求与临床医生共同定义，并形式化为实体关系图，从中推导出数据库的逻辑模式和SQL实现。后者集成了异构来源，连接了母亲的既往史和纵向病史、当前妊娠发现、分娩过程以及分娩和新生儿结局。NL2SQL层使临床医生能够向系统提出自然语言查询，降低了审计和探索性分析的门槛。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.16388) | **Categories:** cs.DB, H.2; H.4.0

---

### [2] [Declarative Techniques for NL Queries over Heterogeneous Data](https://arxiv.org/abs/2510.16470)
*Elham Khabiri, Jeffrey O. Kephart, Fenno F. Heath III, Srideepika Jayaraman, Fateh A. Tipu, Yingjie Li, Dhruv Shah, Achille Fokoue, Anu Bhamidipaty*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: In many industrial settings, users wish to ask questions in natural language, the answers to which require assembling information from diverse structured data sources. With the advent of Large Language Models (LLMs), applications can now translate natural language questions into a set of API calls or database calls, execute them, and combine the results into an appropriate natural language response. However, these applications remain impractical in realistic industrial settings because they do not cope with the data source heterogeneity that typifies such environments. In this work, we simulate the heterogeneity of real industry settings by introducing two extensions of the popular Spider benchmark dataset that require a combination of database and API calls. Then, we introduce a declarative approach to handling such data heterogeneity and demonstrate that it copes with data source heterogeneity significantly better than state-of-the-art LLM-based agentic or imperative code generation systems. Our augmented benchmarks are available to the research community.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.16470) | **Categories:** cs.DB, cs.AI, cs.SE

---

### [3] [AVOCADO: The Streaming Process Mining Challenge](https://arxiv.org/abs/2510.17089)
*Christian Imenkamp, Andrea Maldonado, Hendrik Reiter, Martin Werner, Wilhelm Hasselbring, Agnes Koschmider, Andrea Burattin*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Streaming process mining deals with the real-time analysis of streaming data. Event streams require algorithms capable of processing data incrementally. To systematically address the complexities of this domain, we propose AVOCADO, a standardized challenge framework that provides clear structural divisions: separating the concept and instantiation layers of challenges in streaming process mining for algorithm evaluation. The AVOCADO evaluates algorithms on streaming-specific metrics like accuracy, Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Processing Latency, and robustness. This initiative seeks to foster innovation and community-driven discussions to advance the field of streaming process mining. We present this framework as a foundation and invite the community to contribute to its evolution by suggesting new challenges, such as integrating metrics for system throughput and memory consumption, and expanding the scope to address real-world stream complexities like out-of-order event arrival.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.17089) | **Categories:** cs.DB

---

### [4] [Comprehending Spatio-temporal Data via Cinematic Storytelling using Large Language Models](https://arxiv.org/abs/2510.17301)
*Panos Kalnis. Shuo Shang, Christian S. Jensen*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Spatio-temporal data captures complex dynamics across both space and time, yet traditional visualizations are complex, require domain expertise and often fail to resonate with broader audiences. Here, we propose MapMuse, a storytelling-based framework for interpreting spatio-temporal datasets, transforming them into compelling, narrative-driven experiences. We utilize large language models and employ retrieval augmented generation (RAG) and agent-based techniques to generate comprehensive stories. Drawing on principles common in cinematic storytelling, we emphasize clarity, emotional connection, and audience-centric design. As a case study, we analyze a dataset of taxi trajectories. Two perspectives are presented: a captivating story based on a heat map that visualizes millions of taxi trip endpoints to uncover urban mobility patterns; and a detailed narrative following a single long taxi journey, enriched with city landmarks and temporal shifts. By portraying locations as characters and movement as plot, we argue that data storytelling drives insight, engagement, and action from spatio-temporal information. The case study illustrates how MapMuse can bridge the gap between data complexity and human understanding. The aim of this short paper is to provide a glimpse to the potential of the cinematic storytelling technique as an effective communication tool for spatio-temporal data, as well as to describe open problems and opportunities for future research.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.17301) | **Categories:** cs.DB, cs.AI

---

### [5] [Approximate Nearest Neighbor Search of Large Scale Vectors on Distributed Storage](https://arxiv.org/abs/2510.17326)
*Kun Yu, Jiabao Jin, Xiaoyao Zhong, Peng Cheng, Lei Chen, Zhitao Shen, Jingkuan Song, Hengtao Shen, Xuemin Lin*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Approximate Nearest Neighbor Search (ANNS) in high-dimensional space is an essential operator in many online services, such as information retrieval and recommendation. Indices constructed by the state-of-the-art ANNS algorithms must be stored in single machine's memory or disk for high recall rate and throughput, suffering from substantial storage cost, constraint of limited scale and single point of failure. While distributed storage can provide a cost-effective and robust solution, there is no efficient and effective algorithms for indexing vectors in distributed storage scenarios. In this paper, we present a new graph-cluster hybrid indexing and search system which supports Distributed Storage Approximate Nearest Neighbor Search, called DSANN. DSANN can efficiently index, store, search billion-scale vector database in distributed storage and guarantee the high availability of index service. DSANN employs the concurrent index construction method to significantly reduces the complexity of index building. Then, DSANN applies Point Aggregation Graph to leverage the structural information of graph to aggregate similar vectors, optimizing storage efficiency and improving query throughput via asynchronous I/O in distributed storage. Through extensive experiments, we demonstrate DSANN can efficiently and effectively index, store and search large-scale vector datasets in distributed storage scenarios.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.17326) | **Categories:** cs.DB

---

### [6] [DeepEye-SQL: A Software-Engineering-Inspired Text-to-SQL Framework](https://arxiv.org/abs/2510.17586)
*Boyan Li, Chong Chen, Zhujun Xue, Yinan Mei, Yuyu Luo*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Large language models (LLMs) have advanced Text-to-SQL, yet existing solutions still fall short of system-level reliability. The limitation is not merely in individual modules - e.g., schema linking, reasoning, and verification - but more critically in the lack of structured orchestration that enforces correctness across the entire workflow. This gap motivates a paradigm shift: treating Text-to-SQL not as free-form language generation but as a software-engineering problem that demands structured, verifiable orchestration. We present DeepEye-SQL, a software-engineering-inspired framework that reframes Text-to-SQL as the development of a small software program, executed through a verifiable process guided by the Software Development Life Cycle (SDLC). DeepEye-SQL integrates four synergistic stages: it grounds ambiguous user intent through semantic value retrieval and robust schema linking; enhances fault tolerance with N-version SQL generation using diverse reasoning paradigms; ensures deterministic verification via a tool-chain of unit tests and targeted LLM-guided revision; and introduces confidence-aware selection that clusters execution results to estimate confidence and then takes a high-confidence shortcut or runs unbalanced pairwise adjudication in low-confidence cases, yielding a calibrated, quality-gated output. This SDLC-aligned workflow transforms ad hoc query generation into a disciplined engineering process. Using ~30B open-source LLMs without any fine-tuning, DeepEye-SQL achieves 73.5% execution accuracy on BIRD-Dev and 89.8% on Spider-Test, outperforming state-of-the-art solutions. This highlights that principled orchestration, rather than LLM scaling alone, is key to achieving system-level reliability in Text-to-SQL.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.17586) | **Categories:** cs.DB

---

### [7] [This is Going to Sound Crazy, But What If We Used Large Language Models to Boost Automatic Database Tuning Algorithms By Leveraging Prior History? We Will Find Better Configurations More Quickly Than Retraining From Scratch!](https://arxiv.org/abs/2510.17748)
*William Zhang, Wan Shen Lim, Andrew Pavlo*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Tuning database management systems (DBMSs) is challenging due to trillions of possible configurations and evolving workloads. Recent advances in tuning have led to breakthroughs in optimizing over the possible configurations. However, due to their design and inability to leverage query-level historical insights, existing automated tuners struggle to adapt and re-optimize the DBMS when the environment changes (e.g., workload drift, schema transfer).   This paper presents the Booster framework that assists existing tuners in adapting to environment changes (e.g., drift, cross-schema transfer). Booster structures historical artifacts into query-configuration contexts, prompts large language models (LLMs) to suggest configurations for each query based on relevant contexts, and then composes the query-level suggestions into a holistic configuration with beam search. With multiple OLAP workloads, we evaluate Booster's ability to assist different state-of-the-art tuners (e.g., cost-/machine learning-/LLM-based) in adapting to environment changes. By composing recommendations derived from query-level insights, Booster assists tuners in discovering configurations that are up to 74% better and in up to 4.7x less time than the alternative approach of continuing to tune from historical configurations.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.17748) | **Categories:** cs.DB

---
