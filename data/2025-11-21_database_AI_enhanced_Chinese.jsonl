{"id": "2511.14762", "pdf": "https://arxiv.org/pdf/2511.14762", "abs": "https://arxiv.org/abs/2511.14762", "authors": ["Yongye Su", "Yucheng Zhang", "Zeru Shi", "Bruno Ribeiro", "Elisa Bertino"], "title": "Castle: Causal Cascade Updates in Relational Databases with Large Language Models", "categories": ["cs.DB"], "comment": null, "summary": "This work introduces Castle, the first framework for schema-only cascade update generation using large language models (LLMs). Despite recent advances in LLMs for Text2SQL code generation, existing approaches focus primarily on SELECT queries, neglecting the challenges of SQL update operations and their ripple effects. Traditional CASCADE UPDATE constraints are static and unsuitable for modern, denormalized databases, which demand dynamic, context-aware updates. Castle enables natural language instructions to trigger multi-column, causally consistent SQL UPDATE statements, without revealing table content to the model. By framing UPDATE SQL generation as a divide-and-conquer task with LLMs' reasoning capacity, Castle can determine not only which columns must be directly updated, but also how those updates propagate through the schema, causing cascading updates -- all via nested queries and substructures that ensure data confidentiality. We evaluate it on real-world causal update scenarios, demonstrating its ability to produce accurate SQL updates, and thereby highlighting the reasoning ability of LLMs in automated DBMS.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.15090", "pdf": "https://arxiv.org/pdf/2511.15090", "abs": "https://arxiv.org/abs/2511.15090", "authors": ["Wenhan Yu", "Wang Chen", "Guanqiang Qi", "Weikang Li", "Yang Li", "Lei Sha", "Deguo Xia", "Jizhou Huang"], "title": "BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer", "categories": ["cs.DB", "cs.AI", "cs.CV"], "comment": "22 pages, 4 figures", "summary": "Document Visual Question Answering (DocVQA) is a fundamental task for multimodal document understanding and a key testbed for vision language reasoning. However, most existing DocVQA datasets are limited to the page level and lack fine grained spatial grounding, constraining the interpretability and reasoning capability of Vision Language Models (VLMs). To address this gap, we introduce BBox DocVQA a large scale, bounding box grounded dataset designed to enhance spatial reasoning and evidence localization in visual documents. We further present an automated construction pipeline, Segment Judge and Generate, which integrates a segment model for region segmentation, a VLM for semantic judgment, and another advanced VLM for question answer generation, followed by human verification for quality assurance. The resulting dataset contains 3.6 K diverse documents and 32 K QA pairs, encompassing single and multi region as well as single and multi page scenarios. Each QA instance is grounded on explicit bounding boxes, enabling fine grained evaluation of spatial semantic alignment. Benchmarking multiple state of the art VLMs (e.g., GPT 5, Qwen2.5 VL, and InternVL) on BBox DocVQA reveals persistent challenges in spatial grounding and reasoning accuracy. Furthermore, fine tuning on BBox DocVQA substantially improves both bounding box localization and answer generation, validating its effectiveness for enhancing the reasoning ability of VLMs. Our dataset and code will be publicly released to advance research on interpretable and spatially grounded vision language reasoning.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.15557", "pdf": "https://arxiv.org/pdf/2511.15557", "abs": "https://arxiv.org/abs/2511.15557", "authors": ["Selim Furkan Tekin", "Rajesh Bordawekar"], "title": "B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index", "categories": ["cs.DB", "cs.AI", "cs.DS"], "comment": null, "summary": "Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.15585", "pdf": "https://arxiv.org/pdf/2511.15585", "abs": "https://arxiv.org/abs/2511.15585", "authors": ["Eugene Wu", "Yiru Chen", "Haneen Mohammed", "Zezhou Huang"], "title": "A Decade of Systems for Human Data Interaction", "categories": ["cs.DB", "cs.HC"], "comment": null, "summary": "Human-data interaction (HDI) presents fundamentally different challenges from traditional data management. HDI systems must meet latency, correctness, and consistency needs that stem from usability rather than query semantics; failing to meet these expectations breaks the user experience. Moreover, interfaces and systems are tightly coupled; neither can easily be optimized in isolation, and effective solutions demand their co-design. This dependence also presents a research opportunity: rather than adapt systems to interface demands, systems innovations and database theory can also inspire new interaction and visualization designs. We survey a decade of our lab's work that embraces this coupling and argue that HDI systems are the foundation for reliable, interactive, AI-driven applications.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.15623", "pdf": "https://arxiv.org/pdf/2511.15623", "abs": "https://arxiv.org/abs/2511.15623", "authors": ["Leopoldo Bertossi", "Nina Pardal"], "title": "Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs", "categories": ["cs.DB", "cs.AI", "cs.LO"], "comment": null, "summary": "The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
{"id": "2511.15000", "pdf": "https://arxiv.org/pdf/2511.15000", "abs": "https://arxiv.org/abs/2511.15000", "authors": ["Alexander J Root", "Christophe Gyurgyik", "Purvi Goel", "Kayvon Fatahalian", "Jonathan Ragan-Kelley", "Andrew Adams", "Fredrik Kjolstad"], "title": "Compiling Set Queries into Work-Efficient Tree Traversals", "categories": ["cs.PL", "cs.DB"], "comment": null, "summary": "Trees can accelerate queries that search or aggregate values over large collections. They achieve this by storing metadata that enables quick pruning (or inclusion) of subtrees when predicates on that metadata can prove that none (or all) of the data in a subtree affect the query result. Existing systems implement this pruning logic manually for each query predicate and data structure. We generalize and mechanize this class of optimization. Our method derives conditions for when subtrees can be pruned (or included wholesale), expressed in terms of the metadata available at each node. We efficiently generate these conditions using symbolic interval analysis, extended with new rules to handle geometric predicates (e.g., intersection, containment). Additionally, our compiler fuses compound queries (e.g., reductions on filters) into a single tree traversal. These techniques enable the automatic derivation of generalized single-index and dual-index tree joins that support a wide class of join predicates beyond standard equality and range predicates. The generated traversals match the behavior of expert-written code that implements query-specific traversals, and can asymptotically outperform the linear scans and nested-loop joins that existing systems fall back to when hand-written cases do not apply.", "AI": {"tldr": "\u8fbe\u5230API\u914d\u989d\u9650\u5236\uff0c\u8bf7\u660e\u5929\u518d\u8bd5", "motivation": "Error: API quota exceeded", "method": "Error: API quota exceeded", "result": "Error: API quota exceeded", "conclusion": "\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u6216\u7b49\u5f85\u660e\u5929API\u914d\u989d\u91cd\u7f6e\u3002"}}
