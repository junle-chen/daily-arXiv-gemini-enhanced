# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-10-08

## 目录

- [计算语言学 (Computation and Language) (1)](#cs-cl)
- [cs.DB (3)](#cs-db)
- [机器学习 (Machine Learning) (1)](#cs-lg)

## 计算语言学 (Computation and Language) [cs.CL]
### [1] [Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment](https://arxiv.org/abs/2510.04919)
*Davood Rafiei, Morgan Lindsay Heisler, Weiwei Zhang, Mohammadreza Pourreza, Yong Zhang*

Main category: cs.CL

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Supervised Fine-Tuning (SFT) is an effective method for adapting Large Language Models (LLMs) on downstream tasks. However, variability in training data can hinder a model's ability to generalize across domains. This paper studies the problem of dataset alignment for Natural Language to SQL (NL2SQL or text to SQL), examining how well SFT training data matches the structural characteristics of target queries and how this alignment impacts model performance. We hypothesize that alignment can be accurately estimated by comparing the distributions of structural SQL features across the training set, target data, and the model's predictions prior to SFT. Through comprehensive experiments on three large cross-domain NL2SQL benchmarks and multiple model families, we show that structural alignment is a strong predictor of fine-tuning success. When alignment is high, SFT yields substantial gains in accuracy and SQL generation quality; when alignment is low, improvements are marginal or absent. These findings highlight the importance of alignment-aware data selection for effective fine-tuning and generalization in NL2SQL tasks.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.04919) | **Categories:** cs.CL, cs.AI, cs.DB

---


## cs.DB [cs.DB]
### [1] [Is it Bigger than a Breadbox: Efficient Cardinality Estimation for Real World Workloads](https://arxiv.org/abs/2510.03386)
*Zixuan Yi, Sami Abu-el-Haija, Yawen Wang, Teja Vemparala, Yannis Chronis, Yu Gan, Michael Burrows, Carsten Binnig, Bryan Perozzi, Ryan Marcus, Fatma Ozcan*

Main category: cs.DB

TL;DR: 本文提出了一种基于在线学习的简单回归模型，用于解决数据库查询执行计划中基数估计的难题，该模型具有低开销、高精度和易于部署的优点。


<details>
  <summary>Details</summary>
Motivation: 传统数据库查询优化依赖于启发式规则和人工调整的魔数，导致查询复杂度增加时估计误差显著增大；而现有的基于学习的估计器虽然精度较高，但操作复杂性较高，难以实际应用。

Method: 该方法通过在线学习大量简单的回归模型，并将每个模型与特定的子查询模式相关联。通过子查询图结构的哈希值随机访问相应的回归器。

Result: 在JOB-lite工作负载的IMDb模拟实验中，该方法在仅增加37秒在线学习开销的情况下，将执行速度提高了7.5分钟（超过30%）。

Conclusion: 该方法在精度和运行时性能上均优于传统方法，并且显著降低了操作成本，为基数估计问题提供了一种实用且高效的解决方案。

Abstract: 数据库引擎依赖于成本模型来生成高效的查询执行计划。实际应用中，通常使用启发式方法估计查询的基数，并使用人工调整的“魔数”来提高基准测试的平均性能。但经验表明，估计误差会随着查询复杂度的增加而显著增长。另一方面，基于学习的估计器虽然可以提高准确性，但增加了操作复杂性，从而阻碍了它们在实践中的应用。本文认识到查询工作负载包含高度重复的子查询模式，因此我们在线学习许多简单的回归模型，每个模型都与一个特定的模式相关联。对应于某个模式的回归器可以使用子查询图结构的哈希值进行随机访问。我们的方法开销可以忽略不计，并且在误差指标上与最先进的基于学习的方法竞争。此外，将我们的方法应用于PostgreSQL，与传统方法相比，在准确性和运行时方面都取得了显著的改进，并且与其他学习的基数估计器相比，大大降低了运营成本，从而在帕累托前沿提供了最实用和高效的解决方案。具体而言，在IMDb上模拟JOB-lite工作负载，执行速度提高了7.5分钟（>30%），而在线学习的开销仅为37秒。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.03386) | **Categories:** cs.DB, cs.LG

---

### [2] [Dual Pruning and Sorting-Free Overestimation for Average-Utility Sequential Pattern Mining](https://arxiv.org/abs/2510.04014)
*Kai Cao, Yucong Duan, Wensheng Gan*

Main category: cs.DB

TL;DR: 本文提出了一种新的高平均效用序列模式挖掘算法HAUSP-PG，它采用双重剪枝策略，无需物品排序即可计算平均效用上界。


<details>
  <summary>Details</summary>
Motivation: 现有的高实用性序列模式挖掘（HUSPM）算法在高平均效用方面存在不足，尤其是在处理长序列时效率较低。在网络安全或人工智能等应用中，长序列模式挖掘的需求日益增长，因此需要更高效的算法。

Method: 提出了一种名为HAUSP-PG的新算法，该算法采用两种互补策略独立处理模式前缀和剩余序列，实现双重剪枝效果。此外，该方法无需物品排序即可计算平均效用上界。

Result: 在真实和合成数据集上的实验表明，所提出的算法能够取得令人满意的性能。

Conclusion: 该研究提出了一种有效的高平均效用序列模式挖掘算法，通过双重剪枝和避免物品排序，提高了长序列模式挖掘的效率。

Abstract: 在定量序列数据库中，已经开发了许多用于高实用性序列模式挖掘（HUSPM）的有效算法。HUSPM建立了现实世界中频率和重要性之间的关系，并且比频繁模式挖掘反映了更关键的信息。然而，高平均效用序列模式挖掘（HAUSPM）被认为比HUSPM更公平和更有价值。它通过考虑模式长度，为更长的模式提供了合理的度量。与零售业务分析等场景相比，一些模式挖掘应用，如网络安全或人工智能（AI），通常涉及更长的序列。因此，剪枝策略可以对效率产生更显著的影响。本文提出了一种名为HAUSP-PG的新算法，该算法采用两种互补策略来独立处理模式前缀和剩余序列，从而实现双重剪枝效果。此外，所提出的方法计算平均效用上界，而无需物品排序，与替代方法相比，显著减少了计算时间和内存消耗。通过在真实和合成数据集上进行的实验，我们证明了所提出的算法可以实现令人满意的性能。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.04014) | **Categories:** cs.DB

---

### [3] [Ambidextrous Degree Sequence Bounds for Pessimistic Cardinality Estimation](https://arxiv.org/abs/2510.04249)
*Yu-Ting Lin, Hsin-Po Wang*

Main category: cs.DB

TL;DR: 本文提出了一种新的基数估计方法，通过计算“爪对”来更精确地估计连接查询的基数。


<details>
  <summary>Details</summary>
Motivation: 在大规模数据库系统中，连接查询的基数上限估计至关重要，但现有方法存在过高估计的问题。

Method: 作者提出了一种“左右开弓”的界限计算方法，通过计算关系图中的“爪对”来优化基数估计。

Result: 实验结果表明，新方法在基数估计上优于现有方法，过高估计的程度从x倍降低到x^{3/4}倍。

Conclusion: 该研究提出了一种更精确的基数估计方法，并通过实验验证了其有效性，为大规模数据库系统的查询优化提供了有价值的参考。

Abstract: 在大规模数据库系统中，连接查询的基数上限估计（悲观基数估计）至关重要。Abo Khamis等人提出了一个灵活的框架，该框架包括三个步骤：1）将连接的随机行的熵H(X_1, ..., X_n)等同于连接基数的对数；2）使用香农不等式约束H(X_1, ..., X_n)；3）使用关系图的度序列的p范数约束H(X_i) + p H(X_j | X_i)。本文在第三步中提出了改进，即用计算“爪对”的“左右开弓”界限取代了原先计算“爪∈”的方法。新界限在理论上不逊于旧界限，并且在经验上更紧密：当旧界限高估x倍时，新界限高估x^{3/4}倍。例如，在com-Youtube数据集中计算朋友三元组时，最佳的旧界限为1.2 * 10^9，最佳的新界限为5.1 * 10^8，而实际基数为1.8 * 10^7。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.04249) | **Categories:** cs.DB, cs.IT, math.IT

---


## 机器学习 (Machine Learning) [cs.LG]
### [1] [MetaMP: Seamless Metadata Enrichment and AI Application Framework for Enhanced Membrane Protein Visualization and Analysis](https://arxiv.org/abs/2510.04776)
*Ebenezer Awotoro, Chisom Ezekannagha, Florian Schwarz, Johannes Tauscher, Dominik Heider, Katharina Ladewig, Christel Le Bon, Karine Moncoq, Bruno Miroux, Georges Hattab*

Main category: cs.LG

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Structural biology has made significant progress in determining membrane proteins, leading to a remarkable increase in the number of available structures in dedicated databases. The inherent complexity of membrane protein structures, coupled with challenges such as missing data, inconsistencies, and computational barriers from disparate sources, underscores the need for improved database integration. To address this gap, we present MetaMP, a framework that unifies membrane-protein databases within a web application and uses machine learning for classification. MetaMP improves data quality by enriching metadata, offering a user-friendly interface, and providing eight interactive views for streamlined exploration. MetaMP was effective across tasks of varying difficulty, demonstrating advantages across different levels without compromising speed or accuracy, according to user evaluations. Moreover, MetaMP supports essential functions such as structure classification and outlier detection.   We present three practical applications of Artificial Intelligence (AI) in membrane protein research: predicting transmembrane segments, reconciling legacy databases, and classifying structures with explainable AI support. In a validation focused on statistics, MetaMP resolved 77% of data discrepancies and accurately predicted the class of newly identified membrane proteins 98% of the time and overtook expert curation. Altogether, MetaMP is a much-needed resource that harmonizes current knowledge and empowers AI-driven exploration of membrane-protein architecture.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.04776) | **Categories:** cs.LG, cs.DB

---
