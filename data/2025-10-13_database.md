# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-10-13

## 目录

- [计算机视觉 (Computer Vision) (1)](#cs-cv)
- [cs.DB (4)](#cs-db)
- [机器学习 (Machine Learning) (1)](#cs-lg)
- [cs.LO (1)](#cs-lo)
- [stat.AP (1)](#stat-ap)

## 计算机视觉 (Computer Vision) [cs.CV]
### [1] [Detecting Legend Items on Historical Maps Using GPT-4o with In-Context Learning](https://arxiv.org/abs/2510.08385)
*Sofia Kirsanova, Yao-Yi Chiang, Weiwei Duan*

Main category: cs.CV

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Historical map legends are critical for interpreting cartographic symbols. However, their inconsistent layouts and unstructured formats make automatic extraction challenging. Prior work focuses primarily on segmentation or general optical character recognition (OCR), with few methods effectively matching legend symbols to their corresponding descriptions in a structured manner. We present a method that combines LayoutLMv3 for layout detection with GPT-4o using in-context learning to detect and link legend items and their descriptions via bounding box predictions. Our experiments show that GPT-4 with structured JSON prompts outperforms the baseline, achieving 88% F-1 and 85% IoU, and reveal how prompt design, example counts, and layout alignment affect performance. This approach supports scalable, layout-aware legend parsing and improves the indexing and searchability of historical maps across various visual styles.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.08385) | **Categories:** cs.CV, cs.AI, cs.DB, cs.IR, H.2.8; H.3.3; I.2.10; I.4.8

---


## cs.DB [cs.DB]
### [1] [TCDRM: A Tenant Budget-Aware Data Replication Framework for Multi-Cloud Computing](https://arxiv.org/abs/2510.07833)
*Santatra Hagamalala Bernardin, Riad Mokadem, Franck Morvan, Hasinarivo Ramanana, Hasimandimby Rakotoarivelo*

Main category: cs.DB

TL;DR: 本文提出了一种面向多云环境的租户预算感知数据复制框架（TCDRM），旨在满足租户性能需求的同时，遵守其经济预算约束。


<details>
  <summary>Details</summary>
Motivation: 多云计算系统在确保可接受的性能并遵守租户预算要求方面面临重大挑战。

Method: 提出了一种租户预算感知的数据复制框架（TCDRM），该框架基于响应时间、租户经济预算和数据流行度的预定义阈值动态创建数据副本，并采用启发式副本放置算法。

Result: 实验结果表明，该方法有效地满足了租户的性能目标，同时尊重其经济约束。与非复制方法相比，带宽消耗降低了高达78%，复杂查询的平均响应时间减少了51%，并且都符合租户的预算限制。

Conclusion: TCDRM策略能够利用多云环境提供的能力，在不超出租户预算的情况下，维持所需的性能。

Abstract: 多云计算系统在确保可接受的性能并遵守租户预算要求方面面临重大挑战。本文提出了一种面向多云计算的租户预算感知（以租户为中心）数据复制框架（TCDRM）。所提出的策略基于响应时间、租户经济预算和数据流行度的预定义阈值动态创建数据副本。TCDRM 采用了一种启发式副本放置算法，该算法利用了多个云提供商的不同定价结构。TCDRM 策略旨在通过利用多云环境提供的能力，在不超出租户预算的情况下，维持所需的性能。所考虑的中间件充当租户和多个云提供商之间的中介，促进智能副本放置决策。为了实现这一目标，所提出的 TCDRM 策略为租户预算和响应时间定义了严格的阈值。通过性能评估来验证该策略的有效性。结果表明，我们的方法有效地满足了租户的性能目标，同时尊重其经济约束。与非复制方法相比，带宽消耗降低了高达 78%，复杂查询的平均响应时间减少了 51%，并且都符合租户的预算限制。

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.07833) | **Categories:** cs.DB

---

### [2] [MobilityDuck: Mobility Data Management with DuckDB](https://arxiv.org/abs/2510.07963)
*Nhu Ngoc Hoang, Ngoc Hoa Pham, Viet Phuong Hoang, Esteban Zimányi*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: The analytics of spatiotemporal data is increasingly important for mobility analytics. Despite extensive research on moving object databases (MODs), few systems are ready on production or lightweight enough for analytics. MobilityDB is a notable system that extends PostgreSQL with spatiotemporal data, but it inherits complexity of the architecture as well. In this paper, we present MobilityDuck, a DuckDB extension that integrates the MEOS library to provide support spatiotemporal and other temporal data types in DuckDB. MobilityDuck leverages DuckDB's lightweight, columnar, in-memory executable properties to deliver efficient analytics. To the best of our knowledge, no existing in-memory or embedded analytical system offers native spatiotemporal types and continuous trajectory operators as MobilityDuck does. We evaluate MobilityDuck using the BerlinMOD-Hanoi benchmark dataset and compare its performance to MobilityDB. Our results show that MobilityDuck preserves the expressiveness of spatiotemporal queries while benefiting from DuckDB's in-memory, columnar architecture.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.07963) | **Categories:** cs.DB

---

### [3] [ZeroCard: Cardinality Estimation with Zero Dependence on Target Databases -- No Data, No Query, No Retraining](https://arxiv.org/abs/2510.07983)
*Xianghong Xu, Rong Kang, Xiao He, Lei Zhang, Jianjun Chen, Tieying Zhang*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Cardinality estimation is a fundamental task in database systems and plays a critical role in query optimization. Despite significant advances in learning-based cardinality estimation methods, most existing approaches remain difficult to generalize to new datasets due to their strong dependence on raw data or queries, thus limiting their practicality in real scenarios. To overcome these challenges, we argue that semantics in the schema may benefit cardinality estimation, and leveraging such semantics may alleviate these dependencies. To this end, we introduce ZeroCard, the first semantics-driven cardinality estimation method that can be applied without any dependence on raw data access, query logs, or retraining on the target database. Specifically, we propose to predict data distributions using schema semantics, thereby avoiding raw data dependence. Then, we introduce a query template-agnostic representation method to alleviate query dependence. Finally, we construct a large-scale query dataset derived from real-world tables and pretrain ZeroCard on it, enabling it to learn cardinality from schema semantics and predicate representations. After pretraining, ZeroCard's parameters can be frozen and applied in an off-the-shelf manner. We conduct extensive experiments to demonstrate the distinct advantages of ZeroCard and show its practical applications in query optimization. Its zero-dependence property significantly facilitates deployment in real-world scenarios.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.07983) | **Categories:** cs.DB, cs.AI

---

### [4] [Implementing Semantic Join Operators Efficiently](https://arxiv.org/abs/2510.08489)
*Immanuel Trummer*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Semantic query processing engines often support semantic joins, enabling users to match rows that satisfy conditions specified in natural language. Such join conditions can be evaluated using large language models (LLMs) that solve novel tasks without task-specific training.   Currently, many semantic query processing engines implement semantic joins via nested loops, invoking the LLM to evaluate the join condition on row pairs. Instead, this paper proposes a novel algorithm, inspired by the block nested loops join operator implementation in traditional database systems. The proposed algorithm integrates batches of rows from both input tables into a single prompt. The goal of the LLM invocation is to identify all matching row pairs in the current input. The paper introduces formulas that can be used to optimize the size of the row batches, taking into account constraints on the size of the LLM context window (limiting both input and output size). An adaptive variant of the proposed algorithm refers to cases in which the size of the output is difficult to estimate. A formal analysis of asymptotic processing costs, as well as empirical results, demonstrates that the proposed approach reduces costs significantly and performs well compared to join implementations used by recent semantic query processing engines.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.08489) | **Categories:** cs.DB, cs.LG

---


## 机器学习 (Machine Learning) [cs.LG]
### [1] [MLLM4TS: Leveraging Vision and Multimodal Language Models for General Time-Series Analysis](https://arxiv.org/abs/2510.07513)
*Qinghua Liu, Sam Heshmati, Zheda Mai, Zubin Abraham, John Paparrizos, Liu Ren*

Main category: cs.LG

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Effective analysis of time series data presents significant challenges due to the complex temporal dependencies and cross-channel interactions in multivariate data. Inspired by the way human analysts visually inspect time series to uncover hidden patterns, we ask: can incorporating visual representations enhance automated time-series analysis? Recent advances in multimodal large language models have demonstrated impressive generalization and visual understanding capability, yet their application to time series remains constrained by the modality gap between continuous numerical data and discrete natural language. To bridge this gap, we introduce MLLM4TS, a novel framework that leverages multimodal large language models for general time-series analysis by integrating a dedicated vision branch. Each time-series channel is rendered as a horizontally stacked color-coded line plot in one composite image to capture spatial dependencies across channels, and a temporal-aware visual patch alignment strategy then aligns visual patches with their corresponding time segments. MLLM4TS fuses fine-grained temporal details from the numerical data with global contextual information derived from the visual representation, providing a unified foundation for multimodal time-series analysis. Extensive experiments on standard benchmarks demonstrate the effectiveness of MLLM4TS across both predictive tasks (e.g., classification) and generative tasks (e.g., anomaly detection and forecasting). These results underscore the potential of integrating visual modalities with pretrained language models to achieve robust and generalizable time-series analysis.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.07513) | **Categories:** cs.LG, cs.AI, cs.CV, cs.DB

---


## cs.LO [cs.LO]
### [1] [Homomorphism Problems in Graph Databases and Automatic Structures](https://arxiv.org/abs/2510.07422)
*Rémi Morvan*

Main category: cs.LO

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: This thesis investigates the central role of homomorphism problems (structure-preserving maps) in two complementary domains: database querying over finite, graph-shaped data, and constraint solving over (potentially infinite) structures. Building on the well-known equivalence between conjunctive query evaluation and homomorphism existence, the first part focuses on conjunctive regular path queries, a standard extension of conjunctive queries that incorporates regular-path predicates. We study the fundamental problem of query minimization under two measures: the number of atoms (constraints) and the tree-width of the query graph. In both cases, we prove the problem to be decidable, and provide efficient algorithms for a large fragment of queries used in practice. The second part of the thesis lifts homomorphism problems to automatic structures, which are infinite structures describable by finite automata. We highlight a dichotomy, between homomorphism problems over automatic structures that are decidable in non-deterministic logarithmic space, and those that are undecidable (proving to be the more common case). In contrast to this prevalence of undecidability, we then focus on the language-theoretic properties of these structures, and show, relying on a novel algebraic language theory, that for any well-behaved logic (a pseudovariety), whether an automatic structure can be described in this logic is decidable.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.07422) | **Categories:** cs.LO, cs.DB, cs.FL

---


## stat.AP [stat.AP]
### [1] [Large-scale spatial variable gene atlas for spatial transcriptomics](https://arxiv.org/abs/2510.07653)
*Jiawen Chen, Jinwei Zhang, Dongshen Peng, Yutong Song, Aitong Ruan, Yun Li, Didong Li*

Main category: stat.AP

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Spatial variable genes (SVGs) reveal critical information about tissue architecture, cellular interactions, and disease microenvironments. As spatial transcriptomics (ST) technologies proliferate, accurately identifying SVGs across diverse platforms, tissue types, and disease contexts has become both a major opportunity and a significant computational challenge. Here, we present a comprehensive benchmarking study of 20 state-of-the-art SVG detection methods using human slides from STimage-1K4M, a large-scale resource of ST data comprising 662 slides from more than 18 tissue types. We evaluate each method across a range of biologically and technically meaningful criteria, including recovery of pathologist-annotated domain-specific markers, cross-slide reproducibility, scalability to high-resolution data, and robustness to technical variation. Our results reveal marked differences in performance depending on tissue type, spatial resolution, and study design. Beyond benchmarking, we construct the first cross-tissue atlas of SVGs, enabling comparative analysis of spatial gene programs across cancer and normal tissues. We observe similarities between pairs of tissues that reflect developmental and functional relationships, such as high overlap between thymus and lymph node, and uncover spatial gene programs associated with metastasis, immune infiltration, and tissue-of-origin identity in cancer. Together, our work defines a framework for evaluating and interpreting spatial gene expression and establishes a reference resource for the ST community.

</details>

[**[PDF]**](https://arxiv.org/pdf/2510.07653) | **Categories:** stat.AP, cs.DB, q-bio.GN, q-bio.TO, stat.CO, 62P10, J.3

---
