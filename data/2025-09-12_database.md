# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-09-12

## 目录

- [cs.CR (1)](#cs-cr)
- [cs.DB (5)](#cs-db)
- [quant-ph (1)](#quant-ph)

## cs.CR [cs.CR]
### [1] [Membrane: A Cryptographic Access Control System for Data Lakes](https://arxiv.org/abs/2509.08740)
*Sam Kumar, Samyukta Yagati, Conor Power, David E. Culler, Raluca Ada Popa*

Main category: cs.CR

TL;DR: Membrane提出了一种新的数据湖安全系统，它通过密码学方法强制执行数据相关的访问控制，同时不限制数据科学家的分析查询。


<details>
  <summary>Details</summary>
Motivation: 解决黑客可能入侵数据湖存储以绕过访问控制并访问敏感数据的问题。

Method: Membrane结合了静态加密和SQL感知加密，使用块密码设计了一种新的SQL感知加密协议。

Result: Membrane仅在交互会话开始时因解密视图而增加开销，首次查询结果延迟高达约20倍；后续查询以明文处理解密数据，从而降低了分摊开销。

Conclusion: Membrane通过在静态加密的基础上结合SQL感知加密，在保证数据安全的同时，尽量减少对数据分析性能的影响。

Abstract: 组织使用数据湖来存储和分析敏感数据。但是，黑客可能会破坏数据湖存储，绕过访问控制并访问敏感数据。为了解决这个问题，我们提出了Membrane，一个（1）以密码学方式在数据湖上强制执行数据相关的访问控制视图，（2）而不限制数据科学家可以运行的分析查询的系统。我们观察到，与数据库管理系统不同，数据湖将计算和存储分离到不同的信任域中，即使以明文形式运行分析查询，也足以防御针对数据湖存储的远程攻击者。这导致了Membrane的一种新的系统设计，它将静态加密与SQL感知加密相结合。使用块密码，一种在CPU中具有硬件加速的快速对称密钥原语，我们开发了一种非常适合静态加密的新型SQL感知加密协议。由于解密视图，Membrane仅在交互式会话开始时增加开销，使首次查询结果最多延迟约20倍；后续查询以明文形式处理解密数据，从而降低了分摊开销。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.08740) | **Categories:** cs.CR, cs.DB

---


## cs.DB [cs.DB]
### [1] [Polyglot Persistence in Microservices: Managing Data Diversity in Distributed Systems](https://arxiv.org/abs/2509.08014)
*Festim Halili, Anila Nuhiji, Diellza Mustafai Veliu*

Main category: cs.DB

TL;DR: 本文探讨了微服务架构中polyglot persistence的应用，并通过基准测试和案例研究分析了其优缺点。


<details>
  <summary>Details</summary>
Motivation: 微服务架构在管理异构和分布式数据方面面临挑战，Polyglot persistence 是一种解决方案。

Method: 本文结合理论概念、实际案例和基准测试，对关系型数据库、文档数据库、键值数据库等多种数据库平台进行了比较评估。

Result: Polyglot persistence 提高了适应性、性能和领域对齐，但也增加了治理和运营复杂性。

Conclusion: Polyglot persistence 需要采用 saga workflows、event sourcing 和 outbox integration 等架构模式来应对其权衡。

Abstract: 微服务架构已成为开发可扩展的现代化软件系统的基础，但它们也给管理异构和分布式数据带来了巨大的挑战。务实的解决方案是polyglot persistence，即根据给定的微服务需求有意识地使用几种不同的数据库技术——就是这样一种策略。本文研究了基于微服务的系统中的polyglot persistence。本文将理论概念与来自标准数据库平台的实际实现和比较基准的证据结合在一起。一个比较框架被应用于关系型、文档型、键值型、列族型和图数据库，以评估可扩展性、一致性、查询表达性、运营开销和集成便利性。来自Netflix、Uber和Shopify等行业案例研究的经验数据和调查数据说明了现实生活中的采用趋势和挑战。这些发现表明，polyglot persistence 提高了适应性、性能、领域对齐，但也提高了治理或运营复杂性。为了应对这种权衡，讨论了诸如saga工作流、事件溯源和outbox集成等架构模式。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.08014) | **Categories:** cs.DB

---

### [2] [Infinite Stream Estimation under Personalized $w$-Event Privacy](https://arxiv.org/abs/2509.08387)
*Leilei Du, Peng Cheng, Lei Chen, Heng Tao Shen, Xuemin Lin, Wei Xi*

Main category: cs.DB

TL;DR: 本文提出了一种个性化的w事件隐私保护方法，允许不同用户在私有数据流估计中拥有不同的隐私需求。


<details>
  <summary>Details</summary>
Motivation: 现有的w事件隐私研究主要集中在对所有用户同质的隐私需求，而忽略了个性化隐私需求。

Method: 设计了个性化窗口大小机制（PWSM），并提出了个性化预算分配（PBD）和个性化预算吸收（PBA）两种方案，以在实现w事件级别的个性化差分隐私的同时，准确估计流数据统计。

Result: 在真实和合成数据集上的实验结果表明，PBD和PBA优于现有的隐私流估计方法，PBD在真实数据集上比BD平均减少68%的误差，PBA在合成数据集上比BA平均减少24.9%的误差。

Conclusion: 提出的PBD和PBA方法在满足所有用户隐私需求的同时，提高了流数据统计的准确性。

Abstract: 流数据收集对于流数据分析（如事件监控）是不可或缺的。然而，直接发布这些数据会导致隐私泄露。$w$-事件隐私是保护给定时间窗口内个人隐私同时保持数据收集高准确性的宝贵工具。大多数现有的关于无限数据流的$w$-事件隐私研究只关注于所有用户的同质隐私需求。在本文中，我们提出了一种个性化的$w$-事件隐私保护，允许不同的用户在私有数据流估计中拥有不同的隐私需求。具体来说，我们设计了一种机制，允许用户在每个时隙保持恒定的隐私需求，即个性化窗口大小机制（PWSM）。然后，我们提出了两种解决方案，以在实现$w$-事件级别的$\epsilon$个性化差分隐私（($w$, $\epsilon$)-EPDP）的同时，准确地估计流数据统计，即个性化预算分配（PBD）和个性化预算吸收（PBA）。PBD总是为下一个时间步提供至少与前一次发布中消耗的量一样多的隐私预算。PBA完全吸收前k个时隙的隐私预算，同时还从后k个时隙的隐私预算中借用，以增加当前时隙的隐私预算。我们证明了PBD和PBA在满足所有用户隐私需求的同时，优于最先进的私有流估计方法。与最近的均匀$w$-事件方法，预算分配（BD）和预算吸收（BA）相比，我们在真实和合成数据集上证明了我们的PBD和PBA的效率和有效性。我们的PBD在真实数据集上比BD平均减少68%的误差。此外，我们的PBA在合成数据集上比BA平均减少24.9%的误差。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.08387) | **Categories:** cs.DB

---

### [3] [SINDI: an Efficient Index for Approximate Maximum Inner Product Search on Sparse Vectors](https://arxiv.org/abs/2509.08395)
*Ruoxuan Li, Xiaoyao Zhong, Jiabao Jin, Peng Cheng, Wangze Ni, Lei Chen, Zhitao Shen, Wei Jia, Xiangyu Wang, Xuemin Lin, Heng Tao Shen, Jingkuan Song*

Main category: cs.DB

TL;DR: 本文提出了一种稀疏倒排非冗余距离索引(SINDI)，通过SIMD加速、减少内存访问和向量剪枝，显著提升了RAG中稀疏向量MIPS的检索效率。


<details>
  <summary>Details</summary>
Motivation: 在RAG中，稀疏向量最大内积搜索(MIPS)至关重要，但现有算法存在冗余计算、频繁随机内存访问以及难以利用SIMD加速的问题，限制了其在生产环境中的性能。

Method: 本文提出了稀疏倒排非冗余距离索引(SINDI)，包含三个关键优化：高效内积计算（SIMD加速和消除冗余ID查找）、内存友好设计（顺序访问倒排列表代替随机访问原始向量）、向量剪枝（保留高幅度非零条目）。

Result: 在多个真实数据集上的实验结果表明，SINDI在不同规模、语言和模型的数据集上实现了最先进的性能。在MsMarco数据集上，当Recall@50超过99%时，SINDI的单线程QPS比SEISMIC和PyANNs提高了4.2到26.4倍。

Conclusion: 本文提出的SINDI通过优化计算、内存访问和向量表示，显著提升了稀疏向量MIPS的检索效率，并在实际应用中取得了优异的效果，已集成到蚂蚁集团的开源向量搜索库VSAG中。

Abstract: 稀疏向量最大内积搜索(MIPS)在检索增强生成(RAG)的多路径检索中至关重要。最近基于倒排索引和图的算法已经实现了高搜索精度和实际效率。然而，它们在生产环境中的性能常常受到冗余距离计算和频繁随机内存访问的限制。此外，稀疏向量的压缩存储格式阻碍了SIMD加速的使用。在本文中，我们提出了稀疏倒排非冗余距离索引(SINDI)，它结合了三个关键优化：(i)高效内积计算：SINDI利用SIMD加速并消除冗余标识符查找，从而实现批量内积计算；(ii)内存友好设计：SINDI用对倒排列表的顺序访问代替对原始向量的随机内存访问，从而大大减少了内存限制的延迟。(iii)向量剪枝：SINDI仅保留向量的高幅度非零条目，从而在保持精度的同时提高查询吞吐量。我们在多个真实世界的数据集上评估了SINDI。实验结果表明，SINDI在不同规模、语言和模型的数据集上实现了最先进的性能。在MsMarco数据集上，当Recall@50超过99%时，SINDI提供的单线程每秒查询数(QPS)比SEISMIC和PyANNs提高了4.2到26.4倍。值得注意的是，SINDI已经集成到蚂蚁集团的开源向量搜索库VSAG中。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.08395) | **Categories:** cs.DB

---

### [4] [Un cadre paraconsistant pour l'{é}valuation de similarit{é} dans les bases de connaissances](https://arxiv.org/abs/2509.08433)
*José-Luis Vilchis Medina*

Main category: cs.DB

TL;DR: 本文提出了一种矛盾容错的知识库相似度评估框架，通过引入新的相似度度量 $S^*$ 和矛盾提取器 $E$，实现了对冲突知识的有效管理。


<details>
  <summary>Details</summary>
Motivation: 传统知识库相似度评估方法无法有效处理矛盾信息，本文旨在解决这一问题。

Method: 本文提出了一种矛盾容错框架，包括新的相似度度量 $S^*$、矛盾提取器 $E$ 和修复机制，并定义了 paraconsistent super-categories $ \Xi_K^* $ 以分层组织知识实体。

Result: 理论结果保证了 $S^*$ 的自反性、对称性和有界性，表明该方法在管理冲突知识方面具有潜力。

Conclusion: 该方法为管理冲突知识提供了一种有前景的解决方案，并在多智能体系统中有应用前景。

Abstract: 本文提出了一种用于评估知识库相似性的次协调框架。与经典方法不同，该框架显式地整合了矛盾，从而实现更鲁棒和可解释的相似性度量。本文引入了一种新的度量 $ S^* $，它惩罚不一致性，同时奖励共享属性。定义了次协调超类别 $ \Xi_K^* $，以分层组织知识实体。该模型还包括一个矛盾提取器 $ E $ 和一个修复机制，确保评估的一致性。理论结果保证了 $ S^* $ 的自反性、对称性和有界性。该方法为管理冲突知识提供了一种有前景的解决方案，并在多智能体系统中具有应用前景。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.08433) | **Categories:** cs.DB, cs.IT, cs.LO, cs.SC, math.CT, math.IT

---

### [5] [SQLGovernor: An LLM-powered SQL Toolkit for Real World Application](https://arxiv.org/abs/2509.08575)
*Jie Jiang, Siqi Shen, Haining Xie, Yang Li, Yu Shen, Danqing Huang, Bo Qian, Yinjun Wu, Wentao Zhang, Bin Cui, Peng Chen*

Main category: cs.DB

TL;DR: SQLGovernor是一个LLM驱动的SQL工具包，它统一了多种功能，包括语法纠正、查询重写、查询修改和一致性验证。


<details>
  <summary>Details</summary>
Motivation: 解决真实分析环境中SQL查询存在的语法错误、效率低下或语义不对齐等问题，尤其是在复杂的OLAP场景中。

Method: 提出SQLGovernor，一个LLM驱动的SQL工具包，它统一了多个功能，包括语法纠正、查询重写、查询修改和一致性验证；引入了片段式处理策略，以实现细粒度的重写和局部错误纠正；采用了一种由专家反馈指导的混合自学习机制。

Result: 在BIRD和BIRD CRITIC等基准测试以及工业数据集上的实验表明，SQLGovernor始终将基础模型的性能提高了高达10％，同时最大限度地减少了对人工专业知识的依赖。

Conclusion: SQLGovernor在生产环境中部署，证明了强大的实用性和有效的性能。

Abstract: 真实分析环境中的SQL查询，无论是人工编写还是自动生成，经常会出现语法错误、效率低下或语义不对齐的问题，尤其是在复杂的OLAP场景中。为了解决这些挑战，我们提出了SQLGovernor，一个LLM驱动的SQL工具包，它在一个结构化的框架内统一了多个功能，包括语法纠正、查询重写、查询修改和一致性验证，并通过知识管理进行增强。SQLGovernor引入了一种片段式处理策略，以实现细粒度的重写和局部错误纠正，从而显著减少了LLM的认知负担。它进一步结合了一种由专家反馈指导的混合自学习机制，使系统能够通过DBMS输出分析和规则验证不断改进。在BIRD和BIRD CRITIC等基准测试以及工业数据集上的实验表明，SQLGovernor始终将基础模型的性能提高了高达10％，同时最大限度地减少了对人工专业知识的依赖。SQLGovernor已在生产环境中部署，证明了强大的实用性和有效的性能。

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.08575) | **Categories:** cs.DB

---


## quant-ph [quant-ph]
### [1] [QCardEst/QCardCorr: Quantum Cardinality Estimation and Correction](https://arxiv.org/abs/2509.08817)
*Tobias Winker, Jinghua Groppe, Sven Groppe*

Main category: quant-ph

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Cardinality estimation is an important part of query optimization in DBMS. We develop a Quantum Cardinality Estimation (QCardEst) approach using Quantum Machine Learning with a Hybrid Quantum-Classical Network. We define a compact encoding for turning SQL queries into a quantum state, which requires only qubits equal to the number of tables in the query. This allows the processing of a complete query with a single variational quantum circuit (VQC) on current hardware. In addition, we compare multiple classical post-processing layers to turn the probability vector output of VQC into a cardinality value. We introduce Quantum Cardinality Correction QCardCorr, which improves classical cardinality estimators by multiplying the output with a factor generated by a VQC to improve the cardinality estimation. With QCardCorr, we have an improvement over the standard PostgreSQL optimizer of 6.37 times for JOB-light and 8.66 times for STATS. For JOB-light we even outperform MSCN by a factor of 3.47.

</details>

[**[PDF]**](https://arxiv.org/pdf/2509.08817) | **Categories:** quant-ph, cs.AI, cs.DB, cs.LG

---
