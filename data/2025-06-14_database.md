# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-06-14

## 目录

- [cs.DB (4)](#cs-db)

## cs.DB [cs.DB]
### [1] [GPU Acceleration of SQL Analytics on Compressed Data](https://arxiv.org/abs/2506.10092)
*Zezhou Huang, Krystian Sakowski, Hans Lehnert, Wei Cui, Carlo Curino, Matteo Interlandi, Marius Dumitru, Rathijit Sen*

Main category: cs.DB

TL;DR: 该论文提出了一种直接在轻量级压缩数据上运行查询的方法，以提高GPU处理大数据集的性能。


<details>
  <summary>Details</summary>
Motivation: 当前加速大数据集查询的解决方案面临着主内存带宽较低、主机到设备互连带宽的限制、额外的I/O开销或更高的成本等问题。数据压缩可以缓解这个瓶颈，但理想的解决方案必须包含直接对压缩数据进行操作的计算原语，以避免昂贵的解压缩/解码开销。

Method: 该论文提出了一套新的方法，用于直接在轻量级压缩数据上运行查询，包括游程编码（RLE）、索引编码、位宽缩减和字典编码等方案。该方法还包括在不解压缩的情况下操作多个RLE列，处理异构列编码，并利用PyTorch张量操作实现跨设备的移植性。

Result: 实验评估表明，对于无法放入未压缩GPU内存的生产数据集上的真实查询，与最先进的商业CPU分析系统相比，速度提高了近一个数量级。

Conclusion: 该研究表明，通过直接在轻量级压缩数据上运行查询，可以显著提高GPU在处理大数据集上的性能，为更广泛的GPU应用铺平道路。

Abstract: 由于GPU具有大规模的计算并行性和高带宽内存（HBM），因此非常适合加速（SQL）分析工作负载——当数据集适合GPU HBM时，性能是无与伦比的。不幸的是，与较低带宽的CPU主内存相比，GPU HBM通常仍然很小。除了跨多个GPU进行强力扩展之外，当前加速大型数据集查询的解决方案包括利用数据分区并在GPU HBM中加载较小的数据批处理，以及与连接设备（例如CPU）的混合执行。不幸的是，这些方法暴露于较低的主内存和主机到设备互连带宽的限制，引入了额外的I/O开销，或产生更高的成本。当尝试在更大的数据集上扩展GPU的采用时，这是一个实质性的问题。数据压缩可以缓解这个瓶颈，但为了避免支付昂贵的解压缩/解码费用，理想的解决方案必须包括直接对压缩形式的数据进行操作的计算原语。这是我们论文的重点：一套新的方法，用于直接在轻量级压缩数据上运行查询，使用游程编码（RLE）、索引编码、位宽缩减和字典编码等方案。我们的创新包括在不解压缩的情况下操作多个RLE列，处理异构列编码，并利用PyTorch张量操作实现跨设备的移植性。实验评估表明，对于无法放入未压缩GPU内存的生产数据集上的真实查询，与最先进的商业CPU分析系统相比，速度提高了近一个数量级。这项工作为在更广泛的用例中采用GPU铺平了道路，并且是对大多数其他横向扩展或回退机制的补充。

</details>

[**[PDF]**](https://arxiv.org/pdf/2506.10092) | **Categories:** cs.DB

---

### [2] [A Unifying Algorithm for Hierarchical Queries](https://arxiv.org/abs/2506.10238)
*Mahmoud Abo Khamis, Jesse Comer, Phokion Kolaitis, Sudeepa Roy, Val Tannen*

Main category: cs.DB

TL;DR: 分层查询是概率查询评估、Shapley值计算和bag-set最大化这三个问题易处理性和难处理性之间的界限，它们都允许使用统一的多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 确定分层查询是否也定义了另一个自然算法问题的易处理性和难处理性之间的界限，我们称之为“bag-set最大化”问题。

Method: 针对SJF-BCQ，在从另一个给定数据库$\cal D^r$中添加最多$\theta$个事实的情况下，找到$Q$在数据库$\cal D'$上以bag语义获得的最大值。

Result: 对于非分层查询，bag-set最大化问题是一个NP完全优化问题。对于分层查询，所有三个问题（概率查询评估、Shapley值计算和bag-set最大化）都承认一个统一的多项式时间算法。

Conclusion: 对于分层查询，概率查询评估、Shapley值计算和bag-set最大化问题都承认一个统一的多项式时间算法，该算法作用于一个抽象代数结构，称为“2-monoid”。

Abstract: 已知分层查询定义了以下两个关于无自连接布尔合取查询 (SJF-BCQ) 的广泛研究问题的易处理性和难处理性之间的二分法边界：(i) 在元组独立概率数据库上评估 SJF-BCQ；(ii) 计算数据库中事实的 Shapley 值，在该数据库上 SJF-BCQ 的计算结果为真。在这里，我们确定分层查询也定义了另一个自然算法问题的易处理性和难处理性之间的二分法边界，我们称之为“bag-set 最大化”问题。与 SJF-BCQ $Q$ 相关的 bag-set 最大化问题如下：给定一个数据库 $\cal D$，找到 $Q$ 在数据库 $\cal D'$ 上以 bag 语义获得的最大值，该数据库 $\cal D'$ 是通过从另一个给定数据库 $\cal D^r$ 中添加最多 $\theta$ 个事实而从 $\cal D$ 获得的。对于非分层查询，我们表明 bag-set 最大化问题是一个 NP 完全优化问题。更重要的是，对于分层查询，我们表明所有三个上述问题（概率查询评估、Shapley 值计算和 bag-set 最大化）都承认一个统一的多项式时间算法，该算法作用于一个抽象代数结构，称为“2-monoid”。这三个问题中的每一个都需要针对手头问题量身定制的 2-monoid 的不同实例化。

</details>

[**[PDF]**](https://arxiv.org/pdf/2506.10238) | **Categories:** cs.DB

---

### [3] [A Hybrid Heuristic Framework for Resource-Efficient Querying of Scientific Experiments Data](https://arxiv.org/abs/2506.10422)
*Mayank Patel, Minal Bhise*

Main category: cs.DB

TL;DR: RAW-HF框架通过感知资源可用性和工作负载，有效优化了原始数据的查询，并在实验中表现出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统数据库管理系统（DBMS）和HTAP系统在开始查询执行之前，需要花费大量时间和资源将整个数据集加载到DBMS中。另一方面，原地引擎可能会多次重新解析所需数据，从而增加资源利用率和数据处理成本。此外，过度或不足的资源分配也会增加应用程序的运行成本。

Method: 提出了一种轻量级的资源可用性与工作负载感知的混合框架（RAW-HF），以优化原始数据的查询。

Result: 在真实世界的科学数据集工作负载（如Sloan Digital Sky Survey (SDSS) 和 Linked Observation Data (LOD)）上应用RAW-HF，与广泛使用的传统DBMS PostgreSQL相比，工作负载执行时间（WET）减少了90%以上和85%以上。

Conclusion: 与最先进的混合系统工作负载感知部分加载技术（WA）相比，RAW-HF在CPU、IO资源利用率和WET方面分别降低了26%、25%和26%，同时内存利用率提高了33%。与基于机器学习的资源分配技术（如PCC）相比，RAW-HF使用的MUAR技术也表现出优势。

Abstract: 科学实验和现代应用每天产生大量数据。大多数组织利用内部服务器或云资源来管理应用程序数据和工作负载。传统的数据库管理系统（DBMS）和HTAP系统在开始查询执行之前，需要花费大量时间和资源将整个数据集加载到DBMS中。另一方面，原地引擎可能会多次重新解析所需数据，从而增加资源利用率和数据处理成本。此外，过度或不足的资源分配也会增加应用程序的运行成本。本文提出了一种轻量级的资源可用性与工作负载感知的混合框架（RAW-HF），旨在通过有效利用现有有限资源来优化原始数据的查询。RAW-HF包括一些模块，这些模块有助于优化执行给定工作负载所需的资源，并最大限度地利用现有资源。在真实世界的科学数据集工作负载（如Sloan Digital Sky Survey (SDSS) 和 Linked Observation Data (LOD)）上应用RAW-HF，与广泛使用的传统DBMS PostgreSQL相比，工作负载执行时间（WET）减少了90%以上和85%以上。与最先进的混合系统工作负载感知部分加载技术（WA）相比，总体CPU、IO资源利用率和WET分别降低了26%、25%和26%，同时内存利用率提高了33%。此外，还介绍了RAW-HF使用的MUAR技术与基于机器学习的资源分配技术（如PCC）的比较。

</details>

[**[PDF]**](https://arxiv.org/pdf/2506.10422) | **Categories:** cs.DB, cs.DC, cs.ET, cs.PF

---

### [4] [S3 Mirror: S3Mirror: Making Genomic Data Transfers Fast, Reliable, and Observable with DBOS](https://arxiv.org/abs/2506.10886)
*Steven Vasquez-Grinnell, Alex Poliakov*

Main category: cs.DB

TL;DR: S3Mirror是一个基于DBOSTransact的开源工具，用于在S3存储桶之间高效、可靠地传输大型基因组数据集。


<details>
  <summary>Details</summary>
Motivation: 为了满足大型制药组织的需求，解决大型基因组测序数据集在S3存储桶之间快速传输的问题。

Method: 使用DBOSTransact持久执行框架。

Result: 在DBOS Cloud Pro中，S3Mirror的运行速度比AWS DataSync快40倍，且成本更低。它还具有故障恢复能力，并能实时观察正在进行和过去的传输。

Conclusion: S3Mirror是一个可靠、可观测且经济高效的S3存储桶数据传输工具，尤其在DBOS Cloud Pro环境下性能卓越。

Abstract: 为了满足大型制药组织的需求，我们创建了S3Mirror，这是一个用于在S3存储桶之间快速、可靠且可观察地传输大型基因组测序数据集的应用程序。我们使用DBOSTransact持久执行框架来实现这些目标，并对应用程序的性能和成本进行了基准测试。S3Mirror是一个开源的DBOS Python应用程序，可以在各种环境中运行，包括DBOS Cloud Pro，在其中它的运行速度比AWS DataSync快40倍，而且成本只是它的一小部分。此外，S3Mirror具有弹性，可以应对故障，并允许对正在进行和过去的传输进行实时文件级可观察性。

</details>

[**[PDF]**](https://arxiv.org/pdf/2506.10886) | **Categories:** cs.DB, q-bio.GN

---
