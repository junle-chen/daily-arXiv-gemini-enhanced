{"id": "2510.08705", "pdf": "https://arxiv.org/pdf/2510.08705", "abs": "https://arxiv.org/abs/2510.08705", "authors": ["Noah Steinkr\u00fcger", "Nisarga Nilavadi", "Wolfram Burgard", "Tanja Katharina Kaiser"], "title": "ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Object transportation in cluttered environments is a fundamental task in\nvarious domains, including domestic service and warehouse logistics. In\ncooperative object transport, multiple robots must coordinate to move objects\nthat are too large for a single robot. One transport strategy is pushing, which\nonly requires simple robots. However, careful selection of robot-object contact\npoints is necessary to push the object along a preplanned path. Although this\nselection can be solved analytically, the solution space grows combinatorially\nwith the number of robots and object size, limiting scalability. Inspired by\nhow humans rely on common-sense reasoning for cooperative transport, we propose\ncombining the reasoning capabilities of Large Language Models with local search\nto select suitable contact points. Our LLM-guided local search method for\ncontact point selection, ConPoSe, successfully selects contact points for a\nvariety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate\nthat ConPoSe scales better with the number of robots and object size than the\nanalytical approach, and also outperforms pure LLM-based selection.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u673a\u5668\u4eba\u64cd\u4f5c\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u4f7f\u7528LLM\u6765\u5f15\u5bfc\u63a5\u89e6\u70b9\u7684\u9009\u62e9\uff0c\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u534f\u4f5c\u7269\u4f53\u63a8\u52a8\u3002\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53ca\u4f20\u7edf\u7684\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u5176\u76ee\u6807\u662f\u6cbf\u7740\u9884\u5148\u89c4\u5212\u7684\u8def\u5f84\u63a8\u52a8\u7269\u4f53\uff0c\u8fd9\u4e0e\u8def\u5f84\u89c4\u5212\u76f8\u5173\u3002LLM\u7684\u5e94\u7528\u4f7f\u5f97\u8be5\u8bba\u6587\u4e0e\u5927\u6a21\u578b\u76f8\u5173\u3002", "keywords": ["Large Language Models", "LLM", "cooperative object pushing", "path planning"]}}
{"id": "2510.08754", "pdf": "https://arxiv.org/pdf/2510.08754", "abs": "https://arxiv.org/abs/2510.08754", "authors": ["David Nguyen", "Zulfiqar Zaidi", "Kevin Karol", "Jessica Hodgins", "Zhaoming Xie"], "title": "Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "Submitted to appear in IEEE ICRA 2026", "summary": "Developing table tennis robots that mirror human speed, accuracy, and ability\nto predict and respond to the full range of ball spins remains a significant\nchallenge for legged robots. To demonstrate these capabilities we present a\nsystem to play dynamic table tennis for quadrupedal robots that integrates high\nspeed perception, trajectory prediction, and agile control. Our system uses\nexternal cameras for high-speed ball localization, physical models with learned\nresiduals to infer spin and predict trajectories, and a novel model predictive\ncontrol (MPC) formulation for agile full-body control. Notably, a continuous\nset of stroke strategies emerge automatically from different ball return\nobjectives using this control paradigm. We demonstrate our system in the real\nworld on a Spot quadruped, evaluate accuracy of each system component, and\nexhibit coordination through the system's ability to aim and return balls with\nvarying spin types. As a further demonstration, the system is able to rally\nwith human players.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u56db\u8db3\u673a\u5668\u4eba\u5728\u4e52\u4e53\u7403\u8fd0\u52a8\u4e2d\u7684\u5168\u8eab\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u3002\u867d\u7136\u6d89\u53ca\u8f68\u8ff9\u9884\u6d4b\uff0c\u4f46\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6ca1\u6709\u76f4\u63a5\u5173\u8054\u3002\u8f68\u8ff9\u9884\u6d4b\u5728\u8bba\u6587\u4e2d\u7528\u4e8e\u9884\u6d4b\u7403\u7684\u8fd0\u52a8\u8f68\u8ff9\uff0c\u662f\u5b9e\u73b0\u673a\u5668\u4eba\u8fd0\u52a8\u63a7\u5236\u7684\u4e00\u90e8\u5206\u3002", "keywords": ["trajectory prediction", "model predictive control", "table tennis"]}}
{"id": "2510.08811", "pdf": "https://arxiv.org/pdf/2510.08811", "abs": "https://arxiv.org/abs/2510.08811", "authors": ["Jiurun Song", "Xiao Liang", "Minghui Zheng"], "title": "Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration", "categories": ["cs.RO"], "comment": null, "summary": "Human-robot collaboration (HRC) requires robots to adapt their motions to\nhuman intent to ensure safe and efficient cooperation in shared spaces.\nAlthough large language models (LLMs) provide high-level reasoning for\ninferring human intent, their application to reliable motion planning in HRC\nremains challenging. Physical human-robot interaction (pHRI) is intuitive but\noften relies on continuous kinesthetic guidance, which imposes burdens on\noperators. To address these challenges, a contact-informed adaptive\nmotion-planning framework is introduced to infer human intent directly from\nphysical contact and employ the inferred intent for online motion correction in\nHRC. First, an optimization-based force estimation method is proposed to infer\nhuman-intended contact forces and locations from joint torque measurements and\na robot dynamics model, thereby reducing cost and installation complexity while\nenabling whole-body sensitivity. Then, a torque-based contact detection\nmechanism with link-level localization is introduced to reduce the optimization\nsearch space and to enable real-time estimation. Subsequently, a\ncontact-informed adaptive motion planner is developed to infer human intent\nfrom contacts and to replan robot motion online, while maintaining smoothness\nand adapting to human corrections. Finally, experiments on a 7-DOF manipulator\nare conducted to demonstrate the accuracy of the proposed force estimation\nmethod and the effectiveness of the contact-informed adaptive motion planner\nunder perception uncertainty in HRC.", "relevance_analysis": {"relevance_score": 0.7, "explanation": "This paper discusses adaptive motion planning for human-robot collaboration, which involves inferring human intent for robot motion correction. It explicitly mentions using large language models (LLMs) for high-level reasoning of human intent, although the core of the work focuses on contact-based intent inference rather than directly using LLMs for trajectory prediction. The connection to LLMs is present, but not central to the trajectory planning aspect.", "keywords": ["motion planning", "human-robot collaboration", "large language models", "human intent", "adaptive motion planning"]}}
{"id": "2510.09050", "pdf": "https://arxiv.org/pdf/2510.09050", "abs": "https://arxiv.org/abs/2510.09050", "authors": ["Dildar Ali", "Rajibul Islam", "Suman Banerjee"], "title": "Multi-product Influence Maximization in Billboard Advertisement", "categories": ["cs.DS", "cs.DB"], "comment": "This paper has been accepted in ACM IKDD CODS-2025 conference", "summary": "Billboard Advertisement has emerged as an effective out-of-home advertisement\ntechnique where the goal is to select a limited number of slots and play\nadvertisement content over there with the hope that this will be observed by\nmany people, and effectively, a significant number of them will be influenced\ntowards the brand. Given a trajectory and a billboard database and a positive\ninteger $k$, how can we select $k$ highly influential slots to maximize\ninfluence? In this paper, we study a variant of this problem where a commercial\nhouse wants to make a promotion of multiple products, and there is an influence\ndemand for each product. We have studied two variants of the problem. In the\nfirst variant, our goal is to select $k$ slots such that the respective\ninfluence demand of each product is satisfied. In the other variant of the\nproblem, we are given with $\\ell$ integers $k_1,k_2, \\ldots, k_{\\ell}$, the\ngoal here is to search for $\\ell$ many set of slots $S_1, S_2, \\ldots,\nS_{\\ell}$ such that for all $i \\in [\\ell]$, $|S_{i}| \\leq k_i$ and for all $i\n\\neq j$, $S_i \\cap S_j=\\emptyset$ and the influence demand of each of the\nproducts gets satisfied. We model the first variant of the problem as a\nmulti-submodular cover problem and the second variant as its generalization.\nFor solving the first variant, we adopt the bi-criteria approximation\nalgorithm, and for the other variant, we propose a sampling-based approximation\nalgorithm. Extensive experiments with real-world trajectory and billboard\ndatasets highlight the effectiveness and efficiency of the proposed solution\napproach.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "This paper involves trajectory data and influence maximization, which can be loosely related to trajectory prediction in the context of advertising. While it doesn't directly use or discuss large language models, the use of trajectory data connects it to the broader field of trajectory analysis. The core focus is influence maximization, but it leverages trajectory information.", "keywords": ["trajectory", "influence maximization", "billboard advertisement"]}}
{"id": "2510.08671", "pdf": "https://arxiv.org/pdf/2510.08671", "abs": "https://arxiv.org/abs/2510.08671", "authors": ["Milon Bhattacharya", "Milan Kumar"], "title": "Optimizing delivery for quick commerce factoring qualitative assessment of generated routes", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Indias e-commerce market is projected to grow rapidly, with last-mile\ndelivery accounting for nearly half of operational expenses. Although vehicle\nrouting problem (VRP) based solvers are widely used for delivery planning,\ntheir effectiveness in real-world scenarios is limited due to unstructured\naddresses, incomplete maps, and computational constraints in distance\nestimation. This study proposes a framework that employs large language models\n(LLMs) to critique VRP-generated routes against policy-based criteria, allowing\nlogistics operators to evaluate and prioritise more efficient delivery plans.\nAs a illustration of our approach we generate, annotate and evaluated 400 cases\nusing large language models. Our study found that open-source LLMs identified\nrouting issues with 79% accuracy, while proprietary reasoning models achieved\nreach upto 86%. The results demonstrate that LLM-based evaluation of\nVRP-generated routes can be an effective and scalable layer of evaluation which\ngoes beyond beyond conventional distance and time based metrics. This has\nimplications for improving cost efficiency, delivery reliability, and\nsustainability in last-mile logistics, especially for developing countries like\nIndia.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6765\u8bc4\u4f30\u8f66\u8f86\u8def\u5f84\u89c4\u5212\uff08vehicle routing problem, VRP\uff09\u751f\u6210\u7684\u8def\u7ebf\u3002\u867d\u7136VRP\u53ef\u4ee5\u770b\u4f5c\u662f\u4e00\u79cd\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u4f46\u8be5\u8bba\u6587\u7684\u91cd\u70b9\u5728\u4e8e\u4f7f\u7528LLM\u8bc4\u4f30\u73b0\u6709\u8def\u7ebf\uff0c\u800c\u975e\u76f4\u63a5\u8fdb\u884c\u8f68\u8ff9\u9884\u6d4b\u3002\u56e0\u6b64\u76f8\u5173\u6027\u4e2d\u7b49\u3002", "keywords": ["large language models", "LLMs", "vehicle routing problem", "delivery planning", "routes"]}}
{"id": "2510.08713", "pdf": "https://arxiv.org/pdf/2510.08713", "abs": "https://arxiv.org/abs/2510.08713", "authors": ["Yifei Dong", "Fengyi Wu", "Guangyu Chen", "Zhi-Qi Cheng", "Qiyu Hu", "Yuxuan Zhou", "Jingdong Sun", "Jun-Yan He", "Qi Dai", "Alexander G Hauptmann"], "title": "Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation", "categories": ["cs.AI", "cs.CV", "cs.RO"], "comment": "18 pages, 11 figures, code: https://github.com/F1y1113/UniWM", "summary": "Enabling embodied agents to effectively imagine future states is critical for\nrobust and generalizable visual navigation. Current state-of-the-art\napproaches, however, adopt modular architectures that separate navigation\nplanning from visual world modeling, leading to state-action misalignment and\nlimited adaptability in novel or dynamic scenarios. To overcome this\nfundamental limitation, we propose UniWM, a unified, memory-augmented world\nmodel integrating egocentric visual foresight and planning within a single\nmultimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly\ngrounds action decisions in visually imagined outcomes, ensuring tight\nalignment between prediction and control. A hierarchical memory mechanism\nfurther integrates detailed short-term perceptual cues with longer-term\ntrajectory context, enabling stable, coherent reasoning over extended horizons.\nExtensive experiments across four challenging benchmarks (Go Stanford, ReCon,\nSCAND, HuRoN) demonstrate that UniWM substantially improves navigation success\nrates by up to 30%, significantly reduces trajectory errors compared to strong\nbaselines, and exhibits impressive zero-shot generalization on the unseen\nTartanDrive dataset. These results highlight UniWM as a principled step toward\nunified, imagination-driven embodied navigation.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9\u5bfc\u822a\u4e2d\u7684\u4e16\u754c\u6a21\u578b\uff0c\u6d89\u53ca\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u72b6\u6001\u8fdb\u884c\u89c4\u5212\uff0c\u8fd9\u4e0e\u8f68\u8ff9\u9884\u6d4b\u76f8\u5173\u3002\u8bba\u6587\u63d0\u5230\u4e86\u4f7f\u7528\u591a\u6a21\u6001\u81ea\u56de\u5f52\u9aa8\u5e72\u7f51\u7edc\uff0c\u53ef\u80fd\u9690\u542b\u5730\u4f7f\u7528\u4e86\u5927\u89c4\u6a21\u6a21\u578b\u7684\u4e00\u4e9b\u601d\u60f3\uff0c\u4f46\u6ca1\u6709\u660e\u786e\u63d0\u53ca\u6216\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u76f8\u5173\u6027\u4e2d\u7b49\u3002", "keywords": ["visual navigation", "world model", "foresight", "planning", "trajectory", "autoregressive"]}}
{"id": "2510.08759", "pdf": "https://arxiv.org/pdf/2510.08759", "abs": "https://arxiv.org/abs/2510.08759", "authors": ["Yu Qi", "Haibo Zhao", "Ziyu Guo", "Siyuan Ma", "Ziyan Chen", "Yaokun Han", "Renrui Zhang", "Zitiantao Lin", "Shiji Xin", "Yijian Huang", "Kai Cheng", "Peiheng Wang", "Jiazheng Liu", "Jiayi Zhang", "Yizhe Zhu", "Wenqing Wang", "Yiran Qin", "Xupeng Zhu", "Haojie Huang", "Lawson L. S. Wong"], "title": "BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Embodied capabilities refer to a suite of fundamental abilities for an agent\nto perceive, comprehend, and interact with the physical world. While multimodal\nlarge language models (MLLMs) show promise as embodied agents, a thorough and\nsystematic evaluation of their embodied capabilities remains underexplored, as\nexisting benchmarks primarily focus on specific domains such as planning or\nspatial understanding. To bridge this gap, we introduce BEAR, a comprehensive\nand fine-grained benchmark that evaluates MLLMs on atomic embodied\ncapabilities. BEAR comprises 4,469 interleaved image-video-text entries across\n14 domains in 6 categories, including tasks from low-level pointing, trajectory\nunderstanding, spatial reasoning, to high-level planning. Extensive evaluation\nresults of 20 representative MLLMs reveal their persistent limitations across\nall domains of embodied capabilities. To tackle the shortfall, we propose\nBEAR-Agent, a multimodal conversable agent that integrates pretrained vision\nmodels to strengthen MLLM perception, 3D understanding, and planning\ncapabilities. It substantially enhances MLLM performance across diverse\nembodied capabilities on BEAR, yielding a 9.12% absolute gain and a relative\nimprovement of 17.5% on GPT-5. Furthermore, our experiments indicate that\nimproving MLLM embodied capabilities can benefit embodied tasks in simulated\nenvironments. Project website: https://bear-official66.github.io/", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eab\u667a\u80fd\u65b9\u9762\u7684\u80fd\u529b\u8bc4\u4f30\u548c\u63d0\u5347\u3002\u867d\u7136\u8bba\u6587\u4e2d\u63d0\u5230\u4e86\u201ctrajectory understanding\u201d\uff0c\u4f46\u5176\u91cd\u70b9\u5728\u4e8e\u7406\u89e3agent\u4e0e\u73af\u5883\u4ea4\u4e92\u7684\u80fd\u529b\uff0c\u800c\u975e\u8f68\u8ff9\u9884\u6d4b\u672c\u8eab\u3002\u8bba\u6587\u4e0e\u5927\u6a21\u578b\u6709\u8f83\u5f3a\u7684\u76f8\u5173\u6027\uff0c\u4e0e\u8f68\u8ff9\u9884\u6d4b\u53ea\u6709\u5f31\u76f8\u5173\u3002", "keywords": ["multimodal language models", "MLLMs", "embodied capabilities", "trajectory understanding"]}}
{"id": "2510.09204", "pdf": "https://arxiv.org/pdf/2510.09204", "abs": "https://arxiv.org/abs/2510.09204", "authors": ["Simon Idoko", "Arun Kumar Singh"], "title": "Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Centralized trajectory optimization in the joint space of multiple robots\nallows access to a larger feasible space that can result in smoother\ntrajectories, especially while planning in tight spaces. Unfortunately, it is\noften computationally intractable beyond a very small swarm size. In this\npaper, we propose Flow-Opt, a learning-based approach towards improving the\ncomputational tractability of centralized multi-robot trajectory optimization.\nSpecifically, we reduce the problem to first learning a generative model to\nsample different candidate trajectories and then using a learned\nSafety-Filter(SF) to ensure fast inference-time constraint satisfaction. We\npropose a flow-matching model with a diffusion transformer (DiT) augmented with\npermutation invariant robot position and map encoders as the generative model.\nWe develop a custom solver for our SF and equip it with a neural network that\npredicts context-specific initialization. The initialization network is trained\nin a self-supervised manner, taking advantage of the differentiability of the\nSF solver. We advance the state-of-the-art in the following respects. First, we\nshow that we can generate trajectories of tens of robots in cluttered\nenvironments in a few tens of milliseconds. This is several times faster than\nexisting centralized optimization approaches. Moreover, our approach also\ngenerates smoother trajectories orders of magnitude faster than competing\nbaselines based on diffusion models. Second, each component of our approach can\nbe batched, allowing us to solve a few tens of problem instances in a fraction\nof a second. We believe this is a first such result; no existing approach\nprovides such capabilities. Finally, our approach can generate a diverse set of\ntrajectories between a given set of start and goal locations, which can capture\ndifferent collision-avoidance behaviors.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "\u8be5\u8bba\u6587\u4e3b\u8981\u5173\u6ce8\u591a\u673a\u5668\u4eba\u8f68\u8ff9\u4f18\u5316\uff0c\u4f7f\u7528\u4e86\u6269\u6563\u6a21\u578b\uff08diffusion transformer\uff09\uff0c\u5c5e\u4e8e\u8f68\u8ff9\u9884\u6d4b\u7684\u8303\u7574\u3002\u867d\u7136\u4f7f\u7528\u4e86transformer\uff0c\u4f46\u5e76\u975e\u76f4\u63a5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u56e0\u6b64\u76f8\u5173\u6027\u8bc4\u5206\u4e3a0.6\u3002", "keywords": ["trajectory optimization", "trajectory prediction", "diffusion transformer", "multi-robot"]}}
{"id": "2510.09254", "pdf": "https://arxiv.org/pdf/2510.09254", "abs": "https://arxiv.org/abs/2510.09254", "authors": ["Dominik Urbaniak", "Alejandro Agostini", "Pol Ramon", "Jan Rosell", "Ra\u00fal Su\u00e1rez", "Michael Suppa"], "title": "Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 7 figures", "summary": "Learning-based motion planning can quickly generate near-optimal\ntrajectories. However, it often requires either large training datasets or\ncostly collection of human demonstrations. This work proposes an alternative\napproach that quickly generates smooth, near-optimal collision-free 3D\nCartesian trajectories from a single artificial demonstration. The\ndemonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively\nreshaped using policy-based reinforcement learning to create a diverse\ntrajectory dataset for varying obstacle configurations. This dataset is used to\ntrain a neural network that takes as inputs the task parameters describing the\nobstacle dimensions and location, derived automatically from a point cloud, and\noutputs the DMP parameters that generate the trajectory. The approach is\nvalidated in simulation and real-robot experiments, outperforming a RRT-Connect\nbaseline in terms of computation and execution time, as well as trajectory\nlength, while supporting multi-modal trajectory generation for different\nobstacle geometries and end-effector dimensions. Videos and the implementation\ncode are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on obstacle avoidance using Dynamic Movement Primitives (DMP) and Reinforcement Learning. While it relates to trajectory generation and motion planning, which are aspects of trajectory prediction, it doesn't involve Large Language Models. The use of neural networks for DMP parameter generation brings it closer to modern AI techniques, but still not directly related to LLMs.", "keywords": ["trajectory generation", "motion planning", "obstacle avoidance", "Dynamic Movement Primitives", "Reinforcement Learning"]}}
{"id": "2510.08779", "pdf": "https://arxiv.org/pdf/2510.08779", "abs": "https://arxiv.org/abs/2510.08779", "authors": ["Vaibhav Jain", "Gerrit Grossmann"], "title": "Guiding Exploration in Reinforcement Learning Through LLM-Augmented Observations", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to LM4Plan Workshop @ ICAPS 2025 (withdrawn before\n  presentation due to lack of travel funding)", "summary": "Reinforcement Learning (RL) agents often struggle in sparse-reward\nenvironments where traditional exploration strategies fail to discover\neffective action sequences. Large Language Models (LLMs) possess procedural\nknowledge and reasoning capabilities from text pretraining that could guide RL\nexploration, but existing approaches create rigid dependencies where RL\npolicies must follow LLM suggestions or incorporate them directly into reward\nfunctions. We propose a framework that provides LLM-generated action\nrecommendations through augmented observation spaces, allowing RL agents to\nlearn when to follow or ignore this guidance. Our method leverages LLMs' world\nknowledge and reasoning abilities while maintaining flexibility through soft\nconstraints. We evaluate our approach on three BabyAI environments of\nincreasing complexity and show that the benefits of LLM guidance scale with\ntask difficulty. In the most challenging environment, we achieve 71% relative\nimprovement in final success rates over baseline. The approach provides\nsubstantial sample efficiency gains, with agents reaching performance\nthresholds up to 9 times faster, and requires no modifications to existing RL\nalgorithms. Our results demonstrate an effective method for leveraging LLM\nplanning capabilities to accelerate RL training in challenging environments.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on using Large Language Models (LLMs) to guide exploration in Reinforcement Learning (RL). While it doesn't directly address trajectory prediction, the use of LLMs for decision-making in an environment could potentially be applied to trajectory prediction tasks. The core focus is on RL exploration with LLM assistance, making it moderately relevant.", "keywords": ["Large Language Models", "LLMs", "Reinforcement Learning", "RL", "exploration", "planning"]}}
{"id": "2510.09092", "pdf": "https://arxiv.org/pdf/2510.09092", "abs": "https://arxiv.org/abs/2510.09092", "authors": ["Juanqin Liu", "Leonardo Plotegher", "Eloy Roura", "Shaoming He"], "title": "GL-DT: Multi-UAV Detection and Tracking with Global-Local Integration", "categories": ["cs.CV"], "comment": null, "summary": "The extensive application of unmanned aerial vehicles (UAVs) in military\nreconnaissance, environmental monitoring, and related domains has created an\nurgent need for accurate and efficient multi-object tracking (MOT)\ntechnologies, which are also essential for UAV situational awareness. However,\ncomplex backgrounds, small-scale targets, and frequent occlusions and\ninteractions continue to challenge existing methods in terms of detection\naccuracy and trajectory continuity. To address these issues, this paper\nproposes the Global-Local Detection and Tracking (GL-DT) framework. It employs\na Spatio-Temporal Feature Fusion (STFF) module to jointly model motion and\nappearance features, combined with a global-local collaborative detection\nstrategy, effectively enhancing small-target detection. Building upon this, the\nJPTrack tracking algorithm is introduced to mitigate common issues such as ID\nswitches and trajectory fragmentation. Experimental results demonstrate that\nthe proposed approach significantly improves the continuity and stability of\nMOT while maintaining real-time performance, providing strong support for the\nadvancement of UAV detection and tracking technologies.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on multi-object tracking (MOT) of UAVs, which is related to trajectory prediction. While it doesn't explicitly mention trajectory prediction, tracking inherently involves predicting future locations. It does not mention or use large language models.", "keywords": ["multi-object tracking", "trajectory", "tracking"]}}
{"id": "2510.08911", "pdf": "https://arxiv.org/pdf/2510.08911", "abs": "https://arxiv.org/abs/2510.08911", "authors": ["Maoxin Ji", "Tong Wang", "Qiong Wu", "Pingyi Fan", "Nan Cheng", "Wen Chen"], "title": "Velocity and Density-Aware RRI Analysis and Optimization for AoI Minimization in IoV SPS", "categories": ["cs.LG", "cs.NI"], "comment": "This paper has been submitted to IEEE Communications Letters", "summary": "Addressing the problem of Age of Information (AoI) deterioration caused by\npacket collisions and vehicle speed-related channel uncertainties in\nSemi-Persistent Scheduling (SPS) for the Internet of Vehicles (IoV), this\nletter proposes an optimization approach based on Large Language Models (LLM)\nand Deep Deterministic Policy Gradient (DDPG). First, an AoI calculation model\ninfluenced by vehicle speed, vehicle density, and Resource Reservation Interval\n(RRI) is established, followed by the design of a dual-path optimization\nscheme. The DDPG is guided by the state space and reward function, while the\nLLM leverages contextual learning to generate optimal parameter configurations.\nExperimental results demonstrate that LLM can significantly reduce AoI after\naccumulating a small number of exemplars without requiring model training,\nwhereas the DDPG method achieves more stable performance after training.", "relevance_analysis": {"relevance_score": 0.6, "explanation": "The paper focuses on Age of Information (AoI) minimization in the Internet of Vehicles (IoV) using Large Language Models (LLM) and Deep Deterministic Policy Gradient (DDPG). While it involves vehicle speed and density, which are related to vehicle movement and potentially trajectory, the primary focus is on resource scheduling and AoI. The direct connection to trajectory prediction is weak, but the use of LLM and the context of IoV with vehicle movement warrants a moderate relevance score.", "keywords": ["Large Language Models", "LLM", "IoV", "vehicle speed", "vehicle density"]}}
