# 每日 ArXiv 轨迹预测与大模型摘要速递: 2025-11-14

## 目录

- [cs.DB (4)](#cs-db)
- [人机交互 (Human-Computer Interaction) (1)](#cs-hc)

## cs.DB [cs.DB]
### [1] [FlashMap: A Flash Optimized Key-Value Store](https://arxiv.org/abs/2511.08826)
*Zonglin Guo, Tony Givargis*

Main category: cs.DB

TL;DR: FlashMap是一个针对闪存固态硬盘(SSD)优化的高性能键值存储系统。


<details>
  <summary>Details</summary>
Motivation: 现代计算越来越需要响应性和可扩展性，键值存储已成为工业和研究环境中数据基础设施的关键组成部分。

Method: 提出了FlashMap，一个针对闪存固态硬盘(SSD)优化的高性能键值存储系统。

Result: FlashMap实现了出色的吞吐量，在单个数据中心级服务器上，平均每秒可进行1980万次插入和2380万次随机查找(有效载荷为100字节)。

Conclusion: FlashMap是一个针对闪存固态硬盘优化的高性能键值存储系统，它实现了出色的吞吐量。

Abstract: 键值存储是一种基本的NoSQL数据库，它提供了一种简单而强大的数据存储和检索模型，将信息表示为唯一键和关联值的对。 它们极简的结构实现了极快的访问时间、可扩展性和存储各种数据类型的灵活性，使其成为高性能应用程序（如缓存、会话管理和分布式系统）的理想选择。 随着现代计算越来越需要响应性和可扩展性，键值存储已成为工业和研究环境中数据基础设施的关键组成部分。 在这项工作中，我们提出了FlashMap，这是一种针对基于闪存的固态驱动器（SSD）优化的高性能键值存储。 实验表明，FlashMap实现了出色的吞吐量，在单个数据中心级服务器上，平均每秒可进行1980万次插入和2380万次随机查找（有效载荷为100字节）。

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.08826) | **Categories:** cs.DB

---

### [2] [Contextual Graph Embeddings: Accounting for Data Characteristics in Heterogeneous Data Integration](https://arxiv.org/abs/2511.09001)
*Yuka Haruki, Shigeru Ishikura, Kazuya Demachi, Teruaki Hayashi*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: As organizations continue to access diverse datasets, the demand for effective data integration has increased. Key tasks in this process, such as schema matching and entity resolution, are essential but often require significant effort. Although previous studies have aimed to automate these tasks, the influence of dataset characteristics on the matching effectiveness has not been thoroughly examined, and combinations of different methods remain limited. This study introduces a contextual graph embedding technique that integrates structural details from tabular data and contextual elements such as column descriptions and external knowledge. Tests conducted on datasets with varying properties such as domain specificity, data size, missing rate, and overlap rate showed that our approach consistently surpassed existing graph-based methods, especially in difficult scenarios such those with a high proportion of numerical values or significant missing data. However, we identified specific failure cases, such as columns that were semantically similar but distinct, which remains a challenge for our method. The study highlights two main insights: (i) contextual embeddings enhance the matching reliability, and (ii) dataset characteristics significantly affect the integration outcomes. These contributions can advance the development of practical data integration systems that can support real-world enterprise applications.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.09001) | **Categories:** cs.DB

---

### [3] [Efficient Distributed Exact Subgraph Matching via GNN-PE: Load Balancing, Cache Optimization, and Query Plan Ranking](https://arxiv.org/abs/2511.09052)
*Yu Wang, Hui Wang, Jiake Ge, Xin Wang*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Exact subgraph matching on large-scale graphs remains a challenging problem due to high computational complexity and distributed system constraints. Existing GNN-based path embedding (GNN-PE) frameworks achieve efficient exact matching on single machines but lack scalability and optimization for distributed environments. To address this gap, we propose three core innovations to extend GNN-PE to distributed systems: (1) a lightweight dynamic correlation-aware load balancing and hot migration mechanism that fuses multi-dimensional metrics (CPU, communication, memory) and guarantees index consistency; (2) an online incremental learning-based multi-GPU collaborative dynamic caching strategy with heterogeneous GPU adaptation and graph-structure-aware replacement; (3) a query plan ranking method driven by dominance embedding pruning potential (PE-score) that optimizes execution order. Through METIS partitioning, parallel offline preprocessing, and lightweight metadata management, our approach achieves "minimum edge cut + load balancing + non-interruptible queries" in distributed scenarios (tens of machines), significantly improving the efficiency and stability of distributed subgraph matching.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.09052) | **Categories:** cs.DB

---

### [4] [CheetahGIS: Architecting a Scalable and Efficient Streaming Spatial Query Processing System](https://arxiv.org/abs/2511.09262)
*Jiaping Cao, Ting Sun, Man Lung Yiu, Xiao Yan, Bo Tang*

Main category: cs.DB

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Spatial data analytics systems are widely studied in both the academia and industry. However, existing systems are limited when handling a large number of moving objects and real time spatial queries. In this work, we architect a scalable and efficient system CheetahGIS to process streaming spatial queries over massive moving objects. In particular, CheetahGIS is built upon Apache Flink Stateful Functions (StateFun), an API for building distributed streaming applications with an actor-like model. CheetahGIS enjoys excellent scalability due to its modular architecture, which clearly decomposes different components and allows scaling individual components. To improve the efficiency and scalability of CheetahGIS, we devise a suite of optimizations, e.g., lightweight global grid-based index, metadata synchroniza tion strategies, and load balance mechanisms. We also formulate a generic paradigm for spatial query processing in CheetahGIS, and verify its generality by processing three representative streaming queries (i.e., object query, range count query, and k nearest neighbor query). We conduct extensive experiments on both real and synthetic datasets to evaluate CheetahGIS.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.09262) | **Categories:** cs.DB, cs.DC

---


## 人机交互 (Human-Computer Interaction) [cs.HC]
### [1] [TempoQL: A Readable, Precise, and Portable Query System for Electronic Health Record Data](https://arxiv.org/abs/2511.09337)
*Ziyong Ma, Richard D. Boyce, Adam Perer, Venkatesh Sivaraman*

Main category: cs.HC

TL;DR: 达到API配额限制，请明天再试


<details>
  <summary>Details</summary>
Motivation: Error: API quota exceeded

Method: Error: API quota exceeded

Result: Error: API quota exceeded

Conclusion: 请联系管理员或等待明天API配额重置。

Abstract: Electronic health record (EHR) data is an essential data source for machine learning for health, but researchers and clinicians face steep barriers in extracting and validating EHR data for modeling. Existing tools incur trade-offs between expressivity and usability and are typically specialized to a single data standard, making it difficult to write temporal queries that are ready for modern model-building pipelines and adaptable to new datasets. This paper introduces TempoQL, a Python-based toolkit designed to lower these barriers. TempoQL provides a simple, human-readable language for temporal queries; support for multiple EHR data standards, including OMOP, MEDS, and others; and an interactive notebook-based query interface with optional large language model (LLM) authoring assistance. Through a performance evaluation and two use cases on different datasets, we demonstrate that TempoQL simplifies the creation of cohorts for machine learning while maintaining precision, speed, and reproducibility.

</details>

[**[PDF]**](https://arxiv.org/pdf/2511.09337) | **Categories:** cs.HC, cs.DB

---
